(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[931],{3372:function(e,n,a){Promise.resolve().then(a.bind(a,1570))},1570:function(e,n,a){"use strict";a.r(n),a.d(n,{default:function(){return $}});var t=a(7437),s=a(2914),i=a.n(s),o=a(3611),r=a(1396),c=a.n(r),l=a(6691),d=a.n(l),p=()=>(0,t.jsxs)("div",{children:[(0,t.jsx)("div",{className:"block sm:hidden",children:(0,t.jsx)(d(),{src:"/static/images/hero_diagram_mobile.svg",alt:"Apache Pinot",width:500,height:300,priority:!0,className:"m-auto pb-14"})}),(0,t.jsx)("div",{className:"hidden sm:block",children:(0,t.jsx)(d(),{src:"/static/images/hero_diagram.svg",alt:"Apache Pinot",width:1224,height:500,priority:!0,className:"m-auto pb-14"})})]}),h=()=>(0,t.jsxs)("section",{className:"md:mx-auto md:max-w-screen-outerLiveArea",children:[(0,t.jsxs)("div",{className:"p-8 text-center md:pb-12 md:pt-24",children:[(0,t.jsx)("h1",{className:"mb-4 text-4xl font-bold leading-[45px] md:text-[3.5rem] md:leading-[70px]",children:"Insights, Unlocked in Real Time."}),(0,t.jsx)("p",{className:"m-auto mb-8 max-w-4xl text-lg md:leading-[28.80px]",children:"Apache Pinot™: The real-time analytics open source platform for lightning-fast insights, effortless scaling, and cost-effective data-driven decisions."}),(0,t.jsxs)("div",{className:"flex justify-center gap-4",children:[(0,t.jsx)(o.z,{variant:"default",size:"xl",className:"rounded-lg bg-vine-100 px-8 py-3 text-xl",children:(0,t.jsx)(c(),{href:i().cta.getStarted,target:"_blank",children:"Get Started"})}),(0,t.jsx)(o.z,{variant:"outline",size:"xl",className:"rounded-lg border-2 border-vine-100 px-8 py-3 text-xl text-vine-100 hover:border-vine-120 hover:text-vine-120",children:(0,t.jsx)(c(),{href:i().cta.slackInvite,target:"_blank",children:"Join Slack"})})]})]}),(0,t.jsx)(p,{})]}),m=a(2265),u=a(8291),g=e=>{let{videoUrl:n,title:a}=e;return(0,t.jsx)("section",{className:"bg-stone-100 dark:bg-gray-900",children:(0,t.jsxs)("div",{className:"flex flex-col px-5 py-14 sm:flex-row sm:px-6 md:mx-auto md:max-w-screen-outerLiveArea md:gap-20 md:px-[5.5rem] md:py-[6.5rem]",children:[(0,t.jsxs)("article",{className:"flex flex-1 flex-col",children:[(0,t.jsx)("header",{children:(0,t.jsx)("h2",{className:"mb-3 text-[1.75rem] font-bold md:text-[2.5rem]",children:"What is Apache Pinot?"})}),(0,t.jsx)("p",{className:"text-base leading-relaxed md:text-lg",children:"Originally developed at LinkedIn, Apache PinotTM is a real-time distributed OLAP datastore, purpose-built to provide ultra low-latency analytics at extremely high throughput."}),(0,t.jsx)("br",{}),(0,t.jsx)("p",{className:"text-base leading-relaxed md:text-lg",children:"With its distributed architecture and columnar storage, Apache Pinot empowers businesses to gain valuable insights from real-time data, supporting data-driven decision-making and applications."}),(0,t.jsx)(o.z,{variant:"link",asChild:!0,className:"my-6 mr-2 justify-start p-0 text-lg font-semibold leading-tight text-vine-100",children:(0,t.jsxs)(c(),{href:i().cta.learnMore,target:"_blank",children:["Learn More",(0,t.jsx)(u.Z,{className:"mr-2 h-5 w-5"})]})})]}),(0,t.jsx)("aside",{className:"flex-1",children:(0,t.jsx)("iframe",{className:"h-[197px] w-full md:h-full",src:n,title:a,allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowFullScreen:!0})})]})})},x=e=>{let{description:n}=e;return(0,t.jsx)("p",{className:"text-center leading-relaxed",children:n.map((e,n)=>"string"==typeof e?e:(0,t.jsx)(c(),{className:"text-blue-600 underline hover:text-blue-800",href:e.url,target:"_blank",rel:"noopener noreferrer",children:e.text},n))})},j=e=>{let{imageSrc:n,title:a,description:s}=e;return(0,t.jsxs)("div",{className:"flex flex-col items-center md:w-[20.875rem]",children:[(0,t.jsx)(d(),{src:n,alt:a,className:"mb-4 md:mb-5",width:80,height:80}),(0,t.jsx)("h3",{className:"mb-2 text-lg font-semibold",children:a}),(0,t.jsx)(x,{description:s})]})},f=[{imageSrc:"/static/images/features/fast_queries.svg",title:"Fast Queries",description:["Filter and aggregate petabyte data sets with P90 latencies in the tens of milliseconds—fast enough to return live results interactively in the UI."]},{imageSrc:"/static/images/features/high_concurrency.svg",title:"High Concurrency",description:["With user-facing applications querying Pinot directly, it can serve hundreds of thousands of concurrent queries per second."]},{imageSrc:"/static/images/features/batch_ingest.svg",title:"Batch and Streaming Ingest",description:["Ingest from ",{text:"Apache Kafka",url:"https://kafka.apache.org/"},", ",{text:"Apache Pulsar",url:"https://pulsar.apache.org/"},", and ",{text:"AWS Kinesis",url:"https://aws.amazon.com/kinesis/"}," in real time. Batch ingest from Hadoop, Spark, AWS S3, and more. Combine batch and streaming sources into a single table for querying."]},{imageSrc:"/static/images/features/upsert.svg",title:"Upserts",description:["Ingest the same record many times, but see only the latest value at query time. Upserts are built-in and production-tested since version 0.6."]},{imageSrc:"/static/images/features/versatile_joins.svg",title:"Versatile Joins",description:["Perform arbitrary fact/dimension and fact/fact joins on petabyte data sets."]},{imageSrc:"/static/images/features/options.svg",title:"Rich Indexing Options",description:["Choose from pluggable indexes including ",{text:"timestamp",url:"https://docs.pinot.apache.org/basics/indexing/timestamp-index"},", ",{text:"inverted",url:"https://docs.pinot.apache.org/basics/indexing/inverted-index"},", ",{text:"StarTree",url:"https://docs.pinot.apache.org/basics/indexing/star-tree-index"},", ",{text:"Bloom filter",url:"https://docs.pinot.apache.org/basics/indexing/bloom-filter"},", ",{text:"range",url:"https://docs.pinot.apache.org/basics/indexing/range-index"},", ",{text:"text",url:"https://docs.pinot.apache.org/basics/indexing/text-search-support"},", ",{text:"JSON",url:"https://docs.pinot.apache.org/basics/indexing/json-index"},", and ",{text:"geospatial",url:"https://docs.pinot.apache.org/basics/indexing/geospatial-support"}," options."]},{imageSrc:"/static/images/features/built_scale.svg",title:"Built for Scale",description:["Pinot is horizontally scalable and fault-tolerant, adaptable to workloads across the storage and throughput spectrum."]},{imageSrc:"/static/images/features/sql_query.svg",title:"SQL Query Interface",description:["The highly standard SQL query interface is accessible through a built-in query editor and a REST API."]},{imageSrc:"/static/images/features/multitenancy.svg",title:"Built-in Multitenancy",description:["Manage and secure data in isolated logical namespaces for cloud-friendly resource management."]}],k=()=>(0,t.jsx)("section",{className:"flex px-6 py-14 md:mx-auto md:max-w-screen-outerLiveArea md:px-[6.75rem] md:py-[6.5rem]",children:(0,t.jsxs)("div",{className:"mx-auto max-w-7xl",children:[(0,t.jsx)("h3",{className:"pb-8 text-center text-[1.75rem] font-semibold md:pb-16 md:text-[2rem]",children:"Features"}),(0,t.jsx)("div",{className:"grid grid-cols-1 gap-y-10 sm:grid-cols-2 md:gap-x-[5.625rem] md:gap-y-24 lg:grid-cols-3",children:f.map((e,n)=>(0,t.jsx)(j,{imageSrc:e.imageSrc,title:e.title,description:e.description},n))})]})}),y=a(1836),w=a(1291),b=a(7158),N=a(2134);let v=m.createContext(null);function P(){let e=m.useContext(v);if(!e)throw Error("useCarousel must be used within a <Carousel />");return e}let T=m.forwardRef((e,n)=>{let{orientation:a="horizontal",opts:s,setApi:i,plugins:o,className:r,children:c,...l}=e,[d,p]=(0,y.Z)({...s,axis:"horizontal"===a?"x":"y"},o),[h,u]=m.useState(!1),[g,x]=m.useState(!1),j=m.useCallback(e=>{e&&(u(e.canScrollPrev()),x(e.canScrollNext()))},[]),f=m.useCallback(()=>{null==p||p.scrollPrev()},[p]),k=m.useCallback(()=>{null==p||p.scrollNext()},[p]),w=m.useCallback(e=>{"ArrowLeft"===e.key?(e.preventDefault(),f()):"ArrowRight"===e.key&&(e.preventDefault(),k())},[f,k]);return m.useEffect(()=>{p&&i&&i(p)},[p,i]),m.useEffect(()=>{if(p)return j(p),p.on("reInit",j),p.on("select",j),()=>{null==p||p.off("select",j)}},[p,j]),(0,t.jsx)(v.Provider,{value:{carouselRef:d,api:p,opts:s,orientation:a||((null==s?void 0:s.axis)==="y"?"vertical":"horizontal"),scrollPrev:f,scrollNext:k,canScrollPrev:h,canScrollNext:g},children:(0,t.jsx)("div",{ref:n,onKeyDownCapture:w,className:(0,N.cn)("relative",r),role:"region","aria-roledescription":"carousel",...l,children:c})})});T.displayName="Carousel";let S=m.forwardRef((e,n)=>{let{className:a,...s}=e,{carouselRef:i,orientation:o}=P();return(0,t.jsx)("div",{ref:i,className:"overflow-hidden",children:(0,t.jsx)("div",{ref:n,className:(0,N.cn)("flex",a),...s})})});S.displayName="CarouselContent";let A=m.forwardRef((e,n)=>{let{className:a,...s}=e;return(0,t.jsx)("div",{ref:n,role:"group","aria-roledescription":"slide",className:"min-w-0 shrink-0 grow-0 basis-full p-4 ".concat(a),...s})});A.displayName="CarouselItem";let I=m.forwardRef((e,n)=>{let{className:a,variant:s="outline",size:i="icon",...r}=e,{orientation:c,scrollPrev:l,canScrollPrev:d}=P();return(0,t.jsxs)(o.z,{ref:n,variant:s,size:i,className:(0,N.cn)("absolute  h-8 w-8 rounded-full","horizontal"===c?"-left-12 top-1/2 -translate-y-1/2":"-top-12 left-1/2 -translate-x-1/2 rotate-90",a),disabled:!d,onClick:l,...r,children:[(0,t.jsx)(w.Z,{className:"h-8 w-8",color:"#C69781"}),(0,t.jsx)("span",{className:"sr-only",children:"Previous slide"})]})});I.displayName="CarouselPrevious";let O=m.forwardRef((e,n)=>{let{className:a,variant:s="outline",size:i="icon",...r}=e,{orientation:c,scrollNext:l,canScrollNext:d}=P();return(0,t.jsxs)(o.z,{ref:n,variant:s,size:i,className:(0,N.cn)("absolute h-8 w-8 rounded-full","horizontal"===c?"-right-12 top-1/2 -translate-y-1/2":"-bottom-12 left-1/2 -translate-x-1/2 rotate-90",a),disabled:!d,onClick:l,...r,children:[(0,t.jsx)(b.Z,{className:"h-8 w-8",color:"#C69781"}),(0,t.jsx)("span",{className:"sr-only",children:"Next slide"})]})});O.displayName="CarouselNext";var D=[{logo:"/static/images/carousel/razorpay.svg",company:"Razopay",text:"Apache Pinot has truly played a fundamental role in Razorpay's monitoring journey!",author:"Prashant Pandey"},{logo:"/static/images/carousel/stripe.svg",company:"Stripe",text:"Pinot enables us to execute sub-second, petabyte-scale aggregation queries over fresh financial events in our internal ledger. We chose Pinot because of its rich feature set and scalability, which has enabled better performance than our previous solution — at a lower cost.",author:"Peter Bakkum"},{logo:"/static/images/carousel/webex.svg",company:"Webex",text:"Forget sluggish queries!! Apache Pinot whipped our runtime aggregates, with sub-second latencies on all but the most complex queries. On top of the speed boost, Pinot slashed our storage footprint by 10x, letting us shrink the cluster by a whopping 500 nodes",author:"WEBEX"}],_=a(1530),C=()=>{let[e,n]=(0,m.useState)(null),[a,s]=(0,m.useState)(0);return(0,m.useEffect)(()=>{let n=()=>{e&&s(e.selectedScrollSnap())};return e&&(e.on("select",n),n()),()=>{e&&e.off("select",n)}},[e]),(0,t.jsx)("section",{className:"bg-stone-100 dark:bg-gray-900",children:(0,t.jsxs)("div",{className:"flex flex-col px-[2.625rem] py-14 md:mx-auto md:max-w-screen-outerLiveArea md:px-[13.25rem] md:py-[6.5rem]",children:[(0,t.jsx)("article",{children:(0,t.jsxs)(T,{setApi:n,className:"rounded border-[1.5px] border-amber-800",children:[(0,t.jsx)(I,{variant:"ghost",className:"left-0 z-10 -ml-10"}),(0,t.jsx)(S,{children:D.map((e,n)=>(0,t.jsxs)(A,{className:"flex flex-col items-center justify-center p-4",children:[(0,t.jsx)(d(),{src:e.logo,alt:e.company,className:" pb-5 pt-8",width:132,height:28}),e.text&&(0,t.jsxs)("span",{className:" max-w-[52rem]",children:[(0,t.jsxs)("p",{className:"text-center text-lg text-gray-900 dark:text-white md:text-xl",children:["“",e.text,"”"]}),(0,t.jsxs)("p",{className:"pb-1 pt-4 text-center text-gray-500 dark:text-gray-300 md:text-base",children:["- ",e.author]})]})]},n))}),(0,t.jsx)(O,{variant:"ghost",className:"right-0 z-10 -mr-10"}),(0,t.jsx)("div",{className:"mb-8 flex items-center justify-center",children:D.map((n,s)=>(0,t.jsx)("button",{type:"button",className:"mx-1 h-2 w-2 rounded-full bg-amber-800 transition-opacity duration-300 ".concat(s===a?"opacity-100":"opacity-30"),"aria-label":"Go to slide ".concat(s+1),onClick:()=>null==e?void 0:e.scrollTo(s)},s))})]})}),(0,t.jsx)(o.z,{variant:"link",asChild:!0,className:"justify-center p-0 pt-8 text-base font-semibold leading-tight text-vine-100 md:pt-12",children:(0,t.jsxs)(_.Z,{href:"/powered-by",children:["See Company Stories",(0,t.jsx)(u.Z,{className:"mr-2 h-5 w-5"})]})})]})})};let L=e=>{let{name:n,icon:a,link:s,isWide:i=!1}=e;return(0,t.jsxs)("a",{href:s,className:"flex h-36 w-40 flex-col items-center justify-center rounded-lg border-2 border-amber-800 transition-colors hover:bg-gray-100 focus:bg-gray-100 dark:border-gray-800 dark:hover:bg-gray-800 dark:focus:bg-gray-800",target:"_blank",children:[(0,t.jsx)("div",{className:"".concat(i?"w-auto h-16 flex":"w-16 h-16 flex"," relative mb-2 items-center justify-center"),children:(0,t.jsx)(d(),{src:a,alt:"".concat(n," icon"),width:i?120:44,height:44,style:{width:"auto",height:"auto"}})}),(0,t.jsx)("span",{className:"mt-2 text-lg",children:n})]})};var E=()=>(0,t.jsxs)("section",{className:"px-6 py-14 md:mx-auto md:max-w-screen-outerLiveArea md:px-[13.5rem] md:py-[6.5rem]",children:[(0,t.jsx)("h3",{className:"pb-8 text-center text-[2rem] font-bold md:pb-14",children:"Join our Community"}),(0,t.jsx)("div",{className:"flex flex-wrap justify-center gap-x-[1.375rem] gap-y-6 lg:gap-[6.75rem]",children:i().communityLinks.map(e=>(0,t.jsx)(L,{name:e.name,icon:e.icon,link:e.link,isWide:e.isWide},e.name))})]}),F=()=>{let[e,n]=(0,m.useState)("x86"),[a,s]=(0,m.useState)(!1),i={x86:["docker run -p 9000:9000 \\","apachepinot/pinot:1.2.0 \\","QuickStart -type hybrid"],ARM64:["docker run -p 9000:9000 \\","apachepinot/pinot:1.2.0-arm64 \\","QuickStart -type hybrid"]},r=async()=>{try{await navigator.clipboard.writeText(i[e].join("\n")),s(!0),setTimeout(()=>s(!1),2e3)}catch(e){console.error("Failed to copy text: ",e)}};return(0,t.jsxs)("div",{className:"my-4 rounded-lg border-2 border-amber-800",children:[(0,t.jsxs)("div",{className:"overflow-hidden rounded-lg",children:[(0,t.jsx)("div",{className:"flex items-center justify-between border-b border-amber-800 p-4",children:(0,t.jsxs)("div",{className:"flex space-x-2",children:[(0,t.jsx)("div",{className:"h-3 w-3 rounded-full bg-red-500"}),(0,t.jsx)("div",{className:"h-3 w-3 rounded-full bg-yellow-400"}),(0,t.jsx)("div",{className:"h-3 w-3 rounded-full bg-green-500"})]})}),(0,t.jsx)("div",{className:"mb-2 ml-8 flex space-x-1 border-b-2",children:["x86","ARM64"].map(a=>(0,t.jsx)("button",{className:"border-b-4 px-4 py-2\n                                        pt-5 font-[Source_Code_Pro]\n                            ".concat(e===a?"border-rose-700 text-base font-semibold":"border-transparent opacity-30"),onClick:()=>n(a),children:a},a))}),(0,t.jsx)("div",{className:"table w-full whitespace-pre-wrap p-4 font-[Source_Code_Pro] leading-loose",children:i[e].map((e,n)=>(0,t.jsxs)("div",{className:"table-row",children:[(0,t.jsx)("span",{className:"table-cell select-none pr-1 text-gray-400",children:n+1}),(0,t.jsx)("span",{className:"table-cell",children:e})]},n))})]}),(0,t.jsx)(o.z,{variant:"outline",size:"sm",className:"m-7 w-16 border-2 border-vine-100 text-vine-100",onClick:r,children:a?"copied!":"copy"})]})},q=e=>{let{title:n}=e;return(0,t.jsx)("section",{className:"bg-stone-100 dark:bg-gray-900 ",children:(0,t.jsxs)("div",{className:"mx-auto flex flex-col px-5 py-14 sm:flex-row sm:px-6 md:mx-auto md:max-w-screen-outerLiveArea md:px-[11.75rem] md:py-[6.5rem]",children:[(0,t.jsxs)("article",{className:"flex flex-col",children:[(0,t.jsx)("header",{className:"pb-6 md:pb-8 md:pt-6",children:(0,t.jsx)("h2",{className:" text-[2rem] font-bold leading-10 text-gray-900 dark:text-white md:text-5xl md:leading-[4rem]",children:n})}),(0,t.jsx)("div",{className:"flex justify-start pb-6",children:(0,t.jsx)(o.z,{variant:"default",size:"lg",className:"mr-2 rounded-lg bg-vine-100 px-8 py-3 text-xl",children:(0,t.jsx)(c(),{href:i().cta.getStarted,target:"_blank",children:"Get Started"})})})]}),(0,t.jsx)("aside",{className:"flex flex-col overflow-hidden rounded-lg md:w-4/6",children:(0,t.jsx)(F,{})})]})})},M=a(7577);let R=m.forwardRef((e,n)=>{let{className:a,...s}=e;return(0,t.jsx)("div",{ref:n,className:(0,N.cn)("rounded-lg border bg-card text-card-foreground shadow-sm",a),...s})});R.displayName="Card";let z=m.forwardRef((e,n)=>{let{className:a,...s}=e;return(0,t.jsx)("div",{ref:n,className:(0,N.cn)("flex flex-col space-y-1.5 p-6",a),...s})});z.displayName="CardHeader";let U=m.forwardRef((e,n)=>{let{className:a,...s}=e;return(0,t.jsx)("h3",{ref:n,className:(0,N.cn)("text-2xl font-semibold leading-none tracking-tight",a),...s,children:s.children})});U.displayName="CardTitle";let W=m.forwardRef((e,n)=>{let{className:a,...s}=e;return(0,t.jsx)("p",{ref:n,className:(0,N.cn)("text-sm text-muted-foreground",a),...s})});W.displayName="CardDescription";let B=m.forwardRef((e,n)=>{let{className:a,...s}=e;return(0,t.jsx)("div",{ref:n,className:(0,N.cn)("p-6 pt-0",a),...s})});B.displayName="CardContent";let H=m.forwardRef((e,n)=>{let{className:a,...s}=e;return(0,t.jsx)("div",{ref:n,className:(0,N.cn)("flex items-center p-6 pt-0",a),...s})});H.displayName="CardFooter",a(7561);var K=JSON.parse('[{"title":"A Brief History of Scaling LinkedIn","date":"2015-05-16T00:00:00.000Z","tags":["Pinot","LinkedIn","Data Scaling","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"LinkedIn started in 2003 with the goal of connecting to your network for better job opportunities. It had only 2,700 members the first week. Fast forward many years, and LinkedIn’s product portfolio, member base, and server load has grown tremendously.","authors":["linkedin"],"body":{"raw":"\\n## A Brief History of Scaling LinkedIn\\n\\nLinkedIn started in 2003 with the goal of connecting to your network for better job opportunities. It had only 2,700 members the first week. Fast forward many years, and LinkedIn’s product portfolio, member base, and server load has grown tremendously.\\n\\nToday, LinkedIn operates globally with more than 350 million members. We serve tens of thousands of web pages every second of every day. We\'ve hit our mobile moment where mobile accounts for more than 50 percent of all global traffic. All those requests are fetching data from our backend systems, which in turn handle millions of queries per second.\\n\\nRead More at https://engineering.linkedin.com/architecture/brief-history-scaling-linkedin\\n\\n![A Brief History of Scaling LinkedIn](https://content.linkedin.com/content/dam/engineering/en-us/blog/migrated/data_centers_pops_0.png)\\n","code":"var Component=(()=>{var m=Object.create;var o=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var f=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,p=Object.prototype.hasOwnProperty;var u=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),y=(n,e)=>{for(var i in e)o(n,i,{get:e[i],enumerable:!0})},s=(n,e,i,a)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let r of f(e))!p.call(n,r)&&r!==i&&o(n,r,{get:()=>e[r],enumerable:!(a=h(e,r))||a.enumerable});return n};var b=(n,e,i)=>(i=n!=null?m(g(n)):{},s(e||!n||!n.__esModule?o(i,\\"default\\",{value:n,enumerable:!0}):i,n)),k=n=>s(o({},\\"__esModule\\",{value:!0}),n);var l=u((j,d)=>{d.exports=_jsx_runtime});var L={};y(L,{default:()=>x,frontmatter:()=>w});var t=b(l()),w={title:\\"A Brief History of Scaling LinkedIn\\",date:\\"2015-05-16\\",authors:[\\"linkedin\\"],summary:\\"LinkedIn started in 2003 with the goal of connecting to your network for better job opportunities. It had only 2,700 members the first week. Fast forward many years, and LinkedIn\\\\u2019s product portfolio, member base, and server load has grown tremendously.\\",tags:[\\"Pinot\\",\\"LinkedIn\\",\\"Data Scaling\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function c(n){let e=Object.assign({h2:\\"h2\\",a:\\"a\\",span:\\"span\\",p:\\"p\\",img:\\"img\\"},n.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(e.h2,{id:\\"a-brief-history-of-scaling-linkedin\\",children:[(0,t.jsx)(e.a,{href:\\"#a-brief-history-of-scaling-linkedin\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"A Brief History of Scaling LinkedIn\\"]}),(0,t.jsx)(e.p,{children:\\"LinkedIn started in 2003 with the goal of connecting to your network for better job opportunities. It had only 2,700 members the first week. Fast forward many years, and LinkedIn\\\\u2019s product portfolio, member base, and server load has grown tremendously.\\"}),(0,t.jsx)(e.p,{children:\\"Today, LinkedIn operates globally with more than 350 million members. We serve tens of thousands of web pages every second of every day. We\'ve hit our mobile moment where mobile accounts for more than 50 percent of all global traffic. All those requests are fetching data from our backend systems, which in turn handle millions of queries per second.\\"}),(0,t.jsxs)(e.p,{children:[\\"Read More at \\",(0,t.jsx)(e.a,{href:\\"https://engineering.linkedin.com/architecture/brief-history-scaling-linkedin\\",children:\\"https://engineering.linkedin.com/architecture/brief-history-scaling-linkedin\\"})]}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"A Brief History of Scaling LinkedIn\\",src:\\"https://content.linkedin.com/content/dam/engineering/en-us/blog/migrated/data_centers_pops_0.png\\"})})]})}function I(n={}){let{wrapper:e}=n.components||{};return e?(0,t.jsx)(e,Object.assign({},n,{children:(0,t.jsx)(c,n)})):c(n)}var x=I;return k(L);})();\\n;return Component;"},"_id":"blog/2015-05-16-LinkedIn-Scaling.mdx","_raw":{"sourceFilePath":"blog/2015-05-16-LinkedIn-Scaling.mdx","sourceFileName":"2015-05-16-LinkedIn-Scaling.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2015-05-16-LinkedIn-Scaling"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.58,"time":34800,"words":116},"slug":"2015/05/16/LinkedIn-Scaling","customSlug":"2015/05/16/LinkedIn-Scaling","path":"blog/2015/05/16/LinkedIn-Scaling","customPath":"blog/2015/05/16/LinkedIn-Scaling","filePath":"blog/2015-05-16-LinkedIn-Scaling.mdx","toc":[{"value":"A Brief History of Scaling LinkedIn","url":"#a-brief-history-of-scaling-linkedin","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"A Brief History of Scaling LinkedIn","datePublished":"2015-05-16T00:00:00.000Z","dateModified":"2015-05-16T00:00:00.000Z","description":"LinkedIn started in 2003 with the goal of connecting to your network for better job opportunities. It had only 2,700 members the first week. Fast forward many years, and LinkedIn’s product portfolio, member base, and server load has grown tremendously.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2015-05-16-LinkedIn-Scaling"}},{"title":"Open Sourcing Pinot - Scaling the Wall of Real-Time Analytics","date":"2015-06-10T00:00:00.000Z","tags":["Pinot","A/B Testing","Infrastructure","Analytics","User-Facing Analytics"],"summary":"Introducing Pinot which allow to slice and dice across billions of rows in real-time across a wide variety of products","authors":["Kishore Gopalakrishna"],"body":{"raw":"\\nLinkedIn’s real-time analytics infrastructure, that we built to allow us to slice and dice across billions of rows in real-time across a wide variety of products. Read More at https://engineering.linkedin.com/pinot/open-sourcing-pinot-scaling-wall-real-time-analytics\\n","code":"var Component=(()=>{var d=Object.create;var o=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var h=(n,t)=>()=>(t||n((t={exports:{}}).exports,t),t.exports),w=(n,t)=>{for(var e in t)o(n,e,{get:t[e],enumerable:!0})},r=(n,t,e,s)=>{if(t&&typeof t==\\"object\\"||typeof t==\\"function\\")for(let a of m(t))!f.call(n,a)&&a!==e&&o(n,a,{get:()=>t[a],enumerable:!(s=p(t,a))||s.enumerable});return n};var y=(n,t,e)=>(e=n!=null?d(g(n)):{},r(t||!n||!n.__esModule?o(e,\\"default\\",{value:n,enumerable:!0}):e,n)),x=n=>r(o({},\\"__esModule\\",{value:!0}),n);var l=h((M,c)=>{c.exports=_jsx_runtime});var k={};w(k,{default:()=>b,frontmatter:()=>j});var i=y(l()),j={title:\\"Open Sourcing Pinot - Scaling the Wall of Real-Time Analytics\\",date:new Date(14338944e5),authors:[\\"Kishore Gopalakrishna\\"],summary:\\"Introducing Pinot which allow to slice and dice across billions of rows in real-time across a wide variety of products\\",tags:[\\"Pinot\\",\\"A/B Testing\\",\\"Infrastructure\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function u(n){let t=Object.assign({p:\\"p\\",a:\\"a\\"},n.components);return(0,i.jsxs)(t.p,{children:[\\"LinkedIn\\\\u2019s real-time analytics infrastructure, that we built to allow us to slice and dice across billions of rows in real-time across a wide variety of products. Read More at \\",(0,i.jsx)(t.a,{href:\\"https://engineering.linkedin.com/pinot/open-sourcing-pinot-scaling-wall-real-time-analytics\\",children:\\"https://engineering.linkedin.com/pinot/open-sourcing-pinot-scaling-wall-real-time-analytics\\"})]})}function _(n={}){let{wrapper:t}=n.components||{};return t?(0,i.jsx)(t,Object.assign({},n,{children:(0,i.jsx)(u,n)})):u(n)}var b=_;return x(k);})();\\n;return Component;"},"_id":"blog/2015-06-10-Open-Sourcing-Pinot.mdx","_raw":{"sourceFilePath":"blog/2015-06-10-Open-Sourcing-Pinot.mdx","sourceFileName":"2015-06-10-Open-Sourcing-Pinot.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2015-06-10-Open-Sourcing-Pinot"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.15,"time":9000,"words":30},"slug":"2015/06/10/Open-Sourcing-Pinot","customSlug":"2015/06/10/Open-Sourcing-Pinot","path":"blog/2015/06/10/Open-Sourcing-Pinot","customPath":"blog/2015/06/10/Open-Sourcing-Pinot","filePath":"blog/2015-06-10-Open-Sourcing-Pinot.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Open Sourcing Pinot - Scaling the Wall of Real-Time Analytics","datePublished":"2015-06-10T00:00:00.000Z","dateModified":"2015-06-10T00:00:00.000Z","description":"Introducing Pinot which allow to slice and dice across billions of rows in real-time across a wide variety of products","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2015-06-10-Open-Sourcing-Pinot"}},{"title":"Engineering Restaurant Manager - UberEATS Analytics Dashboard","date":"2017-09-17T00:00:00.000Z","tags":["Pinot","Uber Data","real-time data platform","Realtime","Analytics","User-Facing Analytics","financial intelligence"],"summary":"Restaurant Manager is a comprehensive analytics dashboard and pipeline for our restaurant partners. In this article, we discuss how we architected this analytics platform and its robust data pipeline.","authors":["uber"],"body":{"raw":"\\nAt Uber, we use data analytics to architect more magical user experiences across our products. Whenever possible, we harness these data engineering capabilities to empower our partners to better serve their customers. For instance, in late 2016, the UberEATS engineering team built a comprehensive analytics dashboard that provides restaurant partners with additional insights about the health of their business.\\n\\nRead More at https://eng.uber.com/restaurant-manager/\\n\\n![Engineering Restaurant Manager - UberEATS Analytics Dashboard](https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/image4-2.png)\\n","code":"var Component=(()=>{var p=Object.create;var s=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var b=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),y=(t,e)=>{for(var n in e)s(t,n,{get:e[n],enumerable:!0})},o=(t,e,n,i)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let r of m(e))!g.call(t,r)&&r!==n&&s(t,r,{get:()=>e[r],enumerable:!(i=d(e,r))||i.enumerable});return t};var f=(t,e,n)=>(n=t!=null?p(u(t)):{},o(e||!t||!t.__esModule?s(n,\\"default\\",{value:t,enumerable:!0}):n,t)),w=t=>o(s({},\\"__esModule\\",{value:!0}),t);var l=b((U,c)=>{c.exports=_jsx_runtime});var M={};y(M,{default:()=>j,frontmatter:()=>x});var a=f(l()),x={title:\\"Engineering Restaurant Manager - UberEATS Analytics Dashboard\\",date:\\"2017-09-17\\",authors:[\\"uber\\"],summary:\\"Restaurant Manager is a comprehensive analytics dashboard and pipeline for our restaurant partners. In this article, we discuss how we architected this analytics platform and its robust data pipeline.\\",tags:[\\"Pinot\\",\\"Uber Data\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"financial intelligence\\"]};function h(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.p,{children:\\"At Uber, we use data analytics to architect more magical user experiences across our products. Whenever possible, we harness these data engineering capabilities to empower our partners to better serve their customers. For instance, in late 2016, the UberEATS engineering team built a comprehensive analytics dashboard that provides restaurant partners with additional insights about the health of their business.\\"}),(0,a.jsxs)(e.p,{children:[\\"Read More at \\",(0,a.jsx)(e.a,{href:\\"https://eng.uber.com/restaurant-manager/\\",children:\\"https://eng.uber.com/restaurant-manager/\\"})]}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Engineering Restaurant Manager - UberEATS Analytics Dashboard\\",src:\\"https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/image4-2.png\\"})})]})}function A(t={}){let{wrapper:e}=t.components||{};return e?(0,a.jsx)(e,Object.assign({},t,{children:(0,a.jsx)(h,t)})):h(t)}var j=A;return w(M);})();\\n;return Component;"},"_id":"blog/2017-09-17-Restaurant-Manager.mdx","_raw":{"sourceFilePath":"blog/2017-09-17-Restaurant-Manager.mdx","sourceFileName":"2017-09-17-Restaurant-Manager.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2017-09-17-Restaurant-Manager"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.35,"time":21000,"words":70},"slug":"2017/09/17/Restaurant-Manager","customSlug":"2017/09/17/Restaurant-Manager","path":"blog/2017/09/17/Restaurant-Manager","customPath":"blog/2017/09/17/Restaurant-Manager","filePath":"blog/2017-09-17-Restaurant-Manager.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Engineering Restaurant Manager - UberEATS Analytics Dashboard","datePublished":"2017-09-17T00:00:00.000Z","dateModified":"2017-09-17T00:00:00.000Z","description":"Restaurant Manager is a comprehensive analytics dashboard and pipeline for our restaurant partners. In this article, we discuss how we architected this analytics platform and its robust data pipeline.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2017-09-17-Restaurant-Manager"}},{"title":"Introducing ThirdEye - LinkedIn’s Business-Wide Monitoring Platform","date":"2019-01-09T00:00:00.000Z","tags":["Pinot","LinkedIn","real-time data platform","Realtime","ThirdEye","Analytics","User-Facing Analytics"],"summary":"ThirdEye is a comprehensive platform for real-time monitoring of metrics that covers a wide variety of use-cases.","authors":["linkedin"],"body":{"raw":"\\nThirdEye is a comprehensive platform for real-time monitoring of metrics that covers a wide variety of use-cases. LinkedIn relies on ThirdEye to monitor site performance, track member growth, understand adoption of new features, flag sustained attempts to circumvent system security, and many other areas\\n\\nRead More at https://engineering.linkedin.com/blog/2019/01/introducing-thirdeye--linkedins-business-wide-monitoring-platfor\\n\\n![Star-tree index - Powering fast aggregations on Pinot](https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2019/06/startree3.png)\\n","code":"var Component=(()=>{var g=Object.create;var s=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var h=Object.getOwnPropertyNames;var f=Object.getPrototypeOf,p=Object.prototype.hasOwnProperty;var u=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),y=(t,e)=>{for(var i in e)s(t,i,{get:e[i],enumerable:!0})},a=(t,e,i,o)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let r of h(e))!p.call(t,r)&&r!==i&&s(t,r,{get:()=>e[r],enumerable:!(o=l(e,r))||o.enumerable});return t};var k=(t,e,i)=>(i=t!=null?g(f(t)):{},a(e||!t||!t.__esModule?s(i,\\"default\\",{value:t,enumerable:!0}):i,t)),x=t=>a(s({},\\"__esModule\\",{value:!0}),t);var c=u((E,m)=>{m.exports=_jsx_runtime});var v={};y(v,{default:()=>j,frontmatter:()=>b});var n=k(c()),b={title:\\"Introducing ThirdEye - LinkedIn\\\\u2019s Business-Wide Monitoring Platform\\",date:\\"2019-01-09\\",authors:[\\"linkedin\\"],summary:\\"ThirdEye is a comprehensive platform for real-time monitoring of metrics that covers a wide variety of use-cases.\\",tags:[\\"Pinot\\",\\"LinkedIn\\",\\"real-time data platform\\",\\"Realtime\\",\\"ThirdEye\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function d(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\\"ThirdEye is a comprehensive platform for real-time monitoring of metrics that covers a wide variety of use-cases. LinkedIn relies on ThirdEye to monitor site performance, track member growth, understand adoption of new features, flag sustained attempts to circumvent system security, and many other areas\\"}),(0,n.jsxs)(e.p,{children:[\\"Read More at \\",(0,n.jsx)(e.a,{href:\\"https://engineering.linkedin.com/blog/2019/01/introducing-thirdeye--linkedins-business-wide-monitoring-platfor\\",children:\\"https://engineering.linkedin.com/blog/2019/01/introducing-thirdeye--linkedins-business-wide-monitoring-platfor\\"})]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Star-tree index - Powering fast aggregations on Pinot\\",src:\\"https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2019/06/startree3.png\\"})})]})}function w(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,Object.assign({},t,{children:(0,n.jsx)(d,t)})):d(t)}var j=w;return x(v);})();\\n;return Component;"},"_id":"blog/2019-01-09-LinkedIn-IntroThirdEye.mdx","_raw":{"sourceFilePath":"blog/2019-01-09-LinkedIn-IntroThirdEye.mdx","sourceFileName":"2019-01-09-LinkedIn-IntroThirdEye.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2019-01-09-LinkedIn-IntroThirdEye"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.28,"time":16800,"words":56},"slug":"2019/01/09/LinkedIn-IntroThirdEye","customSlug":"2019/01/09/LinkedIn-IntroThirdEye","path":"blog/2019/01/09/LinkedIn-IntroThirdEye","customPath":"blog/2019/01/09/LinkedIn-IntroThirdEye","filePath":"blog/2019-01-09-LinkedIn-IntroThirdEye.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Introducing ThirdEye - LinkedIn’s Business-Wide Monitoring Platform","datePublished":"2019-01-09T00:00:00.000Z","dateModified":"2019-01-09T00:00:00.000Z","description":"ThirdEye is a comprehensive platform for real-time monitoring of metrics that covers a wide variety of use-cases.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2019-01-09-LinkedIn-IntroThirdEye"}},{"title":"Star-tree index - Powering fast aggregations on Pinot","date":"2019-06-14T00:00:00.000Z","tags":["Pinot","LinkedIn","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Introduced Star-Tree index to utilize the pre-aggregated documents in a smart way that achieves low query latencies, while using the storage space efficiently.","authors":["linkedin"],"body":{"raw":"\\nIntroduced Star-Tree index to utilize the pre-aggregated documents in a smart way that achieves low query latencies, while using the storage space efficiently.\\n\\nRead More at https://engineering.linkedin.com/blog/2019/06/star-tree-index--powering-fast-aggregations-on-pinot\\n\\n![Star-tree index - Powering fast aggregations on Pinot](https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2019/06/startree3.png)\\n","code":"var Component=(()=>{var l=Object.create;var r=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var h=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),x=(t,e)=>{for(var i in e)r(t,i,{get:e[i],enumerable:!0})},o=(t,e,i,s)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of p(e))!u.call(t,a)&&a!==i&&r(t,a,{get:()=>e[a],enumerable:!(s=m(e,a))||s.enumerable});return t};var w=(t,e,i)=>(i=t!=null?l(h(t)):{},o(e||!t||!t.__esModule?r(i,\\"default\\",{value:t,enumerable:!0}):i,t)),y=t=>o(r({},\\"__esModule\\",{value:!0}),t);var c=f((M,g)=>{g.exports=_jsx_runtime});var k={};x(k,{default:()=>b,frontmatter:()=>j});var n=w(c()),j={title:\\"Star-tree index - Powering fast aggregations on Pinot\\",date:\\"2019-06-14\\",authors:[\\"linkedin\\"],summary:\\"Introduced Star-Tree index to utilize the pre-aggregated documents in a smart way that achieves low query latencies, while using the storage space efficiently.\\",tags:[\\"Pinot\\",\\"LinkedIn\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function d(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\\"Introduced Star-Tree index to utilize the pre-aggregated documents in a smart way that achieves low query latencies, while using the storage space efficiently.\\"}),(0,n.jsxs)(e.p,{children:[\\"Read More at \\",(0,n.jsx)(e.a,{href:\\"https://engineering.linkedin.com/blog/2019/06/star-tree-index--powering-fast-aggregations-on-pinot\\",children:\\"https://engineering.linkedin.com/blog/2019/06/star-tree-index--powering-fast-aggregations-on-pinot\\"})]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Star-tree index - Powering fast aggregations on Pinot\\",src:\\"https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2019/06/startree3.png\\"})})]})}function _(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,Object.assign({},t,{children:(0,n.jsx)(d,t)})):d(t)}var b=_;return y(k);})();\\n;return Component;"},"_id":"blog/2019-06-14-LinkedIn-StarTree.mdx","_raw":{"sourceFilePath":"blog/2019-06-14-LinkedIn-StarTree.mdx","sourceFileName":"2019-06-14-LinkedIn-StarTree.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2019-06-14-LinkedIn-StarTree"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.175,"time":10500,"words":35},"slug":"2019/06/14/LinkedIn-StarTree","customSlug":"2019/06/14/LinkedIn-StarTree","path":"blog/2019/06/14/LinkedIn-StarTree","customPath":"blog/2019/06/14/LinkedIn-StarTree","filePath":"blog/2019-06-14-LinkedIn-StarTree.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Star-tree index - Powering fast aggregations on Pinot","datePublished":"2019-06-14T00:00:00.000Z","dateModified":"2019-06-14T00:00:00.000Z","description":"Introduced Star-Tree index to utilize the pre-aggregated documents in a smart way that achieves low query latencies, while using the storage space efficiently.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2019-06-14-LinkedIn-StarTree"}},{"title":"Auto-tuning Pinot real-time consumption","date":"2019-07-11T00:00:00.000Z","tags":["Pinot","LinkedIn","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.","authors":["linkedin"],"body":{"raw":"\\nFocus on Auto tuning Pinot, a scalable distributed columnar OLAP data store developed at LinkedIn, delivers real-time analytics for site-facing use cases such as LinkedIn\'s Who viewed my profile, Talent insights, and more.\\n\\nRead More at https://engineering.linkedin.com/blog/2020/bridging-batch-and-stream-processing\\n\\n![Bridging batch and stream processing for the Recruiter usage statistics dashboard](https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2020/07/bridging-1.png)\\n","code":"var Component=(()=>{var l=Object.create;var s=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var h=Object.getPrototypeOf,p=Object.prototype.hasOwnProperty;var f=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),b=(n,e)=>{for(var i in e)s(n,i,{get:e[i],enumerable:!0})},o=(n,e,i,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of u(e))!p.call(n,a)&&a!==i&&s(n,a,{get:()=>e[a],enumerable:!(r=m(e,a))||r.enumerable});return n};var x=(n,e,i)=>(i=n!=null?l(h(n)):{},o(e||!n||!n.__esModule?s(i,\\"default\\",{value:n,enumerable:!0}):i,n)),k=n=>o(s({},\\"__esModule\\",{value:!0}),n);var g=f((F,c)=>{c.exports=_jsx_runtime});var w={};b(w,{default:()=>_,frontmatter:()=>y});var t=x(g()),y={title:\\"Auto-tuning Pinot real-time consumption\\",date:\\"2019-07-11\\",authors:[\\"linkedin\\"],summary:\\"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.\\",tags:[\\"Pinot\\",\\"LinkedIn\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function d(n){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},n.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.p,{children:\\"Focus on Auto tuning Pinot, a scalable distributed columnar OLAP data store developed at LinkedIn, delivers real-time analytics for site-facing use cases such as LinkedIn\'s Who viewed my profile, Talent insights, and more.\\"}),(0,t.jsxs)(e.p,{children:[\\"Read More at \\",(0,t.jsx)(e.a,{href:\\"https://engineering.linkedin.com/blog/2020/bridging-batch-and-stream-processing\\",children:\\"https://engineering.linkedin.com/blog/2020/bridging-batch-and-stream-processing\\"})]}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"Bridging batch and stream processing for the Recruiter usage statistics dashboard\\",src:\\"https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2020/07/bridging-1.png\\"})})]})}function j(n={}){let{wrapper:e}=n.components||{};return e?(0,t.jsx)(e,Object.assign({},n,{children:(0,t.jsx)(d,n)})):d(n)}var _=j;return k(w);})();\\n;return Component;"},"_id":"blog/2019-07-11-LinkedIn-AutoTune.mdx","_raw":{"sourceFilePath":"blog/2019-07-11-LinkedIn-AutoTune.mdx","sourceFileName":"2019-07-11-LinkedIn-AutoTune.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2019-07-11-LinkedIn-AutoTune"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.24,"time":14400,"words":48},"slug":"2019/07/11/LinkedIn-AutoTune","customSlug":"2019/07/11/LinkedIn-AutoTune","path":"blog/2019/07/11/LinkedIn-AutoTune","customPath":"blog/2019/07/11/LinkedIn-AutoTune","filePath":"blog/2019-07-11-LinkedIn-AutoTune.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Auto-tuning Pinot real-time consumption","datePublished":"2019-07-11T00:00:00.000Z","dateModified":"2019-07-11T00:00:00.000Z","description":"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2019-07-11-LinkedIn-AutoTune"}},{"title":"Engineering SQL Support on Apache Pinot at Uber","date":"2020-01-15T00:00:00.000Z","tags":["Pinot","Uber","real-time data platform","Realtime","Analytics","User-Facing Analytics","Presto","SQL"],"summary":"Talks about solution that linked Presto, a query engine that supports full ANSI SQL, and Pinot, a real-time OLAP (online analytical processing) datastore.","authors":["uber"],"body":{"raw":"\\nUber leverages real-time analytics on aggregate data to improve the user experience across our products, from fighting fraudulent behavior on Uber Eats to forecasting demand on our platform.\\n\\nTo resolve these issues, we built a solution that linked Presto, a query engine that supports full ANSI SQL, and Pinot, a real-time OLAP (online analytical processing) datastore. This married solution allows users to write ad-hoc SQL queries, empowering teams to unlock significant analysis capabilities.\\n\\n[Read More at https://eng.uber.com/engineering-sql-support-on-apache-pinot/](https://eng.uber.com/engineering-sql-support-on-apache-pinot/)\\n\\n![SQL Support on Apache Pinot at Uber](https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2020/01/Header-SQL-768x329.png)\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var g=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var d=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),b=(t,e)=>{for(var a in e)o(t,a,{get:e[a],enumerable:!0})},i=(t,e,a,s)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let r of m(e))!h.call(t,r)&&r!==a&&o(t,r,{get:()=>e[r],enumerable:!(s=g(e,r))||s.enumerable});return t};var y=(t,e,a)=>(a=t!=null?u(d(t)):{},i(e||!t||!t.__esModule?o(a,\\"default\\",{value:t,enumerable:!0}):a,t)),x=t=>i(o({},\\"__esModule\\",{value:!0}),t);var p=f((j,l)=>{l.exports=_jsx_runtime});var w={};b(w,{default:()=>P,frontmatter:()=>S});var n=y(p()),S={title:\\"Engineering SQL Support on Apache Pinot at Uber\\",date:\\"2020-01-15\\",authors:[\\"uber\\"],summary:\\"Talks about solution that linked Presto, a query engine that supports full ANSI SQL, and Pinot, a real-time OLAP (online analytical processing) datastore.\\",tags:[\\"Pinot\\",\\"Uber\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"Presto\\",\\"SQL\\"]};function c(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\\"Uber leverages real-time analytics on aggregate data to improve the user experience across our products, from fighting fraudulent behavior on Uber Eats to forecasting demand on our platform.\\"}),(0,n.jsx)(e.p,{children:\\"To resolve these issues, we built a solution that linked Presto, a query engine that supports full ANSI SQL, and Pinot, a real-time OLAP (online analytical processing) datastore. This married solution allows users to write ad-hoc SQL queries, empowering teams to unlock significant analysis capabilities.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.a,{href:\\"https://eng.uber.com/engineering-sql-support-on-apache-pinot/\\",children:\\"Read More at https://eng.uber.com/engineering-sql-support-on-apache-pinot/\\"})}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"SQL Support on Apache Pinot at Uber\\",src:\\"https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2020/01/Header-SQL-768x329.png\\"})})]})}function L(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,Object.assign({},t,{children:(0,n.jsx)(c,t)})):c(t)}var P=L;return x(w);})();\\n;return Component;"},"_id":"blog/2020-01-15-Pinot-Presto-SQL.mdx","_raw":{"sourceFilePath":"blog/2020-01-15-Pinot-Presto-SQL.mdx","sourceFileName":"2020-01-15-Pinot-Presto-SQL.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-01-15-Pinot-Presto-SQL"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.42,"time":25200,"words":84},"slug":"2020/01/15/Pinot-Presto-SQL","customSlug":"2020/01/15/Pinot-Presto-SQL","path":"blog/2020/01/15/Pinot-Presto-SQL","customPath":"blog/2020/01/15/Pinot-Presto-SQL","filePath":"blog/2020-01-15-Pinot-Presto-SQL.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Engineering SQL Support on Apache Pinot at Uber","datePublished":"2020-01-15T00:00:00.000Z","dateModified":"2020-01-15T00:00:00.000Z","description":"Talks about solution that linked Presto, a query engine that supports full ANSI SQL, and Pinot, a real-time OLAP (online analytical processing) datastore.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-01-15-Pinot-Presto-SQL"}},{"title":"Analyzing anomalies with ThirdEye","date":"2020-02-20T00:00:00.000Z","tags":["Pinot","LinkedIn","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.","authors":["linkedin"],"body":{"raw":"\\nFocus on the behind-the-scenes functionalities of ThirdEye that analyze the multi-dimensional time series data and help our engineers understand why these anomalies happened through a dimension heatmap\\n\\n[Read More at https://engineering.linkedin.com/blog/2020/analyzing-anomalies-with-thirdeye](https://engineering.linkedin.com/blog/2020/analyzing-anomalies-with-thirdeye)\\n\\n![Analyzing anomalies with ThirdEye](https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2020/02/datacube-1.png)\\n","code":"var Component=(()=>{var d=Object.create;var s=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,p=Object.prototype.hasOwnProperty;var y=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),f=(n,e)=>{for(var i in e)s(n,i,{get:e[i],enumerable:!0})},r=(n,e,i,o)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of g(e))!p.call(n,a)&&a!==i&&s(n,a,{get:()=>e[a],enumerable:!(o=m(e,a))||o.enumerable});return n};var w=(n,e,i)=>(i=n!=null?d(u(n)):{},r(e||!n||!n.__esModule?s(i,\\"default\\",{value:n,enumerable:!0}):i,n)),x=n=>r(s({},\\"__esModule\\",{value:!0}),n);var c=y((A,l)=>{l.exports=_jsx_runtime});var k={};f(k,{default:()=>_,frontmatter:()=>b});var t=w(c()),b={title:\\"Analyzing anomalies with ThirdEye\\",date:new Date(15821568e5),authors:[\\"linkedin\\"],summary:\\"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.\\",tags:[\\"Pinot\\",\\"LinkedIn\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function h(n){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},n.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.p,{children:\\"Focus on the behind-the-scenes functionalities of ThirdEye that analyze the multi-dimensional time series data and help our engineers understand why these anomalies happened through a dimension heatmap\\"}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.a,{href:\\"https://engineering.linkedin.com/blog/2020/analyzing-anomalies-with-thirdeye\\",children:\\"Read More at https://engineering.linkedin.com/blog/2020/analyzing-anomalies-with-thirdeye\\"})}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"Analyzing anomalies with ThirdEye\\",src:\\"https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2020/02/datacube-1.png\\"})})]})}function j(n={}){let{wrapper:e}=n.components||{};return e?(0,t.jsx)(e,Object.assign({},n,{children:(0,t.jsx)(h,n)})):h(n)}var _=j;return x(k);})();\\n;return Component;"},"_id":"blog/2020-02-20-LinkedIn-Thirdeye.mdx","_raw":{"sourceFilePath":"blog/2020-02-20-LinkedIn-Thirdeye.mdx","sourceFileName":"2020-02-20-LinkedIn-Thirdeye.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-02-20-LinkedIn-Thirdeye"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.175,"time":10500,"words":35},"slug":"2020/02/20/LinkedIn-Thirdeye","customSlug":"2020/02/20/LinkedIn-Thirdeye","path":"blog/2020/02/20/LinkedIn-Thirdeye","customPath":"blog/2020/02/20/LinkedIn-Thirdeye","filePath":"blog/2020-02-20-LinkedIn-Thirdeye.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Analyzing anomalies with ThirdEye","datePublished":"2020-02-20T00:00:00.000Z","dateModified":"2020-02-20T00:00:00.000Z","description":"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-02-20-LinkedIn-Thirdeye"}},{"title":"Using Apache Pinot and Kafka to Analyze GitHub Events","date":"2021-04-10T00:00:00.000Z","tags":["Pinot","DevBlog","ThirdEye","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Show you how Pinot and Kafka can be used together to ingest, query, and visualize event streams sourced from the public GitHub API.","authors":["bastani"],"body":{"raw":"\\nIn this blog post, we’ll show you how Pinot and Kafka can be used together to ingest, query, and visualize event streams sourced from the public GitHub API. For the step-by-step instructions, please visit our documentation, which will guide you through the specifics of running this example in your development environment.\\n\\nRead More at https://medium.com/apache-pinot-developer-blog/using-apache-pinot-and-kafka-to-analyze-github-events-93cdcb57d5f7\\n\\n![Using Apache Pinot and Kafka to Analyze GitHub Events](https://miro.medium.com/max/4728/1*eR64jBH1ZvC3uNfPP56p5g.png)\\n","code":"var Component=(()=>{var h=Object.create;var o=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var l=Object.getOwnPropertyNames;var p=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),b=(t,e)=>{for(var a in e)o(t,a,{get:e[a],enumerable:!0})},r=(t,e,a,s)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let i of l(e))!g.call(t,i)&&i!==a&&o(t,i,{get:()=>e[i],enumerable:!(s=m(e,i))||s.enumerable});return t};var y=(t,e,a)=>(a=t!=null?h(p(t)):{},r(e||!t||!t.__esModule?o(a,\\"default\\",{value:t,enumerable:!0}):a,t)),v=t=>r(o({},\\"__esModule\\",{value:!0}),t);var u=f((A,c)=>{c.exports=_jsx_runtime});var j={};b(j,{default:()=>P,frontmatter:()=>x});var n=y(u()),x={title:\\"Using Apache Pinot and Kafka to Analyze GitHub Events\\",date:new Date(16180128e5),authors:[\\"bastani\\"],summary:\\"Show you how Pinot and Kafka can be used together to ingest, query, and visualize event streams sourced from the public GitHub API.\\",tags:[\\"Pinot\\",\\"DevBlog\\",\\"ThirdEye\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function d(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\\"In this blog post, we\\\\u2019ll show you how Pinot and Kafka can be used together to ingest, query, and visualize event streams sourced from the public GitHub API. For the step-by-step instructions, please visit our documentation, which will guide you through the specifics of running this example in your development environment.\\"}),(0,n.jsxs)(e.p,{children:[\\"Read More at \\",(0,n.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/using-apache-pinot-and-kafka-to-analyze-github-events-93cdcb57d5f7\\",children:\\"https://medium.com/apache-pinot-developer-blog/using-apache-pinot-and-kafka-to-analyze-github-events-93cdcb57d5f7\\"})]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Using Apache Pinot and Kafka to Analyze GitHub Events\\",src:\\"https://miro.medium.com/max/4728/1*eR64jBH1ZvC3uNfPP56p5g.png\\"})})]})}function w(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,Object.assign({},t,{children:(0,n.jsx)(d,t)})):d(t)}var P=w;return v(j);})();\\n;return Component;"},"_id":"blog/2020-04-10-DevBlog-AnalyzeGitEvents.mdx","_raw":{"sourceFilePath":"blog/2020-04-10-DevBlog-AnalyzeGitEvents.mdx","sourceFileName":"2020-04-10-DevBlog-AnalyzeGitEvents.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-04-10-DevBlog-AnalyzeGitEvents"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.32,"time":19200,"words":64},"slug":"2020/04/10/DevBlog-AnalyzeGitEvents","customSlug":"2020/04/10/DevBlog-AnalyzeGitEvents","path":"blog/2020/04/10/DevBlog-AnalyzeGitEvents","customPath":"blog/2020/04/10/DevBlog-AnalyzeGitEvents","filePath":"blog/2020-04-10-DevBlog-AnalyzeGitEvents.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Using Apache Pinot and Kafka to Analyze GitHub Events","datePublished":"2021-04-10T00:00:00.000Z","dateModified":"2021-04-10T00:00:00.000Z","description":"Show you how Pinot and Kafka can be used together to ingest, query, and visualize event streams sourced from the public GitHub API.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-04-10-DevBlog-AnalyzeGitEvents"}},{"title":"Monitoring business performance data with ThirdEye smart alerts","date":"2020-06-25T00:00:00.000Z","tags":["Pinot","LinkedIn","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.","authors":["linkedin"],"body":{"raw":"\\nExplain how ThirdEye smart alerts and automated dashboards helped the LinkedIn Premium business operations team monitor key metrics—such as new free trial signups—for the timely detection of outliers in business performance data.\\n\\nRead More at https://engineering.linkedin.com/blog/2020/monitoring-business-performance-data-with-thirdeye-smart-alerts\\n\\n![Monitoring business performance data with ThirdEye smart alerts](https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2020/06/thirdeye_business_performance-3.png)\\n","code":"var Component=(()=>{var l=Object.create;var s=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,p=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),y=(t,e)=>{for(var i in e)s(t,i,{get:e[i],enumerable:!0})},o=(t,e,i,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of g(e))!p.call(t,a)&&a!==i&&s(t,a,{get:()=>e[a],enumerable:!(r=h(e,a))||r.enumerable});return t};var b=(t,e,i)=>(i=t!=null?l(u(t)):{},o(e||!t||!t.__esModule?s(i,\\"default\\",{value:t,enumerable:!0}):i,t)),w=t=>o(s({},\\"__esModule\\",{value:!0}),t);var m=f((E,c)=>{c.exports=_jsx_runtime});var j={};y(j,{default:()=>k,frontmatter:()=>x});var n=b(m()),x={title:\\"Monitoring business performance data with ThirdEye smart alerts\\",date:new Date(15930432e5),authors:[\\"linkedin\\"],summary:\\"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.\\",tags:[\\"Pinot\\",\\"LinkedIn\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function d(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\\"Explain how ThirdEye smart alerts and automated dashboards helped the LinkedIn Premium business operations team monitor key metrics\\\\u2014such as new free trial signups\\\\u2014for the timely detection of outliers in business performance data.\\"}),(0,n.jsxs)(e.p,{children:[\\"Read More at \\",(0,n.jsx)(e.a,{href:\\"https://engineering.linkedin.com/blog/2020/monitoring-business-performance-data-with-thirdeye-smart-alerts\\",children:\\"https://engineering.linkedin.com/blog/2020/monitoring-business-performance-data-with-thirdeye-smart-alerts\\"})]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Monitoring business performance data with ThirdEye smart alerts\\",src:\\"https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2020/06/thirdeye_business_performance-3.png\\"})})]})}function _(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,Object.assign({},t,{children:(0,n.jsx)(d,t)})):d(t)}var k=_;return w(j);})();\\n;return Component;"},"_id":"blog/2020-06-25-LinkedIn-SmartAlerts.mdx","_raw":{"sourceFilePath":"blog/2020-06-25-LinkedIn-SmartAlerts.mdx","sourceFileName":"2020-06-25-LinkedIn-SmartAlerts.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-06-25-LinkedIn-SmartAlerts"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.22,"time":13200,"words":44},"slug":"2020/06/25/LinkedIn-SmartAlerts","customSlug":"2020/06/25/LinkedIn-SmartAlerts","path":"blog/2020/06/25/LinkedIn-SmartAlerts","customPath":"blog/2020/06/25/LinkedIn-SmartAlerts","filePath":"blog/2020-06-25-LinkedIn-SmartAlerts.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Monitoring business performance data with ThirdEye smart alerts","datePublished":"2020-06-25T00:00:00.000Z","dateModified":"2020-06-25T00:00:00.000Z","description":"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-06-25-LinkedIn-SmartAlerts"}},{"title":"Building LinkedIn Talent Insights to democratize data-driven decision making","date":"2020-06-29T00:00:00.000Z","tags":["Pinot","LinkedIn","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.","authors":["linkedin"],"body":{"raw":"\\nLinkedIn is a mission-driven organization, and we take our mission of “connecting the world\'s professionals to make them more productive and successful” very seriously.\\n\\nRead More at https://engineering.linkedin.com/blog/2020/building-linkedin-talent-insights\\n\\n![Building LinkedIn Talent Insights to democratize data-driven decision making](https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2020/06/lti-1.png)\\n","code":"var Component=(()=>{var g=Object.create;var s=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var h=Object.getPrototypeOf,p=Object.prototype.hasOwnProperty;var f=(e,n)=>()=>(n||e((n={exports:{}}).exports,n),n.exports),k=(e,n)=>{for(var t in n)s(e,t,{get:n[t],enumerable:!0})},r=(e,n,t,o)=>{if(n&&typeof n==\\"object\\"||typeof n==\\"function\\")for(let a of u(n))!p.call(e,a)&&a!==t&&s(e,a,{get:()=>n[a],enumerable:!(o=m(n,a))||o.enumerable});return e};var x=(e,n,t)=>(t=e!=null?g(h(e)):{},r(n||!e||!e.__esModule?s(t,\\"default\\",{value:e,enumerable:!0}):t,e)),w=e=>r(s({},\\"__esModule\\",{value:!0}),e);var d=f((I,c)=>{c.exports=_jsx_runtime});var _={};k(_,{default:()=>j,frontmatter:()=>y});var i=x(d()),y={title:\\"Building LinkedIn Talent Insights to democratize data-driven decision making\\",date:new Date(15933888e5),authors:[\\"linkedin\\"],summary:\\"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.\\",tags:[\\"Pinot\\",\\"LinkedIn\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function l(e){let n=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},e.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:\\"LinkedIn is a mission-driven organization, and we take our mission of \\\\u201Cconnecting the world\'s professionals to make them more productive and successful\\\\u201D very seriously.\\"}),(0,i.jsxs)(n.p,{children:[\\"Read More at \\",(0,i.jsx)(n.a,{href:\\"https://engineering.linkedin.com/blog/2020/building-linkedin-talent-insights\\",children:\\"https://engineering.linkedin.com/blog/2020/building-linkedin-talent-insights\\"})]}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:\\"Building LinkedIn Talent Insights to democratize data-driven decision making\\",src:\\"https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2020/06/lti-1.png\\"})})]})}function b(e={}){let{wrapper:n}=e.components||{};return n?(0,i.jsx)(n,Object.assign({},e,{children:(0,i.jsx)(l,e)})):l(e)}var j=b;return w(_);})();\\n;return Component;"},"_id":"blog/2020-06-29-LinkedIn-TalentInsight.mdx","_raw":{"sourceFilePath":"blog/2020-06-29-LinkedIn-TalentInsight.mdx","sourceFileName":"2020-06-29-LinkedIn-TalentInsight.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-06-29-LinkedIn-TalentInsight"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.185,"time":11100,"words":37},"slug":"2020/06/29/LinkedIn-TalentInsight","customSlug":"2020/06/29/LinkedIn-TalentInsight","path":"blog/2020/06/29/LinkedIn-TalentInsight","customPath":"blog/2020/06/29/LinkedIn-TalentInsight","filePath":"blog/2020-06-29-LinkedIn-TalentInsight.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Building LinkedIn Talent Insights to democratize data-driven decision making","datePublished":"2020-06-29T00:00:00.000Z","dateModified":"2020-06-29T00:00:00.000Z","description":"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-06-29-LinkedIn-TalentInsight"}},{"title":"Bridging batch and stream processing for the Recruiter usage statistics dashboard","date":"2020-07-14T00:00:00.000Z","tags":["Pinot","LinkedIn","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.","authors":["linkedin"],"body":{"raw":"\\nBatch and streaming computations are often combined together in the Lambda architecture, but carry the cost of maintaining two different code bases for the same logic.\\n\\nRead More at https://engineering.linkedin.com/blog/2020/bridging-batch-and-stream-processing\\n\\n![Bridging batch and stream processing for the Recruiter usage statistics dashboard](https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2020/07/bridging-1.png)\\n","code":"var Component=(()=>{var m=Object.create;var s=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var l=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,p=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),b=(t,e)=>{for(var i in e)s(t,i,{get:e[i],enumerable:!0})},o=(t,e,i,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of l(e))!p.call(t,a)&&a!==i&&s(t,a,{get:()=>e[a],enumerable:!(r=h(e,a))||r.enumerable});return t};var x=(t,e,i)=>(i=t!=null?m(u(t)):{},o(e||!t||!t.__esModule?s(i,\\"default\\",{value:t,enumerable:!0}):i,t)),j=t=>o(s({},\\"__esModule\\",{value:!0}),t);var g=f((M,c)=>{c.exports=_jsx_runtime});var k={};b(k,{default:()=>_,frontmatter:()=>w});var n=x(g()),w={title:\\"Bridging batch and stream processing for the Recruiter usage statistics dashboard\\",date:new Date(15946848e5),authors:[\\"linkedin\\"],summary:\\"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.\\",tags:[\\"Pinot\\",\\"LinkedIn\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function d(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\\"Batch and streaming computations are often combined together in the Lambda architecture, but carry the cost of maintaining two different code bases for the same logic.\\"}),(0,n.jsxs)(e.p,{children:[\\"Read More at \\",(0,n.jsx)(e.a,{href:\\"https://engineering.linkedin.com/blog/2020/bridging-batch-and-stream-processing\\",children:\\"https://engineering.linkedin.com/blog/2020/bridging-batch-and-stream-processing\\"})]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Bridging batch and stream processing for the Recruiter usage statistics dashboard\\",src:\\"https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2020/07/bridging-1.png\\"})})]})}function y(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,Object.assign({},t,{children:(0,n.jsx)(d,t)})):d(t)}var _=y;return j(k);})();\\n;return Component;"},"_id":"blog/2020-07-14-LinkedIn-BatchRealtime.mdx","_raw":{"sourceFilePath":"blog/2020-07-14-LinkedIn-BatchRealtime.mdx","sourceFileName":"2020-07-14-LinkedIn-BatchRealtime.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-07-14-LinkedIn-BatchRealtime"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.205,"time":12300,"words":41},"slug":"2020/07/14/LinkedIn-BatchRealtime","customSlug":"2020/07/14/LinkedIn-BatchRealtime","path":"blog/2020/07/14/LinkedIn-BatchRealtime","customPath":"blog/2020/07/14/LinkedIn-BatchRealtime","filePath":"blog/2020-07-14-LinkedIn-BatchRealtime.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Bridging batch and stream processing for the Recruiter usage statistics dashboard","datePublished":"2020-07-14T00:00:00.000Z","dateModified":"2020-07-14T00:00:00.000Z","description":"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-07-14-LinkedIn-BatchRealtime"}},{"title":"Building a culture around metrics and anomaly detection","date":"2020-07-28T00:00:00.000Z","tags":["Pinot","DevBlog","ThirdEye","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"ThirdEye as a system is a platform that allows you to integrate your metrics (quantitative information) with events (knowledge or qualitative information) and combine the two so you can distinguish between meaningless anomalies and those ones that matter.","authors":["bastani"],"body":{"raw":"\\nAnomaly detection is a very broad term. Usually it means that you want to see if things are running as usual. This could go from your business metrics down to the lowest level of how your systems are running. Anomaly detection is an entire process. It’s not just a tool that you get out of the box that measures time series data. Similar to DevOps, anomaly detection is a culture of different roles engaging in a process that combines tooling with human analysis.\\n\\nRead More at https://medium.com/apache-pinot-developer-blog/building-a-culture-around-metrics-and-anomaly-detection-da740960fcc2\\n\\n![Building a culture around metrics and anomaly detection](https://miro.medium.com/max/1400/0*xYm2ZURZVpyJ1JQ5)\\n","code":"var Component=(()=>{var u=Object.create;var i=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var h=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,y=Object.prototype.hasOwnProperty;var p=(e,t)=>()=>(t||e((t={exports:{}}).exports,t),t.exports),f=(e,t)=>{for(var n in t)i(e,n,{get:t[n],enumerable:!0})},r=(e,t,n,s)=>{if(t&&typeof t==\\"object\\"||typeof t==\\"function\\")for(let o of h(t))!y.call(e,o)&&o!==n&&i(e,o,{get:()=>t[o],enumerable:!(s=d(t,o))||s.enumerable});return e};var b=(e,t,n)=>(n=e!=null?u(g(e)):{},r(t||!e||!e.__esModule?i(n,\\"default\\",{value:e,enumerable:!0}):n,e)),w=e=>r(i({},\\"__esModule\\",{value:!0}),e);var c=p((A,m)=>{m.exports=_jsx_runtime});var _={};f(_,{default:()=>j,frontmatter:()=>x});var a=b(c()),x={title:\\"Building a culture around metrics and anomaly detection\\",date:new Date(15958944e5),authors:[\\"bastani\\"],summary:\\"ThirdEye as a system is a platform that allows you to integrate your metrics (quantitative information) with events (knowledge or qualitative information) and combine the two so you can distinguish between meaningless anomalies and those ones that matter.\\",tags:[\\"Pinot\\",\\"DevBlog\\",\\"ThirdEye\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function l(e){let t=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},e.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.p,{children:\\"Anomaly detection is a very broad term. Usually it means that you want to see if things are running as usual. This could go from your business metrics down to the lowest level of how your systems are running. Anomaly detection is an entire process. It\\\\u2019s not just a tool that you get out of the box that measures time series data. Similar to DevOps, anomaly detection is a culture of different roles engaging in a process that combines tooling with human analysis.\\"}),(0,a.jsxs)(t.p,{children:[\\"Read More at \\",(0,a.jsx)(t.a,{href:\\"https://medium.com/apache-pinot-developer-blog/building-a-culture-around-metrics-and-anomaly-detection-da740960fcc2\\",children:\\"https://medium.com/apache-pinot-developer-blog/building-a-culture-around-metrics-and-anomaly-detection-da740960fcc2\\"})]}),(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:\\"Building a culture around metrics and anomaly detection\\",src:\\"https://miro.medium.com/max/1400/0*xYm2ZURZVpyJ1JQ5\\"})})]})}function v(e={}){let{wrapper:t}=e.components||{};return t?(0,a.jsx)(t,Object.assign({},e,{children:(0,a.jsx)(l,e)})):l(e)}var j=v;return w(_);})();\\n;return Component;"},"_id":"blog/2020-07-28-DevBlog-AnomalyDetection.mdx","_raw":{"sourceFilePath":"blog/2020-07-28-DevBlog-AnomalyDetection.mdx","sourceFileName":"2020-07-28-DevBlog-AnomalyDetection.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-07-28-DevBlog-AnomalyDetection"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.475,"time":28500,"words":95},"slug":"2020/07/28/DevBlog-AnomalyDetection","customSlug":"2020/07/28/DevBlog-AnomalyDetection","path":"blog/2020/07/28/DevBlog-AnomalyDetection","customPath":"blog/2020/07/28/DevBlog-AnomalyDetection","filePath":"blog/2020-07-28-DevBlog-AnomalyDetection.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Building a culture around metrics and anomaly detection","datePublished":"2020-07-28T00:00:00.000Z","dateModified":"2020-07-28T00:00:00.000Z","description":"ThirdEye as a system is a platform that allows you to integrate your metrics (quantitative information) with events (knowledge or qualitative information) and combine the two so you can distinguish between meaningless anomalies and those ones that matter.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-07-28-DevBlog-AnomalyDetection"}},{"title":"Moving developers up the stack with Apache Pinot","date":"2020-07-28T00:00:00.000Z","tags":["Pinot","DevBlog","ThirdEye","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Pinot enters into a storied legacy of innovations that have emerged from one of the world’s largest online social networks. Over a few decades, the Silicon Valley tech giant has helped hundreds of millions of people around the world navigate their careers.","authors":["bastani"],"body":{"raw":"\\nOnce upon a time, an internet company named LinkedIn faced the challenge of having petabytes of connected data with no way to analyze it in real-time. As this was a problem that was the first of its kind, there was only one solution. The company put together a talented team of engineers and tasked them with building the right tool for the job. Today, that tool goes by the name of Apache Pinot.\\n\\nRead More at https://medium.com/apache-pinot-developer-blog/moving-developers-up-the-stack-with-apache-pinot-29d36717a3f4\\n\\n![Moving developers up the stack with Apache Pinot](https://miro.medium.com/max/1400/1*dnSikeGxTrfrF95niX16PA.png)\\n","code":"var Component=(()=>{var d=Object.create;var i=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var u=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),v=(t,e)=>{for(var n in e)i(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let o of m(e))!f.call(t,o)&&o!==n&&i(t,o,{get:()=>e[o],enumerable:!(r=p(e,o))||r.enumerable});return t};var w=(t,e,n)=>(n=t!=null?d(g(t)):{},s(e||!t||!t.__esModule?i(n,\\"default\\",{value:t,enumerable:!0}):n,t)),y=t=>s(i({},\\"__esModule\\",{value:!0}),t);var c=u((_,h)=>{h.exports=_jsx_runtime});var j={};v(j,{default:()=>k,frontmatter:()=>x});var a=w(c()),x={title:\\"Moving developers up the stack with Apache Pinot\\",date:new Date(15958944e5),authors:[\\"bastani\\"],summary:\\"Pinot enters into a storied legacy of innovations that have emerged from one of the world\\\\u2019s largest online social networks. Over a few decades, the Silicon Valley tech giant has helped hundreds of millions of people around the world navigate their careers.\\",tags:[\\"Pinot\\",\\"DevBlog\\",\\"ThirdEye\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function l(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.p,{children:\\"Once upon a time, an internet company named LinkedIn faced the challenge of having petabytes of connected data with no way to analyze it in real-time. As this was a problem that was the first of its kind, there was only one solution. The company put together a talented team of engineers and tasked them with building the right tool for the job. Today, that tool goes by the name of Apache Pinot.\\"}),(0,a.jsxs)(e.p,{children:[\\"Read More at \\",(0,a.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/moving-developers-up-the-stack-with-apache-pinot-29d36717a3f4\\",children:\\"https://medium.com/apache-pinot-developer-blog/moving-developers-up-the-stack-with-apache-pinot-29d36717a3f4\\"})]}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Moving developers up the stack with Apache Pinot\\",src:\\"https://miro.medium.com/max/1400/1*dnSikeGxTrfrF95niX16PA.png\\"})})]})}function b(t={}){let{wrapper:e}=t.components||{};return e?(0,a.jsx)(e,Object.assign({},t,{children:(0,a.jsx)(l,t)})):l(t)}var k=b;return y(j);})();\\n;return Component;"},"_id":"blog/2020-07-28-DevBlog-DevUpStack.mdx","_raw":{"sourceFilePath":"blog/2020-07-28-DevBlog-DevUpStack.mdx","sourceFileName":"2020-07-28-DevBlog-DevUpStack.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-07-28-DevBlog-DevUpStack"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.425,"time":25500,"words":85},"slug":"2020/07/28/DevBlog-DevUpStack","customSlug":"2020/07/28/DevBlog-DevUpStack","path":"blog/2020/07/28/DevBlog-DevUpStack","customPath":"blog/2020/07/28/DevBlog-DevUpStack","filePath":"blog/2020-07-28-DevBlog-DevUpStack.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Moving developers up the stack with Apache Pinot","datePublished":"2020-07-28T00:00:00.000Z","dateModified":"2020-07-28T00:00:00.000Z","description":"Pinot enters into a storied legacy of innovations that have emerged from one of the world’s largest online social networks. Over a few decades, the Silicon Valley tech giant has helped hundreds of millions of people around the world navigate their careers.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-07-28-DevBlog-DevUpStack"}},{"title":"Leverage Plugins to Ingest Parquet Files from S3 in Pinot","date":"2020-08-08T00:00:00.000Z","tags":["Pinot","SLA","DevBlog","ThirdEye","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Pinot is its pluggable architecture. The plugins make it easy to add support for any third-party system which can be an execution framework, a filesystem, or input format.","authors":["pinotdev"],"body":{"raw":"\\nOne of the primary advantages of using Pinot is its pluggable architecture. The plugins make it easy to add support for any third-party system which can be an execution framework, a filesystem, or input format.\\n\\nIn this tutorial, we will use three such plugins to easily ingest data and push it to our Pinot cluster. The plugins we will be using are -\\n\\n-   pinot-batch-ingestion-spark\\n-   pinot-s3\\n-   pinot-parquet\\n\\n[Read more at https://medium.com/apache-pinot-developer-blog/leverage-plugins-to-ingest-parquet-files-from-s3-in-pinot-decb12e4d09d](https://medium.com/apache-pinot-developer-blog/leverage-plugins-to-ingest-parquet-files-from-s3-in-pinot-decb12e4d09d)\\n\\n![Leverage Plugins to Ingest Parquet Files from S3 in Pinot](https://miro.medium.com/max/6000/0*afbs7azGt-GpSVeP)\\n","code":"var Component=(()=>{var u=Object.create;var r=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var d=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),y=(t,e)=>{for(var n in e)r(t,n,{get:e[n],enumerable:!0})},o=(t,e,n,s)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of d(e))!h.call(t,a)&&a!==n&&r(t,a,{get:()=>e[a],enumerable:!(s=m(e,a))||s.enumerable});return t};var b=(t,e,n)=>(n=t!=null?u(g(t)):{},o(e||!t||!t.__esModule?r(n,\\"default\\",{value:t,enumerable:!0}):n,t)),x=t=>o(r({},\\"__esModule\\",{value:!0}),t);var p=f((k,l)=>{l.exports=_jsx_runtime});var j={};y(j,{default:()=>v,frontmatter:()=>P});var i=b(p()),P={title:\\"Leverage Plugins to Ingest Parquet Files from S3 in Pinot\\",date:new Date(15968448e5),authors:[\\"pinotdev\\"],summary:\\"Pinot is its pluggable architecture. The plugins make it easy to add support for any third-party system which can be an execution framework, a filesystem, or input format.\\",tags:[\\"Pinot\\",\\"SLA\\",\\"DevBlog\\",\\"ThirdEye\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function c(t){let e=Object.assign({p:\\"p\\",ul:\\"ul\\",li:\\"li\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.p,{children:\\"One of the primary advantages of using Pinot is its pluggable architecture. The plugins make it easy to add support for any third-party system which can be an execution framework, a filesystem, or input format.\\"}),(0,i.jsx)(e.p,{children:\\"In this tutorial, we will use three such plugins to easily ingest data and push it to our Pinot cluster. The plugins we will be using are -\\"}),(0,i.jsxs)(e.ul,{children:[(0,i.jsx)(e.li,{children:\\"pinot-batch-ingestion-spark\\"}),(0,i.jsx)(e.li,{children:\\"pinot-s3\\"}),(0,i.jsx)(e.li,{children:\\"pinot-parquet\\"})]}),(0,i.jsx)(e.p,{children:(0,i.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/leverage-plugins-to-ingest-parquet-files-from-s3-in-pinot-decb12e4d09d\\",children:\\"Read more at https://medium.com/apache-pinot-developer-blog/leverage-plugins-to-ingest-parquet-files-from-s3-in-pinot-decb12e4d09d\\"})}),(0,i.jsx)(e.p,{children:(0,i.jsx)(e.img,{alt:\\"Leverage Plugins to Ingest Parquet Files from S3 in Pinot\\",src:\\"https://miro.medium.com/max/6000/0*afbs7azGt-GpSVeP\\"})})]})}function w(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(c,t)})):c(t)}var v=w;return x(j);})();\\n;return Component;"},"_id":"blog/2020-08-08-DevBlog-IngestPlugins.mdx","_raw":{"sourceFilePath":"blog/2020-08-08-DevBlog-IngestPlugins.mdx","sourceFileName":"2020-08-08-DevBlog-IngestPlugins.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-08-08-DevBlog-IngestPlugins"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.415,"time":24900,"words":83},"slug":"2020/08/08/DevBlog-IngestPlugins","customSlug":"2020/08/08/DevBlog-IngestPlugins","path":"blog/2020/08/08/DevBlog-IngestPlugins","customPath":"blog/2020/08/08/DevBlog-IngestPlugins","filePath":"blog/2020-08-08-DevBlog-IngestPlugins.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Leverage Plugins to Ingest Parquet Files from S3 in Pinot","datePublished":"2020-08-08T00:00:00.000Z","dateModified":"2020-08-08T00:00:00.000Z","description":"Pinot is its pluggable architecture. The plugins make it easy to add support for any third-party system which can be an execution framework, a filesystem, or input format.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-08-08-DevBlog-IngestPlugins"}},{"title":"Monitoring Apache Pinot with JMX, Prometheus and Grafana","date":"2020-08-08T00:00:00.000Z","tags":["Pinot","Monitoring","JMX","Prometheus","Grafana","DevBlog","ThirdEye","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Blog gives an overview of our use of Apache Pinot to solve some of biggest challenges around Data Analytics in Large Retail Chain","authors":["pinotdev"],"body":{"raw":"\\nI may be kicking open doors here, but a simple question has always helped me start from somewhere. When it comes to investigating degraded user experience caused by latency, can I observe high resource usage on all or some nodes of the system?\\n\\n[Read more at https://medium.com/apache-pinot-developer-blog/monitoring-apache-pinot-99034050c1a5](https://medium.com/apache-pinot-developer-blog/monitoring-apache-pinot-99034050c1a5)\\n\\n![Monitoring Apache Pinot with JMX, Prometheus and Grafana](https://miro.medium.com/max/1400/1*5kWginewoWzzQHQoZdPAGQ.png)\\n","code":"var Component=(()=>{var g=Object.create;var i=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var d=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),x=(t,e)=>{for(var n in e)i(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let o of p(e))!u.call(t,o)&&o!==n&&i(t,o,{get:()=>e[o],enumerable:!(r=l(e,o))||r.enumerable});return t};var y=(t,e,n)=>(n=t!=null?g(d(t)):{},s(e||!t||!t.__esModule?i(n,\\"default\\",{value:t,enumerable:!0}):n,t)),v=t=>s(i({},\\"__esModule\\",{value:!0}),t);var c=f((A,m)=>{m.exports=_jsx_runtime});var P={};x(P,{default:()=>w,frontmatter:()=>b});var a=y(c()),b={title:\\"Monitoring Apache Pinot with JMX, Prometheus and Grafana\\",date:new Date(15968448e5),authors:[\\"pinotdev\\"],summary:\\"Blog gives an overview of our use of Apache Pinot to solve some of biggest challenges around Data Analytics in Large Retail Chain\\",tags:[\\"Pinot\\",\\"Monitoring\\",\\"JMX\\",\\"Prometheus\\",\\"Grafana\\",\\"DevBlog\\",\\"ThirdEye\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function h(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.p,{children:\\"I may be kicking open doors here, but a simple question has always helped me start from somewhere. When it comes to investigating degraded user experience caused by latency, can I observe high resource usage on all or some nodes of the system?\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/monitoring-apache-pinot-99034050c1a5\\",children:\\"Read more at https://medium.com/apache-pinot-developer-blog/monitoring-apache-pinot-99034050c1a5\\"})}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Monitoring Apache Pinot with JMX, Prometheus and Grafana\\",src:\\"https://miro.medium.com/max/1400/1*5kWginewoWzzQHQoZdPAGQ.png\\"})})]})}function M(t={}){let{wrapper:e}=t.components||{};return e?(0,a.jsx)(e,Object.assign({},t,{children:(0,a.jsx)(h,t)})):h(t)}var w=M;return v(P);})();\\n;return Component;"},"_id":"blog/2020-08-08-DevBlog-PinotMonitoring.mdx","_raw":{"sourceFilePath":"blog/2020-08-08-DevBlog-PinotMonitoring.mdx","sourceFileName":"2020-08-08-DevBlog-PinotMonitoring.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-08-08-DevBlog-PinotMonitoring"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.275,"time":16500,"words":55},"slug":"2020/08/08/DevBlog-PinotMonitoring","customSlug":"2020/08/08/DevBlog-PinotMonitoring","path":"blog/2020/08/08/DevBlog-PinotMonitoring","customPath":"blog/2020/08/08/DevBlog-PinotMonitoring","filePath":"blog/2020-08-08-DevBlog-PinotMonitoring.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Monitoring Apache Pinot with JMX, Prometheus and Grafana","datePublished":"2020-08-08T00:00:00.000Z","dateModified":"2020-08-08T00:00:00.000Z","description":"Blog gives an overview of our use of Apache Pinot to solve some of biggest challenges around Data Analytics in Large Retail Chain","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-08-08-DevBlog-PinotMonitoring"}},{"title":"Achieving 99th percentile latency SLA using Apache Pinot","date":"2020-08-08T00:00:00.000Z","tags":["Pinot","SLA","DevBlog","ThirdEye","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"How users can build critical site-facing analytical applications requiring high throughput and strict p99th query latency SLA","authors":["pinotdev"],"body":{"raw":"\\nIn this article, we talk about how users can build critical site-facing analytical applications requiring high throughput and strict p99th query latency SLA using Apache Pinot.\\n\\n[Read more at https://medium.com/apache-pinot-developer-blog/achieving-99th-percentile-latency-sla-using-apache-pinot-2ba4ce1d9eff](https://medium.com/apache-pinot-developer-blog/achieving-99th-percentile-latency-sla-using-apache-pinot-2ba4ce1d9eff)\\n\\n![Achieving 99th percentile latency SLA using Apache Pinot](https://miro.medium.com/max/1140/0*VCPyrmNB2PteCmnC)\\n","code":"var Component=(()=>{var p=Object.create;var c=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,d=Object.prototype.hasOwnProperty;var y=(e,t)=>()=>(t||e((t={exports:{}}).exports,t),t.exports),f=(e,t)=>{for(var n in t)c(e,n,{get:t[n],enumerable:!0})},s=(e,t,n,r)=>{if(t&&typeof t==\\"object\\"||typeof t==\\"function\\")for(let a of u(t))!d.call(e,a)&&a!==n&&c(e,a,{get:()=>t[a],enumerable:!(r=m(t,a))||r.enumerable});return e};var A=(e,t,n)=>(n=e!=null?p(g(e)):{},s(t||!e||!e.__esModule?c(n,\\"default\\",{value:e,enumerable:!0}):n,e)),x=e=>s(c({},\\"__esModule\\",{value:!0}),e);var l=y((P,o)=>{o.exports=_jsx_runtime});var _={};f(_,{default:()=>j,frontmatter:()=>b});var i=A(l()),b={title:\\"Achieving 99th percentile latency SLA using Apache Pinot\\",date:new Date(15968448e5),authors:[\\"pinotdev\\"],summary:\\"How users can build critical site-facing analytical applications requiring high throughput and strict p99th query latency SLA\\",tags:[\\"Pinot\\",\\"SLA\\",\\"DevBlog\\",\\"ThirdEye\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function h(e){let t=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},e.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.p,{children:\\"In this article, we talk about how users can build critical site-facing analytical applications requiring high throughput and strict p99th query latency SLA using Apache Pinot.\\"}),(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:\\"https://medium.com/apache-pinot-developer-blog/achieving-99th-percentile-latency-sla-using-apache-pinot-2ba4ce1d9eff\\",children:\\"Read more at https://medium.com/apache-pinot-developer-blog/achieving-99th-percentile-latency-sla-using-apache-pinot-2ba4ce1d9eff\\"})}),(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:\\"Achieving 99th percentile latency SLA using Apache Pinot\\",src:\\"https://miro.medium.com/max/1140/0*VCPyrmNB2PteCmnC\\"})})]})}function v(e={}){let{wrapper:t}=e.components||{};return t?(0,i.jsx)(t,Object.assign({},e,{children:(0,i.jsx)(h,e)})):h(e)}var j=v;return x(_);})();\\n;return Component;"},"_id":"blog/2020-08-08-DevBlog-SLAApps.mdx","_raw":{"sourceFilePath":"blog/2020-08-08-DevBlog-SLAApps.mdx","sourceFileName":"2020-08-08-DevBlog-SLAApps.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-08-08-DevBlog-SLAApps"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.19,"time":11400,"words":38},"slug":"2020/08/08/DevBlog-SLAApps","customSlug":"2020/08/08/DevBlog-SLAApps","path":"blog/2020/08/08/DevBlog-SLAApps","customPath":"blog/2020/08/08/DevBlog-SLAApps","filePath":"blog/2020-08-08-DevBlog-SLAApps.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Achieving 99th percentile latency SLA using Apache Pinot","datePublished":"2020-08-08T00:00:00.000Z","dateModified":"2020-08-08T00:00:00.000Z","description":"How users can build critical site-facing analytical applications requiring high throughput and strict p99th query latency SLA","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-08-08-DevBlog-SLAApps"}},{"title":"Utilize UDFs to Supercharge Queries in Apache Pinot","date":"2020-08-08T00:00:00.000Z","tags":["Pinot","SLA","DevBlog","ThirdEye","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Scalar Functions that allow users to write and add their functions as a plugin.","authors":["pinotdev"],"body":{"raw":"\\nApache Pinot is a realtime distributed OLAP datastore that can answer hundreds of thousands of queries with millisecond latencies. You can head over to https://pinot.apache.org/ to get started with Apache Pinot.\\n\\nWhile using any database, we can come across a scenario where a function required for the query is not supported out of the box. In such time, we have to resort to raising a pull request for a new function or finding a tedious workaround.\\n\\nScalar Functions that allow users to write and add their functions as a plugin.\\n\\n[Read more at https://medium.com/apache-pinot-developer-blog/utilize-udfs-to-supercharge-queries-in-apache-pinot-e488a0f164f1](https://medium.com/apache-pinot-developer-blog/utilize-udfs-to-supercharge-queries-in-apache-pinot-e488a0f164f1)\\n\\n![Utilize UDFs to Supercharge Queries in Apache Pinot](https://miro.medium.com/max/10368/0*VtswFI-HcaXyyjhK)\\n","code":"var Component=(()=>{var d=Object.create;var o=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var l=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var g=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var i in e)o(t,i,{get:e[i],enumerable:!0})},s=(t,e,i,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let n of l(e))!f.call(t,n)&&n!==i&&o(t,n,{get:()=>e[n],enumerable:!(r=p(e,n))||r.enumerable});return t};var x=(t,e,i)=>(i=t!=null?d(m(t)):{},s(e||!t||!t.__esModule?o(i,\\"default\\",{value:t,enumerable:!0}):i,t)),y=t=>s(o({},\\"__esModule\\",{value:!0}),t);var h=g((q,c)=>{c.exports=_jsx_runtime});var b={};w(b,{default:()=>F,frontmatter:()=>j});var a=x(h()),j={title:\\"Utilize UDFs to Supercharge Queries in Apache Pinot\\",date:new Date(15968448e5),authors:[\\"pinotdev\\"],summary:\\"Scalar Functions that allow users to write and add their functions as a plugin.\\",tags:[\\"Pinot\\",\\"SLA\\",\\"DevBlog\\",\\"ThirdEye\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function u(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(e.p,{children:[\\"Apache Pinot is a realtime distributed OLAP datastore that can answer hundreds of thousands of queries with millisecond latencies. You can head over to \\",(0,a.jsx)(e.a,{href:\\"https://pinot.apache.org/\\",children:\\"https://pinot.apache.org/\\"}),\\" to get started with Apache Pinot.\\"]}),(0,a.jsx)(e.p,{children:\\"While using any database, we can come across a scenario where a function required for the query is not supported out of the box. In such time, we have to resort to raising a pull request for a new function or finding a tedious workaround.\\"}),(0,a.jsx)(e.p,{children:\\"Scalar Functions that allow users to write and add their functions as a plugin.\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/utilize-udfs-to-supercharge-queries-in-apache-pinot-e488a0f164f1\\",children:\\"Read more at https://medium.com/apache-pinot-developer-blog/utilize-udfs-to-supercharge-queries-in-apache-pinot-e488a0f164f1\\"})}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Utilize UDFs to Supercharge Queries in Apache Pinot\\",src:\\"https://miro.medium.com/max/10368/0*VtswFI-HcaXyyjhK\\"})})]})}function A(t={}){let{wrapper:e}=t.components||{};return e?(0,a.jsx)(e,Object.assign({},t,{children:(0,a.jsx)(u,t)})):u(t)}var F=A;return y(b);})();\\n;return Component;"},"_id":"blog/2020-08-08-DevBlog-ScalarUDFs.mdx","_raw":{"sourceFilePath":"blog/2020-08-08-DevBlog-ScalarUDFs.mdx","sourceFileName":"2020-08-08-DevBlog-ScalarUDFs.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-08-08-DevBlog-ScalarUDFs"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.51,"time":30600,"words":102},"slug":"2020/08/08/DevBlog-ScalarUDFs","customSlug":"2020/08/08/DevBlog-ScalarUDFs","path":"blog/2020/08/08/DevBlog-ScalarUDFs","customPath":"blog/2020/08/08/DevBlog-ScalarUDFs","filePath":"blog/2020-08-08-DevBlog-ScalarUDFs.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Utilize UDFs to Supercharge Queries in Apache Pinot","datePublished":"2020-08-08T00:00:00.000Z","dateModified":"2020-08-08T00:00:00.000Z","description":"Scalar Functions that allow users to write and add their functions as a plugin.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-08-08-DevBlog-ScalarUDFs"}},{"title":"Deep Analysis of Russian Twitter Trolls","date":"2020-10-16T00:00:00.000Z","tags":["Pinot","DevBlog","ThirdEye","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Show you how to use Apache Pinot and Superset to analyze 3 million tweets by the Internet Research Agency (IRA) open-sourced by FiveThirtyEight.","authors":["bastani"],"body":{"raw":"\\nThe history behind Russian disinformation is a dense and continuously evolving subject. The world’s best research hasn’t seemed to hit the mainstream yet, which made this an excellent opportunity to see if I could use some open source tooling to surface new analytical evidence.\\n\\nIn this blog post, I’ll show you how to use Apache Pinot and Superset to analyze 3 million tweets by the Internet Research Agency (IRA) open-sourced by FiveThirtyEight.\\n\\n[Read More at https://towardsdatascience.com/a-deep-analysis-of-russian-trolls-with-apache-pinot-and-superset-590c8c4d1843](https://towardsdatascience.com/a-deep-analysis-of-russian-trolls-with-apache-pinot-and-superset-590c8c4d1843)\\n\\n![Deep Analysis of Russian Twitter Trolls](https://miro.medium.com/max/4320/0*iqUTy0GkLFTcSYlR.png)\\n","code":"var Component=(()=>{var d=Object.create;var o=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,y=Object.prototype.hasOwnProperty;var g=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},r=(t,e,n,i)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of u(e))!y.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(i=p(e,a))||i.enumerable});return t};var f=(t,e,n)=>(n=t!=null?d(m(t)):{},r(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),b=t=>r(o({},\\"__esModule\\",{value:!0}),t);var l=g((I,c)=>{c.exports=_jsx_runtime});var R={};w(R,{default:()=>A,frontmatter:()=>x});var s=f(l()),x={title:\\"Deep Analysis of Russian Twitter Trolls\\",date:new Date(16028064e5),authors:[\\"bastani\\"],summary:\\"Show you how to use Apache Pinot and Superset to analyze 3 million tweets by the Internet Research Agency (IRA) open-sourced by FiveThirtyEight.\\",tags:[\\"Pinot\\",\\"DevBlog\\",\\"ThirdEye\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function h(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.p,{children:\\"The history behind Russian disinformation is a dense and continuously evolving subject. The world\\\\u2019s best research hasn\\\\u2019t seemed to hit the mainstream yet, which made this an excellent opportunity to see if I could use some open source tooling to surface new analytical evidence.\\"}),(0,s.jsx)(e.p,{children:\\"In this blog post, I\\\\u2019ll show you how to use Apache Pinot and Superset to analyze 3 million tweets by the Internet Research Agency (IRA) open-sourced by FiveThirtyEight.\\"}),(0,s.jsx)(e.p,{children:(0,s.jsx)(e.a,{href:\\"https://towardsdatascience.com/a-deep-analysis-of-russian-trolls-with-apache-pinot-and-superset-590c8c4d1843\\",children:\\"Read More at https://towardsdatascience.com/a-deep-analysis-of-russian-trolls-with-apache-pinot-and-superset-590c8c4d1843\\"})}),(0,s.jsx)(e.p,{children:(0,s.jsx)(e.img,{alt:\\"Deep Analysis of Russian Twitter Trolls\\",src:\\"https://miro.medium.com/max/4320/0*iqUTy0GkLFTcSYlR.png\\"})})]})}function T(t={}){let{wrapper:e}=t.components||{};return e?(0,s.jsx)(e,Object.assign({},t,{children:(0,s.jsx)(h,t)})):h(t)}var A=T;return b(R);})();\\n;return Component;"},"_id":"blog/2020-10-16-DevBlog-TwitterTrollAnalysis.mdx","_raw":{"sourceFilePath":"blog/2020-10-16-DevBlog-TwitterTrollAnalysis.mdx","sourceFileName":"2020-10-16-DevBlog-TwitterTrollAnalysis.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-10-16-DevBlog-TwitterTrollAnalysis"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.41,"time":24600,"words":82},"slug":"2020/10/16/DevBlog-TwitterTrollAnalysis","customSlug":"2020/10/16/DevBlog-TwitterTrollAnalysis","path":"blog/2020/10/16/DevBlog-TwitterTrollAnalysis","customPath":"blog/2020/10/16/DevBlog-TwitterTrollAnalysis","filePath":"blog/2020-10-16-DevBlog-TwitterTrollAnalysis.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Deep Analysis of Russian Twitter Trolls","datePublished":"2020-10-16T00:00:00.000Z","dateModified":"2020-10-16T00:00:00.000Z","description":"Show you how to use Apache Pinot and Superset to analyze 3 million tweets by the Internet Research Agency (IRA) open-sourced by FiveThirtyEight.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-10-16-DevBlog-TwitterTrollAnalysis"}},{"title":"Operating Apache Pinot at Uber Scale","date":"2020-10-20T00:00:00.000Z","tags":["Pinot","Uber","real-time data platform","Realtime","Analytics","User-Facing Analytics","financial intelligence"],"summary":"Present details of this platform and how it fits in Uber’s ecosystem. Explain how uber scaled from a few use cases to a multi-cluster powering hundreds of use cases for querying terabyte-scale data with millisecond latencies.","authors":["uber"],"body":{"raw":"\\nUber has a complex marketplace consisting of riders, drivers, eaters, restaurants and so on. Operating that marketplace at a global scale requires real-time intelligence and decision making. For instance, identifying delayed Uber Eats orders or abandoned carts helps to enable our community operations team to take corrective action. Having a real-time dashboard of different events such as consumer demand, driver availability, or trips happening in a city is crucial for day-to-day operation, incident triaging, and financial intelligence.\\n\\nRead More at https://eng.uber.com/operating-apache-pinot/\\n\\n![Operating Apache Pinot at Uber Scale](https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/1224-5.png)\\n","code":"var Component=(()=>{var p=Object.create;var r=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),b=(t,e)=>{for(var n in e)r(t,n,{get:e[n],enumerable:!0})},o=(t,e,n,s)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let i of g(e))!h.call(t,i)&&i!==n&&r(t,i,{get:()=>e[i],enumerable:!(s=m(e,i))||s.enumerable});return t};var y=(t,e,n)=>(n=t!=null?p(u(t)):{},o(e||!t||!t.__esModule?r(n,\\"default\\",{value:t,enumerable:!0}):n,t)),x=t=>o(r({},\\"__esModule\\",{value:!0}),t);var l=f((v,c)=>{c.exports=_jsx_runtime});var _={};b(_,{default:()=>U,frontmatter:()=>w});var a=y(l()),w={title:\\"Operating Apache Pinot at Uber Scale\\",date:new Date(1603152e6),authors:[\\"uber\\"],summary:\\"Present details of this platform and how it fits in Uber\\\\u2019s ecosystem. Explain how uber scaled from a few use cases to a multi-cluster powering hundreds of use cases for querying terabyte-scale data with millisecond latencies.\\",tags:[\\"Pinot\\",\\"Uber\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"financial intelligence\\"]};function d(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.p,{children:\\"Uber has a complex marketplace consisting of riders, drivers, eaters, restaurants and so on. Operating that marketplace at a global scale requires real-time intelligence and decision making. For instance, identifying delayed Uber Eats orders or abandoned carts helps to enable our community operations team to take corrective action. Having a real-time dashboard of different events such as consumer demand, driver availability, or trips happening in a city is crucial for day-to-day operation, incident triaging, and financial intelligence.\\"}),(0,a.jsxs)(e.p,{children:[\\"Read More at \\",(0,a.jsx)(e.a,{href:\\"https://eng.uber.com/operating-apache-pinot/\\",children:\\"https://eng.uber.com/operating-apache-pinot/\\"})]}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Operating Apache Pinot at Uber Scale\\",src:\\"https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/1224-5.png\\"})})]})}function j(t={}){let{wrapper:e}=t.components||{};return e?(0,a.jsx)(e,Object.assign({},t,{children:(0,a.jsx)(d,t)})):d(t)}var U=j;return x(_);})();\\n;return Component;"},"_id":"blog/2020-10-20-Uber-Operating.mdx","_raw":{"sourceFilePath":"blog/2020-10-20-Uber-Operating.mdx","sourceFileName":"2020-10-20-Uber-Operating.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-10-20-Uber-Operating"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.435,"time":26100,"words":87},"slug":"2020/10/20/Uber-Operating","customSlug":"2020/10/20/Uber-Operating","path":"blog/2020/10/20/Uber-Operating","customPath":"blog/2020/10/20/Uber-Operating","filePath":"blog/2020-10-20-Uber-Operating.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Operating Apache Pinot at Uber Scale","datePublished":"2020-10-20T00:00:00.000Z","dateModified":"2020-10-20T00:00:00.000Z","description":"Present details of this platform and how it fits in Uber’s ecosystem. Explain how uber scaled from a few use cases to a multi-cluster powering hundreds of use cases for querying terabyte-scale data with millisecond latencies.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-10-20-Uber-Operating"}},{"title":"From Lambda to Lambda-less Lessons learned","date":"2020-12-01T00:00:00.000Z","tags":["Pinot","LinkedIn","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"The Lambda architecture has become a popular architectural style that promises both speed and accuracy in data processing by using a hybrid approach of both batch processing and stream processing methods.","authors":["linkedin"],"body":{"raw":"\\nThe Lambda architecture has become a popular architectural style that promises both speed and accuracy in data processing by using a hybrid approach of both batch processing and stream processing methods.\\n\\nRead More at https://engineering.linkedin.com/blog/2020/lambda-to-lambda-less-architecture\\n\\n![From Lambda to Lambda-less Lessons learned](https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2019/03/pinotincubator2.png)\\n","code":"var Component=(()=>{var l=Object.create;var r=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var b=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var u=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),y=(a,e)=>{for(var n in e)r(a,n,{get:e[n],enumerable:!0})},i=(a,e,n,o)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let s of p(e))!g.call(a,s)&&s!==n&&r(a,s,{get:()=>e[s],enumerable:!(o=h(e,s))||o.enumerable});return a};var L=(a,e,n)=>(n=a!=null?l(b(a)):{},i(e||!a||!a.__esModule?r(n,\\"default\\",{value:a,enumerable:!0}):n,a)),f=a=>i(r({},\\"__esModule\\",{value:!0}),a);var m=u((M,c)=>{c.exports=_jsx_runtime});var k={};y(k,{default:()=>_,frontmatter:()=>x});var t=L(m()),x={title:\\"From Lambda to Lambda-less Lessons learned\\",date:new Date(16067808e5),authors:[\\"linkedin\\"],summary:\\"The Lambda architecture has become a popular architectural style that promises both speed and accuracy in data processing by using a hybrid approach of both batch processing and stream processing methods.\\",tags:[\\"Pinot\\",\\"LinkedIn\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function d(a){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},a.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.p,{children:\\"The Lambda architecture has become a popular architectural style that promises both speed and accuracy in data processing by using a hybrid approach of both batch processing and stream processing methods.\\"}),(0,t.jsxs)(e.p,{children:[\\"Read More at \\",(0,t.jsx)(e.a,{href:\\"https://engineering.linkedin.com/blog/2020/lambda-to-lambda-less-architecture\\",children:\\"https://engineering.linkedin.com/blog/2020/lambda-to-lambda-less-architecture\\"})]}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"From Lambda to Lambda-less Lessons learned\\",src:\\"https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2019/03/pinotincubator2.png\\"})})]})}function j(a={}){let{wrapper:e}=a.components||{};return e?(0,t.jsx)(e,Object.assign({},a,{children:(0,t.jsx)(d,a)})):d(a)}var _=j;return f(k);})();\\n;return Component;"},"_id":"blog/2020-12-01-LinkedIn-Lamda.mdx","_raw":{"sourceFilePath":"blog/2020-12-01-LinkedIn-Lamda.mdx","sourceFileName":"2020-12-01-LinkedIn-Lamda.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2020-12-01-LinkedIn-Lamda"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.205,"time":12300,"words":41},"slug":"2020/12/01/LinkedIn-Lamda","customSlug":"2020/12/01/LinkedIn-Lamda","path":"blog/2020/12/01/LinkedIn-Lamda","customPath":"blog/2020/12/01/LinkedIn-Lamda","filePath":"blog/2020-12-01-LinkedIn-Lamda.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"From Lambda to Lambda-less Lessons learned","datePublished":"2020-12-01T00:00:00.000Z","dateModified":"2020-12-01T00:00:00.000Z","description":"The Lambda architecture has become a popular architectural style that promises both speed and accuracy in data processing by using a hybrid approach of both batch processing and stream processing methods.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2020-12-01-LinkedIn-Lamda"}},{"title":"Change Data Analysis with Debezium and Apache Pinot","date":"2021-01-08T00:00:00.000Z","tags":["Pinot","DevBlog","Debezium","CDC","Change Data Analysis","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Pinot enters into a storied legacy of innovations that have emerged from one of the world’s largest online social networks. Over a few decades, the Silicon Valley tech giant has helped hundreds of millions of people around the world navigate their careers.","authors":["bastani"],"body":{"raw":"\\nIn this blog post, we’re going to explore an exciting new world of real-time analytics based on combining the popular CDC tool, Debezium, with the real-time OLAP datastore, Apache Pinot.\\n\\n[Read More at https://medium.com/apache-pinot-developer-blog/change-data-analysis-with-debezium-and-apache-pinot-b4093dc178a7](https://medium.com/apache-pinot-developer-blog/change-data-analysis-with-debezium-and-apache-pinot-b4093dc178a7)\\n\\n![Change Data Analysis with Debezium and Apache Pinot](https://miro.medium.com/max/1400/1*dnSikeGxTrfrF95niX16PA.png)\\n","code":"var Component=(()=>{var d=Object.create;var o=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var b=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),f=(a,e)=>{for(var n in e)o(a,n,{get:e[n],enumerable:!0})},r=(a,e,n,s)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let i of p(e))!u.call(a,i)&&i!==n&&o(a,i,{get:()=>e[i],enumerable:!(s=m(e,i))||s.enumerable});return a};var w=(a,e,n)=>(n=a!=null?d(g(a)):{},r(e||!a||!a.__esModule?o(n,\\"default\\",{value:a,enumerable:!0}):n,a)),x=a=>r(o({},\\"__esModule\\",{value:!0}),a);var c=b((v,l)=>{l.exports=_jsx_runtime});var C={};f(C,{default:()=>A,frontmatter:()=>D});var t=w(c()),D={title:\\"Change Data Analysis with Debezium and Apache Pinot\\",date:new Date(1610064e6),authors:[\\"bastani\\"],summary:\\"Pinot enters into a storied legacy of innovations that have emerged from one of the world\\\\u2019s largest online social networks. Over a few decades, the Silicon Valley tech giant has helped hundreds of millions of people around the world navigate their careers.\\",tags:[\\"Pinot\\",\\"DevBlog\\",\\"Debezium\\",\\"CDC\\",\\"Change Data Analysis\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function h(a){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},a.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.p,{children:\\"In this blog post, we\\\\u2019re going to explore an exciting new world of real-time analytics based on combining the popular CDC tool, Debezium, with the real-time OLAP datastore, Apache Pinot.\\"}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/change-data-analysis-with-debezium-and-apache-pinot-b4093dc178a7\\",children:\\"Read More at https://medium.com/apache-pinot-developer-blog/change-data-analysis-with-debezium-and-apache-pinot-b4093dc178a7\\"})}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"Change Data Analysis with Debezium and Apache Pinot\\",src:\\"https://miro.medium.com/max/1400/1*dnSikeGxTrfrF95niX16PA.png\\"})})]})}function y(a={}){let{wrapper:e}=a.components||{};return e?(0,t.jsx)(e,Object.assign({},a,{children:(0,t.jsx)(h,a)})):h(a)}var A=y;return x(C);})();\\n;return Component;"},"_id":"blog/2021-01-08-DevBlog-DebeziumCDC.mdx","_raw":{"sourceFilePath":"blog/2021-01-08-DevBlog-DebeziumCDC.mdx","sourceFileName":"2021-01-08-DevBlog-DebeziumCDC.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2021-01-08-DevBlog-DebeziumCDC"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.21,"time":12600,"words":42},"slug":"2021/01/08/DevBlog-DebeziumCDC","customSlug":"2021/01/08/DevBlog-DebeziumCDC","path":"blog/2021/01/08/DevBlog-DebeziumCDC","customPath":"blog/2021/01/08/DevBlog-DebeziumCDC","filePath":"blog/2021-01-08-DevBlog-DebeziumCDC.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Change Data Analysis with Debezium and Apache Pinot","datePublished":"2021-01-08T00:00:00.000Z","dateModified":"2021-01-08T00:00:00.000Z","description":"Pinot enters into a storied legacy of innovations that have emerged from one of the world’s largest online social networks. Over a few decades, the Silicon Valley tech giant has helped hundreds of millions of people around the world navigate their careers.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2021-01-08-DevBlog-DebeziumCDC"}},{"title":"Real-time Analytics with Presto and Apache Pinot","date":"2021-02-02T00:00:00.000Z","tags":["Pinot","Presto","Trino","PrestoSQL","DevBlog","ThirdEye","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Blog gives an overview of our use of Apache Pinot to solve some of biggest challenges around Data Analytics in Large Retail Chain","authors":["pinotdev"],"body":{"raw":"\\nIn this world, most analytics products either focus on ad-hoc analytics, which requires query flexibility without guaranteed latency, or low latency analytics with limited query capability. In this blog, we will explore how to get the best of both worlds using Apache Pinot and Presto.\\n\\n[Read Part 1 at https://www.startree.ai/blogs/real-time-analytics-with-presto-and-apache-pinot-part-i/](https://www.startree.ai/blogs/real-time-analytics-with-presto-and-apache-pinot-part-i/)\\n\\n[Read Part 2 at https://www.startree.ai/blogs/real-time-analytics-with-presto-and-apache-pinot-part-ii/](https://www.startree.ai/blogs/real-time-analytics-with-presto-and-apache-pinot-part-ii/)\\n\\n![Real-time Analytics with Presto and Apache Pinot](https://miro.medium.com/max/1400/0*hJc6aV9aBJaKyXcx)\\n","code":"var Component=(()=>{var p=Object.create;var r=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var w=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var y=(e,t)=>()=>(t||e((t={exports:{}}).exports,t),t.exports),u=(e,t)=>{for(var i in t)r(e,i,{get:t[i],enumerable:!0})},s=(e,t,i,o)=>{if(t&&typeof t==\\"object\\"||typeof t==\\"function\\")for(let n of m(t))!g.call(e,n)&&n!==i&&r(e,n,{get:()=>t[n],enumerable:!(o=d(t,n))||o.enumerable});return e};var f=(e,t,i)=>(i=e!=null?p(w(e)):{},s(t||!e||!e.__esModule?r(i,\\"default\\",{value:e,enumerable:!0}):i,e)),x=e=>s(r({},\\"__esModule\\",{value:!0}),e);var c=y((v,l)=>{l.exports=_jsx_runtime});var j={};u(j,{default:()=>A,frontmatter:()=>b});var a=f(c()),b={title:\\"Real-time Analytics with Presto and Apache Pinot\\",date:new Date(1612224e6),authors:[\\"pinotdev\\"],summary:\\"Blog gives an overview of our use of Apache Pinot to solve some of biggest challenges around Data Analytics in Large Retail Chain\\",tags:[\\"Pinot\\",\\"Presto\\",\\"Trino\\",\\"PrestoSQL\\",\\"DevBlog\\",\\"ThirdEye\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function h(e){let t=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},e.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.p,{children:\\"In this world, most analytics products either focus on ad-hoc analytics, which requires query flexibility without guaranteed latency, or low latency analytics with limited query capability. In this blog, we will explore how to get the best of both worlds using Apache Pinot and Presto.\\"}),(0,a.jsx)(t.p,{children:(0,a.jsx)(t.a,{href:\\"https://www.startree.ai/blogs/real-time-analytics-with-presto-and-apache-pinot-part-i/\\",children:\\"Read Part 1 at https://www.startree.ai/blogs/real-time-analytics-with-presto-and-apache-pinot-part-i/\\"})}),(0,a.jsx)(t.p,{children:(0,a.jsx)(t.a,{href:\\"https://www.startree.ai/blogs/real-time-analytics-with-presto-and-apache-pinot-part-ii/\\",children:\\"Read Part 2 at https://www.startree.ai/blogs/real-time-analytics-with-presto-and-apache-pinot-part-ii/\\"})}),(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:\\"Real-time Analytics with Presto and Apache Pinot\\",src:\\"https://miro.medium.com/max/1400/0*hJc6aV9aBJaKyXcx\\"})})]})}function P(e={}){let{wrapper:t}=e.components||{};return t?(0,a.jsx)(t,Object.assign({},e,{children:(0,a.jsx)(h,e)})):h(e)}var A=P;return x(j);})();\\n;return Component;"},"_id":"blog/2021-02-02-DevBlog-PrestoPinot.mdx","_raw":{"sourceFilePath":"blog/2021-02-02-DevBlog-PrestoPinot.mdx","sourceFileName":"2021-02-02-DevBlog-PrestoPinot.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2021-02-02-DevBlog-PrestoPinot"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.31,"time":18600,"words":62},"slug":"2021/02/02/DevBlog-PrestoPinot","customSlug":"2021/02/02/DevBlog-PrestoPinot","path":"blog/2021/02/02/DevBlog-PrestoPinot","customPath":"blog/2021/02/02/DevBlog-PrestoPinot","filePath":"blog/2021-02-02-DevBlog-PrestoPinot.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Real-time Analytics with Presto and Apache Pinot","datePublished":"2021-02-02T00:00:00.000Z","dateModified":"2021-02-02T00:00:00.000Z","description":"Blog gives an overview of our use of Apache Pinot to solve some of biggest challenges around Data Analytics in Large Retail Chain","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2021-02-02-DevBlog-PrestoPinot"}},{"title":"Introduction to Upserts in Apache Pinot","date":"2021-04-08T00:00:00.000Z","tags":["Pinot","DevBlog","Upsert","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Introduction to Pinot Upsert and explain why it’s exciting and how you can start using it.","authors":["bastani"],"body":{"raw":"\\nSince the 0.6.0 release of Apache Pinot, a new feature was made available for stream ingestion that allows you to upsert events from an immutable log. Typically, upsert is a term used to describe inserting a record into a database if it does not already exist or update it if it does exist. In Apache Pinot’s case, upsert isn’t precisely the same concept, and I wanted to write this blog post to explain why it’s exciting and how you can start using it.\\n\\nRead More at https://medium.com/apache-pinot-developer-blog/introduction-to-upserts-in-apache-pinot-987c12149d93\\n\\n![Introduction to Upserts in Apache Pinot](https://miro.medium.com/max/1400/0*So3GjHjLY7DJAiaP)\\n","code":"var Component=(()=>{var m=Object.create;var o=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var h=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var x=(e,t)=>()=>(t||e((t={exports:{}}).exports,t),t.exports),f=(e,t)=>{for(var a in t)o(e,a,{get:t[a],enumerable:!0})},r=(e,t,a,s)=>{if(t&&typeof t==\\"object\\"||typeof t==\\"function\\")for(let i of u(t))!g.call(e,i)&&i!==a&&o(e,i,{get:()=>t[i],enumerable:!(s=l(t,i))||s.enumerable});return e};var y=(e,t,a)=>(a=e!=null?m(h(e)):{},r(t||!e||!e.__esModule?o(a,\\"default\\",{value:e,enumerable:!0}):a,e)),w=e=>r(o({},\\"__esModule\\",{value:!0}),e);var p=x((v,c)=>{c.exports=_jsx_runtime});var P={};f(P,{default:()=>A,frontmatter:()=>b});var n=y(p()),b={title:\\"Introduction to Upserts in Apache Pinot\\",date:new Date(161784e7),authors:[\\"bastani\\"],summary:\\"Introduction to Pinot Upsert and explain why it\\\\u2019s exciting and how you can start using it.\\",tags:[\\"Pinot\\",\\"DevBlog\\",\\"Upsert\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function d(e){let t=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},e.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.p,{children:\\"Since the 0.6.0 release of Apache Pinot, a new feature was made available for stream ingestion that allows you to upsert events from an immutable log. Typically, upsert is a term used to describe inserting a record into a database if it does not already exist or update it if it does exist. In Apache Pinot\\\\u2019s case, upsert isn\\\\u2019t precisely the same concept, and I wanted to write this blog post to explain why it\\\\u2019s exciting and how you can start using it.\\"}),(0,n.jsxs)(t.p,{children:[\\"Read More at \\",(0,n.jsx)(t.a,{href:\\"https://medium.com/apache-pinot-developer-blog/introduction-to-upserts-in-apache-pinot-987c12149d93\\",children:\\"https://medium.com/apache-pinot-developer-blog/introduction-to-upserts-in-apache-pinot-987c12149d93\\"})]}),(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:\\"Introduction to Upserts in Apache Pinot\\",src:\\"https://miro.medium.com/max/1400/0*So3GjHjLY7DJAiaP\\"})})]})}function j(e={}){let{wrapper:t}=e.components||{};return t?(0,n.jsx)(t,Object.assign({},e,{children:(0,n.jsx)(d,e)})):d(e)}var A=j;return w(P);})();\\n;return Component;"},"_id":"blog/2021-04-08-DevBlog-UpsertsIntro.mdx","_raw":{"sourceFilePath":"blog/2021-04-08-DevBlog-UpsertsIntro.mdx","sourceFileName":"2021-04-08-DevBlog-UpsertsIntro.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2021-04-08-DevBlog-UpsertsIntro"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.465,"time":27900,"words":93},"slug":"2021/04/08/DevBlog-UpsertsIntro","customSlug":"2021/04/08/DevBlog-UpsertsIntro","path":"blog/2021/04/08/DevBlog-UpsertsIntro","customPath":"blog/2021/04/08/DevBlog-UpsertsIntro","filePath":"blog/2021-04-08-DevBlog-UpsertsIntro.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Introduction to Upserts in Apache Pinot","datePublished":"2021-04-08T00:00:00.000Z","dateModified":"2021-04-08T00:00:00.000Z","description":"Introduction to Pinot Upsert and explain why it’s exciting and how you can start using it.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2021-04-08-DevBlog-UpsertsIntro"}},{"title":"Solving for the cardinality of set intersection at scale with Pinot and Theta Sketches","date":"2021-04-16T00:00:00.000Z","tags":["Pinot","LinkedIn","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.","authors":["linkedin"],"body":{"raw":"\\nThe Lambda architecture has become a popular architectural style that promises both speed and accuracy in data processing by using a hybrid approach of both batch processing and stream processing methods.\\n\\nRead More at https://engineering.linkedin.com/blog/2021/pinot-and-theta-sketches\\n\\n![From Lambda to Lambda-less Lessons learned](https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2021/04/thetasketches2.png)\\n","code":"var Component=(()=>{var l=Object.create;var s=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var p=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),b=(t,e)=>{for(var a in e)s(t,a,{get:e[a],enumerable:!0})},r=(t,e,a,o)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let i of g(e))!u.call(t,i)&&i!==a&&s(t,i,{get:()=>e[i],enumerable:!(o=m(e,i))||o.enumerable});return t};var y=(t,e,a)=>(a=t!=null?l(p(t)):{},r(e||!t||!t.__esModule?s(a,\\"default\\",{value:t,enumerable:!0}):a,t)),k=t=>r(s({},\\"__esModule\\",{value:!0}),t);var h=f((F,c)=>{c.exports=_jsx_runtime});var _={};b(_,{default:()=>w,frontmatter:()=>x});var n=y(h()),x={title:\\"Solving for the cardinality of set intersection at scale with Pinot and Theta Sketches\\",date:new Date(16185312e5),authors:[\\"linkedin\\"],summary:\\"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.\\",tags:[\\"Pinot\\",\\"LinkedIn\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function d(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\\"The Lambda architecture has become a popular architectural style that promises both speed and accuracy in data processing by using a hybrid approach of both batch processing and stream processing methods.\\"}),(0,n.jsxs)(e.p,{children:[\\"Read More at \\",(0,n.jsx)(e.a,{href:\\"https://engineering.linkedin.com/blog/2021/pinot-and-theta-sketches\\",children:\\"https://engineering.linkedin.com/blog/2021/pinot-and-theta-sketches\\"})]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"From Lambda to Lambda-less Lessons learned\\",src:\\"https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2021/04/thetasketches2.png\\"})})]})}function j(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,Object.assign({},t,{children:(0,n.jsx)(d,t)})):d(t)}var w=j;return k(_);})();\\n;return Component;"},"_id":"blog/2021-04-16-LinkedIn-Theta.mdx","_raw":{"sourceFilePath":"blog/2021-04-16-LinkedIn-Theta.mdx","sourceFileName":"2021-04-16-LinkedIn-Theta.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2021-04-16-LinkedIn-Theta"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.205,"time":12300,"words":41},"slug":"2021/04/16/LinkedIn-Theta","customSlug":"2021/04/16/LinkedIn-Theta","path":"blog/2021/04/16/LinkedIn-Theta","customPath":"blog/2021/04/16/LinkedIn-Theta","filePath":"blog/2021-04-16-LinkedIn-Theta.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Solving for the cardinality of set intersection at scale with Pinot and Theta Sketches","datePublished":"2021-04-16T00:00:00.000Z","dateModified":"2021-04-16T00:00:00.000Z","description":"Focus on using large set intersection cardinality approximations with Apache Pinot and Theta Sketches, which allow us to efficiently figure out the unique size of a targeted audience when factoring in multiple criteria of an advertising campaign.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2021-04-16-LinkedIn-Theta"}},{"title":"Deploying Apache Pinot at a Large Retail Chain","date":"2021-04-27T00:00:00.000Z","tags":["Pinot","DevBlog","ThirdEye","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Blog gives an overview of our use of Apache Pinot to solve some of biggest challenges around Data Analytics in Large Retail Chain","authors":["pinotdev"],"body":{"raw":"\\nBlog gives an overview of our use of Apache Pinot to solve some of biggest challenges around Data Analytics in Large Retail Chain\\n\\n[Read More at https://medium.com/apache-pinot-developer-blog/deploying-apache-pinot-at-a-large-retail-chain-42aed2921a38](https://medium.com/apache-pinot-developer-blog/deploying-apache-pinot-at-a-large-retail-chain-42aed2921a38)\\n\\n![Deploying Apache Pinot at a Large Retail Chain](https://miro.medium.com/max/1400/1*EtqD0vTPEe569jybXCt69w.png)\\n","code":"var Component=(()=>{var p=Object.create;var i=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var h=Object.getOwnPropertyNames;var d=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var f=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),v=(a,e)=>{for(var n in e)i(a,n,{get:e[n],enumerable:!0})},s=(a,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let o of h(e))!u.call(a,o)&&o!==n&&i(a,o,{get:()=>e[o],enumerable:!(r=m(e,o))||r.enumerable});return a};var y=(a,e,n)=>(n=a!=null?p(d(a)):{},s(e||!a||!a.__esModule?i(n,\\"default\\",{value:a,enumerable:!0}):n,a)),x=a=>s(i({},\\"__esModule\\",{value:!0}),a);var c=f((_,l)=>{l.exports=_jsx_runtime});var b={};v(b,{default:()=>A,frontmatter:()=>D});var t=y(c()),D={title:\\"Deploying Apache Pinot at a Large Retail Chain\\",date:new Date(16194816e5),authors:[\\"pinotdev\\"],summary:\\"Blog gives an overview of our use of Apache Pinot to solve some of biggest challenges around Data Analytics in Large Retail Chain\\",tags:[\\"Pinot\\",\\"DevBlog\\",\\"ThirdEye\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function g(a){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},a.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.p,{children:\\"Blog gives an overview of our use of Apache Pinot to solve some of biggest challenges around Data Analytics in Large Retail Chain\\"}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/deploying-apache-pinot-at-a-large-retail-chain-42aed2921a38\\",children:\\"Read More at https://medium.com/apache-pinot-developer-blog/deploying-apache-pinot-at-a-large-retail-chain-42aed2921a38\\"})}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"Deploying Apache Pinot at a Large Retail Chain\\",src:\\"https://miro.medium.com/max/1400/1*EtqD0vTPEe569jybXCt69w.png\\"})})]})}function j(a={}){let{wrapper:e}=a.components||{};return e?(0,t.jsx)(e,Object.assign({},a,{children:(0,t.jsx)(g,a)})):g(a)}var A=j;return x(b);})();\\n;return Component;"},"_id":"blog/2021-04-27-DevBlog-PinotInRetailChain.mdx","_raw":{"sourceFilePath":"blog/2021-04-27-DevBlog-PinotInRetailChain.mdx","sourceFileName":"2021-04-27-DevBlog-PinotInRetailChain.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2021-04-27-DevBlog-PinotInRetailChain"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.175,"time":10500,"words":35},"slug":"2021/04/27/DevBlog-PinotInRetailChain","customSlug":"2021/04/27/DevBlog-PinotInRetailChain","path":"blog/2021/04/27/DevBlog-PinotInRetailChain","customPath":"blog/2021/04/27/DevBlog-PinotInRetailChain","filePath":"blog/2021-04-27-DevBlog-PinotInRetailChain.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Deploying Apache Pinot at a Large Retail Chain","datePublished":"2021-04-27T00:00:00.000Z","dateModified":"2021-04-27T00:00:00.000Z","description":"Blog gives an overview of our use of Apache Pinot to solve some of biggest challenges around Data Analytics in Large Retail Chain","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2021-04-27-DevBlog-PinotInRetailChain"}},{"title":"Automating Merchant Live Monitoring with Real-Time Analytics - Charon","date":"2021-04-29T00:00:00.000Z","tags":["Pinot","Uber","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Focus on Uber’s real-time data platform components to build a tool called Charon to reduce impact of poor marketplace reliability on the merchants.","authors":["uber"],"body":{"raw":"\\nAt Uber, live monitoring and automation of Ops is critical to preserve marketplace health, maintain reliability, and gain efficiency in markets. By the virtue of the word “live”, this monitoring needs to show what is happening now, with prompt access to fresh data, and the ability to recommend appropriate actions based on that data. Uber’s data platform provides the self-serve tools which empower the Ops teams to build their own live monitoring tools, and support their regional teams by building rich solutions.\\n\\nFor this project, the requirement was to provide merchant level monitoring and handle the edge cases which remain unaddressed by the sophisticated internal marketplace management tools. We used a variety of Uber’s real-time data platform components to build a tool called Charon to reduce impact of poor marketplace reliability on the merchants.\\n\\nRead More at https://eng.uber.com/charon/\\n\\n![Operating Apache Pinot at Uber Scale](https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2021/04/deliverDoor@3x-768x263.png)\\n","code":"var Component=(()=>{var h=Object.create;var r=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var d=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var b=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),f=(t,e)=>{for(var n in e)r(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,i)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let o of d(e))!g.call(t,o)&&o!==n&&r(t,o,{get:()=>e[o],enumerable:!(i=p(e,o))||i.enumerable});return t};var y=(t,e,n)=>(n=t!=null?h(u(t)):{},s(e||!t||!t.__esModule?r(n,\\"default\\",{value:t,enumerable:!0}):n,t)),w=t=>s(r({},\\"__esModule\\",{value:!0}),t);var l=b((_,c)=>{c.exports=_jsx_runtime});var k={};f(k,{default:()=>j,frontmatter:()=>v});var a=y(l()),v={title:\\"Automating Merchant Live Monitoring with Real-Time Analytics - Charon\\",date:new Date(16196544e5),authors:[\\"uber\\"],summary:\\"Focus on Uber\\\\u2019s real-time data platform components to build a tool called Charon to reduce impact of poor marketplace reliability on the merchants.\\",tags:[\\"Pinot\\",\\"Uber\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function m(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.p,{children:\\"At Uber, live monitoring and automation of Ops is critical to preserve marketplace health, maintain reliability, and gain efficiency in markets. By the virtue of the word \\\\u201Clive\\\\u201D, this monitoring needs to show what is happening now, with prompt access to fresh data, and the ability to recommend appropriate actions based on that data. Uber\\\\u2019s data platform provides the self-serve tools which empower the Ops teams to build their own live monitoring tools, and support their regional teams by building rich solutions.\\"}),(0,a.jsx)(e.p,{children:\\"For this project, the requirement was to provide merchant level monitoring and handle the edge cases which remain unaddressed by the sophisticated internal marketplace management tools. We used a variety of Uber\\\\u2019s real-time data platform components to build a tool called Charon to reduce impact of poor marketplace reliability on the merchants.\\"}),(0,a.jsxs)(e.p,{children:[\\"Read More at \\",(0,a.jsx)(e.a,{href:\\"https://eng.uber.com/charon/\\",children:\\"https://eng.uber.com/charon/\\"})]}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Operating Apache Pinot at Uber Scale\\",src:\\"https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2021/04/deliverDoor@3x-768x263.png\\"})})]})}function x(t={}){let{wrapper:e}=t.components||{};return e?(0,a.jsx)(e,Object.assign({},t,{children:(0,a.jsx)(m,t)})):m(t)}var j=x;return w(k);})();\\n;return Component;"},"_id":"blog/2021-04-29-Uber-Charon.mdx","_raw":{"sourceFilePath":"blog/2021-04-29-Uber-Charon.mdx","sourceFileName":"2021-04-29-Uber-Charon.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2021-04-29-Uber-Charon"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.72,"time":43200,"words":144},"slug":"2021/04/29/Uber-Charon","customSlug":"2021/04/29/Uber-Charon","path":"blog/2021/04/29/Uber-Charon","customPath":"blog/2021/04/29/Uber-Charon","filePath":"blog/2021-04-29-Uber-Charon.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Automating Merchant Live Monitoring with Real-Time Analytics - Charon","datePublished":"2021-04-29T00:00:00.000Z","dateModified":"2021-04-29T00:00:00.000Z","description":"Focus on Uber’s real-time data platform components to build a tool called Charon to reduce impact of poor marketplace reliability on the merchants.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2021-04-29-Uber-Charon"}},{"title":"Introduction to Geospatial Queries in Apache Pinot","date":"2021-06-13T00:00:00.000Z","tags":["Pinot","DevBlog","H3","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"Discuss the challenges of analyzing geospatial at scale and propose the geospatial support in Pinot.","authors":["bastani"],"body":{"raw":"\\nGeospatial data has been widely used across the industry, spanning multiple verticals, such as ride-sharing and delivery, transportation infrastructure, defense and intel, public health. Deriving insights from timely and accurate geospatial data could enable mission-critical use cases in the organizations and fuel a vibrant marketplace across the industry. In the design document for this new Pinot feature, we discuss the challenges of analyzing geospatial at scale and propose the geospatial support in Pinot.\\n\\nRead More at https://medium.com/apache-pinot-developer-blog/introduction-to-geospatial-queries-in-apache-pinot-b63e2362e2a9\\n\\n![Introduction to Geospatial Queries in Apache Pinot](https://miro.medium.com/max/1400/0*1xrDSs9lLZ5dD3zK)\\n","code":"var Component=(()=>{var d=Object.create;var s=Object.defineProperty;var u=Object.getOwnPropertyDescriptor;var h=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),b=(t,e)=>{for(var n in e)s(t,n,{get:e[n],enumerable:!0})},r=(t,e,n,o)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let i of h(e))!g.call(t,i)&&i!==n&&s(t,i,{get:()=>e[i],enumerable:!(o=u(e,i))||o.enumerable});return t};var x=(t,e,n)=>(n=t!=null?d(m(t)):{},r(e||!t||!t.__esModule?s(n,\\"default\\",{value:t,enumerable:!0}):n,t)),y=t=>r(s({},\\"__esModule\\",{value:!0}),t);var l=f((w,c)=>{c.exports=_jsx_runtime});var _={};b(_,{default:()=>v,frontmatter:()=>D});var a=x(l()),D={title:\\"Introduction to Geospatial Queries in Apache Pinot\\",date:new Date(16235424e5),authors:[\\"bastani\\"],summary:\\"Discuss the challenges of analyzing geospatial at scale and propose the geospatial support in Pinot.\\",tags:[\\"Pinot\\",\\"DevBlog\\",\\"H3\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function p(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.p,{children:\\"Geospatial data has been widely used across the industry, spanning multiple verticals, such as ride-sharing and delivery, transportation infrastructure, defense and intel, public health. Deriving insights from timely and accurate geospatial data could enable mission-critical use cases in the organizations and fuel a vibrant marketplace across the industry. In the design document for this new Pinot feature, we discuss the challenges of analyzing geospatial at scale and propose the geospatial support in Pinot.\\"}),(0,a.jsxs)(e.p,{children:[\\"Read More at \\",(0,a.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/introduction-to-geospatial-queries-in-apache-pinot-b63e2362e2a9\\",children:\\"https://medium.com/apache-pinot-developer-blog/introduction-to-geospatial-queries-in-apache-pinot-b63e2362e2a9\\"})]}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Introduction to Geospatial Queries in Apache Pinot\\",src:\\"https://miro.medium.com/max/1400/0*1xrDSs9lLZ5dD3zK\\"})})]})}function j(t={}){let{wrapper:e}=t.components||{};return e?(0,a.jsx)(e,Object.assign({},t,{children:(0,a.jsx)(p,t)})):p(t)}var v=j;return y(_);})();\\n;return Component;"},"_id":"blog/2021-06-13-DevBlog-Geospatial.mdx","_raw":{"sourceFilePath":"blog/2021-06-13-DevBlog-Geospatial.mdx","sourceFileName":"2021-06-13-DevBlog-Geospatial.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2021-06-13-DevBlog-Geospatial"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.42,"time":25200,"words":84},"slug":"2021/06/13/DevBlog-Geospatial","customSlug":"2021/06/13/DevBlog-Geospatial","path":"blog/2021/06/13/DevBlog-Geospatial","customPath":"blog/2021/06/13/DevBlog-Geospatial","filePath":"blog/2021-06-13-DevBlog-Geospatial.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Introduction to Geospatial Queries in Apache Pinot","datePublished":"2021-06-13T00:00:00.000Z","dateModified":"2021-06-13T00:00:00.000Z","description":"Discuss the challenges of analyzing geospatial at scale and propose the geospatial support in Pinot.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2021-06-13-DevBlog-Geospatial"}},{"title":"Text analytics on LinkedIn Talent Insights using Apache Pinot","date":"2021-06-16T00:00:00.000Z","tags":["Pinot","LinkedIn","Data","Text analytics","real-time data platform","Realtime","ThirdEye","Analytics","User-Facing Analytics"],"summary":"Introduction LinkedIn Talent Insights (LTI) is a platform that helps organizations understand the external labor market and their internal workforce, and enables the long term success of their employees","authors":["linkedin"],"body":{"raw":"\\nLinkedIn Talent Insights (LTI) is a platform that helps organizations understand the external labor market and their internal workforce, and enables the long term success of their employees. Users of LTI have the flexibility to construct searches using the various facets of the LinkedIn Economic Graph (skills, titles, location, company, etc.).\\n\\n[Read More at https://engineering.linkedin.com/blog/2021/text-analytics-on-linkedin-talent-insights-using-apache-pinot](https://engineering.linkedin.com/blog/2021/text-analytics-on-linkedin-talent-insights-using-apache-pinot)\\n\\n![Text analytics on LinkedIn Talent Insights using Apache Pinot](https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2021/06/ltipinot6.png)\\n","code":"var Component=(()=>{var g=Object.create;var s=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var p=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var f=(t,n)=>()=>(n||t((n={exports:{}}).exports,n),n.exports),k=(t,n)=>{for(var i in n)s(t,i,{get:n[i],enumerable:!0})},r=(t,n,i,o)=>{if(n&&typeof n==\\"object\\"||typeof n==\\"function\\")for(let a of m(n))!u.call(t,a)&&a!==i&&s(t,a,{get:()=>n[a],enumerable:!(o=d(n,a))||o.enumerable});return t};var x=(t,n,i)=>(i=t!=null?g(p(t)):{},r(n||!t||!t.__esModule?s(i,\\"default\\",{value:t,enumerable:!0}):i,t)),y=t=>r(s({},\\"__esModule\\",{value:!0}),t);var c=f((_,l)=>{l.exports=_jsx_runtime});var L={};k(L,{default:()=>b,frontmatter:()=>I});var e=x(c()),I={title:\\"Text analytics on LinkedIn Talent Insights using Apache Pinot\\",date:new Date(16238016e5),authors:[\\"linkedin\\"],summary:\\"Introduction LinkedIn Talent Insights (LTI) is a platform that helps organizations understand the external labor market and their internal workforce, and enables the long term success of their employees\\",tags:[\\"Pinot\\",\\"LinkedIn\\",\\"Data\\",\\"Text analytics\\",\\"real-time data platform\\",\\"Realtime\\",\\"ThirdEye\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function h(t){let n=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,e.jsxs)(e.Fragment,{children:[(0,e.jsx)(n.p,{children:\\"LinkedIn Talent Insights (LTI) is a platform that helps organizations understand the external labor market and their internal workforce, and enables the long term success of their employees. Users of LTI have the flexibility to construct searches using the various facets of the LinkedIn Economic Graph (skills, titles, location, company, etc.).\\"}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.a,{href:\\"https://engineering.linkedin.com/blog/2021/text-analytics-on-linkedin-talent-insights-using-apache-pinot\\",children:\\"Read More at https://engineering.linkedin.com/blog/2021/text-analytics-on-linkedin-talent-insights-using-apache-pinot\\"})}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.img,{alt:\\"Text analytics on LinkedIn Talent Insights using Apache Pinot\\",src:\\"https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2021/06/ltipinot6.png\\"})})]})}function T(t={}){let{wrapper:n}=t.components||{};return n?(0,e.jsx)(n,Object.assign({},t,{children:(0,e.jsx)(h,t)})):h(t)}var b=T;return y(L);})();\\n;return Component;"},"_id":"blog/2021-06-16-LinkedIn-TextAnalytics.mdx","_raw":{"sourceFilePath":"blog/2021-06-16-LinkedIn-TextAnalytics.mdx","sourceFileName":"2021-06-16-LinkedIn-TextAnalytics.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2021-06-16-LinkedIn-TextAnalytics"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.32,"time":19200,"words":64},"slug":"2021/06/16/LinkedIn-TextAnalytics","customSlug":"2021/06/16/LinkedIn-TextAnalytics","path":"blog/2021/06/16/LinkedIn-TextAnalytics","customPath":"blog/2021/06/16/LinkedIn-TextAnalytics","filePath":"blog/2021-06-16-LinkedIn-TextAnalytics.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Text analytics on LinkedIn Talent Insights using Apache Pinot","datePublished":"2021-06-16T00:00:00.000Z","dateModified":"2021-06-16T00:00:00.000Z","description":"Introduction LinkedIn Talent Insights (LTI) is a platform that helps organizations understand the external labor market and their internal workforce, and enables the long term success of their employees","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2021-06-16-LinkedIn-TextAnalytics"}},{"title":"Announcing Apache Pinot 0.10","date":"2022-04-04T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","Releases"],"summary":"Learn more about the release of Apache Pinot 0.10 and all of new features that have been included in this version of the product.","authors":["pinotdev"],"body":{"raw":"\\nWe are excited to announce the release this week of Apache Pinot 0.10. Apache Pinot is a real-time distributed datastore designed to answer OLAP queries with high throughput and low latency.\\n\\nThis release is cut from commit [fd9c58a11ed16d27109baefcee138eea30132ad3](https://github.com/apache/pinot/commit/fd9c58a11ed16d27109baefcee138eea30132ad3). You can find a full list of everything included in the [release notes](https://docs.pinot.apache.org/basics/releases/0.10.0).\\n\\nLet’s have a look at some of the changes, with the help of the batch [QuickStart configuration](https://docs.pinot.apache.org/basics/getting-started/running-pinot-in-docker).\\n\\n## Query Plans\\n\\nAmrish Lal implemented the `EXPLAIN PLAN` clause, which returns the execution plan that will be chosen by the Pinot Query Engine. This lets us see what the query is likely to do without actually having to run it.\\n\\n```sql\\nEXPLAIN PLAN FOR\\nSELECT *\\nFROM baseballStats\\nWHERE league = \'NL\'\\n```\\n\\nIf we run this query, we\'ll see the following results:\\n\\n| Operator | Operator_Id | Parent_Id |\\n| --- | --- | --- |\\n| BROKER_REDUCE(limit:10) | 0 | -1 |\\n| COMBINE_SELECT | 1 | 0 |\\n| SELECT(selectList:AtBatting, G_old, baseOnBalls, caughtStealing, doules, groundedIntoDoublePlays, hits, hitsByPitch, homeRuns, intentionalWalks, league, numberOfGames, numberOfGamesAsBatter, playerID, playerName, playerStint, runs, runsBattedIn, sacrificeFlies, sacrificeHits, stolenBases, strikeouts, teamID, tripples, yearID) | 2 | 1 |\\n| TRANSFORM_PASSTHROUGH(AtBatting, G_old, baseOnBalls, caughtStealing, doules, groundedIntoDoublePlays, hits, hitsByPitch, homeRuns, intentionalWalks, league, numberOfGames, numberOfGamesAsBatter, playerID, playerName, playerStint, runs, runsBattedIn, sacrificeFlies, sacrificeHits, stolenBases, strikeouts, teamID, tripples, yearID) | 3 | 2 |\\n| PROJECT(homeRuns, playerStint, groundedIntoDoublePlays, numberOfGames, AtBatting, stolenBases, tripples, hitsByPitch, teamID, numberOfGamesAsBatter, strikeouts, sacrificeFlies, caughtStealing, baseOnBalls, playerName, doules, league, yearID, hits, runsBattedIn, G_old, sacrificeHits, intentionalWalks, runs, playerID) | 4 | 3 |\\n| FILTER_FULL_SCAN(operator:EQ,predicate:league = \'NL\') | 5 | 4 |\\n\\n## FILTER Clauses for Aggregates\\n\\nAtri Sharma added the filter clause for aggregates. This feature makes it possible to write queries like this:\\n\\n```sql\\nSELECT SUM(homeRuns) FILTER(WHERE league = \'NL\') AS nlHomeRuns,\\n       SUM(homeRuns) FILTER(WHERE league = \'AL\') AS alHomeRuns\\nFROM baseballStats\\n```\\n\\nIf we run this query, we\'ll see the following output:\\n\\n| nlHomeRuns | alHomeRuns |\\n| ---------- | ---------- |\\n| 135486     | 135990     |\\n\\n## greatest and least\\n\\nRichard Startin added the `greatest` and `least` functions:\\n\\n```sql\\nSELECT playerID,\\n       least(5.0, max(homeRuns)) AS homeRuns,\\n\\t   greatest(5.0, max(hits)) AS hits\\nFROM baseballStats\\nWHERE league = \'NL\' AND teamID = \'SFN\'\\nGROUP BY playerID\\nLIMIT 5\\n```\\n\\nIf we run this query, we\'ll see the following output:\\n\\n| playerID  | homeRuns | hits |\\n| --------- | -------- | ---- |\\n| ramirju01 | 0        | 5    |\\n| milneed01 | 4        | 54   |\\n| testani01 | 0        | 5    |\\n| shawbo01  | 0        | 8    |\\n| vogelry01 | 0        | 12   |\\n\\n## DistinctCountSmartHLL\\n\\nXiaotian (Jackie) Jiang added the `DistinctCountSmartHLL` aggregation function, which automatically converts the Set to HyperLogLog if the set size grows too big to protect the servers from running out of memory:\\n\\n```sql\\nSELECT DISTINCTCOUNTSMARTHLL(homeRuns, \'hllLog2m=8;hllConversionThreshold=10\')\\nFROM baseballStats\\n```\\n\\nIf we run this query, we\'ll see the following output:\\n\\n| distinctcountsmarthll(homeRuns) |\\n| ------------------------------- |\\n| 66                              |\\n\\n## UI updates\\n\\nThere were also a bunch of updates to the Pinot Data Explorer, by Sanket Shah and Johan Adami.\\n\\nThe display of reported size and estimated size is now in a human readable format:\\n\\n![Human readable sizes](/static/images/blogs/announcing-apache-pinot-0-10/human-readable-sizes.png)\\n\\nFixes for the following issues:\\n\\n-   Error messages weren\'t showing on the UI when an invalid operation is attempted:\\n\\n![A backwards incompatible attempted schema change](/static/images/blogs/announcing-apache-pinot-0-10/backwards-incompatible.png)\\n\\n-   Query console goes blank on syntax error.\\n-   Query console cannot show query result when multiple columns have the same name.\\n-   Adding extra fields after `SELECT *` would throw a NullPointerException.\\n-   Some queries were returning `--` instead of `0`.\\n-   Query console couldn\'t show the query result if multiple columns had the same name.\\n-   Pinot Dashboard tenant view showing the incorrect amount of servers and brokers.\\n\\n## RealTimeToOffline Task\\n\\nXiaotian (Jackie) Jiang made some fixes to the [RealTimeToOffline job](https://dev.startree.ai/docs/pinot/recipes/real-time-offline-job) to handle time gaps and proceed to the next time window when no segment matches the current one.\\n\\n## Empty QuickStart\\n\\nbastani added an empty QuickStart command, which lets you quickly spin up an empty Pinot cluster:\\n\\n```bash\\ndocker run \\\\\\n  -p 8000:8000 \\\\\\n  -p 9000:9000 \\\\\\n  apachepinot/pinot:0.10.0 QuickStart \\\\\\n  -type empty\\n```\\n\\nYou can then ingest your own dataset without needing to worry about spinning up each of the Pinot components individually.\\n\\n## Data Ingestion\\n\\n-   Richard Startin fixed some issues with real-time ingestion where consumption of messages would stop if a bad batch of messages was consumed from Kafka.\\n\\n-   Mohemmad Zaid Khan added the BoundedColumnValue partition function, which partitions segments based on column values.\\n\\n-   Xiaobing Li added the fixed name segment generator, which can be used when you want to replace a specific existing segment.\\n\\n## Other changes\\n\\n-   Richard Startin set LZ4 compression as the default for all metrics fields.\\n-   Mark Needham added the `ST_Within` geospatial function.\\n-   Rong Rong fixed a bug where query stats wouldn\'t show if there was an error processing the query (e.g. if the query timed out).\\n-   Prashant Pandey fixed the query engine to handle extra columns added to a `SELECT *` statement.\\n-   Richard Startin added support for forward indexes on JSON columns.\\n-   Rong Rong added the GRPC broker request handler so that data can be streamed back from the server to the broker when processing queries.\\n-   deemoliu made it possible to add a default strategy when using the [partial upsert feature](https://dev.startree.ai/docs/pinot/recipes/upserts-partial).\\n-   Jeff Moszuti added support for the `TIMESTAMP` data type in the [configuration recommendation engine](https://docs.pinot.apache.org/operators/configuration-recommendation-engine).\\n\\n## Dependency updates\\n\\nThe following dependencies were updated:\\n\\n-   async-http-client because the library moved to a different organization.\\n-   RoaringBitmap to 0.9.25\\n-   JsonPath to 2.7.0\\n-   Kafka to 2.8.1\\n-   Prometheus to 0.16.1\\n\\n## Resources\\n\\nIf you want to try out Apache Pinot, the following resources will help you get started:\\n\\n-   Download page: https://pinot.apache.org/download/\\n-   Getting started: https://docs.pinot.apache.org/getting-started\\n-   Apache Pinot Recipes: https://dev.startree.ai/docs/pinot/recipes/\\n-   Join our Slack channel: https://communityinviter.com/apps/apache-pinot/apache-pinot\\n-   See our upcoming events: https://www.meetup.com/apache-pinot\\n-   Follow us on Twitter: https://twitter.com/startreedata\\n-   Subscribe to our YouTube channel: https://www.youtube.com/c/StarTree\\n","code":"var Component=(()=>{var h=Object.create;var s=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var k=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),f=(a,e)=>{for(var t in e)s(a,t,{get:e[t],enumerable:!0})},l=(a,e,t,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let i of u(e))!g.call(a,i)&&i!==t&&s(a,i,{get:()=>e[i],enumerable:!(r=p(e,i))||r.enumerable});return a};var N=(a,e,t)=>(t=a!=null?h(m(a)):{},l(e||!a||!a.__esModule?s(t,\\"default\\",{value:a,enumerable:!0}):t,a)),w=a=>l(s({},\\"__esModule\\",{value:!0}),a);var d=k((L,c)=>{c.exports=_jsx_runtime});var R={};f(R,{default:()=>I,frontmatter:()=>y});var n=N(d()),y={title:\\"Announcing Apache Pinot 0.10\\",date:new Date(16490304e5),authors:[\\"pinotdev\\"],summary:\\"Learn more about the release of Apache Pinot 0.10 and all of new features that have been included in this version of the product.\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"Releases\\"]};function o(a){let e=Object.assign({p:\\"p\\",a:\\"a\\",h2:\\"h2\\",span:\\"span\\",code:\\"code\\",pre:\\"pre\\",table:\\"table\\",thead:\\"thead\\",tr:\\"tr\\",th:\\"th\\",tbody:\\"tbody\\",td:\\"td\\",div:\\"div\\",ul:\\"ul\\",li:\\"li\\"},a.components),{Image:t}=e;return t||S(\\"Image\\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\\"We are excited to announce the release this week of Apache Pinot 0.10. Apache Pinot is a real-time distributed datastore designed to answer OLAP queries with high throughput and low latency.\\"}),(0,n.jsxs)(e.p,{children:[\\"This release is cut from commit \\",(0,n.jsx)(e.a,{href:\\"https://github.com/apache/pinot/commit/fd9c58a11ed16d27109baefcee138eea30132ad3\\",children:\\"fd9c58a11ed16d27109baefcee138eea30132ad3\\"}),\\". You can find a full list of everything included in the \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/releases/0.10.0\\",children:\\"release notes\\"}),\\".\\"]}),(0,n.jsxs)(e.p,{children:[\\"Let\\\\u2019s have a look at some of the changes, with the help of the batch \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/getting-started/running-pinot-in-docker\\",children:\\"QuickStart configuration\\"}),\\".\\"]}),(0,n.jsxs)(e.h2,{id:\\"query-plans\\",children:[(0,n.jsx)(e.a,{href:\\"#query-plans\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Query Plans\\"]}),(0,n.jsxs)(e.p,{children:[\\"Amrish Lal implemented the \\",(0,n.jsx)(e.code,{children:\\"EXPLAIN PLAN\\"}),\\" clause, which returns the execution plan that will be chosen by the Pinot Query Engine. This lets us see what the query is likely to do without actually having to run it.\\"]}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"language-sql code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"EXPLAIN\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"PLAN\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FOR\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"SELECT\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),` baseballStats\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),\\" league \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'NL\'\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"If we run this query, we\'ll see the following results:\\"}),(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\\"Operator\\"}),(0,n.jsx)(e.th,{children:\\"Operator_Id\\"}),(0,n.jsx)(e.th,{children:\\"Parent_Id\\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"BROKER_REDUCE(limit:10)\\"}),(0,n.jsx)(e.td,{children:\\"0\\"}),(0,n.jsx)(e.td,{children:\\"-1\\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"COMBINE_SELECT\\"}),(0,n.jsx)(e.td,{children:\\"1\\"}),(0,n.jsx)(e.td,{children:\\"0\\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"SELECT(selectList:AtBatting, G_old, baseOnBalls, caughtStealing, doules, groundedIntoDoublePlays, hits, hitsByPitch, homeRuns, intentionalWalks, league, numberOfGames, numberOfGamesAsBatter, playerID, playerName, playerStint, runs, runsBattedIn, sacrificeFlies, sacrificeHits, stolenBases, strikeouts, teamID, tripples, yearID)\\"}),(0,n.jsx)(e.td,{children:\\"2\\"}),(0,n.jsx)(e.td,{children:\\"1\\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"TRANSFORM_PASSTHROUGH(AtBatting, G_old, baseOnBalls, caughtStealing, doules, groundedIntoDoublePlays, hits, hitsByPitch, homeRuns, intentionalWalks, league, numberOfGames, numberOfGamesAsBatter, playerID, playerName, playerStint, runs, runsBattedIn, sacrificeFlies, sacrificeHits, stolenBases, strikeouts, teamID, tripples, yearID)\\"}),(0,n.jsx)(e.td,{children:\\"3\\"}),(0,n.jsx)(e.td,{children:\\"2\\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"PROJECT(homeRuns, playerStint, groundedIntoDoublePlays, numberOfGames, AtBatting, stolenBases, tripples, hitsByPitch, teamID, numberOfGamesAsBatter, strikeouts, sacrificeFlies, caughtStealing, baseOnBalls, playerName, doules, league, yearID, hits, runsBattedIn, G_old, sacrificeHits, intentionalWalks, runs, playerID)\\"}),(0,n.jsx)(e.td,{children:\\"4\\"}),(0,n.jsx)(e.td,{children:\\"3\\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"FILTER_FULL_SCAN(operator:EQ,predicate:league = \'NL\')\\"}),(0,n.jsx)(e.td,{children:\\"5\\"}),(0,n.jsx)(e.td,{children:\\"4\\"})]})]})]}),(0,n.jsxs)(e.h2,{id:\\"filter-clauses-for-aggregates\\",children:[(0,n.jsx)(e.a,{href:\\"#filter-clauses-for-aggregates\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"FILTER Clauses for Aggregates\\"]}),(0,n.jsx)(e.p,{children:\\"Atri Sharma added the filter clause for aggregates. This feature makes it possible to write queries like this:\\"}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"language-sql code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"SELECT\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"SUM\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"homeRuns\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" FILTER\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),\\" league \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'NL\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"AS\\"}),\\" nlHomeRuns\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"       \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"SUM\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"homeRuns\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" FILTER\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),\\" league \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'AL\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"AS\\"}),` alHomeRuns\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),` baseballStats\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"If we run this query, we\'ll see the following output:\\"}),(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\\"nlHomeRuns\\"}),(0,n.jsx)(e.th,{children:\\"alHomeRuns\\"})]})}),(0,n.jsx)(e.tbody,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"135486\\"}),(0,n.jsx)(e.td,{children:\\"135990\\"})]})})]}),(0,n.jsxs)(e.h2,{id:\\"greatest-and-least\\",children:[(0,n.jsx)(e.a,{href:\\"#greatest-and-least\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"greatest and least\\"]}),(0,n.jsxs)(e.p,{children:[\\"Richard Startin added the \\",(0,n.jsx)(e.code,{children:\\"greatest\\"}),\\" and \\",(0,n.jsx)(e.code,{children:\\"least\\"}),\\" functions:\\"]}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"language-sql code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"SELECT\\"}),\\" playerID\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"       least\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"5.0\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"max\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"homeRuns\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"AS\\"}),\\" homeRuns\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"\\t   greatest\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"5.0\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"max\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"hits\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"AS\\"}),` hits\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),` baseballStats\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),\\" league \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'NL\'\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"AND\\"}),\\" teamID \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'SFN\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"GROUP\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),` playerID\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"LIMIT\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"5\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"If we run this query, we\'ll see the following output:\\"}),(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\\"playerID\\"}),(0,n.jsx)(e.th,{children:\\"homeRuns\\"}),(0,n.jsx)(e.th,{children:\\"hits\\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"ramirju01\\"}),(0,n.jsx)(e.td,{children:\\"0\\"}),(0,n.jsx)(e.td,{children:\\"5\\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"milneed01\\"}),(0,n.jsx)(e.td,{children:\\"4\\"}),(0,n.jsx)(e.td,{children:\\"54\\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"testani01\\"}),(0,n.jsx)(e.td,{children:\\"0\\"}),(0,n.jsx)(e.td,{children:\\"5\\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"shawbo01\\"}),(0,n.jsx)(e.td,{children:\\"0\\"}),(0,n.jsx)(e.td,{children:\\"8\\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"vogelry01\\"}),(0,n.jsx)(e.td,{children:\\"0\\"}),(0,n.jsx)(e.td,{children:\\"12\\"})]})]})]}),(0,n.jsxs)(e.h2,{id:\\"distinctcountsmarthll\\",children:[(0,n.jsx)(e.a,{href:\\"#distinctcountsmarthll\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"DistinctCountSmartHLL\\"]}),(0,n.jsxs)(e.p,{children:[\\"Xiaotian (Jackie) Jiang added the \\",(0,n.jsx)(e.code,{children:\\"DistinctCountSmartHLL\\"}),\\" aggregation function, which automatically converts the Set to HyperLogLog if the set size grows too big to protect the servers from running out of memory:\\"]}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"language-sql code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"SELECT\\"}),\\" DISTINCTCOUNTSMARTHLL\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"homeRuns\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'hllLog2m=8;hllConversionThreshold=10\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),` baseballStats\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"If we run this query, we\'ll see the following output:\\"}),(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsx)(e.tr,{children:(0,n.jsx)(e.th,{children:\\"distinctcountsmarthll(homeRuns)\\"})})}),(0,n.jsx)(e.tbody,{children:(0,n.jsx)(e.tr,{children:(0,n.jsx)(e.td,{children:\\"66\\"})})})]}),(0,n.jsxs)(e.h2,{id:\\"ui-updates\\",children:[(0,n.jsx)(e.a,{href:\\"#ui-updates\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"UI updates\\"]}),(0,n.jsx)(e.p,{children:\\"There were also a bunch of updates to the Pinot Data Explorer, by Sanket Shah and Johan Adami.\\"}),(0,n.jsx)(e.p,{children:\\"The display of reported size and estimated size is now in a human readable format:\\"}),(0,n.jsx)(e.div,{children:(0,n.jsx)(t,{alt:\\"Human readable sizes\\",src:\\"/static/images/blogs/announcing-apache-pinot-0-10/human-readable-sizes.png\\",width:\\"1055\\",height:\\"115\\"})}),(0,n.jsx)(e.p,{children:\\"Fixes for the following issues:\\"}),(0,n.jsx)(e.ul,{children:(0,n.jsx)(e.li,{children:\\"Error messages weren\'t showing on the UI when an invalid operation is attempted:\\"})}),(0,n.jsx)(e.div,{children:(0,n.jsx)(t,{alt:\\"A backwards incompatible attempted schema change\\",src:\\"/static/images/blogs/announcing-apache-pinot-0-10/backwards-incompatible.png\\",width:\\"615\\",height:\\"87\\"})}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"Query console goes blank on syntax error.\\"}),(0,n.jsx)(e.li,{children:\\"Query console cannot show query result when multiple columns have the same name.\\"}),(0,n.jsxs)(e.li,{children:[\\"Adding extra fields after \\",(0,n.jsx)(e.code,{children:\\"SELECT *\\"}),\\" would throw a NullPointerException.\\"]}),(0,n.jsxs)(e.li,{children:[\\"Some queries were returning \\",(0,n.jsx)(e.code,{children:\\"--\\"}),\\" instead of \\",(0,n.jsx)(e.code,{children:\\"0\\"}),\\".\\"]}),(0,n.jsx)(e.li,{children:\\"Query console couldn\'t show the query result if multiple columns had the same name.\\"}),(0,n.jsx)(e.li,{children:\\"Pinot Dashboard tenant view showing the incorrect amount of servers and brokers.\\"})]}),(0,n.jsxs)(e.h2,{id:\\"realtimetooffline-task\\",children:[(0,n.jsx)(e.a,{href:\\"#realtimetooffline-task\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"RealTimeToOffline Task\\"]}),(0,n.jsxs)(e.p,{children:[\\"Xiaotian (Jackie) Jiang made some fixes to the \\",(0,n.jsx)(e.a,{href:\\"https://dev.startree.ai/docs/pinot/recipes/real-time-offline-job\\",children:\\"RealTimeToOffline job\\"}),\\" to handle time gaps and proceed to the next time window when no segment matches the current one.\\"]}),(0,n.jsxs)(e.h2,{id:\\"empty-quickstart\\",children:[(0,n.jsx)(e.a,{href:\\"#empty-quickstart\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Empty QuickStart\\"]}),(0,n.jsx)(e.p,{children:\\"bastani added an empty QuickStart command, which lets you quickly spin up an empty Pinot cluster:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-p\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"8000\\"}),\\":8000 \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-p\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"9000\\"}),\\":9000 \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  apachepinot/pinot:0.10.0 QuickStart \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-type\\"}),` empty\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"You can then ingest your own dataset without needing to worry about spinning up each of the Pinot components individually.\\"}),(0,n.jsxs)(e.h2,{id:\\"data-ingestion\\",children:[(0,n.jsx)(e.a,{href:\\"#data-ingestion\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Data Ingestion\\"]}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:(0,n.jsx)(e.p,{children:\\"Richard Startin fixed some issues with real-time ingestion where consumption of messages would stop if a bad batch of messages was consumed from Kafka.\\"})}),(0,n.jsx)(e.li,{children:(0,n.jsx)(e.p,{children:\\"Mohemmad Zaid Khan added the BoundedColumnValue partition function, which partitions segments based on column values.\\"})}),(0,n.jsx)(e.li,{children:(0,n.jsx)(e.p,{children:\\"Xiaobing Li added the fixed name segment generator, which can be used when you want to replace a specific existing segment.\\"})})]}),(0,n.jsxs)(e.h2,{id:\\"other-changes\\",children:[(0,n.jsx)(e.a,{href:\\"#other-changes\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Other changes\\"]}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"Richard Startin set LZ4 compression as the default for all metrics fields.\\"}),(0,n.jsxs)(e.li,{children:[\\"Mark Needham added the \\",(0,n.jsx)(e.code,{children:\\"ST_Within\\"}),\\" geospatial function.\\"]}),(0,n.jsx)(e.li,{children:\\"Rong Rong fixed a bug where query stats wouldn\'t show if there was an error processing the query (e.g. if the query timed out).\\"}),(0,n.jsxs)(e.li,{children:[\\"Prashant Pandey fixed the query engine to handle extra columns added to a \\",(0,n.jsx)(e.code,{children:\\"SELECT *\\"}),\\" statement.\\"]}),(0,n.jsx)(e.li,{children:\\"Richard Startin added support for forward indexes on JSON columns.\\"}),(0,n.jsx)(e.li,{children:\\"Rong Rong added the GRPC broker request handler so that data can be streamed back from the server to the broker when processing queries.\\"}),(0,n.jsxs)(e.li,{children:[\\"deemoliu made it possible to add a default strategy when using the \\",(0,n.jsx)(e.a,{href:\\"https://dev.startree.ai/docs/pinot/recipes/upserts-partial\\",children:\\"partial upsert feature\\"}),\\".\\"]}),(0,n.jsxs)(e.li,{children:[\\"Jeff Moszuti added support for the \\",(0,n.jsx)(e.code,{children:\\"TIMESTAMP\\"}),\\" data type in the \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/operators/configuration-recommendation-engine\\",children:\\"configuration recommendation engine\\"}),\\".\\"]})]}),(0,n.jsxs)(e.h2,{id:\\"dependency-updates\\",children:[(0,n.jsx)(e.a,{href:\\"#dependency-updates\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Dependency updates\\"]}),(0,n.jsx)(e.p,{children:\\"The following dependencies were updated:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"async-http-client because the library moved to a different organization.\\"}),(0,n.jsx)(e.li,{children:\\"RoaringBitmap to 0.9.25\\"}),(0,n.jsx)(e.li,{children:\\"JsonPath to 2.7.0\\"}),(0,n.jsx)(e.li,{children:\\"Kafka to 2.8.1\\"}),(0,n.jsx)(e.li,{children:\\"Prometheus to 0.16.1\\"})]}),(0,n.jsxs)(e.h2,{id:\\"resources\\",children:[(0,n.jsx)(e.a,{href:\\"#resources\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Resources\\"]}),(0,n.jsx)(e.p,{children:\\"If you want to try out Apache Pinot, the following resources will help you get started:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsxs)(e.li,{children:[\\"Download page: \\",(0,n.jsx)(e.a,{href:\\"https://pinot.apache.org/download/\\",children:\\"https://pinot.apache.org/download/\\"})]}),(0,n.jsxs)(e.li,{children:[\\"Getting started: \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/getting-started\\",children:\\"https://docs.pinot.apache.org/getting-started\\"})]}),(0,n.jsxs)(e.li,{children:[\\"Apache Pinot Recipes: \\",(0,n.jsx)(e.a,{href:\\"https://dev.startree.ai/docs/pinot/recipes/\\",children:\\"https://dev.startree.ai/docs/pinot/recipes/\\"})]}),(0,n.jsxs)(e.li,{children:[\\"Join our Slack channel: \\",(0,n.jsx)(e.a,{href:\\"https://communityinviter.com/apps/apache-pinot/apache-pinot\\",children:\\"https://communityinviter.com/apps/apache-pinot/apache-pinot\\"})]}),(0,n.jsxs)(e.li,{children:[\\"See our upcoming events: \\",(0,n.jsx)(e.a,{href:\\"https://www.meetup.com/apache-pinot\\",children:\\"https://www.meetup.com/apache-pinot\\"})]}),(0,n.jsxs)(e.li,{children:[\\"Follow us on Twitter: \\",(0,n.jsx)(e.a,{href:\\"https://twitter.com/startreedata\\",children:\\"https://twitter.com/startreedata\\"})]}),(0,n.jsxs)(e.li,{children:[\\"Subscribe to our YouTube channel: \\",(0,n.jsx)(e.a,{href:\\"https://www.youtube.com/c/StarTree\\",children:\\"https://www.youtube.com/c/StarTree\\"})]})]})]})}function b(a={}){let{wrapper:e}=a.components||{};return e?(0,n.jsx)(e,Object.assign({},a,{children:(0,n.jsx)(o,a)})):o(a)}var I=b;function S(a,e){throw new Error(\\"Expected \\"+(e?\\"component\\":\\"object\\")+\\" `\\"+a+\\"` to be defined: you likely forgot to import, pass, or provide it.\\")}return w(R);})();\\n;return Component;"},"_id":"blog/2022-04-04-Announcing-Apache-Pinot-0-10.mdx","_raw":{"sourceFilePath":"blog/2022-04-04-Announcing-Apache-Pinot-0-10.mdx","sourceFileName":"2022-04-04-Announcing-Apache-Pinot-0-10.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2022-04-04-Announcing-Apache-Pinot-0-10"},"type":"Blog","readingTime":{"text":"5 min read","minutes":4.975,"time":298500,"words":995},"slug":"2022/04/04/Announcing-Apache-Pinot-0-10","customSlug":"2022/04/04/Announcing-Apache-Pinot-0-10","path":"blog/2022/04/04/Announcing-Apache-Pinot-0-10","customPath":"blog/2022/04/04/Announcing-Apache-Pinot-0-10","filePath":"blog/2022-04-04-Announcing-Apache-Pinot-0-10.mdx","toc":[{"value":"Query Plans","url":"#query-plans","depth":2},{"value":"FILTER Clauses for Aggregates","url":"#filter-clauses-for-aggregates","depth":2},{"value":"greatest and least","url":"#greatest-and-least","depth":2},{"value":"DistinctCountSmartHLL","url":"#distinctcountsmarthll","depth":2},{"value":"UI updates","url":"#ui-updates","depth":2},{"value":"RealTimeToOffline Task","url":"#realtimetooffline-task","depth":2},{"value":"Empty QuickStart","url":"#empty-quickstart","depth":2},{"value":"Data Ingestion","url":"#data-ingestion","depth":2},{"value":"Other changes","url":"#other-changes","depth":2},{"value":"Dependency updates","url":"#dependency-updates","depth":2},{"value":"Resources","url":"#resources","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Announcing Apache Pinot 0.10","datePublished":"2022-04-04T00:00:00.000Z","dateModified":"2022-04-04T00:00:00.000Z","description":"Learn more about the release of Apache Pinot 0.10 and all of new features that have been included in this version of the product.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2022-04-04-Announcing-Apache-Pinot-0-10"}},{"title":"GapFill Function For Time-Series Datasets In Pinot","date":"2022-08-02T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","interpolation","gapfilling"],"summary":"Gapfilling functions in Pinot to provide the on-the-fly interpolation (filling the missing data) functionality to better handle time-series data.","authors":["sun","velusamy"],"body":{"raw":"\\nMany real-world datasets are time-series in nature, tracking the value or state changes of entities over time. The values may be polled and recorded at constant time intervals or at random irregular intervals or only when the value/state changes. There are many real-world use cases of time series data. Here are some specific examples:\\n\\n-   Telemetry from sensors monitoring the status of industrial equipment.\\n-   Real-time vehicle data such as speed, braking, and acceleration, to produce the driver\'s risk score trend.\\n-   Server performance metrics such as CPU, I/O, memory, and network usage over time.\\n-   An automated system tracking the status of a store or items in an online marketplace.\\n\\nLet us use an IOT dataset tracking the occupancy status of the individual parking slots in a parking garage using automated sensors in this post. The granularity of recorded data points might be sparse or the events could be missing due to network and other device issues in the IOT environment. The following figure demonstrates entities emitting values at irregular intervals as the value changes. Polling and recording values of all entities regularly at a lower granularity would consume more resources, take up more space on disk and during processing and incur high costs. But analytics applications that are operating on these datasets, might be querying for values at a lower granularity than the data recording interval (Ex: A dashboard showing the total no of occupied parking slots at 15 min granularity in the past week when the sensors are not recording status as frequent).\\n\\n![Entities emitting data over time at irregular intervals](https://www.datocms-assets.com/75153/1661700264-entities-emitting-data.png \'Entities emitting data over time at irregular intervals\')\\n\\nIt is important for Pinot to provide the on-the-fly interpolation (filling the missing data) functionality to better handle time-series data.\\n\\nStarting from the 0.11.0 release, we introduced the new query syntax, gapfilling functions to interpolate data and perform powerful aggregations and data processing over time series data.\\n\\nWe will discuss the query syntax with an example and then the internal architecture.\\n\\n## Processing time series data in Pinot\\n\\nLet us use the following sample data set tracking the status of parking lots in the parking space to understand this feature in detail.\\n\\n### Sample Dataset:\\n\\n![Sample parking lot dataset](https://www.datocms-assets.com/75153/1661700333-parking-data-table.png \'Sample parking lot dataset\')\\n\\nparking_data table\\n\\nUse case:\xa0We want to find out the total number of parking lots that are occupied over a period of time, which would be a common use case for a company that manages parking spaces.\\n\\nLet us take 30 minutes time bucket as an example:\\n\\n![Sample parking lot dataset with 30 minute time bucket](https://www.datocms-assets.com/75153/1661700377-30-min-bucket-example.png \'Sample parking lot dataset with 30 minute time bucket\')\\n\\nIn the 30 mins aggregation results table above, we can see a lot of missing data as many lots didn\'t have anything recorded in those 30-minute windows. To calculate the number of occupied parking lots per time bucket, we need to gap-fill the missing data for each of these 30-minute windows.\\n\\n## Interpolating missing data\\n\\nThere are multiple ways to infer and fill the missing values. In the current version, we introduce the following methods, which are more common:\\n\\n-   FILL_PREVIOUS_VALUE\xa0can be used to fill time buckets missing values for entities with the last observed value. If no previous observed value can be found, the default value is used as an alternative.\\n-   FILL_DEFAULT_VALUE\xa0can be used to fill time buckets missing values for entities with the default value depending on the data type.\\n\\nMore advanced gapfilling strategies such as using the next observed value, the value from the previous day or past week, or the value computed using a subquery shall be introduced in the future.\\n\\n## Gapfill Query with a Use Case:\\n\\nLet us write a query to\xa0*get*\xa0*the total number of occupied parking lots every 30 minutes over time on the parking lot dataset*\xa0discussed above.\\n\\n### Query Syntax:\\n\\n```sql\\nSELECT time_col, SUM(status) AS occupied_slots_count\\nFROM (\\n    SELECT GAPFILL(time_col,\'1:MILLISECONDS:SIMPLE_DATE_FORMAT:yyyy-MM-dd HH:mm:ss.SSS\',\'2021-10-01 09:00:00.000\',\\n                   \'2021-10-01 12:00:00.000\',\'30:MINUTES\', FILL(status, \'FILL_PREVIOUS_VALUE\'),\\n                    TIMESERIESON(lot_id)), lot_id, status\\n    FROM (\\n        SELECT DATETIMECONVERT(event_time,\'1:MILLISECONDS:EPOCH\',\\n               \'1:MILLISECONDS:SIMPLE_DATE_FORMAT:yyyy-MM-dd HH:mm:ss.SSS\',\'30:MINUTES\') AS time_col,\\n               lot_id, lastWithTime(is_occupied, event_time, \'INT\') AS status\\n        FROM parking_data\\n        WHERE event_time >= 1633078800000 AND  event_time <= 1633089600000\\n        GROUP BY 1, 2\\n        ORDER BY 1\\n        LIMIT 100)\\n    LIMIT 100)\\nGROUP BY 1\\nLIMIT 100\\n```\\n\\nThis query suggests three main steps:\\n\\n1.  The raw data will be aggregated;\\n2.  The aggregated data will be gapfilled;\\n3.  The gapfilled data will be aggregated.\\n\\nWe make one assumption that the raw data is sorted by timestamp. The Gapfill and Post-Gapfill Aggregation will not sort the data.\\n\\n### Query components:\\n\\nThe following concepts were added to interpolate and handle time-series data.\\n\\n-   LastWithTime(dataColumn, timeColumn, \'dataType\')\xa0\\\\- To get the last value of\xa0dataColumn\xa0where the\xa0timeColumn\xa0is used to define the time of dataColumn. This is useful to pick the latest value when there are multiple values found within a time bucket. Please see\xa0[https://docs.pinot.apache.org/users/user-guide-query/supported-aggregations](https://docs.pinot.apache.org/users/user-guide-query/supported-aggregations)\xa0for more details.\\n-   Fill(colum, FILL_TYPE)\xa0- To fill the missing data of the column with the FILL_TYPE.\\n-   TimeSeriesOn\xa0- To specify the columns to uniquely identify entities whose data will be interpolated.\\n-   Gapfill\xa0- Specify the time range, the time bucket size, how to fill the missing data, and entity definition.\\n\\n### Query Workflow\\n\\nThe innermost sql will convert the raw event table to the following table.\\n\\n![Sample parking lot query workflow innermost SQL](https://www.datocms-assets.com/75153/1661700439-innermost-sql.png \'Sample parking lot query workflow innermost SQL\')\\n\\nThe second most nested sql will gap fill the returned data as below:\\n\\n![Sample parking lot query workflow second most SQL](https://www.datocms-assets.com/75153/1661700473-second-most.png \'Sample parking lot query workflow second most SQL\')\\n\\nThe outermost query will aggregate the gapfilled data as follows:\\n\\n![Sample parking lot query workflow outermost SQL](https://www.datocms-assets.com/75153/1661700517-outermost.png \'Sample parking lot query workflow outermost SQL\')\\n\\n### Other Supported Query Scenarios:\\n\\nThe above example demonstrates the support to aggregate before and post gapfilling. Pre and/or post aggregations can be skipped if they are not needed. The gapfilling query syntax is flexible to support the following use cases:\\n\\n-   Select/Gapfill\xa0- Gapfill the missing data for the time bucket. Just the raw events are fetched, gapfilled, and returned. No aggregation is needed.\\n-   Aggregate/Gapfill\xa0- If there are multiple entries within the time bucket we can pick a representative value by applying an aggregate function. Then the missing data for the time buckets will be gap filled.\\n-   Gapfill/Aggregate\xa0- Gapfill the data and perform some form of aggregation on the interpolated data.\\n\\nFor detailed query syntax and how it works, please refer to the documentation here:\xa0[https://docs.pinot.apache.org/users/user-guide-query/gap-fill-functions](https://docs.pinot.apache.org/users/user-guide-query/gap-fill-functions).\\n\\n## How does it work?\\n\\nLet us use the sample query given above as an example to understand what\'s going on behind the scenes and how Pinot executes the gapfill queries.\\n\\n### Request Flow\\n\\nHere is the list of steps in executing the query at a high level:\\n\\n1.  Pinot Broker receives the gapfill query. It will strip off the gapfill part and send out the stripped SQL query to the pinot server.\\n2.  The pinot server will process the query as a normal query and return the result back to the pinot broker.\\n3.  The pinot broker will run the DataTableReducer to merge the results from pinot servers. The result will be sent to GapfillProcessor.\\n4.  The GapfillProcessor will gapfill the received result and apply the filter against the gap-filled result.\\n5.  Post-Gapfill aggregation and filtering will be applied to the result from the last step.\\n\\nThere are two gapfill-specific steps:\\n\\n1.  When Pinot Broker Server receives the gapfill SQL query, it will strip out gapfill related information and send out the stripped SQL query to the pinot server\\n2.  GapfillProcessor will process the result from BrokerReducerService. The gapfill logic will be applied to the reduced result.\\n\\n![Gapfill steps](https://www.datocms-assets.com/75153/1661700601-gapfill-steps.png \'Gapfill steps\')\\n\\nHere is the stripped version of the sql query sent to servers for the query shared above:\\n\\n```sql\\nSELECT DATETIMECONVERT(event_time,\'1:MILLISECONDS:EPOCH\',\\n               \'1:MILLISECONDS:SIMPLE_DATE_FORMAT:yyyy-MM-dd HH:mm:ss.SSS\',\'30:MINUTES\') AS time_col,\\n               lot_id, lastWithTime(is_occupied, event_time, \'INT\') AS status\\n        FROM parking_data\\n        WHERE event_time >= 1633078800000 AND  event_time <= 1633089600000\\n        GROUP BY 1, 2\\n        ORDER BY 1\\n        LIMIT 100\\n```\\n\\n### Execution Plan\\n\\nThe sample execution plan for this query is as shown in the figure below:\\n\\n![Sample query execution plan](https://www.datocms-assets.com/75153/1661700642-execution-plan.png \'Sample query execution plan\')\\n\\n### Time and Space complexity:\\n\\nLet us say there are M entities, R rows returned from servers, and N time buckets. The data is gapfilled time bucket by time bucket to limit the broker memory usage to O(M + N + R). When the data is gapfilled for a time bucket, it will be aggregated and stored in the final result (which has N slots). The previous values for each of the M entities are maintained in memory and carried forward as the gapfilling is performed in sequence. The time complexity is O(M \\\\* N) where M is the number of entities and N is the number of time buckets.\\n\\n### Challenges\\n\\n![Sample server challenges graph](https://www.datocms-assets.com/75153/1661700716-challenges.png \'Sample server challenges graph\')\\n\\nAs the time-series datasets are enormous and partitioned, it\'s hard to get answers to the following questions:\\n\\n-   How many different entities exist within the query time frame. In the temporal partition scheme demonstrated above, a server/partition may not know the answer.\\n-   What\'s the previously observed value for entities especially for the first data points in a time bucket where previous time buckets don’t exist in the same server.\\n\\nFor the scenario shown in the figure above, server2 may not know about the circle entity, as there are no events for the circle in Server2. It would also not know the last observed value for the square entity frame beginning of the time bucket till the first observed value timestamp within the partition.\\n\\n## The Future Work\\n\\nWhen doing the gapfill for one or a few entities, there might not be too much data. But when we deal with a large dataset that has multiple entities queried over a long date range without any filtering, this gets tricky. Since gapfill happens at the pinot broker, it will become very slow and the broker will become a bottleneck. The raw data transferred from servers to brokers would be enormous. Data explodes when interpolated. Parallelism is limited as the single broker instance is handling the query.\\n\\nThe next step of the gapfill project is to remove the pinot broker as a bottleneck. The gapfill logic will be pushed down to the servers and be running where the data live. This will reduce the data transmission and increase the parallelism and performance of gapfill.\\n","code":"var Component=(()=>{var h=Object.create;var i=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var k=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),f=(a,e)=>{for(var t in e)i(a,t,{get:e[t],enumerable:!0})},r=(a,e,t,l)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let s of m(e))!g.call(a,s)&&s!==t&&i(a,s,{get:()=>e[s],enumerable:!(l=p(e,s))||l.enumerable});return a};var w=(a,e,t)=>(t=a!=null?h(u(a)):{},r(e||!a||!a.__esModule?i(t,\\"default\\",{value:a,enumerable:!0}):t,a)),N=a=>r(i({},\\"__esModule\\",{value:!0}),a);var c=k((I,o)=>{o.exports=_jsx_runtime});var S={};f(S,{default:()=>v,frontmatter:()=>y});var n=w(c()),y={title:\\"GapFill Function For Time-Series Datasets In Pinot\\",date:new Date(16593984e5),authors:[\\"sun\\",\\"velusamy\\"],summary:\\"Gapfilling functions in Pinot to provide the on-the-fly interpolation (filling the missing data) functionality to better handle time-series data.\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"interpolation\\",\\"gapfilling\\"]};function d(a){let e=Object.assign({p:\\"p\\",ul:\\"ul\\",li:\\"li\\",img:\\"img\\",h2:\\"h2\\",a:\\"a\\",span:\\"span\\",h3:\\"h3\\",em:\\"em\\",pre:\\"pre\\",code:\\"code\\",ol:\\"ol\\"},a.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\\"Many real-world datasets are time-series in nature, tracking the value or state changes of entities over time. The values may be polled and recorded at constant time intervals or at random irregular intervals or only when the value/state changes. There are many real-world use cases of time series data. Here are some specific examples:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"Telemetry from sensors monitoring the status of industrial equipment.\\"}),(0,n.jsx)(e.li,{children:\\"Real-time vehicle data such as speed, braking, and acceleration, to produce the driver\'s risk score trend.\\"}),(0,n.jsx)(e.li,{children:\\"Server performance metrics such as CPU, I/O, memory, and network usage over time.\\"}),(0,n.jsx)(e.li,{children:\\"An automated system tracking the status of a store or items in an online marketplace.\\"})]}),(0,n.jsx)(e.p,{children:\\"Let us use an IOT dataset tracking the occupancy status of the individual parking slots in a parking garage using automated sensors in this post. The granularity of recorded data points might be sparse or the events could be missing due to network and other device issues in the IOT environment. The following figure demonstrates entities emitting values at irregular intervals as the value changes. Polling and recording values of all entities regularly at a lower granularity would consume more resources, take up more space on disk and during processing and incur high costs. But analytics applications that are operating on these datasets, might be querying for values at a lower granularity than the data recording interval (Ex: A dashboard showing the total no of occupied parking slots at 15 min granularity in the past week when the sensors are not recording status as frequent).\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Entities emitting data over time at irregular intervals\\",src:\\"https://www.datocms-assets.com/75153/1661700264-entities-emitting-data.png\\",title:\\"Entities emitting data over time at irregular intervals\\"})}),(0,n.jsx)(e.p,{children:\\"It is important for Pinot to provide the on-the-fly interpolation (filling the missing data) functionality to better handle time-series data.\\"}),(0,n.jsx)(e.p,{children:\\"Starting from the 0.11.0 release, we introduced the new query syntax, gapfilling functions to interpolate data and perform powerful aggregations and data processing over time series data.\\"}),(0,n.jsx)(e.p,{children:\\"We will discuss the query syntax with an example and then the internal architecture.\\"}),(0,n.jsxs)(e.h2,{id:\\"processing-time-series-data-in-pinot\\",children:[(0,n.jsx)(e.a,{href:\\"#processing-time-series-data-in-pinot\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Processing time series data in Pinot\\"]}),(0,n.jsx)(e.p,{children:\\"Let us use the following sample data set tracking the status of parking lots in the parking space to understand this feature in detail.\\"}),(0,n.jsxs)(e.h3,{id:\\"sample-dataset\\",children:[(0,n.jsx)(e.a,{href:\\"#sample-dataset\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Sample Dataset:\\"]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample parking lot dataset\\",src:\\"https://www.datocms-assets.com/75153/1661700333-parking-data-table.png\\",title:\\"Sample parking lot dataset\\"})}),(0,n.jsx)(e.p,{children:\\"parking_data table\\"}),(0,n.jsx)(e.p,{children:\\"Use case:\\\\xA0We want to find out the total number of parking lots that are occupied over a period of time, which would be a common use case for a company that manages parking spaces.\\"}),(0,n.jsx)(e.p,{children:\\"Let us take 30 minutes time bucket as an example:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample parking lot dataset with 30 minute time bucket\\",src:\\"https://www.datocms-assets.com/75153/1661700377-30-min-bucket-example.png\\",title:\\"Sample parking lot dataset with 30 minute time bucket\\"})}),(0,n.jsx)(e.p,{children:\\"In the 30 mins aggregation results table above, we can see a lot of missing data as many lots didn\'t have anything recorded in those 30-minute windows. To calculate the number of occupied parking lots per time bucket, we need to gap-fill the missing data for each of these 30-minute windows.\\"}),(0,n.jsxs)(e.h2,{id:\\"interpolating-missing-data\\",children:[(0,n.jsx)(e.a,{href:\\"#interpolating-missing-data\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Interpolating missing data\\"]}),(0,n.jsx)(e.p,{children:\\"There are multiple ways to infer and fill the missing values. In the current version, we introduce the following methods, which are more common:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"FILL_PREVIOUS_VALUE\\\\xA0can be used to fill time buckets missing values for entities with the last observed value. If no previous observed value can be found, the default value is used as an alternative.\\"}),(0,n.jsx)(e.li,{children:\\"FILL_DEFAULT_VALUE\\\\xA0can be used to fill time buckets missing values for entities with the default value depending on the data type.\\"})]}),(0,n.jsx)(e.p,{children:\\"More advanced gapfilling strategies such as using the next observed value, the value from the previous day or past week, or the value computed using a subquery shall be introduced in the future.\\"}),(0,n.jsxs)(e.h2,{id:\\"gapfill-query-with-a-use-case\\",children:[(0,n.jsx)(e.a,{href:\\"#gapfill-query-with-a-use-case\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Gapfill Query with a Use Case:\\"]}),(0,n.jsxs)(e.p,{children:[\\"Let us write a query to\\\\xA0\\",(0,n.jsx)(e.em,{children:\\"get\\"}),\\"\\\\xA0\\",(0,n.jsx)(e.em,{children:\\"the total number of occupied parking lots every 30 minutes over time on the parking lot dataset\\"}),\\"\\\\xA0discussed above.\\"]}),(0,n.jsxs)(e.h3,{id:\\"query-syntax\\",children:[(0,n.jsx)(e.a,{href:\\"#query-syntax\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Query Syntax:\\"]}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"language-sql code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"SELECT\\"}),\\" time_col\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"SUM\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"status\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"AS\\"}),` occupied_slots_count\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"SELECT\\"}),\\" GAPFILL\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"time_col\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'1:MILLISECONDS:SIMPLE_DATE_FORMAT:yyyy-MM-dd HH:mm:ss.SSS\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'2021-10-01 09:00:00.000\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                   \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'2021-10-01 12:00:00.000\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'30:MINUTES\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" FILL\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"status\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'FILL_PREVIOUS_VALUE\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                    TIMESERIESON\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"lot_id\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" lot_id\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"status\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"SELECT\\"}),\\" DATETIMECONVERT\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"event_time\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'1:MILLISECONDS:EPOCH\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"               \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'1:MILLISECONDS:SIMPLE_DATE_FORMAT:yyyy-MM-dd HH:mm:ss.SSS\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'30:MINUTES\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"AS\\"}),\\" time_col\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"               lot_id\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" lastWithTime\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"is_occupied\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" event_time\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'INT\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"AS\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"status\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),` parking_data\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),\\" event_time \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\">=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1633078800000\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"AND\\"}),\\"  event_time \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"<=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1633089600000\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"GROUP\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"2\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"ORDER\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"LIMIT\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"100\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"LIMIT\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"100\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"GROUP\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"LIMIT\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"100\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"This query suggests three main steps:\\"}),(0,n.jsxs)(e.ol,{children:[(0,n.jsx)(e.li,{children:\\"The raw data will be aggregated;\\"}),(0,n.jsx)(e.li,{children:\\"The aggregated data will be gapfilled;\\"}),(0,n.jsx)(e.li,{children:\\"The gapfilled data will be aggregated.\\"})]}),(0,n.jsx)(e.p,{children:\\"We make one assumption that the raw data is sorted by timestamp. The Gapfill and Post-Gapfill Aggregation will not sort the data.\\"}),(0,n.jsxs)(e.h3,{id:\\"query-components\\",children:[(0,n.jsx)(e.a,{href:\\"#query-components\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Query components:\\"]}),(0,n.jsx)(e.p,{children:\\"The following concepts were added to interpolate and handle time-series data.\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsxs)(e.li,{children:[\\"LastWithTime(dataColumn, timeColumn, \'dataType\')\\\\xA0- To get the last value of\\\\xA0dataColumn\\\\xA0where the\\\\xA0timeColumn\\\\xA0is used to define the time of dataColumn. This is useful to pick the latest value when there are multiple values found within a time bucket. Please see\\\\xA0\\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/users/user-guide-query/supported-aggregations\\",children:\\"https://docs.pinot.apache.org/users/user-guide-query/supported-aggregations\\"}),\\"\\\\xA0for more details.\\"]}),(0,n.jsx)(e.li,{children:\\"Fill(colum, FILL_TYPE)\\\\xA0- To fill the missing data of the column with the FILL_TYPE.\\"}),(0,n.jsx)(e.li,{children:\\"TimeSeriesOn\\\\xA0- To specify the columns to uniquely identify entities whose data will be interpolated.\\"}),(0,n.jsx)(e.li,{children:\\"Gapfill\\\\xA0- Specify the time range, the time bucket size, how to fill the missing data, and entity definition.\\"})]}),(0,n.jsxs)(e.h3,{id:\\"query-workflow\\",children:[(0,n.jsx)(e.a,{href:\\"#query-workflow\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Query Workflow\\"]}),(0,n.jsx)(e.p,{children:\\"The innermost sql will convert the raw event table to the following table.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample parking lot query workflow innermost SQL\\",src:\\"https://www.datocms-assets.com/75153/1661700439-innermost-sql.png\\",title:\\"Sample parking lot query workflow innermost SQL\\"})}),(0,n.jsx)(e.p,{children:\\"The second most nested sql will gap fill the returned data as below:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample parking lot query workflow second most SQL\\",src:\\"https://www.datocms-assets.com/75153/1661700473-second-most.png\\",title:\\"Sample parking lot query workflow second most SQL\\"})}),(0,n.jsx)(e.p,{children:\\"The outermost query will aggregate the gapfilled data as follows:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample parking lot query workflow outermost SQL\\",src:\\"https://www.datocms-assets.com/75153/1661700517-outermost.png\\",title:\\"Sample parking lot query workflow outermost SQL\\"})}),(0,n.jsxs)(e.h3,{id:\\"other-supported-query-scenarios\\",children:[(0,n.jsx)(e.a,{href:\\"#other-supported-query-scenarios\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Other Supported Query Scenarios:\\"]}),(0,n.jsx)(e.p,{children:\\"The above example demonstrates the support to aggregate before and post gapfilling. Pre and/or post aggregations can be skipped if they are not needed. The gapfilling query syntax is flexible to support the following use cases:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"Select/Gapfill\\\\xA0- Gapfill the missing data for the time bucket. Just the raw events are fetched, gapfilled, and returned. No aggregation is needed.\\"}),(0,n.jsx)(e.li,{children:\\"Aggregate/Gapfill\\\\xA0- If there are multiple entries within the time bucket we can pick a representative value by applying an aggregate function. Then the missing data for the time buckets will be gap filled.\\"}),(0,n.jsx)(e.li,{children:\\"Gapfill/Aggregate\\\\xA0- Gapfill the data and perform some form of aggregation on the interpolated data.\\"})]}),(0,n.jsxs)(e.p,{children:[\\"For detailed query syntax and how it works, please refer to the documentation here:\\\\xA0\\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/users/user-guide-query/gap-fill-functions\\",children:\\"https://docs.pinot.apache.org/users/user-guide-query/gap-fill-functions\\"}),\\".\\"]}),(0,n.jsxs)(e.h2,{id:\\"how-does-it-work\\",children:[(0,n.jsx)(e.a,{href:\\"#how-does-it-work\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"How does it work?\\"]}),(0,n.jsx)(e.p,{children:\\"Let us use the sample query given above as an example to understand what\'s going on behind the scenes and how Pinot executes the gapfill queries.\\"}),(0,n.jsxs)(e.h3,{id:\\"request-flow\\",children:[(0,n.jsx)(e.a,{href:\\"#request-flow\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Request Flow\\"]}),(0,n.jsx)(e.p,{children:\\"Here is the list of steps in executing the query at a high level:\\"}),(0,n.jsxs)(e.ol,{children:[(0,n.jsx)(e.li,{children:\\"Pinot Broker receives the gapfill query. It will strip off the gapfill part and send out the stripped SQL query to the pinot server.\\"}),(0,n.jsx)(e.li,{children:\\"The pinot server will process the query as a normal query and return the result back to the pinot broker.\\"}),(0,n.jsx)(e.li,{children:\\"The pinot broker will run the DataTableReducer to merge the results from pinot servers. The result will be sent to GapfillProcessor.\\"}),(0,n.jsx)(e.li,{children:\\"The GapfillProcessor will gapfill the received result and apply the filter against the gap-filled result.\\"}),(0,n.jsx)(e.li,{children:\\"Post-Gapfill aggregation and filtering will be applied to the result from the last step.\\"})]}),(0,n.jsx)(e.p,{children:\\"There are two gapfill-specific steps:\\"}),(0,n.jsxs)(e.ol,{children:[(0,n.jsx)(e.li,{children:\\"When Pinot Broker Server receives the gapfill SQL query, it will strip out gapfill related information and send out the stripped SQL query to the pinot server\\"}),(0,n.jsx)(e.li,{children:\\"GapfillProcessor will process the result from BrokerReducerService. The gapfill logic will be applied to the reduced result.\\"})]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Gapfill steps\\",src:\\"https://www.datocms-assets.com/75153/1661700601-gapfill-steps.png\\",title:\\"Gapfill steps\\"})}),(0,n.jsx)(e.p,{children:\\"Here is the stripped version of the sql query sent to servers for the query shared above:\\"}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"language-sql code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"SELECT\\"}),\\" DATETIMECONVERT\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"event_time\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'1:MILLISECONDS:EPOCH\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"               \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'1:MILLISECONDS:SIMPLE_DATE_FORMAT:yyyy-MM-dd HH:mm:ss.SSS\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'30:MINUTES\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"AS\\"}),\\" time_col\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"               lot_id\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" lastWithTime\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"is_occupied\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" event_time\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'INT\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"AS\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"status\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),` parking_data\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),\\" event_time \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\">=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1633078800000\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"AND\\"}),\\"  event_time \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"<=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1633089600000\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"GROUP\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"2\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"ORDER\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"LIMIT\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"100\\"}),`\\n`]})]})}),(0,n.jsxs)(e.h3,{id:\\"execution-plan\\",children:[(0,n.jsx)(e.a,{href:\\"#execution-plan\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Execution Plan\\"]}),(0,n.jsx)(e.p,{children:\\"The sample execution plan for this query is as shown in the figure below:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample query execution plan\\",src:\\"https://www.datocms-assets.com/75153/1661700642-execution-plan.png\\",title:\\"Sample query execution plan\\"})}),(0,n.jsxs)(e.h3,{id:\\"time-and-space-complexity\\",children:[(0,n.jsx)(e.a,{href:\\"#time-and-space-complexity\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Time and Space complexity:\\"]}),(0,n.jsx)(e.p,{children:\\"Let us say there are M entities, R rows returned from servers, and N time buckets. The data is gapfilled time bucket by time bucket to limit the broker memory usage to O(M + N + R). When the data is gapfilled for a time bucket, it will be aggregated and stored in the final result (which has N slots). The previous values for each of the M entities are maintained in memory and carried forward as the gapfilling is performed in sequence. The time complexity is O(M * N) where M is the number of entities and N is the number of time buckets.\\"}),(0,n.jsxs)(e.h3,{id:\\"challenges\\",children:[(0,n.jsx)(e.a,{href:\\"#challenges\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Challenges\\"]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample server challenges graph\\",src:\\"https://www.datocms-assets.com/75153/1661700716-challenges.png\\",title:\\"Sample server challenges graph\\"})}),(0,n.jsx)(e.p,{children:\\"As the time-series datasets are enormous and partitioned, it\'s hard to get answers to the following questions:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"How many different entities exist within the query time frame. In the temporal partition scheme demonstrated above, a server/partition may not know the answer.\\"}),(0,n.jsx)(e.li,{children:\\"What\'s the previously observed value for entities especially for the first data points in a time bucket where previous time buckets don\\\\u2019t exist in the same server.\\"})]}),(0,n.jsx)(e.p,{children:\\"For the scenario shown in the figure above, server2 may not know about the circle entity, as there are no events for the circle in Server2. It would also not know the last observed value for the square entity frame beginning of the time bucket till the first observed value timestamp within the partition.\\"}),(0,n.jsxs)(e.h2,{id:\\"the-future-work\\",children:[(0,n.jsx)(e.a,{href:\\"#the-future-work\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"The Future Work\\"]}),(0,n.jsx)(e.p,{children:\\"When doing the gapfill for one or a few entities, there might not be too much data. But when we deal with a large dataset that has multiple entities queried over a long date range without any filtering, this gets tricky. Since gapfill happens at the pinot broker, it will become very slow and the broker will become a bottleneck. The raw data transferred from servers to brokers would be enormous. Data explodes when interpolated. Parallelism is limited as the single broker instance is handling the query.\\"}),(0,n.jsx)(e.p,{children:\\"The next step of the gapfill project is to remove the pinot broker as a bottleneck. The gapfill logic will be pushed down to the servers and be running where the data live. This will reduce the data transmission and increase the parallelism and performance of gapfill.\\"})]})}function b(a={}){let{wrapper:e}=a.components||{};return e?(0,n.jsx)(e,Object.assign({},a,{children:(0,n.jsx)(d,a)})):d(a)}var v=b;return N(S);})();\\n;return Component;"},"_id":"blog/2022-08-02-GapFill-Function-For-Time-Series-Datasets-In-Pinot.mdx","_raw":{"sourceFilePath":"blog/2022-08-02-GapFill-Function-For-Time-Series-Datasets-In-Pinot.mdx","sourceFileName":"2022-08-02-GapFill-Function-For-Time-Series-Datasets-In-Pinot.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2022-08-02-GapFill-Function-For-Time-Series-Datasets-In-Pinot"},"type":"Blog","readingTime":{"text":"9 min read","minutes":8.59,"time":515400,"words":1718},"slug":"2022/08/02/GapFill-Function-For-Time-Series-Datasets-In-Pinot","customSlug":"2022/08/02/GapFill-Function-For-Time-Series-Datasets-In-Pinot","path":"blog/2022/08/02/GapFill-Function-For-Time-Series-Datasets-In-Pinot","customPath":"blog/2022/08/02/GapFill-Function-For-Time-Series-Datasets-In-Pinot","filePath":"blog/2022-08-02-GapFill-Function-For-Time-Series-Datasets-In-Pinot.mdx","toc":[{"value":"Processing time series data in Pinot","url":"#processing-time-series-data-in-pinot","depth":2},{"value":"Sample Dataset:","url":"#sample-dataset","depth":3},{"value":"Interpolating missing data","url":"#interpolating-missing-data","depth":2},{"value":"Gapfill Query with a Use Case:","url":"#gapfill-query-with-a-use-case","depth":2},{"value":"Query Syntax:","url":"#query-syntax","depth":3},{"value":"Query components:","url":"#query-components","depth":3},{"value":"Query Workflow","url":"#query-workflow","depth":3},{"value":"Other Supported Query Scenarios:","url":"#other-supported-query-scenarios","depth":3},{"value":"How does it work?","url":"#how-does-it-work","depth":2},{"value":"Request Flow","url":"#request-flow","depth":3},{"value":"Execution Plan","url":"#execution-plan","depth":3},{"value":"Time and Space complexity:","url":"#time-and-space-complexity","depth":3},{"value":"Challenges","url":"#challenges","depth":3},{"value":"The Future Work","url":"#the-future-work","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"GapFill Function For Time-Series Datasets In Pinot","datePublished":"2022-08-02T00:00:00.000Z","dateModified":"2022-08-02T00:00:00.000Z","description":"Gapfilling functions in Pinot to provide the on-the-fly interpolation (filling the missing data) functionality to better handle time-series data.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2022-08-02-GapFill-Function-For-Time-Series-Datasets-In-Pinot"}},{"title":"Apache Pinot™ 0.11 - How do I see my indexes?","date":"2022-11-08T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","Indexes"],"summary":"How you can work out which indexes are currently defined on a Pinot table","authors":["needham"],"body":{"raw":"\\nWe recently released [Pinot 0.11.0](https://medium.com/apache-pinot-developer-blog/apache-pinot-0-11-released-d564684df5d4) , which has lots of goodies for you to play with. This is the first in a series of blog posts showing off some of the new features in this release.\\n\\nA common question from the community is: how can you work out which indexes are currently defined on a Pinot table? This information has always been [available via the REST API](https://docs.pinot.apache.org/users/api/pinot-rest-admin-interface), but sometimes you simply want to see it on the UI and not have to parse your way through a bunch of JSON. Let\'s see how it works!\\n\\n## Spinning up Pinot\\n\\nWe’re going to spin up the Batch [QuickStart](https://docs.pinot.apache.org/basics/getting-started/quick-start) in Docker using the following command:\\n\\n```bash\\ndocker run \\\\\\n  -p 8000:8000 \\\\\\n  -p 9000:9000 \\\\\\n  apachepinot/pinot:0.11.0 \\\\\\n  QuickStart -type BATCH\\n```\\n\\nOr if you’re on a Mac M1, change the name of the image to have the arm-64 suffix, like this:\\n\\n```bash\\ndocker run \\\\\\n  -p 8000:8000 \\\\\\n  -p 9000:9000 \\\\\\n  apachepinot/pinot:0.11.0-arm64 \\\\\\n  QuickStart -type BATCH\\n```\\n\\nOnce that’s up and running, navigate to [http://localhost:9000/#/](http://localhost:9000/#/) and click on Tables. Under the tables section click on airlineStats_OFFLINE. You should see a page that looks like this:\\n\\n![airlineStats_OFFLINE page](https://www.datocms-assets.com/75153/1667915561-image1-edittable.png \'airlineStats_OFFLINE page\')\\n\\nClick on Edit Table. This will show a window with the config for this table.\\n\\n![Window with configuration for airlineStats_OFFLINE table](https://www.datocms-assets.com/75153/1667915654-image3.png \'Window with configuration for airlineStats_OFFLINE table\')\\n\\n## Indexing Config\\n\\nWe’re interested in the tableIndexConfig and fieldConfigList sections. These sections are responsible for defining indexes, which are applied to a table on a per segment basis.\\n\\n-   tableIndexConfig is responsible for inverted, JSON, range, Geospatial, and StarTree indexes.\\n-   fieldConfigList is responsible for timestamp and text indexes.\\n\\ntableIndexConfig is defined below:\\n\\n```json\\n\\"tableIndexConfig\\": {\\n  \\"rangeIndexVersion\\": 2,\\n  \\"autoGeneratedInvertedIndex\\": false,\\n  \\"createInvertedIndexDuringSegmentGeneration\\": false,\\n  \\"loadMode\\": \\"MMAP\\",\\n  \\"enableDefaultStarTree\\": false,\\n  \\"enableDynamicStarTreeCreation\\": false,\\n  \\"aggregateMetrics\\": false,\\n  \\"nullHandlingEnabled\\": false,\\n  \\"optimizeDictionaryForMetrics\\": false,\\n  \\"noDictionarySizeRatioThreshold\\": 0\\n},\\n```\\n\\nFrom reading this config we learn that no indexes have been explicitly defined.\\n\\nNow for fieldConfigList, which is defined below:\\n\\n```json\\n\\"fieldConfigList\\": [\\n  {\\n    \\"name\\": \\"ts\\",\\n    \\"encodingType\\": \\"DICTIONARY\\",\\n    \\"indexType\\": \\"TIMESTAMP\\",\\n    \\"indexTypes\\": [\\n      \\"TIMESTAMP\\"\\n    ],\\n    \\"timestampConfig\\": {\\n      \\"granularities\\": [\\n        \\"DAY\\",\\n        \\"WEEK\\",\\n        \\"MONTH\\"\\n      ]\\n    }\\n  }\\n],\\n```\\n\\nFrom reading this config we learn that a timestamp index is being applied to the _ts_ column. It is applied at DAY, WEEK, and MONTH granularities, which means that the derived columns $ts$DAY, $ts$WEEK, and $ts$MONTH will be created for the segments in this table.\\n\\n## Viewing Indexes\\n\\nNow, close the table config modal, and under the segments section, open airlineStats_OFFLINE_16071_16071_0 and airlineStats_OFFLINE_16073_16073_0 in new tabs.\\n\\nIf you look at one of those segments, you’ll see the following grid that lists columns/field names against the indexes defined on those fields.\\n\\n![Segment grid that lists columns/field names against the indexes defined on those fields](https://www.datocms-assets.com/75153/1667915996-image7.png \'Segment grid that lists columns/field names against the indexes defined on those fields\')\\n\\nAll the fields on display are persisting their values using the dictionary/forward [index format](https://docs.pinot.apache.org/basics/indexing/forward-index) ). Still, we can also see that the Quarter column is sorted and has an inverted index, neither of which we explicitly defined.\\n\\nThis is because Pinot will automatically create sorted and inverted indexes for columns whose data is sorted when the segment is created.\\n\\nSo the data for the Quarter column was sorted, and hence it has a sorted index.\\n\\nI’ve written a couple of blog posts explaining how sorted indexes work on offline and real-time tables:\\n\\n## Adding an Index\\n\\nNext, let’s see what happens if we add an explicit index. We’re going to add an inverted index to the FlightNum column. Go to Edit Table config again and update tableIndexConfig to have the following value:\\n\\n![Inverted index addition](https://www.datocms-assets.com/75153/1667916147-image6.png \'Inverted index addition\')\\n\\nIf you go back to the page for segment airlineStats_OFFLINE_16073_16073_0, notice that it does not have an inverted index for this field.\\n\\n![page for segment airlineStats_OFFLINE_16073_16073_0 without an inverted index](https://www.datocms-assets.com/75153/1667916232-image2.png \'page for segment airlineStats_OFFLINE_16073_16073_0 without an inverted index\')\\n\\nThis is because indexes are applied on a per segment basis. If we want the inverted index on the FlightNum column in this segment, we can click _Reload Segment_ on this page, or we can go back to the table page and click _Reload All Segments_.\\n\\nIf we do that, all the segments in the airlineStats_OFFLINE table will eventually have an inverted index on FlightNum.\\n\\n## Summary\\n\\nAs I mentioned in the introduction, information about the indexes on each segment has always been available via the REST API, but this feature democratizes that information.\\n\\nIf you have any questions about this feature, feel free to join us on [Slack](https://stree.ai/slack), where we’ll be happy to help you out.\\n","code":"var Component=(()=>{var h=Object.create;var t=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var N=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var g=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),k=(a,e)=>{for(var s in e)t(a,s,{get:e[s],enumerable:!0})},c=(a,e,s,l)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let i of m(e))!u.call(a,i)&&i!==s&&t(a,i,{get:()=>e[i],enumerable:!(l=p(e,i))||l.enumerable});return a};var f=(a,e,s)=>(s=a!=null?h(N(a)):{},c(e||!a||!a.__esModule?t(s,\\"default\\",{value:a,enumerable:!0}):s,a)),w=a=>c(t({},\\"__esModule\\",{value:!0}),a);var r=g((S,o)=>{o.exports=_jsx_runtime});var I={};k(I,{default:()=>y,frontmatter:()=>x});var n=f(r()),x={title:\\"Apache Pinot\\\\u2122 0.11 - How do I see my indexes?\\",date:new Date(16678656e5),authors:[\\"needham\\"],summary:\\"How you can work out which indexes are currently defined on a Pinot table\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"Indexes\\"]};function d(a){let e=Object.assign({p:\\"p\\",a:\\"a\\",h2:\\"h2\\",span:\\"span\\",pre:\\"pre\\",code:\\"code\\",img:\\"img\\",ul:\\"ul\\",li:\\"li\\",em:\\"em\\",math:\\"math\\",semantics:\\"semantics\\",mrow:\\"mrow\\",mi:\\"mi\\",annotation:\\"annotation\\"},a.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.p,{children:[\\"We recently released \\",(0,n.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/apache-pinot-0-11-released-d564684df5d4\\",children:\\"Pinot 0.11.0\\"}),\\" , which has lots of goodies for you to play with. This is the first in a series of blog posts showing off some of the new features in this release.\\"]}),(0,n.jsxs)(e.p,{children:[\\"A common question from the community is: how can you work out which indexes are currently defined on a Pinot table? This information has always been \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/users/api/pinot-rest-admin-interface\\",children:\\"available via the REST API\\"}),\\", but sometimes you simply want to see it on the UI and not have to parse your way through a bunch of JSON. Let\'s see how it works!\\"]}),(0,n.jsxs)(e.h2,{id:\\"spinning-up-pinot\\",children:[(0,n.jsx)(e.a,{href:\\"#spinning-up-pinot\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Spinning up Pinot\\"]}),(0,n.jsxs)(e.p,{children:[\\"We\\\\u2019re going to spin up the Batch \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/getting-started/quick-start\\",children:\\"QuickStart\\"}),\\" in Docker using the following command:\\"]}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-p\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"8000\\"}),\\":8000 \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-p\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"9000\\"}),\\":9000 \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  apachepinot/pinot:0.11.0 \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  QuickStart \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-type\\"}),` BATCH\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"Or if you\\\\u2019re on a Mac M1, change the name of the image to have the arm-64 suffix, like this:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-p\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"8000\\"}),\\":8000 \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-p\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"9000\\"}),\\":9000 \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  apachepinot/pinot:0.11.0-arm64 \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  QuickStart \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-type\\"}),` BATCH\\n`]})]})}),(0,n.jsxs)(e.p,{children:[\\"Once that\\\\u2019s up and running, navigate to \\",(0,n.jsx)(e.a,{href:\\"http://localhost:9000/#/\\",children:\\"http://localhost:9000/#/\\"}),\\" and click on Tables. Under the tables section click on airlineStats_OFFLINE. You should see a page that looks like this:\\"]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"airlineStats_OFFLINE page\\",src:\\"https://www.datocms-assets.com/75153/1667915561-image1-edittable.png\\",title:\\"airlineStats_OFFLINE page\\"})}),(0,n.jsx)(e.p,{children:\\"Click on Edit Table. This will show a window with the config for this table.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Window with configuration for airlineStats_OFFLINE table\\",src:\\"https://www.datocms-assets.com/75153/1667915654-image3.png\\",title:\\"Window with configuration for airlineStats_OFFLINE table\\"})}),(0,n.jsxs)(e.h2,{id:\\"indexing-config\\",children:[(0,n.jsx)(e.a,{href:\\"#indexing-config\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Indexing Config\\"]}),(0,n.jsx)(e.p,{children:\\"We\\\\u2019re interested in the tableIndexConfig and fieldConfigList sections. These sections are responsible for defining indexes, which are applied to a table on a per segment basis.\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"tableIndexConfig is responsible for inverted, JSON, range, Geospatial, and StarTree indexes.\\"}),(0,n.jsx)(e.li,{children:\\"fieldConfigList is responsible for timestamp and text indexes.\\"})]}),(0,n.jsx)(e.p,{children:\\"tableIndexConfig is defined below:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableIndexConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"rangeIndexVersion\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"2\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"autoGeneratedInvertedIndex\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"createInvertedIndexDuringSegmentGeneration\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"loadMode\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"MMAP\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"enableDefaultStarTree\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"enableDynamicStarTreeCreation\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"aggregateMetrics\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"nullHandlingEnabled\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"optimizeDictionaryForMetrics\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"noDictionarySizeRatioThreshold\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"0\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"From reading this config we learn that no indexes have been explicitly defined.\\"}),(0,n.jsx)(e.p,{children:\\"Now for fieldConfigList, which is defined below:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"fieldConfigList\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"encodingType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"DICTIONARY\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"indexType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"TIMESTAMP\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"indexTypes\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"TIMESTAMP\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"timestampConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"granularities\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"DAY\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"WEEK\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"MONTH\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]})]})}),(0,n.jsxs)(e.p,{children:[\\"From reading this config we learn that a timestamp index is being applied to the \\",(0,n.jsx)(e.em,{children:\\"ts\\"}),\\" column. It is applied at DAY, WEEK, and MONTH granularities, which means that the derived columns \\",(0,n.jsx)(e.span,{className:\\"math math-inline\\",children:(0,n.jsxs)(e.span,{className:\\"katex\\",children:[(0,n.jsx)(e.span,{className:\\"katex-mathml\\",children:(0,n.jsx)(e.math,{xmlns:\\"http://www.w3.org/1998/Math/MathML\\",children:(0,n.jsxs)(e.semantics,{children:[(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mi,{children:\\"t\\"}),(0,n.jsx)(e.mi,{children:\\"s\\"})]}),(0,n.jsx)(e.annotation,{encoding:\\"application/x-tex\\",children:\\"ts\\"})]})})}),(0,n.jsx)(e.span,{className:\\"katex-html\\",\\"aria-hidden\\":\\"true\\",children:(0,n.jsxs)(e.span,{className:\\"base\\",children:[(0,n.jsx)(e.span,{className:\\"strut\\",style:{height:\\".6151em\\"}}),(0,n.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"t\\"}),(0,n.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"s\\"})]})})]})}),\\"DAY, \\",(0,n.jsx)(e.span,{className:\\"math math-inline\\",children:(0,n.jsxs)(e.span,{className:\\"katex\\",children:[(0,n.jsx)(e.span,{className:\\"katex-mathml\\",children:(0,n.jsx)(e.math,{xmlns:\\"http://www.w3.org/1998/Math/MathML\\",children:(0,n.jsxs)(e.semantics,{children:[(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mi,{children:\\"t\\"}),(0,n.jsx)(e.mi,{children:\\"s\\"})]}),(0,n.jsx)(e.annotation,{encoding:\\"application/x-tex\\",children:\\"ts\\"})]})})}),(0,n.jsx)(e.span,{className:\\"katex-html\\",\\"aria-hidden\\":\\"true\\",children:(0,n.jsxs)(e.span,{className:\\"base\\",children:[(0,n.jsx)(e.span,{className:\\"strut\\",style:{height:\\".6151em\\"}}),(0,n.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"t\\"}),(0,n.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"s\\"})]})})]})}),\\"WEEK, and \\",(0,n.jsx)(e.span,{className:\\"math math-inline\\",children:(0,n.jsxs)(e.span,{className:\\"katex\\",children:[(0,n.jsx)(e.span,{className:\\"katex-mathml\\",children:(0,n.jsx)(e.math,{xmlns:\\"http://www.w3.org/1998/Math/MathML\\",children:(0,n.jsxs)(e.semantics,{children:[(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mi,{children:\\"t\\"}),(0,n.jsx)(e.mi,{children:\\"s\\"})]}),(0,n.jsx)(e.annotation,{encoding:\\"application/x-tex\\",children:\\"ts\\"})]})})}),(0,n.jsx)(e.span,{className:\\"katex-html\\",\\"aria-hidden\\":\\"true\\",children:(0,n.jsxs)(e.span,{className:\\"base\\",children:[(0,n.jsx)(e.span,{className:\\"strut\\",style:{height:\\".6151em\\"}}),(0,n.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"t\\"}),(0,n.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"s\\"})]})})]})}),\\"MONTH will be created for the segments in this table.\\"]}),(0,n.jsxs)(e.h2,{id:\\"viewing-indexes\\",children:[(0,n.jsx)(e.a,{href:\\"#viewing-indexes\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Viewing Indexes\\"]}),(0,n.jsx)(e.p,{children:\\"Now, close the table config modal, and under the segments section, open airlineStats_OFFLINE_16071_16071_0 and airlineStats_OFFLINE_16073_16073_0 in new tabs.\\"}),(0,n.jsx)(e.p,{children:\\"If you look at one of those segments, you\\\\u2019ll see the following grid that lists columns/field names against the indexes defined on those fields.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Segment grid that lists columns/field names against the indexes defined on those fields\\",src:\\"https://www.datocms-assets.com/75153/1667915996-image7.png\\",title:\\"Segment grid that lists columns/field names against the indexes defined on those fields\\"})}),(0,n.jsxs)(e.p,{children:[\\"All the fields on display are persisting their values using the dictionary/forward \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/indexing/forward-index\\",children:\\"index format\\"}),\\" ). Still, we can also see that the Quarter column is sorted and has an inverted index, neither of which we explicitly defined.\\"]}),(0,n.jsx)(e.p,{children:\\"This is because Pinot will automatically create sorted and inverted indexes for columns whose data is sorted when the segment is created.\\"}),(0,n.jsx)(e.p,{children:\\"So the data for the Quarter column was sorted, and hence it has a sorted index.\\"}),(0,n.jsx)(e.p,{children:\\"I\\\\u2019ve written a couple of blog posts explaining how sorted indexes work on offline and real-time tables:\\"}),(0,n.jsxs)(e.h2,{id:\\"adding-an-index\\",children:[(0,n.jsx)(e.a,{href:\\"#adding-an-index\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Adding an Index\\"]}),(0,n.jsx)(e.p,{children:\\"Next, let\\\\u2019s see what happens if we add an explicit index. We\\\\u2019re going to add an inverted index to the FlightNum column. Go to Edit Table config again and update tableIndexConfig to have the following value:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Inverted index addition\\",src:\\"https://www.datocms-assets.com/75153/1667916147-image6.png\\",title:\\"Inverted index addition\\"})}),(0,n.jsx)(e.p,{children:\\"If you go back to the page for segment airlineStats_OFFLINE_16073_16073_0, notice that it does not have an inverted index for this field.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"page for segment airlineStats_OFFLINE_16073_16073_0 without an inverted index\\",src:\\"https://www.datocms-assets.com/75153/1667916232-image2.png\\",title:\\"page for segment airlineStats_OFFLINE_16073_16073_0 without an inverted index\\"})}),(0,n.jsxs)(e.p,{children:[\\"This is because indexes are applied on a per segment basis. If we want the inverted index on the FlightNum column in this segment, we can click \\",(0,n.jsx)(e.em,{children:\\"Reload Segment\\"}),\\" on this page, or we can go back to the table page and click \\",(0,n.jsx)(e.em,{children:\\"Reload All Segments\\"}),\\".\\"]}),(0,n.jsx)(e.p,{children:\\"If we do that, all the segments in the airlineStats_OFFLINE table will eventually have an inverted index on FlightNum.\\"}),(0,n.jsxs)(e.h2,{id:\\"summary\\",children:[(0,n.jsx)(e.a,{href:\\"#summary\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),(0,n.jsx)(e.p,{children:\\"As I mentioned in the introduction, information about the indexes on each segment has always been available via the REST API, but this feature democratizes that information.\\"}),(0,n.jsxs)(e.p,{children:[\\"If you have any questions about this feature, feel free to join us on \\",(0,n.jsx)(e.a,{href:\\"https://stree.ai/slack\\",children:\\"Slack\\"}),\\", where we\\\\u2019ll be happy to help you out.\\"]})]})}function b(a={}){let{wrapper:e}=a.components||{};return e?(0,n.jsx)(e,Object.assign({},a,{children:(0,n.jsx)(d,a)})):d(a)}var y=b;return w(I);})();\\n;return Component;"},"_id":"blog/2022-11-08-Apache Pinot-How-do-I-see-my-indexes.mdx","_raw":{"sourceFilePath":"blog/2022-11-08-Apache Pinot-How-do-I-see-my-indexes.mdx","sourceFileName":"2022-11-08-Apache Pinot-How-do-I-see-my-indexes.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2022-11-08-Apache Pinot-How-do-I-see-my-indexes"},"type":"Blog","readingTime":{"text":"4 min read","minutes":3.79,"time":227400,"words":758},"slug":"2022/11/08/Apache Pinot-How-do-I-see-my-indexes","customSlug":"2022/11/08/Apache Pinot-How-do-I-see-my-indexes","path":"blog/2022/11/08/Apache Pinot-How-do-I-see-my-indexes","customPath":"blog/2022/11/08/Apache Pinot-How-do-I-see-my-indexes","filePath":"blog/2022-11-08-Apache Pinot-How-do-I-see-my-indexes.mdx","toc":[{"value":"Spinning up Pinot","url":"#spinning-up-pinot","depth":2},{"value":"Indexing Config","url":"#indexing-config","depth":2},{"value":"Viewing Indexes","url":"#viewing-indexes","depth":2},{"value":"Adding an Index","url":"#adding-an-index","depth":2},{"value":"Summary","url":"#summary","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Pinot™ 0.11 - How do I see my indexes?","datePublished":"2022-11-08T00:00:00.000Z","dateModified":"2022-11-08T00:00:00.000Z","description":"How you can work out which indexes are currently defined on a Pinot table","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2022-11-08-Apache Pinot-How-do-I-see-my-indexes"}},{"title":"Apache Pinot™ 0.11 - Inserts from SQL","date":"2022-11-17T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","Insert"],"summary":"Explore the INSERT INTO clause, which makes ingesting batch data into Pinot as easy as writing a SQL query.","authors":["needham"],"body":{"raw":"\\nThe Apache Pinot community recently released version [0.11.0](https://medium.com/apache-pinot-developer-blog/apache-pinot-0-11-released-d564684df5d4), which has lots of goodies for you to play with. This is the second in a series of blog posts showing off some of the new features in this release.\\n\\nIn this post, we’re going to explore the [INSERT INTO clause](https://docs.pinot.apache.org/basics/data-import/from-query-console), which makes ingesting batch data into Pinot as easy as writing a SQL query.\\n\\n## Batch importing: The Job Specification\\n\\nThe power of this new clause is only fully appreciated if we look at what we had to do before it existed.\\n\\nIn the [Batch Import JSON from Amazon S3 into Apache Pinot | StarTree Recipes](https://www.youtube.com/watch?v=1EMBx1XeI9o) video (and [accompanying developer guide](https://dev.startree.ai/docs/pinot/recipes/ingest-csv-files-from-s3)), we showed how to ingest data into Pinot from an S3 bucket.\\n\\nThe contents of that bucket are shown in the screenshot below:\\n\\n![Sample data ingested into Apache Pinot from a S3 bucket](https://www.datocms-assets.com/75153/1668701275-image4.png \'Sample data ingested into Apache Pinot from a S3 bucket\')\\n\\nLet’s quickly recap the steps that we had to do to import those files into Pinot. We have a table called events, which has the following schema:\\n\\n![Events schema table](https://www.datocms-assets.com/75153/1668701353-image1.png \'Events schema table\')\\n\\nWe first created a job specification file, which contains a description of our import job. The job file is shown below:\\n\\n```yaml\\nexecutionFrameworkSpec:\\n    name: \'standalone\'\\n    segmentGenerationJobRunnerClassName: \'org.apache.pinot.plugin.ingestion.batch.standalone.SegmentGenerationJobRunner\'\\n    segmentTarPushJobRunnerClassName: \'org.apache.pinot.plugin.ingestion.batch.standalone.SegmentTarPushJobRunner\'\\n    segmentUriPushJobRunnerClassName: \'org.apache.pinot.plugin.ingestion.batch.standalone.SegmentUriPushJobRunner\'\\njobType: SegmentCreationAndTarPush\\ninputDirURI: \'s3://marks-st-cloud-bucket/events/\'\\nincludeFileNamePattern: \'glob:**/*.json\'\\noutputDirURI: \'/data\'\\noverwriteOutput: true\\npinotFSSpecs:\\n    - scheme: s3\\n      className: org.apache.pinot.plugin.filesystem.S3PinotFS\\n      configs:\\n          region: \'eu-west-2\'\\n    - scheme: file\\n      className: org.apache.pinot.spi.filesystem.LocalPinotFS\\nrecordReaderSpec:\\n    dataFormat: \'json\'\\n    className: \'org.apache.pinot.plugin.inputformat.json.JSONRecordReader\'\\ntableSpec:\\n    tableName: \'events\'\\npinotClusterSpecs:\\n    - controllerURI: \'http://${PINOT_CONTROLLER}:9000\'\\n```\\n\\nAt a high level, this file describes a batch import job that will ingest files from the S3 bucket at s3://marks-st-cloud-bucket/events/ where the files match the glob:\\\\*\\\\*/\\\\*.json pattern.\\n\\nWe can import the data by running the following command from the terminal:\\n\\n```bash\\ndocker run \\\\\\n  --network ingest-json-files-s3 \\\\\\n  -v $PWD/config:/config \\\\\\n  -e AWS_ACCESS_KEY_ID=AKIARCOCT6DWLUB7F77Z \\\\\\n  -e AWS_SECRET_ACCESS_KEY=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 \\\\\\n  apachepinot/pinot:0.11.0 LaunchDataIngestionJob \\\\\\n  -jobSpecFile /config/job-spec.yml \\\\\\n  -values PINOT_CONTROLLER=pinot-controller\\n```\\n\\nAnd don’t worry, those credentials have already been deleted; I find it easier to understand what values go where if we use real values.\\n\\nOnce we’ve run this command, if we go to the Pinot UI\xa0at [http://localhost:9000](http://localhost:9000/) and click through to the events table from the Query Console menu, we’ll see that the records have been imported, as shown in the screenshot below:\\n\\n![Sample imported records shown in the Apache Pinot Query Console menu](https://www.datocms-assets.com/75153/1668701512-image3.png \'Sample imported records shown in the Apache Pinot Query Console menu\')\\n\\nThis approach works, and we may still prefer to use it when we need fine-grained control over the ingestion parameters, but it is a bit heavyweight for your everyday data import!\\n\\n## Batch Importing with SQL\\n\\nNow let’s do the same thing in SQL.\\n\\nThere are some prerequisites to using the SQL approach, so let’s go through those now, so you don’t end up with a bunch of exceptions when you try this out!\\n\\nFirst of all, you must have a [Minion](https://docs.pinot.apache.org/basics/components/minion) in the Pinot cluster, as this is the component that will do the data import.\\n\\nYou’ll also need to include the following in your table config:\\n\\n```json\\n\\"task\\": {\\n  \\"taskTypeConfigsMap\\": { \\"SegmentGenerationAndPushTask\\": {} }\\n}\\n```\\n\\nAs long as you’ve done those two things, we’re ready to write our import query! A query that imports JSON files from my S3 bucket is shown below:\\n\\n```sql\\nINSERT INTO events\\nFROM FILE \'s3://marks-st-cloud-bucket/events/\'\\nOPTION(\\n  taskName=events-task,\\n  includeFileNamePattern=glob:**/*.json,\\n  input.fs.className=org.apache.pinot.plugin.filesystem.S3PinotFS,\\n  input.fs.prop.accessKey=AKIARCOCT6DWLUB7F77Z,\\n  input.fs.prop.secretKey=gfz71RX+Tj4udve43YePCBqMsIeN1PvHXrVFyxJS,\\n  input.fs.prop.region=eu-west-2\\n);\\n```\\n\\nIf we run this query, we’ll see the following output:\\n\\n![Sample events_OFFLINE query result](https://www.datocms-assets.com/75153/1668701654-image5.png \'Sample events_OFFLINE query result\')\\n\\nWe can check on the state of the ingestion job via the Swagger REST API. If we navigate to [http://localhost:9000/help#/Task/getTaskState](http://localhost:9000/help#/Task/getTaskState), paste Task_SegmentGenerationAndPushTask_events-task as our task name, and then click Execute, we’ll see the following:\\n\\n![Checking the state of an ingestion job screen](https://www.datocms-assets.com/75153/1668701727-image2.png \'Checking the state of an ingestion job screen\')\\n\\nIf we see the state COMPLETED, this means the data has been ingested, which we can check by going back to the Query console and clicking on the events table.\\n\\n## Summary\\n\\nI have to say that batch ingestion of data into Apache Pinot has always felt a bit clunky, but with this new clause, it’s super easy, and it’s gonna save us all a bunch of time.\\n\\nAlso, anything that means I’m not writing YAML files has got to be a good thing!\\n\\nSo give it a try and let us know how you get on. If you have any questions about this feature, feel free to join us on [Slack](https://stree.ai/slack), where we’ll be happy to help you out.\\n","code":"var Component=(()=>{var p=Object.create;var c=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,N=Object.prototype.hasOwnProperty;var k=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),g=(a,e)=>{for(var s in e)c(a,s,{get:e[s],enumerable:!0})},i=(a,e,s,l)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let t of m(e))!N.call(a,t)&&t!==s&&c(a,t,{get:()=>e[t],enumerable:!(l=d(e,t))||l.enumerable});return a};var w=(a,e,s)=>(s=a!=null?p(u(a)):{},i(e||!a||!a.__esModule?c(s,\\"default\\",{value:a,enumerable:!0}):s,a)),f=a=>i(c({},\\"__esModule\\",{value:!0}),a);var r=k((T,o)=>{o.exports=_jsx_runtime});var v={};g(v,{default:()=>S,frontmatter:()=>y});var n=w(r()),y={title:\\"Apache Pinot\\\\u2122 0.11 - Inserts from SQL\\",date:new Date(16686432e5),authors:[\\"needham\\"],summary:\\"Explore the INSERT INTO clause, which makes ingesting batch data into Pinot as easy as writing a SQL query.\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"Insert\\"]};function h(a){let e=Object.assign({p:\\"p\\",a:\\"a\\",h2:\\"h2\\",span:\\"span\\",img:\\"img\\",pre:\\"pre\\",code:\\"code\\"},a.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.p,{children:[\\"The Apache Pinot community recently released version \\",(0,n.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/apache-pinot-0-11-released-d564684df5d4\\",children:\\"0.11.0\\"}),\\", which has lots of goodies for you to play with. This is the second in a series of blog posts showing off some of the new features in this release.\\"]}),(0,n.jsxs)(e.p,{children:[\\"In this post, we\\\\u2019re going to explore the \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/data-import/from-query-console\\",children:\\"INSERT INTO clause\\"}),\\", which makes ingesting batch data into Pinot as easy as writing a SQL query.\\"]}),(0,n.jsxs)(e.h2,{id:\\"batch-importing-the-job-specification\\",children:[(0,n.jsx)(e.a,{href:\\"#batch-importing-the-job-specification\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Batch importing: The Job Specification\\"]}),(0,n.jsx)(e.p,{children:\\"The power of this new clause is only fully appreciated if we look at what we had to do before it existed.\\"}),(0,n.jsxs)(e.p,{children:[\\"In the \\",(0,n.jsx)(e.a,{href:\\"https://www.youtube.com/watch?v=1EMBx1XeI9o\\",children:\\"Batch Import JSON from Amazon S3 into Apache Pinot | StarTree Recipes\\"}),\\" video (and \\",(0,n.jsx)(e.a,{href:\\"https://dev.startree.ai/docs/pinot/recipes/ingest-csv-files-from-s3\\",children:\\"accompanying developer guide\\"}),\\"), we showed how to ingest data into Pinot from an S3 bucket.\\"]}),(0,n.jsx)(e.p,{children:\\"The contents of that bucket are shown in the screenshot below:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample data ingested into Apache Pinot from a S3 bucket\\",src:\\"https://www.datocms-assets.com/75153/1668701275-image4.png\\",title:\\"Sample data ingested into Apache Pinot from a S3 bucket\\"})}),(0,n.jsx)(e.p,{children:\\"Let\\\\u2019s quickly recap the steps that we had to do to import those files into Pinot. We have a table called events, which has the following schema:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Events schema table\\",src:\\"https://www.datocms-assets.com/75153/1668701353-image1.png\\",title:\\"Events schema table\\"})}),(0,n.jsx)(e.p,{children:\\"We first created a job specification file, which contains a description of our import job. The job file is shown below:\\"}),(0,n.jsx)(e.pre,{className:\\"language-yaml\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-yaml\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"executionFrameworkSpec\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"name\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'standalone\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"segmentGenerationJobRunnerClassName\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'org.apache.pinot.plugin.ingestion.batch.standalone.SegmentGenerationJobRunner\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"segmentTarPushJobRunnerClassName\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'org.apache.pinot.plugin.ingestion.batch.standalone.SegmentTarPushJobRunner\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"segmentUriPushJobRunnerClassName\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'org.apache.pinot.plugin.ingestion.batch.standalone.SegmentUriPushJobRunner\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"jobType\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),` SegmentCreationAndTarPush\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"inputDirURI\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'s3://marks-st-cloud-bucket/events/\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"includeFileNamePattern\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'glob:**/*.json\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"outputDirURI\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'/data\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"overwriteOutput\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean important\\",children:\\"true\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"pinotFSSpecs\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"scheme\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),` s3\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"className\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),` org.apache.pinot.plugin.filesystem.S3PinotFS\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"configs\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"          \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"region\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'eu-west-2\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"scheme\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),` file\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"className\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),` org.apache.pinot.spi.filesystem.LocalPinotFS\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"recordReaderSpec\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"dataFormat\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'json\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"className\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'org.apache.pinot.plugin.inputformat.json.JSONRecordReader\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"tableSpec\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"tableName\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'events\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"pinotClusterSpecs\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"controllerURI\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'http://${PINOT_CONTROLLER}:9000\'\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"At a high level, this file describes a batch import job that will ingest files from the S3 bucket at s3://marks-st-cloud-bucket/events/ where the files match the glob:**/*.json pattern.\\"}),(0,n.jsx)(e.p,{children:\\"We can import the data by running the following command from the terminal:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--network\\"}),\\" ingest-json-files-s3 \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-v\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token constant environment\\",children:\\"$PWD\\"}),\\"/config:/config \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-e\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token variable assign-left\\",children:\\"AWS_ACCESS_KEY_ID\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\"AKIARCOCT6DWLUB7F77Z \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-e\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token variable assign-left\\",children:\\"AWS_SECRET_ACCESS_KEY\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\"gfz71RX+Tj4udve43YePCBqMsIeN1PvHXrVFyxJS \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  apachepinot/pinot:0.11.0 LaunchDataIngestionJob \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-jobSpecFile\\"}),\\" /config/job-spec.yml \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-values\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token variable assign-left\\",children:\\"PINOT_CONTROLLER\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),`pinot-controller\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"And don\\\\u2019t worry, those credentials have already been deleted; I find it easier to understand what values go where if we use real values.\\"}),(0,n.jsxs)(e.p,{children:[\\"Once we\\\\u2019ve run this command, if we go to the Pinot UI\\\\xA0at \\",(0,n.jsx)(e.a,{href:\\"http://localhost:9000/\\",children:\\"http://localhost:9000\\"}),\\" and click through to the events table from the Query Console menu, we\\\\u2019ll see that the records have been imported, as shown in the screenshot below:\\"]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample imported records shown in the Apache Pinot Query Console menu\\",src:\\"https://www.datocms-assets.com/75153/1668701512-image3.png\\",title:\\"Sample imported records shown in the Apache Pinot Query Console menu\\"})}),(0,n.jsx)(e.p,{children:\\"This approach works, and we may still prefer to use it when we need fine-grained control over the ingestion parameters, but it is a bit heavyweight for your everyday data import!\\"}),(0,n.jsxs)(e.h2,{id:\\"batch-importing-with-sql\\",children:[(0,n.jsx)(e.a,{href:\\"#batch-importing-with-sql\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Batch Importing with SQL\\"]}),(0,n.jsx)(e.p,{children:\\"Now let\\\\u2019s do the same thing in SQL.\\"}),(0,n.jsx)(e.p,{children:\\"There are some prerequisites to using the SQL approach, so let\\\\u2019s go through those now, so you don\\\\u2019t end up with a bunch of exceptions when you try this out!\\"}),(0,n.jsxs)(e.p,{children:[\\"First of all, you must have a \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/components/minion\\",children:\\"Minion\\"}),\\" in the Pinot cluster, as this is the component that will do the data import.\\"]}),(0,n.jsx)(e.p,{children:\\"You\\\\u2019ll also need to include the following in your table config:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"task\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"taskTypeConfigsMap\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"SegmentGenerationAndPushTask\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"As long as you\\\\u2019ve done those two things, we\\\\u2019re ready to write our import query! A query that imports JSON files from my S3 bucket is shown below:\\"}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-sql\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"INSERT\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"INTO\\"}),` events\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FILE\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'s3://marks-st-cloud-bucket/events/\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"OPTION\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  taskName\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\"events\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"-\\"}),\\"task\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  includeFileNamePattern\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\"glob:\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"/\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"json\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  input\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"fs\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"className\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\"org\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"apache\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"pinot\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"plugin\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"filesystem\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"S3PinotFS\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  input\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"fs\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"prop\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"accessKey\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\"AKIARCOCT6DWLUB7F77Z\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  input\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"fs\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"prop\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"secretKey\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\"gfz71RX\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"+\\"}),\\"Tj4udve43YePCBqMsIeN1PvHXrVFyxJS\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  input\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"fs\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"prop\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"region\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\"eu\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"-\\"}),\\"west\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"-\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"2\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"If we run this query, we\\\\u2019ll see the following output:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample events_OFFLINE query result\\",src:\\"https://www.datocms-assets.com/75153/1668701654-image5.png\\",title:\\"Sample events_OFFLINE query result\\"})}),(0,n.jsxs)(e.p,{children:[\\"We can check on the state of the ingestion job via the Swagger REST API. If we navigate to \\",(0,n.jsx)(e.a,{href:\\"http://localhost:9000/help#/Task/getTaskState\\",children:\\"http://localhost:9000/help#/Task/getTaskState\\"}),\\", paste Task_SegmentGenerationAndPushTask_events-task as our task name, and then click Execute, we\\\\u2019ll see the following:\\"]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Checking the state of an ingestion job screen\\",src:\\"https://www.datocms-assets.com/75153/1668701727-image2.png\\",title:\\"Checking the state of an ingestion job screen\\"})}),(0,n.jsx)(e.p,{children:\\"If we see the state COMPLETED, this means the data has been ingested, which we can check by going back to the Query console and clicking on the events table.\\"}),(0,n.jsxs)(e.h2,{id:\\"summary\\",children:[(0,n.jsx)(e.a,{href:\\"#summary\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),(0,n.jsx)(e.p,{children:\\"I have to say that batch ingestion of data into Apache Pinot has always felt a bit clunky, but with this new clause, it\\\\u2019s super easy, and it\\\\u2019s gonna save us all a bunch of time.\\"}),(0,n.jsx)(e.p,{children:\\"Also, anything that means I\\\\u2019m not writing YAML files has got to be a good thing!\\"}),(0,n.jsxs)(e.p,{children:[\\"So give it a try and let us know how you get on. If you have any questions about this feature, feel free to join us on \\",(0,n.jsx)(e.a,{href:\\"https://stree.ai/slack\\",children:\\"Slack\\"}),\\", where we\\\\u2019ll be happy to help you out.\\"]})]})}function b(a={}){let{wrapper:e}=a.components||{};return e?(0,n.jsx)(e,Object.assign({},a,{children:(0,n.jsx)(h,a)})):h(a)}var S=b;return f(v);})();\\n;return Component;"},"_id":"blog/2022-11-17-Apache Pinot-Inserts-from-SQL.mdx","_raw":{"sourceFilePath":"blog/2022-11-17-Apache Pinot-Inserts-from-SQL.mdx","sourceFileName":"2022-11-17-Apache Pinot-Inserts-from-SQL.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2022-11-17-Apache Pinot-Inserts-from-SQL"},"type":"Blog","readingTime":{"text":"4 min read","minutes":3.775,"time":226500,"words":755},"slug":"2022/11/17/Apache Pinot-Inserts-from-SQL","customSlug":"2022/11/17/Apache Pinot-Inserts-from-SQL","path":"blog/2022/11/17/Apache Pinot-Inserts-from-SQL","customPath":"blog/2022/11/17/Apache Pinot-Inserts-from-SQL","filePath":"blog/2022-11-17-Apache Pinot-Inserts-from-SQL.mdx","toc":[{"value":"Batch importing: The Job Specification","url":"#batch-importing-the-job-specification","depth":2},{"value":"Batch Importing with SQL","url":"#batch-importing-with-sql","depth":2},{"value":"Summary","url":"#summary","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Pinot™ 0.11 - Inserts from SQL","datePublished":"2022-11-17T00:00:00.000Z","dateModified":"2022-11-17T00:00:00.000Z","description":"Explore the INSERT INTO clause, which makes ingesting batch data into Pinot as easy as writing a SQL query.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2022-11-17-Apache Pinot-Inserts-from-SQL"}},{"title":"Apache Pinot™ 0.11 - Timestamp Indexes","date":"2022-11-22T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","Timestamp","datetrunc"],"summary":"Users write queries that use the datetrunc function to filter at a coarser grain of functionality. Unfortunately, this approach results in scanning data and time value conversion work that takes a long time at large data volumes. The timestamp index solves that problem!","authors":["needham"],"body":{"raw":"\\n{/* [![Watch the video](https://i3.ytimg.com/vi/DetGpHZuzDU/maxresdefault.jpg)](https://youtu.be/DetGpHZuzDU?si=f0ejecqPBbBK21z-) */}\\n\\n<VideoEmbed src=\\"https://www.youtube.com/embed/DetGpHZuzDU\\" title=\\"YouTube video player\\" />\\n\\nThe recent Apache [Pinot™ 0.11.0](https://medium.com/apache-pinot-developer-blog/apache-pinot-0-11-released-d564684df5d4) release has lots of goodies for you to play with. This is the third in a series of blog posts showing off some of the new features in this release.\\n\\nPinot introduced the TIMESTAMP data type in the 0.8 release, which stores the time in millisecond epoch long format internally. The community feedback has been that the queries they’re running against timestamp columns don’t need this low-level granularity.\\n\\nInstead, users write queries that use the datetrunc function to filter at a coarser grain of functionality. Unfortunately, this approach results in scanning data and time value conversion work that takes a long time at large data volumes.\\n\\nThe [timestamp index](https://docs.pinot.apache.org/basics/indexing/timestamp-index) solves that problem! In this blog post, we’ll use it to get an almost 5x query speed improvement on a relatively small dataset of only 7m rows.\\n\\n![Time in milliseconds with and without timestamp indexes bar chart](https://www.datocms-assets.com/75153/1669133004-image1.png \'Time in milliseconds with and without timestamp indexes bar chart\')\\n\\n## Spinning up Pinot\\n\\nWe’re going to be using the Pinot Docker container, but first, we’re going to create a network, as we’ll need that later on:\\n\\ndocker network create timestamp_blog\\n\\nWe’re going to spin up the empty [QuickStart](https://docs.pinot.apache.org/basics/getting-started/quick-start) in a container named pinot-timestamp-blog:\\n\\n```bash\\ndocker run \\\\\\n  -p 8000:8000 \\\\\\n  -p 9000:9000 \\\\\\n --name pinot-timestamp-blog \\\\\\n  --network timestamp_blog \\\\\\n  apachepinot/pinot:0.11.0 \\\\\\n  QuickStart -type EMPTY\\n```\\n\\nOr if you’re on a Mac M1, change the name of the image to have the arm-64 suffix, like this:\\n\\n```bash\\ndocker run \\\\\\n  -p 8000:8000 \\\\\\n  -p 9000:9000 \\\\\\n    --network timestamp_blog \\\\\\n --name pinot-timestamp-blog \\\\\\n  apachepinot/pinot:0.11.0-arm64 \\\\\\n  QuickStart -type EMPTY\\n```\\n\\nOnce that’s up and running, we’ll be able to access the Pinot Data Explorer at [http://localhost:9000](http://localhost:9000/), but at the moment, we don’t have any data to play with.\\n\\n## Importing Chicago Crime Dataset\\n\\nThe [Chicago Crime dataset](https://startree.ai/blog/analyzing-chicago-crimes-with-apache-pinot-and-streamlit) is a small to medium-sized dataset with 7 million records representing reported crimes in the City of Chicago from 2001 until today.\\n\\nIt contains details of the type of crime, where it was committed, whether an arrest was recorded, which beat it occurred on, and more.\\n\\nEach of the crimes has an associated timestamp, which makes it a good dataset to demonstrate timestamp indexes.\\n\\nYou can find the code used in this blog post in the [Analyzing Chicago Crimes](https://github.com/startreedata/pinot-recipes/tree/main/recipes/analyzing-chicago-crimes) recipe section of [Pinot Recipes GitHub repository](https://github.com/startreedata/pinot-recipes). From here on, I’m assuming that you’ve downloaded this repository and are in the recipes/analyzing-chicago-crimes directory.\\n\\nWe’re going to create a schema and table named crimes by running the following command:\\n\\n```bash\\ndocker run \\\\\\n   --network timestamp_blog \\\\\\n   -v $PWD/config:/config \\\\\\n   apachepinot/pinot:0.11.0-arm64 AddTable \\\\\\n     -schemaFile /config/schema.json \\\\\\n     -tableConfigFile /config/table.json \\\\\\n     -controllerHost pinot-timestamp-blog \\\\\\n    -exec\\n\\n```\\n\\nWe should see the following output:\\n\\n```bash\\n  2022/11/03 13:07:57.169 INFO \\\\[AddTableCommand\\\\] \\\\[main\\\\] {\\"unrecognizedProperties\\":{},\\"status\\":\\"TableConfigs crimes successfully added\\"}\\n```\\n\\nA screenshot of the schema is shown below:\\n\\n![Chicago crime dataset table schema](https://www.datocms-assets.com/75153/1669132979-image3.png \'Chicago crime dataset table schema\')\\n\\nWe won’t go through the table config and schema files in this blog post because we did that in the last post, but you can find them in the [config](https://github.com/startreedata/pinot-recipes/tree/main/recipes/analyzing-chicago-crimes/config) directory on GitHub.\\n\\nNow, let’s import the dataset.\\n\\n```bash\\ndocker run \\\\\\n   --network timestamp_blog \\\\\\n   -v $PWD/config:/config \\\\\\n   -v $PWD/data:/data \\\\\\n   apachepinot/pinot:0.11.0-arm64 LaunchDataIngestionJob \\\\\\n    -jobSpecFile /config/job-spec.yml \\\\\\n     -values controllerHost=pinot-timestamp-blog\\n```\\n\\nIt will take a few minutes to load, but once that command has finished, we’re ready to query the crimes table.\\n\\n## Querying crimes by date\\n\\nThe following query finds the number of crimes that happened after 16th January 2017, grouped by week of the year, with the most crime-filled weeks shown first:\\n\\n```sql\\nselect datetrunc(\'WEEK\', DateEpoch) as tsWeek, count(*)\\nfrom crimes\\nWHERE tsWeek > fromDateTime(\'2017-01-16\', \'yyyy-MM-dd\')\\ngroup by tsWeek\\norder by count(*) DESC\\nlimit 10\\n```\\n\\nIf we run that query, we’ll see the following results:\\n\\n![Chicago crime dataset query result](https://www.datocms-assets.com/75153/1669133027-image6.png \'Chicago crime dataset query result\')\\n\\nAnd, if we look above the query result, there’s metadata about the query, including the time that it took to run.\\n\\n![Chicago crime dataset metadata about the query, including the time that it took to run](https://www.datocms-assets.com/75153/1669133059-image5.png \'Chicago crime dataset metadata about the query, including the time that it took to run\')\\n\\nThe query took 141 ms to execute, so that’s our baseline.\\n\\n## Adding the timestamp index\\n\\nWe could add a timestamp index directly to this table and then compare query performance, but to make it easier to do comparisons, we’re going to create an identical table with the timestamp index applied.\\n\\nThe full table config is available in the [config/table-index.json](https://github.com/startreedata/pinot-recipes/blob/main/recipes/analyzing-chicago-crimes/config/table-index.json) file, and the main change is that we’ve added the following section to add a timestamp index on the DateEpoch column:\\n\\n```json\\n\\"fieldConfigList\\": [\\n  {\\n    \\"name\\": \\"DateEpoch\\",\\n    \\"encodingType\\": \\"DICTIONARY\\",\\n    \\"indexTypes\\": [\\"TIMESTAMP\\"],\\n    \\"timestampConfig\\": {\\n      \\"granularities\\": [\\n        \\"DAY\\",\\n        \\"WEEK\\",\\n        \\"MONTH\\"\\n      ]\\n    }\\n  }\\n],\\n```\\n\\n_encodingType_ will always be ‘DICTIONARY’ and _indexTypes_ must contain ‘TIMESTAMP’. We should specify granularities based on our query patterns.\\n\\nAs a rule of thumb, work out which values you most commonly pass as the first argument to the [datetrunc function](https://docs.pinot.apache.org/configuration-reference/functions/datetrunc) in your queries and include those values.\\n\\nThe full list of valid granularities is: _millisecond_, _second_, _minute_, _hour_, _day_, _week_, _month_, _quarter_, and _year_.\\n\\nOur new table is called crimes_indexed, and we’re also going to create a new schema with all the same columns called crimes_indexed, as Pinot requires the table and schema names to match.\\n\\nWe can create the schema and table by running the following command:\\n\\n```bash\\ndocker run \\\\\\n   --network timestamp_blog \\\\\\n   -v $PWD/config:/config \\\\\\n   apachepinot/pinot:0.11.0-arm64 AddTable \\\\\\n     -schemaFile /config/schema-index.json \\\\\\n     -tableConfigFile /config/table-index.json \\\\\\n     -controllerHost pinot-timestamp-blog \\\\\\n    -exec\\n```\\n\\nWe’ll populate that table by copying the segment that we created earlier for the crimes table.\\n\\n```bash\\ndocker run \\\\\\n   --network timestamp_blog \\\\\\n   -v $PWD/config:/config \\\\\\n   -v $PWD/data:/data \\\\\\n   apachepinot/pinot:0.11.0-arm64 LaunchDataIngestionJob \\\\\\n    -jobSpecFile /config/job-spec-download.yml \\\\\\n     -values controllerHost=pinot-timestamp-blog\\n```\\n\\nIf you’re curious how that job spec works, I [wrote a blog post explaining it in a bit more detail](https://www.markhneedham.com/blog/2021/12/06/apache-pinot-copy-segment-new-table/).\\n\\nOnce the Pinot Server has downloaded this segment, it will apply the timestamp index to the DateEpoch column.\\n\\nFor the curious, we can see this happening in the log files by connecting to the Pinot container and running the following grep command:\\n\\n```bash\\n​​docker exec -iti pinot-timestamp-blog \\\\\\n  grep -rni -A10 \\"Successfully downloaded segment:.*crimes_indexed_OFFLINE.*\\" \\\\\\n  logs/pinot-all.log\\n```\\n\\nWe’ll see something like the following (tidied up for brevity):\\n\\n```log\\n[BaseTableDataManager]  Successfully downloaded segment: crimes_OFFLINE_0 of table: crimes_indexed_OFFLINE to index dir: /tmp/1667490598253/quickstart/PinotServerDataDir0/crimes_indexed_OFFLINE/crimes_OFFLINE_0\\n[V3DefaultColumnHandler]  Starting default column action: ADD_DATE_TIME on column: $DateEpoch$DAY\\n[SegmentDictionaryCreator]  Created dictionary for LONG column: $DateEpoch$DAY with cardinality: 7969, range: 978307200000 to 1666742400000\\n[V3DefaultColumnHandler]  Starting default column action: ADD_DATE_TIME on column: $DateEpoch$WEEK\\n[SegmentDictionaryCreator]  Created dictionary for LONG column: $DateEpoch$WEEK with cardinality: 1139, range: 978307200000 to 1666569600000\\n[V3DefaultColumnHandler]  Starting default column action: ADD_DATE_TIME on column: $DateEpoch$MONTH\\n[SegmentDictionaryCreator]  Created dictionary for LONG column: $DateEpoch$MONTH with cardinality: 262, range: 978307200000 to 1664582400000\\n[RangeIndexHandler]  Creating new range index for segment: crimes_OFFLINE_0, column: $DateEpoch$DAY\\n[RangeIndexHandler]  Created range index for segment: crimes_OFFLINE_0, column: $DateEpoch$DAY\\n[RangeIndexHandler]  Creating new range index for segment: crimes_OFFLINE_0, column: $DateEpoch$WEEK\\n[RangeIndexHandler]  Created range index for segment: crimes_OFFLINE_0, column: $DateEpoch$WEEK\\n\\n```\\n\\n## What does a timestamp index do?\\n\\nSo, the timestamp index has now been created, but what does it actually do?\\n\\nWhen we add a timestamp index on a column, Pinot creates a derived column for each granularity and adds a range index for each new column.\\n\\nIn our case, that means we’ll have these extra columns: $DateEpoch$DAY, $DateEpoch$WEEK, and $DateEpoch$MONTH.\\n\\nWe can check if the extra columns and indexes have been added by navigating to the [segment_page](http://localhost:9000/#/tenants/table/crimes_indexed_OFFLINE/crimes_OFFLINE_0) and typing $Date$Epoch in the search box.\xa0 You should see the following:\\n\\n![Apache Pinot timestamp index on a column](https://www.datocms-assets.com/75153/1669133112-image2.png \'Apache Pinot timestamp index on a column\')\\n\\nThese columns will be assigned the following values:\\n\\n-   $DateEpoch$DAY = dateTrunc(‘DAY’, DateEpoch)\\n-   $DateEpoch$WEEK = dateTrunc(‘WEEK’, DateEpoch)\\n-   $DateEpoch$MONTH = dateTrunc(‘MONTH’, DateEpoch)\\n\\nPinot will also rewrite any queries that use the dateTrunc function with DAY, WEEK, or MONTH and the DateEpoch field to use those new columns.\\n\\nThis means that this query:\\n\\n```sql\\nselect datetrunc(\'WEEK\', DateEpoch) as tsWeek, count(*)\\nfrom crimes_indexed\\nGROUP BY tsWeek\\nlimit 10\\n```\\n\\nWould be rewritten as:\\n\\n```sql\\nselect  $DateEpoch$WEEK as tsWeek, count(*)\\nfrom crimes_indexed\\nGROUP BY tsWeek\\nlimit 10\\n```\\n\\nAnd our query:\\n\\n```sql\\nselect datetrunc(\'WEEK\', DateEpoch) as tsWeek, count(*)\\nfrom crimes\\nWHERE tsWeek > fromDateTime(\'2017-01-16\', \'yyyy-MM-dd\')\\ngroup by tsWeek\\norder by count(*) DESC\\nlimit 10\\n```\\n\\nWould be rewritten as:\\n\\n```sql\\nselect $DateEpoch$WEEK as tsWeek, count(*)\\nfrom crimes\\nWHERE tsWeek > fromDateTime(\'2017-01-16\', \'yyyy-MM-dd\')\\ngroup by tsWeek\\norder by count(*) DESC\\nlimit 10\\n```\\n\\n## Re-running the query\\n\\nLet’s now run our initial query against the _crimes_indexed_ table. We’ll get exactly the same results as before, but let’s take a look at the query stats:\\n\\n![Chicago crime dataset updated query stats](https://www.datocms-assets.com/75153/1669133083-image4.png \'Chicago crime dataset updated query stats\')\\n\\nThis time the query takes 36 milliseconds rather than 140 milliseconds. That’s an almost 5x improvement, thanks to the timestamp index.\\n\\n## Summary\\n\\nHopefully, you’ll agree that timestamp indexes are pretty cool, and achieving a 5x query improvement without much work is always welcome!\\n\\nIf you’re using timestamps in your Pinot tables, be sure to try out this index and let us know how it goes on the [StarTree Community Slack](https://stree.ai/slack) . We’re always happy to help out with any questions or problems you encounter.\\n","code":"var Component=(()=>{var m=Object.create;var t=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,N=Object.prototype.hasOwnProperty;var k=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),g=(n,e)=>{for(var s in e)t(n,s,{get:e[s],enumerable:!0})},i=(n,e,s,l)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let c of p(e))!N.call(n,c)&&c!==s&&t(n,c,{get:()=>e[c],enumerable:!(l=h(e,c))||l.enumerable});return n};var y=(n,e,s)=>(s=n!=null?m(u(n)):{},i(e||!n||!n.__esModule?t(s,\\"default\\",{value:n,enumerable:!0}):s,n)),b=n=>i(t({},\\"__esModule\\",{value:!0}),n);var o=k((T,r)=>{r.exports=_jsx_runtime});var D={};g(D,{default:()=>x,frontmatter:()=>w});var a=y(o()),w={title:\\"Apache Pinot\\\\u2122 0.11 - Timestamp Indexes\\",date:new Date(16690752e5),authors:[\\"needham\\"],summary:\\"Users write queries that use the datetrunc function to filter at a coarser grain of functionality. Unfortunately, this approach results in scanning data and time value conversion work that takes a long time at large data volumes. The timestamp index solves that problem!\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"Timestamp\\",\\"datetrunc\\"]};function d(n){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\",h2:\\"h2\\",span:\\"span\\",pre:\\"pre\\",code:\\"code\\",em:\\"em\\",math:\\"math\\",semantics:\\"semantics\\",mrow:\\"mrow\\",mi:\\"mi\\",annotation:\\"annotation\\",ul:\\"ul\\",li:\\"li\\"},n.components),{VideoEmbed:s}=e;return s||E(\\"VideoEmbed\\",!0),(0,a.jsxs)(a.Fragment,{children:[\\" \\",(0,a.jsx)(s,{src:\\"https://www.youtube.com/embed/DetGpHZuzDU\\",title:\\"YouTube video player\\"}),(0,a.jsxs)(e.p,{children:[\\"The recent Apache \\",(0,a.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/apache-pinot-0-11-released-d564684df5d4\\",children:\\"Pinot\\\\u2122 0.11.0\\"}),\\" release has lots of goodies for you to play with. This is the third in a series of blog posts showing off some of the new features in this release.\\"]}),(0,a.jsx)(e.p,{children:\\"Pinot introduced the TIMESTAMP data type in the 0.8 release, which stores the time in millisecond epoch long format internally. The community feedback has been that the queries they\\\\u2019re running against timestamp columns don\\\\u2019t need this low-level granularity.\\"}),(0,a.jsx)(e.p,{children:\\"Instead, users write queries that use the datetrunc function to filter at a coarser grain of functionality. Unfortunately, this approach results in scanning data and time value conversion work that takes a long time at large data volumes.\\"}),(0,a.jsxs)(e.p,{children:[\\"The \\",(0,a.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/indexing/timestamp-index\\",children:\\"timestamp index\\"}),\\" solves that problem! In this blog post, we\\\\u2019ll use it to get an almost 5x query speed improvement on a relatively small dataset of only 7m rows.\\"]}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Time in milliseconds with and without timestamp indexes bar chart\\",src:\\"https://www.datocms-assets.com/75153/1669133004-image1.png\\",title:\\"Time in milliseconds with and without timestamp indexes bar chart\\"})}),(0,a.jsxs)(e.h2,{id:\\"spinning-up-pinot\\",children:[(0,a.jsx)(e.a,{href:\\"#spinning-up-pinot\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Spinning up Pinot\\"]}),(0,a.jsx)(e.p,{children:\\"We\\\\u2019re going to be using the Pinot Docker container, but first, we\\\\u2019re going to create a network, as we\\\\u2019ll need that later on:\\"}),(0,a.jsx)(e.p,{children:\\"docker network create timestamp_blog\\"}),(0,a.jsxs)(e.p,{children:[\\"We\\\\u2019re going to spin up the empty \\",(0,a.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/getting-started/quick-start\\",children:\\"QuickStart\\"}),\\" in a container named pinot-timestamp-blog:\\"]}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"language-bash code-highlight\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-p\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"8000\\"}),\\":8000 \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-p\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"9000\\"}),\\":9000 \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--name\\"}),\\" pinot-timestamp-blog \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--network\\"}),\\" timestamp_blog \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  apachepinot/pinot:0.11.0 \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  QuickStart \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-type\\"}),` EMPTY\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"Or if you\\\\u2019re on a Mac M1, change the name of the image to have the arm-64 suffix, like this:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"language-bash code-highlight\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-p\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"8000\\"}),\\":8000 \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-p\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"9000\\"}),\\":9000 \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--network\\"}),\\" timestamp_blog \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--name\\"}),\\" pinot-timestamp-blog \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  apachepinot/pinot:0.11.0-arm64 \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  QuickStart \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-type\\"}),` EMPTY\\n`]})]})}),(0,a.jsxs)(e.p,{children:[\\"Once that\\\\u2019s up and running, we\\\\u2019ll be able to access the Pinot Data Explorer at \\",(0,a.jsx)(e.a,{href:\\"http://localhost:9000/\\",children:\\"http://localhost:9000\\"}),\\", but at the moment, we don\\\\u2019t have any data to play with.\\"]}),(0,a.jsxs)(e.h2,{id:\\"importing-chicago-crime-dataset\\",children:[(0,a.jsx)(e.a,{href:\\"#importing-chicago-crime-dataset\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Importing Chicago Crime Dataset\\"]}),(0,a.jsxs)(e.p,{children:[\\"The \\",(0,a.jsx)(e.a,{href:\\"https://startree.ai/blog/analyzing-chicago-crimes-with-apache-pinot-and-streamlit\\",children:\\"Chicago Crime dataset\\"}),\\" is a small to medium-sized dataset with 7 million records representing reported crimes in the City of Chicago from 2001 until today.\\"]}),(0,a.jsx)(e.p,{children:\\"It contains details of the type of crime, where it was committed, whether an arrest was recorded, which beat it occurred on, and more.\\"}),(0,a.jsx)(e.p,{children:\\"Each of the crimes has an associated timestamp, which makes it a good dataset to demonstrate timestamp indexes.\\"}),(0,a.jsxs)(e.p,{children:[\\"You can find the code used in this blog post in the \\",(0,a.jsx)(e.a,{href:\\"https://github.com/startreedata/pinot-recipes/tree/main/recipes/analyzing-chicago-crimes\\",children:\\"Analyzing Chicago Crimes\\"}),\\" recipe section of \\",(0,a.jsx)(e.a,{href:\\"https://github.com/startreedata/pinot-recipes\\",children:\\"Pinot Recipes GitHub repository\\"}),\\". From here on, I\\\\u2019m assuming that you\\\\u2019ve downloaded this repository and are in the recipes/analyzing-chicago-crimes directory.\\"]}),(0,a.jsx)(e.p,{children:\\"We\\\\u2019re going to create a schema and table named crimes by running the following command:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"language-bash code-highlight\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--network\\"}),\\" timestamp_blog \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-v\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token constant environment\\",children:\\"$PWD\\"}),\\"/config:/config \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   apachepinot/pinot:0.11.0-arm64 AddTable \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-schemaFile\\"}),\\" /config/schema.json \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-tableConfigFile\\"}),\\" /config/table.json \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-controllerHost\\"}),\\" pinot-timestamp-blog \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-exec\\"}),`\\n`]}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:`\\n`})]})}),(0,a.jsx)(e.p,{children:\\"We should see the following output:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsx)(e.code,{className:\\"language-bash code-highlight\\",children:(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"2022\\"}),\\"/11/03 \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"13\\"}),\\":07:57.169 INFO \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"AddTableCommand\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"main\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"unrecognizedProperties\\"\'}),\\":\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),\\",\\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"status\\"\'}),(0,a.jsx)(e.span,{className:\\"token builtin class-name\\",children:\\":\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"TableConfigs crimes successfully added\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})})}),(0,a.jsx)(e.p,{children:\\"A screenshot of the schema is shown below:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Chicago crime dataset table schema\\",src:\\"https://www.datocms-assets.com/75153/1669132979-image3.png\\",title:\\"Chicago crime dataset table schema\\"})}),(0,a.jsxs)(e.p,{children:[\\"We won\\\\u2019t go through the table config and schema files in this blog post because we did that in the last post, but you can find them in the \\",(0,a.jsx)(e.a,{href:\\"https://github.com/startreedata/pinot-recipes/tree/main/recipes/analyzing-chicago-crimes/config\\",children:\\"config\\"}),\\" directory on GitHub.\\"]}),(0,a.jsx)(e.p,{children:\\"Now, let\\\\u2019s import the dataset.\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"language-bash code-highlight\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--network\\"}),\\" timestamp_blog \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-v\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token constant environment\\",children:\\"$PWD\\"}),\\"/config:/config \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-v\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token constant environment\\",children:\\"$PWD\\"}),\\"/data:/data \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   apachepinot/pinot:0.11.0-arm64 LaunchDataIngestionJob \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-jobSpecFile\\"}),\\" /config/job-spec.yml \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-values\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token variable assign-left\\",children:\\"controllerHost\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),`pinot-timestamp-blog\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"It will take a few minutes to load, but once that command has finished, we\\\\u2019re ready to query the crimes table.\\"}),(0,a.jsxs)(e.h2,{id:\\"querying-crimes-by-date\\",children:[(0,a.jsx)(e.a,{href:\\"#querying-crimes-by-date\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Querying crimes by date\\"]}),(0,a.jsx)(e.p,{children:\\"The following query finds the number of crimes that happened after 16th January 2017, grouped by week of the year, with the most crime-filled weeks shown first:\\"}),(0,a.jsx)(e.pre,{className:\\"language-sql\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-sql\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" datetrunc\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\\"\'WEEK\'\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" DateEpoch\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" tsWeek\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),` crimes\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),\\" tsWeek \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\">\\"}),\\" fromDateTime\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\\"\'2017-01-16\'\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\\"\'yyyy-MM-dd\'\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"group\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"by\\"}),` tsWeek\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"order\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"by\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"DESC\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"limit\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"10\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"If we run that query, we\\\\u2019ll see the following results:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Chicago crime dataset query result\\",src:\\"https://www.datocms-assets.com/75153/1669133027-image6.png\\",title:\\"Chicago crime dataset query result\\"})}),(0,a.jsx)(e.p,{children:\\"And, if we look above the query result, there\\\\u2019s metadata about the query, including the time that it took to run.\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Chicago crime dataset metadata about the query, including the time that it took to run\\",src:\\"https://www.datocms-assets.com/75153/1669133059-image5.png\\",title:\\"Chicago crime dataset metadata about the query, including the time that it took to run\\"})}),(0,a.jsx)(e.p,{children:\\"The query took 141 ms to execute, so that\\\\u2019s our baseline.\\"}),(0,a.jsxs)(e.h2,{id:\\"adding-the-timestamp-index\\",children:[(0,a.jsx)(e.a,{href:\\"#adding-the-timestamp-index\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Adding the timestamp index\\"]}),(0,a.jsx)(e.p,{children:\\"We could add a timestamp index directly to this table and then compare query performance, but to make it easier to do comparisons, we\\\\u2019re going to create an identical table with the timestamp index applied.\\"}),(0,a.jsxs)(e.p,{children:[\\"The full table config is available in the \\",(0,a.jsx)(e.a,{href:\\"https://github.com/startreedata/pinot-recipes/blob/main/recipes/analyzing-chicago-crimes/config/table-index.json\\",children:\\"config/table-index.json\\"}),\\" file, and the main change is that we\\\\u2019ve added the following section to add a timestamp index on the DateEpoch column:\\"]}),(0,a.jsx)(e.pre,{className:\\"language-json\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"fieldConfigList\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"DateEpoch\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"encodingType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"DICTIONARY\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"indexTypes\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"TIMESTAMP\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"timestampConfig\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"granularities\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"DAY\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"WEEK\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"MONTH\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]})]})}),(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.em,{children:\\"encodingType\\"}),\\" will always be \\\\u2018DICTIONARY\\\\u2019 and \\",(0,a.jsx)(e.em,{children:\\"indexTypes\\"}),\\" must contain \\\\u2018TIMESTAMP\\\\u2019. We should specify granularities based on our query patterns.\\"]}),(0,a.jsxs)(e.p,{children:[\\"As a rule of thumb, work out which values you most commonly pass as the first argument to the \\",(0,a.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/configuration-reference/functions/datetrunc\\",children:\\"datetrunc function\\"}),\\" in your queries and include those values.\\"]}),(0,a.jsxs)(e.p,{children:[\\"The full list of valid granularities is: \\",(0,a.jsx)(e.em,{children:\\"millisecond\\"}),\\", \\",(0,a.jsx)(e.em,{children:\\"second\\"}),\\", \\",(0,a.jsx)(e.em,{children:\\"minute\\"}),\\", \\",(0,a.jsx)(e.em,{children:\\"hour\\"}),\\", \\",(0,a.jsx)(e.em,{children:\\"day\\"}),\\", \\",(0,a.jsx)(e.em,{children:\\"week\\"}),\\", \\",(0,a.jsx)(e.em,{children:\\"month\\"}),\\", \\",(0,a.jsx)(e.em,{children:\\"quarter\\"}),\\", and \\",(0,a.jsx)(e.em,{children:\\"year\\"}),\\".\\"]}),(0,a.jsx)(e.p,{children:\\"Our new table is called crimes_indexed, and we\\\\u2019re also going to create a new schema with all the same columns called crimes_indexed, as Pinot requires the table and schema names to match.\\"}),(0,a.jsx)(e.p,{children:\\"We can create the schema and table by running the following command:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"language-bash code-highlight\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--network\\"}),\\" timestamp_blog \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-v\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token constant environment\\",children:\\"$PWD\\"}),\\"/config:/config \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   apachepinot/pinot:0.11.0-arm64 AddTable \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-schemaFile\\"}),\\" /config/schema-index.json \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-tableConfigFile\\"}),\\" /config/table-index.json \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-controllerHost\\"}),\\" pinot-timestamp-blog \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-exec\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"We\\\\u2019ll populate that table by copying the segment that we created earlier for the crimes table.\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"language-bash code-highlight\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--network\\"}),\\" timestamp_blog \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-v\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token constant environment\\",children:\\"$PWD\\"}),\\"/config:/config \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-v\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token constant environment\\",children:\\"$PWD\\"}),\\"/data:/data \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   apachepinot/pinot:0.11.0-arm64 LaunchDataIngestionJob \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-jobSpecFile\\"}),\\" /config/job-spec-download.yml \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-values\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token variable assign-left\\",children:\\"controllerHost\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),`pinot-timestamp-blog\\n`]})]})}),(0,a.jsxs)(e.p,{children:[\\"If you\\\\u2019re curious how that job spec works, I \\",(0,a.jsx)(e.a,{href:\\"https://www.markhneedham.com/blog/2021/12/06/apache-pinot-copy-segment-new-table/\\",children:\\"wrote a blog post explaining it in a bit more detail\\"}),\\".\\"]}),(0,a.jsx)(e.p,{children:\\"Once the Pinot Server has downloaded this segment, it will apply the timestamp index to the DateEpoch column.\\"}),(0,a.jsx)(e.p,{children:\\"For the curious, we can see this happening in the log files by connecting to the Pinot container and running the following grep command:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"language-bash code-highlight\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"\\\\u200B\\\\u200Bdocker \\",(0,a.jsx)(e.span,{className:\\"token builtin class-name\\",children:\\"exec\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-iti\\"}),\\" pinot-timestamp-blog \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"grep\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-rni\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-A10\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"Successfully downloaded segment:.*crimes_indexed_OFFLINE.*\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:`  logs/pinot-all.log\\n`})]})}),(0,a.jsx)(e.p,{children:\\"We\\\\u2019ll see something like the following (tidied up for brevity):\\"}),(0,a.jsx)(e.pre,{className:\\"language-log\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-log\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"BaseTableDataManager\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\"  \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"Successfully downloaded segment:\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"crimes_OFFLINE_0 of table:\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"crimes_indexed_OFFLINE to index dir:\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string file-path\\",children:\\"/tmp/1667490598253/quickstart/PinotServerDataDir0/crimes_indexed_OFFLINE/crimes_OFFLINE_0\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"V3DefaultColumnHandler\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\"  \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"Starting default column action:\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"ADD_DATE_TIME on column:\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),\\"DateEpoch\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),`DAY\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"SegmentDictionaryCreator\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\"  \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"Created dictionary for LONG column:\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),\\"DateEpoch\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),\\"DAY with cardinality\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"7969\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" range\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"978307200000\\"}),\\" to \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"1666742400000\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"V3DefaultColumnHandler\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\"  \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"Starting default column action:\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"ADD_DATE_TIME on column:\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),\\"DateEpoch\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),`WEEK\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"SegmentDictionaryCreator\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\"  \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"Created dictionary for LONG column:\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),\\"DateEpoch\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),\\"WEEK with cardinality\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"1139\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" range\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"978307200000\\"}),\\" to \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"1666569600000\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"V3DefaultColumnHandler\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\"  \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"Starting default column action:\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"ADD_DATE_TIME on column:\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),\\"DateEpoch\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),`MONTH\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"SegmentDictionaryCreator\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\"  \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"Created dictionary for LONG column:\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),\\"DateEpoch\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),\\"MONTH with cardinality\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"262\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" range\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"978307200000\\"}),\\" to \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"1664582400000\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"RangeIndexHandler\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\"  \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"Creating new range index for segment:\\"}),\\" crimes_OFFLINE_0\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" column\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),\\"DateEpoch\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),`DAY\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"RangeIndexHandler\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\"  \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"Created range index for segment:\\"}),\\" crimes_OFFLINE_0\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" column\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),\\"DateEpoch\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),`DAY\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"RangeIndexHandler\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\"  \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"Creating new range index for segment:\\"}),\\" crimes_OFFLINE_0\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" column\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),\\"DateEpoch\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),`WEEK\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"RangeIndexHandler\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\"  \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\\"Created range index for segment:\\"}),\\" crimes_OFFLINE_0\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" column\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),\\"DateEpoch\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"$\\"}),`WEEK\\n`]}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:`\\n`})]})}),(0,a.jsxs)(e.h2,{id:\\"what-does-a-timestamp-index-do\\",children:[(0,a.jsx)(e.a,{href:\\"#what-does-a-timestamp-index-do\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"What does a timestamp index do?\\"]}),(0,a.jsx)(e.p,{children:\\"So, the timestamp index has now been created, but what does it actually do?\\"}),(0,a.jsx)(e.p,{children:\\"When we add a timestamp index on a column, Pinot creates a derived column for each granularity and adds a range index for each new column.\\"}),(0,a.jsxs)(e.p,{children:[\\"In our case, that means we\\\\u2019ll have these extra columns: \\",(0,a.jsx)(e.span,{className:\\"math math-inline\\",children:(0,a.jsxs)(e.span,{className:\\"katex\\",children:[(0,a.jsx)(e.span,{className:\\"katex-mathml\\",children:(0,a.jsx)(e.math,{xmlns:\\"http://www.w3.org/1998/Math/MathML\\",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mi,{children:\\"D\\"}),(0,a.jsx)(e.mi,{children:\\"a\\"}),(0,a.jsx)(e.mi,{children:\\"t\\"}),(0,a.jsx)(e.mi,{children:\\"e\\"}),(0,a.jsx)(e.mi,{children:\\"E\\"}),(0,a.jsx)(e.mi,{children:\\"p\\"}),(0,a.jsx)(e.mi,{children:\\"o\\"}),(0,a.jsx)(e.mi,{children:\\"c\\"}),(0,a.jsx)(e.mi,{children:\\"h\\"})]}),(0,a.jsx)(e.annotation,{encoding:\\"application/x-tex\\",children:\\"DateEpoch\\"})]})})}),(0,a.jsx)(e.span,{className:\\"katex-html\\",\\"aria-hidden\\":\\"true\\",children:(0,a.jsxs)(e.span,{className:\\"base\\",children:[(0,a.jsx)(e.span,{className:\\"strut\\",style:{height:\\".8889em\\",verticalAlign:\\"-.1944em\\"}}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",style:{marginRight:\\".02778em\\"},children:\\"D\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"a\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"t\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"e\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"Ep\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"oc\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"h\\"})]})})]})}),\\"DAY, \\",(0,a.jsx)(e.span,{className:\\"math math-inline\\",children:(0,a.jsxs)(e.span,{className:\\"katex\\",children:[(0,a.jsx)(e.span,{className:\\"katex-mathml\\",children:(0,a.jsx)(e.math,{xmlns:\\"http://www.w3.org/1998/Math/MathML\\",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mi,{children:\\"D\\"}),(0,a.jsx)(e.mi,{children:\\"a\\"}),(0,a.jsx)(e.mi,{children:\\"t\\"}),(0,a.jsx)(e.mi,{children:\\"e\\"}),(0,a.jsx)(e.mi,{children:\\"E\\"}),(0,a.jsx)(e.mi,{children:\\"p\\"}),(0,a.jsx)(e.mi,{children:\\"o\\"}),(0,a.jsx)(e.mi,{children:\\"c\\"}),(0,a.jsx)(e.mi,{children:\\"h\\"})]}),(0,a.jsx)(e.annotation,{encoding:\\"application/x-tex\\",children:\\"DateEpoch\\"})]})})}),(0,a.jsx)(e.span,{className:\\"katex-html\\",\\"aria-hidden\\":\\"true\\",children:(0,a.jsxs)(e.span,{className:\\"base\\",children:[(0,a.jsx)(e.span,{className:\\"strut\\",style:{height:\\".8889em\\",verticalAlign:\\"-.1944em\\"}}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",style:{marginRight:\\".02778em\\"},children:\\"D\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"a\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"t\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"e\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"Ep\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"oc\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"h\\"})]})})]})}),\\"WEEK, and \\",(0,a.jsx)(e.span,{className:\\"math math-inline\\",children:(0,a.jsxs)(e.span,{className:\\"katex\\",children:[(0,a.jsx)(e.span,{className:\\"katex-mathml\\",children:(0,a.jsx)(e.math,{xmlns:\\"http://www.w3.org/1998/Math/MathML\\",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mi,{children:\\"D\\"}),(0,a.jsx)(e.mi,{children:\\"a\\"}),(0,a.jsx)(e.mi,{children:\\"t\\"}),(0,a.jsx)(e.mi,{children:\\"e\\"}),(0,a.jsx)(e.mi,{children:\\"E\\"}),(0,a.jsx)(e.mi,{children:\\"p\\"}),(0,a.jsx)(e.mi,{children:\\"o\\"}),(0,a.jsx)(e.mi,{children:\\"c\\"}),(0,a.jsx)(e.mi,{children:\\"h\\"})]}),(0,a.jsx)(e.annotation,{encoding:\\"application/x-tex\\",children:\\"DateEpoch\\"})]})})}),(0,a.jsx)(e.span,{className:\\"katex-html\\",\\"aria-hidden\\":\\"true\\",children:(0,a.jsxs)(e.span,{className:\\"base\\",children:[(0,a.jsx)(e.span,{className:\\"strut\\",style:{height:\\".8889em\\",verticalAlign:\\"-.1944em\\"}}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",style:{marginRight:\\".02778em\\"},children:\\"D\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"a\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"t\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"e\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"Ep\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"oc\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"h\\"})]})})]})}),\\"MONTH.\\"]}),(0,a.jsxs)(e.p,{children:[\\"We can check if the extra columns and indexes have been added by navigating to the \\",(0,a.jsx)(e.a,{href:\\"http://localhost:9000/#/tenants/table/crimes_indexed_OFFLINE/crimes_OFFLINE_0\\",children:\\"segment_page\\"}),\\" and typing \\",(0,a.jsx)(e.span,{className:\\"math math-inline\\",children:(0,a.jsxs)(e.span,{className:\\"katex\\",children:[(0,a.jsx)(e.span,{className:\\"katex-mathml\\",children:(0,a.jsx)(e.math,{xmlns:\\"http://www.w3.org/1998/Math/MathML\\",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mi,{children:\\"D\\"}),(0,a.jsx)(e.mi,{children:\\"a\\"}),(0,a.jsx)(e.mi,{children:\\"t\\"}),(0,a.jsx)(e.mi,{children:\\"e\\"})]}),(0,a.jsx)(e.annotation,{encoding:\\"application/x-tex\\",children:\\"Date\\"})]})})}),(0,a.jsx)(e.span,{className:\\"katex-html\\",\\"aria-hidden\\":\\"true\\",children:(0,a.jsxs)(e.span,{className:\\"base\\",children:[(0,a.jsx)(e.span,{className:\\"strut\\",style:{height:\\".6833em\\"}}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",style:{marginRight:\\".02778em\\"},children:\\"D\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"a\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"t\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"e\\"})]})})]})}),\\"Epoch in the search box.\\\\xA0 You should see the following:\\"]}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Apache Pinot timestamp index on a column\\",src:\\"https://www.datocms-assets.com/75153/1669133112-image2.png\\",title:\\"Apache Pinot timestamp index on a column\\"})}),(0,a.jsx)(e.p,{children:\\"These columns will be assigned the following values:\\"}),(0,a.jsxs)(e.ul,{children:[(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.span,{className:\\"math math-inline\\",children:(0,a.jsxs)(e.span,{className:\\"katex\\",children:[(0,a.jsx)(e.span,{className:\\"katex-mathml\\",children:(0,a.jsx)(e.math,{xmlns:\\"http://www.w3.org/1998/Math/MathML\\",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mi,{children:\\"D\\"}),(0,a.jsx)(e.mi,{children:\\"a\\"}),(0,a.jsx)(e.mi,{children:\\"t\\"}),(0,a.jsx)(e.mi,{children:\\"e\\"}),(0,a.jsx)(e.mi,{children:\\"E\\"}),(0,a.jsx)(e.mi,{children:\\"p\\"}),(0,a.jsx)(e.mi,{children:\\"o\\"}),(0,a.jsx)(e.mi,{children:\\"c\\"}),(0,a.jsx)(e.mi,{children:\\"h\\"})]}),(0,a.jsx)(e.annotation,{encoding:\\"application/x-tex\\",children:\\"DateEpoch\\"})]})})}),(0,a.jsx)(e.span,{className:\\"katex-html\\",\\"aria-hidden\\":\\"true\\",children:(0,a.jsxs)(e.span,{className:\\"base\\",children:[(0,a.jsx)(e.span,{className:\\"strut\\",style:{height:\\".8889em\\",verticalAlign:\\"-.1944em\\"}}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",style:{marginRight:\\".02778em\\"},children:\\"D\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"a\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"t\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"e\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"Ep\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"oc\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"h\\"})]})})]})}),\\"DAY = dateTrunc(\\\\u2018DAY\\\\u2019, DateEpoch)\\"]}),(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.span,{className:\\"math math-inline\\",children:(0,a.jsxs)(e.span,{className:\\"katex\\",children:[(0,a.jsx)(e.span,{className:\\"katex-mathml\\",children:(0,a.jsx)(e.math,{xmlns:\\"http://www.w3.org/1998/Math/MathML\\",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mi,{children:\\"D\\"}),(0,a.jsx)(e.mi,{children:\\"a\\"}),(0,a.jsx)(e.mi,{children:\\"t\\"}),(0,a.jsx)(e.mi,{children:\\"e\\"}),(0,a.jsx)(e.mi,{children:\\"E\\"}),(0,a.jsx)(e.mi,{children:\\"p\\"}),(0,a.jsx)(e.mi,{children:\\"o\\"}),(0,a.jsx)(e.mi,{children:\\"c\\"}),(0,a.jsx)(e.mi,{children:\\"h\\"})]}),(0,a.jsx)(e.annotation,{encoding:\\"application/x-tex\\",children:\\"DateEpoch\\"})]})})}),(0,a.jsx)(e.span,{className:\\"katex-html\\",\\"aria-hidden\\":\\"true\\",children:(0,a.jsxs)(e.span,{className:\\"base\\",children:[(0,a.jsx)(e.span,{className:\\"strut\\",style:{height:\\".8889em\\",verticalAlign:\\"-.1944em\\"}}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",style:{marginRight:\\".02778em\\"},children:\\"D\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"a\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"t\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"e\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"Ep\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"oc\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"h\\"})]})})]})}),\\"WEEK = dateTrunc(\\\\u2018WEEK\\\\u2019, DateEpoch)\\"]}),(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.span,{className:\\"math math-inline\\",children:(0,a.jsxs)(e.span,{className:\\"katex\\",children:[(0,a.jsx)(e.span,{className:\\"katex-mathml\\",children:(0,a.jsx)(e.math,{xmlns:\\"http://www.w3.org/1998/Math/MathML\\",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mi,{children:\\"D\\"}),(0,a.jsx)(e.mi,{children:\\"a\\"}),(0,a.jsx)(e.mi,{children:\\"t\\"}),(0,a.jsx)(e.mi,{children:\\"e\\"}),(0,a.jsx)(e.mi,{children:\\"E\\"}),(0,a.jsx)(e.mi,{children:\\"p\\"}),(0,a.jsx)(e.mi,{children:\\"o\\"}),(0,a.jsx)(e.mi,{children:\\"c\\"}),(0,a.jsx)(e.mi,{children:\\"h\\"})]}),(0,a.jsx)(e.annotation,{encoding:\\"application/x-tex\\",children:\\"DateEpoch\\"})]})})}),(0,a.jsx)(e.span,{className:\\"katex-html\\",\\"aria-hidden\\":\\"true\\",children:(0,a.jsxs)(e.span,{className:\\"base\\",children:[(0,a.jsx)(e.span,{className:\\"strut\\",style:{height:\\".8889em\\",verticalAlign:\\"-.1944em\\"}}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",style:{marginRight:\\".02778em\\"},children:\\"D\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"a\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"t\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"e\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"Ep\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"oc\\"}),(0,a.jsx)(e.span,{className:\\"mathnormal mord\\",children:\\"h\\"})]})})]})}),\\"MONTH = dateTrunc(\\\\u2018MONTH\\\\u2019, DateEpoch)\\"]})]}),(0,a.jsx)(e.p,{children:\\"Pinot will also rewrite any queries that use the dateTrunc function with DAY, WEEK, or MONTH and the DateEpoch field to use those new columns.\\"}),(0,a.jsx)(e.p,{children:\\"This means that this query:\\"}),(0,a.jsx)(e.pre,{className:\\"language-sql\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-sql\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" datetrunc\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\\"\'WEEK\'\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" DateEpoch\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" tsWeek\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),` crimes_indexed\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"GROUP\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),` tsWeek\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"limit\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"10\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"Would be rewritten as:\\"}),(0,a.jsx)(e.pre,{className:\\"language-sql\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-sql\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\"  $DateEpoch$WEEK \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" tsWeek\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),` crimes_indexed\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"GROUP\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),` tsWeek\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"limit\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"10\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"And our query:\\"}),(0,a.jsx)(e.pre,{className:\\"language-sql\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-sql\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" datetrunc\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\\"\'WEEK\'\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" DateEpoch\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" tsWeek\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),` crimes\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),\\" tsWeek \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\">\\"}),\\" fromDateTime\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\\"\'2017-01-16\'\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\\"\'yyyy-MM-dd\'\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"group\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"by\\"}),` tsWeek\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"order\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"by\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"DESC\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"limit\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"10\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"Would be rewritten as:\\"}),(0,a.jsx)(e.pre,{className:\\"language-sql\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-sql\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" $DateEpoch$WEEK \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" tsWeek\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),` crimes\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),\\" tsWeek \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\">\\"}),\\" fromDateTime\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\\"\'2017-01-16\'\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\\"\'yyyy-MM-dd\'\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"group\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"by\\"}),` tsWeek\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"order\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"by\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"DESC\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"limit\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"10\\"}),`\\n`]})]})}),(0,a.jsxs)(e.h2,{id:\\"re-running-the-query\\",children:[(0,a.jsx)(e.a,{href:\\"#re-running-the-query\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Re-running the query\\"]}),(0,a.jsxs)(e.p,{children:[\\"Let\\\\u2019s now run our initial query against the \\",(0,a.jsx)(e.em,{children:\\"crimes_indexed\\"}),\\" table. We\\\\u2019ll get exactly the same results as before, but let\\\\u2019s take a look at the query stats:\\"]}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Chicago crime dataset updated query stats\\",src:\\"https://www.datocms-assets.com/75153/1669133083-image4.png\\",title:\\"Chicago crime dataset updated query stats\\"})}),(0,a.jsx)(e.p,{children:\\"This time the query takes 36 milliseconds rather than 140 milliseconds. That\\\\u2019s an almost 5x improvement, thanks to the timestamp index.\\"}),(0,a.jsxs)(e.h2,{id:\\"summary\\",children:[(0,a.jsx)(e.a,{href:\\"#summary\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),(0,a.jsx)(e.p,{children:\\"Hopefully, you\\\\u2019ll agree that timestamp indexes are pretty cool, and achieving a 5x query improvement without much work is always welcome!\\"}),(0,a.jsxs)(e.p,{children:[\\"If you\\\\u2019re using timestamps in your Pinot tables, be sure to try out this index and let us know how it goes on the \\",(0,a.jsx)(e.a,{href:\\"https://stree.ai/slack\\",children:\\"StarTree Community Slack\\"}),\\" . We\\\\u2019re always happy to help out with any questions or problems you encounter.\\"]})]})}function f(n={}){let{wrapper:e}=n.components||{};return e?(0,a.jsx)(e,Object.assign({},n,{children:(0,a.jsx)(d,n)})):d(n)}var x=f;function E(n,e){throw new Error(\\"Expected \\"+(e?\\"component\\":\\"object\\")+\\" `\\"+n+\\"` to be defined: you likely forgot to import, pass, or provide it.\\")}return b(D);})();\\n;return Component;"},"_id":"blog/2022-11-22-Apache-Pinot-Timestamp-Indexes.mdx","_raw":{"sourceFilePath":"blog/2022-11-22-Apache-Pinot-Timestamp-Indexes.mdx","sourceFileName":"2022-11-22-Apache-Pinot-Timestamp-Indexes.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2022-11-22-Apache-Pinot-Timestamp-Indexes"},"type":"Blog","readingTime":{"text":"8 min read","minutes":7.77,"time":466200,"words":1554},"slug":"2022/11/22/Apache-Pinot-Timestamp-Indexes","customSlug":"2022/11/22/Apache-Pinot-Timestamp-Indexes","path":"blog/2022/11/22/Apache-Pinot-Timestamp-Indexes","customPath":"blog/2022/11/22/Apache-Pinot-Timestamp-Indexes","filePath":"blog/2022-11-22-Apache-Pinot-Timestamp-Indexes.mdx","toc":[{"value":"Spinning up Pinot","url":"#spinning-up-pinot","depth":2},{"value":"Importing Chicago Crime Dataset","url":"#importing-chicago-crime-dataset","depth":2},{"value":"Querying crimes by date","url":"#querying-crimes-by-date","depth":2},{"value":"Adding the timestamp index","url":"#adding-the-timestamp-index","depth":2},{"value":"What does a timestamp index do?","url":"#what-does-a-timestamp-index-do","depth":2},{"value":"Re-running the query","url":"#re-running-the-query","depth":2},{"value":"Summary","url":"#summary","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Pinot™ 0.11 - Timestamp Indexes","datePublished":"2022-11-22T00:00:00.000Z","dateModified":"2022-11-22T00:00:00.000Z","description":"Users write queries that use the datetrunc function to filter at a coarser grain of functionality. Unfortunately, this approach results in scanning data and time value conversion work that takes a long time at large data volumes. The timestamp index solves that problem!","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2022-11-22-Apache-Pinot-Timestamp-Indexes"}},{"title":"Apache Pinot™ 0.11 - Pausing Real-Time Ingestion","date":"2022-11-28T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","pause","resume","real-time ingestion"],"summary":"Learn about a feature that lets you pause and resume real-time data ingestion in Apache Pinot","authors":["needham"],"body":{"raw":"\\n[![Watch the video](https://i3.ytimg.com/vi/u9CwDpMZRog/maxresdefault.jpg)](https://youtu.be/u9CwDpMZRog)\\n\\nThe Apache Pinot community recently released version [0.11.0](https://medium.com/apache-pinot-developer-blog/apache-pinot-0-11-released-d564684df5d4), which has lots of goodies for you to play with.\\n\\nIn this post, we will learn about a feature that lets you pause and resume real-time data ingestion. Sajjad Moradi has [also written a blog post about this feature](https://medium.com/apache-pinot-developer-blog/pause-stream-consumption-on-apache-pinot-772a971ef403), so you can treat this post as a complement to that one.\\n\\n## How does real-time ingestion work?\\n\\nBefore we get into this feature, let’s first recap how real-time ingestion works.\\n\\nThis only applies to tables that have the REALTIME type. These tables ingest data that comes in from a streaming platform (e.g., Kafka).\\n\\nPinot servers ingest rows into consuming segments that reside in volatile memory.\\n\\nOnce a segment reaches the [segment threshold,](https://dev.startree.ai/docs/pinot/recipes/configuring-segment-threshold) it will be persisted to disk as a completed segment, and a new consuming segment will be created. This new segment takes over the ingestion of new events from the streaming platform.\\n\\nThe diagram below shows what things might look like when we’re ingesting data from a Kafka topic that has 3 partitions:\\n\\n![Apache pinot 0.11 Real Time Data Ingestion](https://www.datocms-assets.com/75153/1669733133-pinot_0-11-realtime_injestion-diagram-v1.png \'Apache pinot 0.11 Real Time Data Ingestion\')\\n\\nA table has one consuming segment per partition but would have many completed segments.\\n\\n## Why do we need to pause and resume ingestion?\\n\\nThere are many reasons why you might want to pause and resume ingestion of a stream. Some of the common ones are described below:\\n\\n-   There’s a problem with the underlying stream, and we need to restart the server, reset offsets, or recreate a topic\\n-   We want to ingest data from different streams into the same table.\\n-   We made a mistake in our ingestion config in Pinot, and it’s now throwing exceptions and isn’t able to ingest any more data.\\n\\nThe 0.11 release adds the following REST API endpoints:\\n\\n-   `/tables/{tableName}/pauseCompletion`\\n-   `/tables/{tableName}/resumeCompletion`\\n\\nAs the names suggest, these endpoints can be used to pause and resume streaming ingestion for a specific table. This release also adds the `/tables/{tableName}/pauseStatus` endpoint, which returns the pause status for a table.\\n\\nLet’s see how to use this functionality with help from a worked example.\\n\\n## Data Generation\\n\\nLet’s imagine that we want to ingest events generated by the following Python script:\\n\\n```python\\nimport datetime\\nimport uuid\\nimport random\\nimport json\\n\\nwhile True:\\n    ts = datetime.datetime.now().strftime(\\"%Y-%m-%dT%H:%M:%S.%fZ\\")\\n    id = str(uuid.uuid4())\\n    count = random.randint(0, 1000)\\n    print(\\n        json.dumps({\\"tsString\\": ts, \\"uuid\\": id, \\"count\\": count})\\n    )\\n```\\n\\nWe can view the data generated by this script by pasting the above code into a file called datagen.py and then running the following command:\\n\\npython datagen.py 2>/dev/null | head -n3 | jq\\n\\nWe’ll see the following output:\\n\\n```json\\n{\\n  \\"tsString\\": \\"2022-11-23T12:08:44.127481Z\\",\\n  \\"uuid\\": \\"e1c58795-a009-4e21-ae76-cdd66e090797\\",\\n  \\"count\\": 203\\n}\\n{\\n  \\"tsString\\": \\"2022-11-23T12:08:44.127531Z\\",\\n  \\"uuid\\": \\"4eedce04-d995-4e99-82ab-6f836b35c580\\",\\n  \\"count\\": 216\\n}\\n{\\n  \\"tsString\\": \\"2022-11-23T12:08:44.127550Z\\",\\n  \\"uuid\\": \\"6d72411b-55f5-4f9f-84e4-7c8c5c4581ff\\",\\n  \\"count\\": 721\\n}\\n```\\n\\nWe’re going to pipe this data into a Kafka stream called ‘events’ like this:\\n\\npython datagen.py | kcat -P -b localhost:9092 -t events\\n\\nWe’re not setting a key for these messages in Kafka for simplicity’s sake, but Robin Moffat has an [excellent blog post that explains how to do it](https://rmoff.net/2020/09/30/setting-key-value-when-piping-from-jq-to-kafkacat/).\\n\\n## Pinot Schema/Table Config\\n\\nWe want to ingest this data into a Pinot table with the same name. Let’s first define a schema:\\n\\nSchema:\\n\\n```json\\n{\\n    \\"schemaName\\": \\"events\\",\\n    \\"dimensionFieldSpecs\\": [{ \\"name\\": \\"uuid\\", \\"dataType\\": \\"STRING\\" }],\\n    \\"metricFieldSpecs\\": [{ \\"name\\": \\"count\\", \\"dataType\\": \\"INT\\" }],\\n    \\"dateTimeFieldSpecs\\": [\\n        {\\n            \\"name\\": \\"ts\\",\\n            \\"dataType\\": \\"TIMESTAMP\\",\\n            \\"format\\": \\"1:MILLISECONDS:EPOCH\\",\\n            \\"granularity\\": \\"1:MILLISECONDS\\"\\n        }\\n    ]\\n}\\n```\\n\\nNote that the timestamp field is called ts and not tsString, as it is in the Kafka stream. We will transform the DateTime string value held in that field into a proper timestamp using a transformation function.\\n\\nOur table config is described below:\\n\\n```json\\n{\\n    \\"tableName\\": \\"events\\",\\n    \\"tableType\\": \\"REALTIME\\",\\n    \\"segmentsConfig\\": {\\n        \\"timeColumnName\\": \\"ts\\",\\n        \\"schemaName\\": \\"events\\",\\n        \\"replication\\": \\"1\\",\\n        \\"replicasPerPartition\\": \\"1\\"\\n    },\\n    \\"tableIndexConfig\\": {\\n        \\"loadMode\\": \\"MMAP\\",\\n        \\"streamConfigs\\": {\\n            \\"streamType\\": \\"kafka\\",\\n            \\"stream.kafka.topic.name\\": \\"events\\",\\n            \\"stream.kafka.broker.list\\": \\"kafka-pause-resume:9093\\",\\n            \\"stream.kafka.consumer.type\\": \\"lowlevel\\",\\n            \\"stream.kafka.consumer.prop.auto.offset.reset\\": \\"smallest\\",\\n            \\"stream.kafka.consumer.factory.class.name\\": \\"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\\",\\n            \\"stream.kafka.decoder.class.name\\": \\"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\\"\\n        }\\n    },\\n    \\"ingestionConfig\\": {\\n        \\"transformConfigs\\": [\\n            {\\n                \\"columnName\\": \\"ts\\",\\n                \\"transformFunction\\": \\"FromDateTime(tsString, \'YYYY-MM-dd\'\'T\'\'HH:mm:ss.SS\'\'Z\'\'\')\\"\\n            }\\n        ]\\n    },\\n    \\"tenants\\": {},\\n    \\"metadata\\": {}\\n}\\n```\\n\\nOur transformation has a subtle error. The second parameter passed to the FromDateTime function describes the format of the DateTime string, which we defined as:\\n\\nYYYY-MM-dd\'\'T\'\'HH:mm:ss.SS\'\'Z\'\'\\n\\nBut tsString has values in the following format:\\n\\n2022-11-23T12:08:44.127550Z\\n\\ni.e., we don’t have enough S values - there should be 5 rather than 2.\\n\\nIf we create the table using the following command:\\n\\n```bash\\ndocker run \\\\\\n   --network  pause-resume \\\\\\n   -v $PWD/pinot/config:/config \\\\\\n   apachepinot/pinot:0.11.0-arm64 AddTable \\\\\\n     -schemaFile /config/schema.json \\\\\\n     -tableConfigFile /config/table.json \\\\\\n     -controllerHost pinot-controller-pause-resume \\\\\\n    -exec\\n```\\n\\nPinot will immediately start trying to ingest data from Kafka, and it will throw a lot of exceptions that look like this:\\n\\n```log\\njava.lang.RuntimeException: Caught exception while executing function: fromDateTime(tsString,\'YYYY-MM-dd\'T\'HH:mm:ss.SS\'Z\'\')\\n…\\nCaused by: java.lang.IllegalStateException: Caught exception while invoking method: public static long org.apache.pinot.common.function.scalar.DateTimeFunctions.fromDateTime(java.lang.String,java.lang.String) with arguments: [2022-11-23T11:12:34.682504Z, YYYY-MM-dd\'T\'HH:mm:ss.SS\'Z\']\\n\\n```\\n\\nAt this point, we’d usually be stuck and would need to fix the transformation function and then restart the Pinot server. With the pause/resume feature, we can fix this problem without resorting to such drastic measures.\\n\\n## The Pause/Resume Flow\\n\\nInstead, we can follow these steps:\\n\\n-   Pause ingestion for the table\\n-   Fix the transformation function\\n-   Resume ingestion\\n-   Profit $$$\\n\\nWe can pause ingestion by running the following command:\\n\\n```bash\\ncurl -X POST \\\\\\n  \\"http://localhost:9000/tables/events/pauseConsumption\\" \\\\\\n  -H \\"accept: application/json\\"\\n```\\n\\nThe response should be something like this:\\n\\n```json\\n{\\n    \\"pauseFlag\\": true,\\n    \\"consumingSegments\\": [\\"events__0__0__20221123T1106Z\\"],\\n    \\"description\\": \\"Pause flag is set. Consuming segments are being committed. Use /pauseStatus endpoint in a few moments to check if all consuming segments have been committed.\\"\\n}\\n```\\n\\nLet’s follow the response’s advice and check the consuming segments status:\\n\\n```bash\\ncurl -X GET \\\\\\n  \\"http://localhost:9000/tables/events/pauseStatus\\" \\\\\\n  -H \\"accept: application/json\\"\\n```\\n\\nWe’ll see the following response:\\n\\n```json\\n{\\n    \\"pauseFlag\\": true,\\n    \\"consumingSegments\\": []\\n}\\n```\\n\\nSo far, so good. Now we need to fix the table. We have a config, table-fixed.json, that contains a working transformation config. These are the lines of interest:\\n\\n```json\\n{\\n    \\"ingestionConfig\\": {\\n        \\"transformConfigs\\": [\\n            {\\n                \\"columnName\\": \\"ts\\",\\n                \\"transformFunction\\": \\"FromDateTime(tsString, \'YYYY-MM-dd\'\'T\'\'HH:mm:ss.SSSSSS\'\'Z\'\'\')\\"\\n            }\\n        ]\\n    }\\n}\\n```\\n\\nWe now have five S values rather than two, which should sort out our ingestion.\\n\\nUpdate the table config:\\n\\n```bash\\ncurl -X PUT \\"http://localhost:9000/tables/events\\" \\\\\\n -H \\"accept: application/json\\" \\\\\\n -H \\"Content-Type: application/json\\" \\\\\\n -d @pinot/config/table-fixed.json\\n```\\n\\nAnd then resume ingestion. You can pass in the query string parameter consumeFrom, which takes a value of smallest or largest. We’ll pass in smallest since no data has been consumed yet:\\n\\n```bash\\ncurl -X POST \\\\\\n  \\"http://localhost:9000/tables/events/resumeConsumption?consumeFrom=smallest\\" \\\\\\n  -H \\"accept: application/json\\"\\n```\\n\\nThe response will be like this:\\n\\n```json\\n{\\n    \\"pauseFlag\\": false,\\n    \\"consumingSegments\\": [],\\n    \\"description\\": \\"Pause flag is cleared. Consuming segments are being created. Use /pauseStatus endpoint in a few moments to double check.\\"\\n}\\n```\\n\\nAgain, let’s check the consuming segments status:\\n\\n```bash\\ncurl -X GET \\\\\\n  \\"http://localhost:9000/tables/events/pauseStatus\\" \\\\\\n  -H \\"accept: application/json\\"\\n```\\n\\nThis time we will see some consuming segments:\\n\\n```json\\n{\\n    \\"pauseFlag\\": false,\\n    \\"consumingSegments\\": [\\"events__0__22__20221123T1124Z\\"]\\n}\\n```\\n\\nNavigate to [http://localhost:9000/#/query](http://localhost:9000/#/query) and click on the events table. You should see the following:\\n\\n![Sample events table containing records](https://www.datocms-assets.com/75153/1669668611-image2.png \'Sample events table containing records\')\\n\\nWe have records! We can also run our data generator again, and more events will be ingested.\\n\\n## Summary\\n\\nThis feature makes real-time data ingestion a bit more forgiving when things go wrong, which has got to be a good thing in my book.\\n\\nWhen you look at the name of this feature, it can seem a bit esoteric and perhaps not something that you’d want to use, but I think you’ll find it to be extremely useful.\\n\\nSo give it a try and let us know how you get on. If you have any questions about this feature, feel free to join us on [Slack](https://stree.ai/slack), where we’ll be happy to help you out.\\n","code":"var Component=(()=>{var d=Object.create;var t=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,N=Object.prototype.hasOwnProperty;var k=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),g=(a,e)=>{for(var s in e)t(a,s,{get:e[s],enumerable:!0})},i=(a,e,s,l)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let c of m(e))!N.call(a,c)&&c!==s&&t(a,c,{get:()=>e[c],enumerable:!(l=h(e,c))||l.enumerable});return a};var f=(a,e,s)=>(s=a!=null?d(u(a)):{},i(e||!a||!a.__esModule?t(s,\\"default\\",{value:a,enumerable:!0}):s,a)),b=a=>i(t({},\\"__esModule\\",{value:!0}),a);var r=k((j,o)=>{o.exports=_jsx_runtime});var T={};g(T,{default:()=>v,frontmatter:()=>y});var n=f(r()),y={title:\\"Apache Pinot\\\\u2122 0.11 - Pausing Real-Time Ingestion\\",date:new Date(16695936e5),authors:[\\"needham\\"],summary:\\"Learn about a feature that lets you pause and resume real-time data ingestion in Apache Pinot\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"pause\\",\\"resume\\",\\"real-time ingestion\\"]};function p(a){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\",h2:\\"h2\\",span:\\"span\\",ul:\\"ul\\",li:\\"li\\",code:\\"code\\",pre:\\"pre\\"},a.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:(0,n.jsx)(e.a,{href:\\"https://youtu.be/u9CwDpMZRog\\",children:(0,n.jsx)(e.img,{alt:\\"Watch the video\\",src:\\"https://i3.ytimg.com/vi/u9CwDpMZRog/maxresdefault.jpg\\"})})}),(0,n.jsxs)(e.p,{children:[\\"The Apache Pinot community recently released version \\",(0,n.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/apache-pinot-0-11-released-d564684df5d4\\",children:\\"0.11.0\\"}),\\", which has lots of goodies for you to play with.\\"]}),(0,n.jsxs)(e.p,{children:[\\"In this post, we will learn about a feature that lets you pause and resume real-time data ingestion. Sajjad Moradi has \\",(0,n.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/pause-stream-consumption-on-apache-pinot-772a971ef403\\",children:\\"also written a blog post about this feature\\"}),\\", so you can treat this post as a complement to that one.\\"]}),(0,n.jsxs)(e.h2,{id:\\"how-does-real-time-ingestion-work\\",children:[(0,n.jsx)(e.a,{href:\\"#how-does-real-time-ingestion-work\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"How does real-time ingestion work?\\"]}),(0,n.jsx)(e.p,{children:\\"Before we get into this feature, let\\\\u2019s first recap how real-time ingestion works.\\"}),(0,n.jsx)(e.p,{children:\\"This only applies to tables that have the REALTIME type. These tables ingest data that comes in from a streaming platform (e.g., Kafka).\\"}),(0,n.jsx)(e.p,{children:\\"Pinot servers ingest rows into consuming segments that reside in volatile memory.\\"}),(0,n.jsxs)(e.p,{children:[\\"Once a segment reaches the \\",(0,n.jsx)(e.a,{href:\\"https://dev.startree.ai/docs/pinot/recipes/configuring-segment-threshold\\",children:\\"segment threshold,\\"}),\\" it will be persisted to disk as a completed segment, and a new consuming segment will be created. This new segment takes over the ingestion of new events from the streaming platform.\\"]}),(0,n.jsx)(e.p,{children:\\"The diagram below shows what things might look like when we\\\\u2019re ingesting data from a Kafka topic that has 3 partitions:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Apache pinot 0.11 Real Time Data Ingestion\\",src:\\"https://www.datocms-assets.com/75153/1669733133-pinot_0-11-realtime_injestion-diagram-v1.png\\",title:\\"Apache pinot 0.11 Real Time Data Ingestion\\"})}),(0,n.jsx)(e.p,{children:\\"A table has one consuming segment per partition but would have many completed segments.\\"}),(0,n.jsxs)(e.h2,{id:\\"why-do-we-need-to-pause-and-resume-ingestion\\",children:[(0,n.jsx)(e.a,{href:\\"#why-do-we-need-to-pause-and-resume-ingestion\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Why do we need to pause and resume ingestion?\\"]}),(0,n.jsx)(e.p,{children:\\"There are many reasons why you might want to pause and resume ingestion of a stream. Some of the common ones are described below:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"There\\\\u2019s a problem with the underlying stream, and we need to restart the server, reset offsets, or recreate a topic\\"}),(0,n.jsx)(e.li,{children:\\"We want to ingest data from different streams into the same table.\\"}),(0,n.jsx)(e.li,{children:\\"We made a mistake in our ingestion config in Pinot, and it\\\\u2019s now throwing exceptions and isn\\\\u2019t able to ingest any more data.\\"})]}),(0,n.jsx)(e.p,{children:\\"The 0.11 release adds the following REST API endpoints:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:(0,n.jsx)(e.code,{children:\\"/tables/{tableName}/pauseCompletion\\"})}),(0,n.jsx)(e.li,{children:(0,n.jsx)(e.code,{children:\\"/tables/{tableName}/resumeCompletion\\"})})]}),(0,n.jsxs)(e.p,{children:[\\"As the names suggest, these endpoints can be used to pause and resume streaming ingestion for a specific table. This release also adds the \\",(0,n.jsx)(e.code,{children:\\"/tables/{tableName}/pauseStatus\\"}),\\" endpoint, which returns the pause status for a table.\\"]}),(0,n.jsx)(e.p,{children:\\"Let\\\\u2019s see how to use this functionality with help from a worked example.\\"}),(0,n.jsxs)(e.h2,{id:\\"data-generation\\",children:[(0,n.jsx)(e.a,{href:\\"#data-generation\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Data Generation\\"]}),(0,n.jsx)(e.p,{children:\\"Let\\\\u2019s imagine that we want to ingest events generated by the following Python script:\\"}),(0,n.jsx)(e.pre,{className:\\"language-python\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-python\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"import\\"}),` datetime\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"import\\"}),` uuid\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"import\\"}),` random\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"import\\"}),` json\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"while\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"True\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    ts \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" datetime\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"datetime\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"now\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"strftime\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"%Y-%m-%dT%H:%M:%S.%fZ\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token builtin\\",children:\\"id\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token builtin\\",children:\\"str\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"uuid\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"uuid4\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    count \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" random\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"randint\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"0\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1000\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"print\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        json\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"dumps\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"tsString\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" ts\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"uuid\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token builtin\\",children:\\"id\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"count\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" count\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"We can view the data generated by this script by pasting the above code into a file called datagen.py and then running the following command:\\"}),(0,n.jsx)(e.p,{children:\\"python datagen.py 2>/dev/null | head -n3 | jq\\"}),(0,n.jsx)(e.p,{children:\\"We\\\\u2019ll see the following output:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tsString\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"2022-11-23T12:08:44.127481Z\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"uuid\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"e1c58795-a009-4e21-ae76-cdd66e090797\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"count\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"203\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tsString\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"2022-11-23T12:08:44.127531Z\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"uuid\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"4eedce04-d995-4e99-82ab-6f836b35c580\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"count\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"216\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tsString\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"2022-11-23T12:08:44.127550Z\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"uuid\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"6d72411b-55f5-4f9f-84e4-7c8c5c4581ff\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"count\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"721\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"We\\\\u2019re going to pipe this data into a Kafka stream called \\\\u2018events\\\\u2019 like this:\\"}),(0,n.jsx)(e.p,{children:\\"python datagen.py | kcat -P -b localhost:9092 -t events\\"}),(0,n.jsxs)(e.p,{children:[\\"We\\\\u2019re not setting a key for these messages in Kafka for simplicity\\\\u2019s sake, but Robin Moffat has an \\",(0,n.jsx)(e.a,{href:\\"https://rmoff.net/2020/09/30/setting-key-value-when-piping-from-jq-to-kafkacat/\\",children:\\"excellent blog post that explains how to do it\\"}),\\".\\"]}),(0,n.jsxs)(e.h2,{id:\\"pinot-schematable-config\\",children:[(0,n.jsx)(e.a,{href:\\"#pinot-schematable-config\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Pinot Schema/Table Config\\"]}),(0,n.jsx)(e.p,{children:\\"We want to ingest this data into a Pinot table with the same name. Let\\\\u2019s first define a schema:\\"}),(0,n.jsx)(e.p,{children:\\"Schema:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"events\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dimensionFieldSpecs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"uuid\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"metricFieldSpecs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"count\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"INT\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dateTimeFieldSpecs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"TIMESTAMP\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"format\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS:EPOCH\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"granularity\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"Note that the timestamp field is called ts and not tsString, as it is in the Kafka stream. We will transform the DateTime string value held in that field into a proper timestamp using a transformation function.\\"}),(0,n.jsx)(e.p,{children:\\"Our table config is described below:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"events\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"REALTIME\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"segmentsConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"timeColumnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"events\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"replication\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"replicasPerPartition\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableIndexConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"loadMode\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"MMAP\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"streamConfigs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"streamType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"kafka\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.topic.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"events\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.broker.list\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"kafka-pause-resume:9093\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.type\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"lowlevel\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.prop.auto.offset.reset\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"smallest\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.factory.class.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.class.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"ingestionConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformConfigs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"columnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformFunction\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:`\\"FromDateTime(tsString, \'YYYY-MM-dd\'\'T\'\'HH:mm:ss.SS\'\'Z\'\'\')\\"`}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tenants\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"metadata\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"Our transformation has a subtle error. The second parameter passed to the FromDateTime function describes the format of the DateTime string, which we defined as:\\"}),(0,n.jsx)(e.p,{children:\\"YYYY-MM-dd\'\'T\'\'HH:mm:ss.SS\'\'Z\'\'\\"}),(0,n.jsx)(e.p,{children:\\"But tsString has values in the following format:\\"}),(0,n.jsx)(e.p,{children:\\"2022-11-23T12:08:44.127550Z\\"}),(0,n.jsx)(e.p,{children:\\"i.e., we don\\\\u2019t have enough S values - there should be 5 rather than 2.\\"}),(0,n.jsx)(e.p,{children:\\"If we create the table using the following command:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"--network\\"}),\\"  pause-resume \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-v\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token constant environment\\",children:\\"$PWD\\"}),\\"/pinot/config:/config \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   apachepinot/pinot:0.11.0-arm64 AddTable \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-schemaFile\\"}),\\" /config/schema.json \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-tableConfigFile\\"}),\\" /config/table.json \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-controllerHost\\"}),\\" pinot-controller-pause-resume \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-exec\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"Pinot will immediately start trying to ingest data from Kafka, and it will throw a lot of exceptions that look like this:\\"}),(0,n.jsx)(e.pre,{className:\\"language-log\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-log\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token property\\",children:\\"java.lang.RuntimeException:\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\\"Caught exception while executing function:\\"}),\\" fromDateTime\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"(\\"}),\\"tsString\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'YYYY-MM-dd\'\\"}),\\"T\\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'HH:mm:ss.SS\'\\"}),\\"Z\\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'\'\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\")\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\\\u2026\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token property\\",children:\\"Caused by:\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\\"java.lang.IllegalStateException:\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\\"Caught exception while invoking method:\\"}),\\" public static long org\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"apache\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"pinot\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"common\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"function\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"scalar\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"DateTimeFunctions\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"fromDateTime\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"(\\"}),\\"java\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"lang\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"String\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\"java\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"lang\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"String\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\")\\"}),\\" with arguments\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token number date\\",children:\\"2022-11-23T\\"}),(0,n.jsx)(e.span,{className:\\"token number time\\",children:\\"11:12:34.682504Z\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" YYYY\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"-\\"}),\\"MM\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"-\\"}),\\"dd\\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'T\'\\"}),\\"HH\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\"mm\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\"ss\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"SS\\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'Z\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`})]})}),(0,n.jsx)(e.p,{children:\\"At this point, we\\\\u2019d usually be stuck and would need to fix the transformation function and then restart the Pinot server. With the pause/resume feature, we can fix this problem without resorting to such drastic measures.\\"}),(0,n.jsxs)(e.h2,{id:\\"the-pauseresume-flow\\",children:[(0,n.jsx)(e.a,{href:\\"#the-pauseresume-flow\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"The Pause/Resume Flow\\"]}),(0,n.jsx)(e.p,{children:\\"Instead, we can follow these steps:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"Pause ingestion for the table\\"}),(0,n.jsx)(e.li,{children:\\"Fix the transformation function\\"}),(0,n.jsx)(e.li,{children:\\"Resume ingestion\\"}),(0,n.jsx)(e.li,{children:\\"Profit $$$\\"})]}),(0,n.jsx)(e.p,{children:\\"We can pause ingestion by running the following command:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"curl\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-X\\"}),\\" POST \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"http://localhost:9000/tables/events/pauseConsumption\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-H\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"accept: application/json\\"\'}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"The response should be something like this:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"pauseFlag\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"true\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"consumingSegments\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"events__0__0__20221123T1106Z\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"description\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Pause flag is set. Consuming segments are being committed. Use /pauseStatus endpoint in a few moments to check if all consuming segments have been committed.\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"Let\\\\u2019s follow the response\\\\u2019s advice and check the consuming segments status:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"curl\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-X\\"}),\\" GET \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"http://localhost:9000/tables/events/pauseStatus\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-H\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"accept: application/json\\"\'}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"We\\\\u2019ll see the following response:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"pauseFlag\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"true\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"consumingSegments\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"So far, so good. Now we need to fix the table. We have a config, table-fixed.json, that contains a working transformation config. These are the lines of interest:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"ingestionConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformConfigs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"columnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformFunction\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:`\\"FromDateTime(tsString, \'YYYY-MM-dd\'\'T\'\'HH:mm:ss.SSSSSS\'\'Z\'\'\')\\"`}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"We now have five S values rather than two, which should sort out our ingestion.\\"}),(0,n.jsx)(e.p,{children:\\"Update the table config:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"curl\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-X\\"}),\\" PUT \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"http://localhost:9000/tables/events\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-H\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"accept: application/json\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-H\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Content-Type: application/json\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-d\\"}),` @pinot/config/table-fixed.json\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"And then resume ingestion. You can pass in the query string parameter consumeFrom, which takes a value of smallest or largest. We\\\\u2019ll pass in smallest since no data has been consumed yet:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"curl\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-X\\"}),\\" POST \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"http://localhost:9000/tables/events/resumeConsumption?consumeFrom=smallest\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-H\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"accept: application/json\\"\'}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"The response will be like this:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"pauseFlag\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"consumingSegments\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"description\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Pause flag is cleared. Consuming segments are being created. Use /pauseStatus endpoint in a few moments to double check.\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"Again, let\\\\u2019s check the consuming segments status:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"curl\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-X\\"}),\\" GET \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"http://localhost:9000/tables/events/pauseStatus\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-H\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"accept: application/json\\"\'}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"This time we will see some consuming segments:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"pauseFlag\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"consumingSegments\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"events__0__22__20221123T1124Z\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsxs)(e.p,{children:[\\"Navigate to \\",(0,n.jsx)(e.a,{href:\\"http://localhost:9000/#/query\\",children:\\"http://localhost:9000/#/query\\"}),\\" and click on the events table. You should see the following:\\"]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample events table containing records\\",src:\\"https://www.datocms-assets.com/75153/1669668611-image2.png\\",title:\\"Sample events table containing records\\"})}),(0,n.jsx)(e.p,{children:\\"We have records! We can also run our data generator again, and more events will be ingested.\\"}),(0,n.jsxs)(e.h2,{id:\\"summary\\",children:[(0,n.jsx)(e.a,{href:\\"#summary\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),(0,n.jsx)(e.p,{children:\\"This feature makes real-time data ingestion a bit more forgiving when things go wrong, which has got to be a good thing in my book.\\"}),(0,n.jsx)(e.p,{children:\\"When you look at the name of this feature, it can seem a bit esoteric and perhaps not something that you\\\\u2019d want to use, but I think you\\\\u2019ll find it to be extremely useful.\\"}),(0,n.jsxs)(e.p,{children:[\\"So give it a try and let us know how you get on. If you have any questions about this feature, feel free to join us on \\",(0,n.jsx)(e.a,{href:\\"https://stree.ai/slack\\",children:\\"Slack\\"}),\\", where we\\\\u2019ll be happy to help you out.\\"]})]})}function w(a={}){let{wrapper:e}=a.components||{};return e?(0,n.jsx)(e,Object.assign({},a,{children:(0,n.jsx)(p,a)})):p(a)}var v=w;return b(T);})();\\n;return Component;"},"_id":"blog/2022-11-28-Apache-Pinot-Pausing-Real-Time-Ingestion.mdx","_raw":{"sourceFilePath":"blog/2022-11-28-Apache-Pinot-Pausing-Real-Time-Ingestion.mdx","sourceFileName":"2022-11-28-Apache-Pinot-Pausing-Real-Time-Ingestion.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2022-11-28-Apache-Pinot-Pausing-Real-Time-Ingestion"},"type":"Blog","readingTime":{"text":"7 min read","minutes":6.475,"time":388500,"words":1295},"slug":"2022/11/28/Apache-Pinot-Pausing-Real-Time-Ingestion","customSlug":"2022/11/28/Apache-Pinot-Pausing-Real-Time-Ingestion","path":"blog/2022/11/28/Apache-Pinot-Pausing-Real-Time-Ingestion","customPath":"blog/2022/11/28/Apache-Pinot-Pausing-Real-Time-Ingestion","filePath":"blog/2022-11-28-Apache-Pinot-Pausing-Real-Time-Ingestion.mdx","toc":[{"value":"How does real-time ingestion work?","url":"#how-does-real-time-ingestion-work","depth":2},{"value":"Why do we need to pause and resume ingestion?","url":"#why-do-we-need-to-pause-and-resume-ingestion","depth":2},{"value":"Data Generation","url":"#data-generation","depth":2},{"value":"Pinot Schema/Table Config","url":"#pinot-schematable-config","depth":2},{"value":"The Pause/Resume Flow","url":"#the-pauseresume-flow","depth":2},{"value":"Summary","url":"#summary","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Pinot™ 0.11 - Pausing Real-Time Ingestion","datePublished":"2022-11-28T00:00:00.000Z","dateModified":"2022-11-28T00:00:00.000Z","description":"Learn about a feature that lets you pause and resume real-time data ingestion in Apache Pinot","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2022-11-28-Apache-Pinot-Pausing-Real-Time-Ingestion"}},{"title":"Apache Pinot™ 0.11 - Deduplication on Real-Time Tables","date":"2023-01-29T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","deduplication"],"summary":"Learn about the deduplication for the real-time tables feature in Apache Pinot","authors":["needham"],"body":{"raw":"\\nLast fall, the Apache Pinot community released version [0.11.0](https://medium.com/apache-pinot-developer-blog/apache-pinot-0-11-released-d564684df5d4), which has lots of goodies for you to play with.\\n\\nIn this post, we’re going to learn about the [deduplication for the real-time tables feature](https://docs.pinot.apache.org/basics/data-import/dedup).\\n\\n## Why do we need deduplication on real-time tables?\\n\\nThis feature was built to deal with duplicate data in the streaming platform.\\n\\nUsers have previously used the upsert feature to de-duplicate data, but this has the following limitations:\\n\\n-   It forces us to keep redundant records that we don’t want to keep, which increases overall storage costs.\\n-   We can’t yet use the StarTree index with upserts, so the speed benefits we get from using that indexing technique are lost.\\n\\n## How does dedup differ from upserts?\\n\\nBoth upserts and dedup keep track of multiple documents that have the same primary key. They differ as follows:\\n\\n-   Upserts are used when we want to get the latest copy of a document for a given primary key. It’s likely that some or all of the other fields will be different. Pinot stores all documents it receives, but when querying it will only return the latest document for each primary key.\\n-   Dedup is used when we know that multiple documents with the same primary key are identical. Only the first event received for a given primary key is stored in Pinot—any future events with the same primary key are thrown away.\\n\\nLet’s see how to use this functionality with help from a worked example.\\n\\n## Setting up Apache Kafka and Apache Pinot\\n\\nWe’re going to spin up Kafka and Pinot using the following Docker Compose config:\\n\\n```yaml\\nversion: \'3\'\\nservices:\\n    zookeeper:\\n        image: zookeeper:3.8.0\\n        hostname: zookeeper\\n        container_name: zookeeper-dedup-blog\\n        ports:\\n            - \'2181:2181\'\\n        environment:\\n            ZOOKEEPER_CLIENT_PORT: 2181\\n            ZOOKEEPER_TICK_TIME: 2000\\n        networks:\\n            - dedup_blog\\n    kafka:\\n        image: wurstmeister/kafka:latest\\n        restart: unless-stopped\\n        container_name: \'kafka-dedup-blog\'\\n        ports:\\n            - \'9092:9092\'\\n        expose:\\n            - \'9093\'\\n        depends_on:\\n            - zookeeper\\n        environment:\\n            KAFKA_ZOOKEEPER_CONNECT: zookeeper-dedup-blog:2181/kafka\\n            KAFKA_BROKER_ID: 0\\n            KAFKA_ADVERTISED_HOST_NAME: kafka-dedup-blog\\n            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-dedup-blog:9093,OUTSIDE://localhost:9092\\n            KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092\\n            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,OUTSIDE:PLAINTEXT\\n        networks:\\n            - dedup_blog\\n    pinot-controller:\\n        image: apachepinot/pinot:0.11.0-arm64\\n        command: \'QuickStart -type EMPTY\'\\n        container_name: \'pinot-controller-dedup-blog\'\\n        volumes:\\n            - ./config:/config\\n        restart: unless-stopped\\n        ports:\\n            - \'9000:9000\'\\n        networks:\\n            - dedup_blog\\nnetworks:\\n    dedup_blog:\\n        name: dedup_blog\\n```\\n\\nWe can spin up our infrastructure using the following command:\\n\\n```bash\\ndocker-compose up\\n```\\n\\n## Data Generation\\n\\nLet’s imagine that we want to ingest events generated by the following Python script:\\n\\n```python\\nimport datetime\\nimport uuid\\nimport random\\nimport json\\n\\nwhile True:\\n    ts = datetime.datetime.now().strftime(\\"%Y-%m-%dT%H:%M:%S.%fZ\\")\\n    id = str(uuid.uuid4())\\n    count = random.randint(0, 1000)\\n    print(\\n        json.dumps({\\"tsString\\": ts, \\"uuid\\": id[:3], \\"count\\": count})\\n    )\\n```\\n\\nWe can view the data generated by this script by pasting the above code into a file called datagen.py and then running the following command:\\n\\n```bash\\npython datagen.py 2>/dev/null | head -n3 | jq\\n```\\n\\nWe’ll see the following output:\\n\\n```json\\n{\\n  \\"tsString\\": \\"2023-01-03T10:59:17.355081Z\\",\\n  \\"uuid\\": \\"f94\\",\\n  \\"count\\": 541\\n}\\n{\\n  \\"tsString\\": \\"2023-01-03T10:59:17.355125Z\\",\\n  \\"uuid\\": \\"057\\",\\n  \\"count\\": 96\\n}\\n{\\n  \\"tsString\\": \\"2023-01-03T10:59:17.355141Z\\",\\n  \\"uuid\\": \\"d7b\\",\\n  \\"count\\": 288\\n}\\n```\\n\\nIf we generate only 25,000 events, we’ll get some duplicates, which we can see by running the following command:\\n\\n```bash\\npython datagen.py 2>/dev/null  |\\njq -r \'.uuid\' | head -n25000 | uniq -cd\\n```\\n\\nThe results of running that command are shown below:\\n\\n```text\\n2 3a2\\n2 a04\\n2 433\\n2 291\\n2 d73\\n```\\n\\nWe’re going to pipe this data into a Kafka stream called events, like this:\\n\\n```bash\\npython datagen.py 2>/dev/null |\\njq -cr --arg sep \uD83D\uDE0A \'[.uuid, tostring] | join($sep)\' |\\nkcat -P -b localhost:9092 -t events -K\uD83D\uDE0A\\n```\\n\\nThe construction of the key/value structure comes from Robin Moffatt’s [excellent blog post](https://rmoff.net/2020/09/30/setting-key-value-when-piping-from-jq-to-kafkacat/). Since that blog post was written, kcat has started supporting multi byte separators, which is why we can use a smiley face to separate our key and value.\\n\\n## Pinot Schema/Table Config\\n\\nNext, we’re going to create a Pinot table and schema with the same name. Let’s first define a schema:\\n\\n```json\\n{\\n    \\"schemaName\\": \\"events\\",\\n    \\"dimensionFieldSpecs\\": [{ \\"name\\": \\"uuid\\", \\"dataType\\": \\"STRING\\" }],\\n    \\"metricFieldSpecs\\": [{ \\"name\\": \\"count\\", \\"dataType\\": \\"INT\\" }],\\n    \\"dateTimeFieldSpecs\\": [\\n        {\\n            \\"name\\": \\"ts\\",\\n            \\"dataType\\": \\"TIMESTAMP\\",\\n            \\"format\\": \\"1:MILLISECONDS:EPOCH\\",\\n            \\"granularity\\": \\"1:MILLISECONDS\\"\\n        }\\n    ]\\n}\\n```\\n\\nNote that the timestamp field is called ts and not tsString, as it is in the Kafka stream. We’re going to transform the DateTime string value held in that field into a proper timestamp using a transformation function.\\n\\nOur table config is described below:\\n\\n```json\\n{\\n    \\"tableName\\": \\"events\\",\\n    \\"tableType\\": \\"REALTIME\\",\\n    \\"segmentsConfig\\": {\\n        \\"timeColumnName\\": \\"ts\\",\\n        \\"schemaName\\": \\"events\\",\\n        \\"replication\\": \\"1\\",\\n        \\"replicasPerPartition\\": \\"1\\"\\n    },\\n    \\"tableIndexConfig\\": {\\n        \\"loadMode\\": \\"MMAP\\",\\n        \\"streamConfigs\\": {\\n            \\"streamType\\": \\"kafka\\",\\n            \\"stream.kafka.topic.name\\": \\"events\\",\\n            \\"stream.kafka.broker.list\\": \\"kafka-dedup-blog:9093\\",\\n            \\"stream.kafka.consumer.type\\": \\"lowlevel\\",\\n            \\"stream.kafka.consumer.prop.auto.offset.reset\\": \\"smallest\\",\\n            \\"stream.kafka.consumer.factory.class.name\\": \\"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\\",\\n            \\"stream.kafka.decoder.class.name\\": \\"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\\"\\n        }\\n    },\\n    \\"ingestionConfig\\": {\\n        \\"transformConfigs\\": [\\n            {\\n                \\"columnName\\": \\"ts\\",\\n                \\"transformFunction\\": \\"FromDateTime(tsString, \'YYYY-MM-dd\'\'T\'\'HH:mm:ss.SSSSSS\'\'Z\'\'\')\\"\\n            }\\n        ]\\n    },\\n    \\"tenants\\": {},\\n    \\"metadata\\": {}\\n}\\n```\\n\\nLet’s create the table using the following command:\\n\\n```bash\\ndocker run \\\\\\n   --network dedup_blog \\\\\\n   -v $PWD/pinot/config:/config \\\\\\n   apachepinot/pinot:0.11.0-arm64 AddTable \\\\\\n     -schemaFile /config/schema.json \\\\\\n     -tableConfigFile /config/table.json \\\\\\n     -controllerHost \\"pinot-controller-dedup-blog\\" \\\\\\n    -exec\\n```\\n\\nNow we can navigate to [http://localhost:9000](http://localhost:9000/) and run a query that will return a count of the number of each uuid:\\n\\n```sql\\nselect uuid, count(*)\\nfrom events\\ngroup by uuid\\norder by count(*)\\nlimit 10\\n```\\n\\nThe results of this query are shown below:\\n\\n![Sample Apache Pinot real-time query response stats including duplicates](https://www.datocms-assets.com/75153/1673273173-image4.png \'Sample Apache Pinot real-time query response stats including duplicates\')\\n\\nWe can see loads of duplicates!\\n\\nNow let’s add a table and schema that uses the de-duplicate feature, starting with the schema:\\n\\n```json\\n{\\n    \\"schemaName\\": \\"events_dedup\\",\\n    \\"primaryKeyColumns\\": [\\"uuid\\"],\\n    \\"dimensionFieldSpecs\\": [{ \\"name\\": \\"uuid\\", \\"dataType\\": \\"STRING\\" }],\\n    \\"metricFieldSpecs\\": [{ \\"name\\": \\"count\\", \\"dataType\\": \\"INT\\" }],\\n    \\"dateTimeFieldSpecs\\": [\\n        {\\n            \\"name\\": \\"ts\\",\\n            \\"dataType\\": \\"TIMESTAMP\\",\\n            \\"format\\": \\"1:MILLISECONDS:EPOCH\\",\\n            \\"granularity\\": \\"1:MILLISECONDS\\"\\n        }\\n    ]\\n}\\n```\\n\\nThe main difference between this schema and the events schema is that we need to specify a primary key. This key can be any number of fields, but in this case, we’re only using the uuid field.\\n\\nNext, the table config:\\n\\n```json\\n{\\n    \\"tableName\\": \\"events_dedup\\",\\n    \\"tableType\\": \\"REALTIME\\",\\n    \\"segmentsConfig\\": {\\n        \\"timeColumnName\\": \\"ts\\",\\n        \\"schemaName\\": \\"events_dedup\\",\\n        \\"replication\\": \\"1\\",\\n        \\"replicasPerPartition\\": \\"1\\"\\n    },\\n    \\"tableIndexConfig\\": {\\n        \\"loadMode\\": \\"MMAP\\",\\n        \\"streamConfigs\\": {\\n            \\"streamType\\": \\"kafka\\",\\n            \\"stream.kafka.topic.name\\": \\"events\\",\\n            \\"stream.kafka.broker.list\\": \\"kafka-dedup-blog:9093\\",\\n            \\"stream.kafka.consumer.type\\": \\"lowlevel\\",\\n            \\"stream.kafka.consumer.prop.auto.offset.reset\\": \\"smallest\\",\\n            \\"stream.kafka.consumer.factory.class.name\\": \\"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\\",\\n            \\"stream.kafka.decoder.class.name\\": \\"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\\"\\n        }\\n    },\\n    \\"routing\\": { \\"instanceSelectorType\\": \\"strictReplicaGroup\\" },\\n    \\"dedupConfig\\": { \\"dedupEnabled\\": true, \\"hashFunction\\": \\"NONE\\" },\\n    \\"ingestionConfig\\": {\\n        \\"transformConfigs\\": [\\n            {\\n                \\"columnName\\": \\"ts\\",\\n                \\"transformFunction\\": \\"FromDateTime(tsString, \'YYYY-MM-dd\'\'T\'\'HH:mm:ss.SSSSSS\'\'Z\'\'\')\\"\\n            }\\n        ]\\n    },\\n    \\"tenants\\": {},\\n    \\"metadata\\": {}\\n}\\n```\\n\\nThe changes to notice here are:\\n\\n-   `\\"dedupConfig\\": {\\"dedupEnabled\\": true, \\"hashFunction\\": \\"NONE\\"}` - This enables the feature and indicates that we won’t use a hash function on our primary key.\\n-   `\\"routing\\": {\\"instanceSelectorType\\": \\"strictReplicaGroup\\"}` - This makes sure that all segments of the same partition are served from the same server to ensure data consistency across the segments.\\n\\n```bash\\n    docker run \\\\\\n    --network dedup_blog \\\\\\n    -v $PWD/pinot/config:/config \\\\\\n    apachepinot/pinot:0.11.0-arm64 AddTable \\\\\\n        -schemaFile /config/schema-dedup.json \\\\\\n        -tableConfigFile /config/table-dedup.json \\\\\\n        -controllerHost \\"pinot-controller-dedup-blog\\" \\\\\\n        -exec\\n\\n    select uuid, count(*)\\n    from events_dedup\\n    group by uuid\\n    order by count(*)\\n    limit 10\\n```\\n\\n![Sample Apache Pinot real-time query response stats deduplicated](https://www.datocms-assets.com/75153/1673273248-image3.png \'Sample Apache Pinot real-time query response stats deduplicated\')\\n\\nWe have every combination of hex values (16^3=4096) and no duplicates! Pinot’s de-duplication feature has done its job.\\n\\n## How does it work?\xa0\\n\\nWhen we’re not using the deduplication feature, events are ingested from our streaming platform into Pinot, as shown in the diagram below:\\n\\n![Events ingested from a streaming platform into Apache Pinot without using the deduplication feature](https://www.datocms-assets.com/75153/1673273272-pinot_0-11-de-duplication-diagram_1-v2.png \'Events ingested from a streaming platform into Apache Pinot without using the deduplication feature\')\\n\\nWhen de-dup is enabled, we have to check whether records can be ingested, as shown in the diagram below:\\n\\n![Events ingested from a streaming platform into Apache Pinot using the deduplication feature](https://www.datocms-assets.com/75153/1673273289-pinot_0-11-de-duplication-diagram_2-v3.png \'Events ingested from a streaming platform into Apache Pinot using the deduplication feature\')\\n\\nDe-dup works out whether a primary key has already been ingested by using an in memory map of (primary key -> corresponding segment reference).\\n\\nWe need to take that into account when using this feature, otherwise, we’ll end up using all the available memory on the Pinot Server. Below are some tips for using this feature:\\n\\n-   Try to use a simple primary key type and avoid composite keys. If you don’t have a simple primary key, consider using one of the available hash functions to reduce the space taken up.\\n-   Create more partitions in the streaming platform than you might otherwise create. The number of partitions determines the partition numbers of the Pinot table. The more partitions you have in the streaming platform, the more Pinot servers you can distribute the Pinot table to, and the more horizontally scalable the table will be.\\n\\n## Summary\\n\\nThis feature makes it easier to ensure that we don’t end up with duplicate data in our Apache Pinot estate.\\n\\nSo give it a try and let us know how you get on. If you have any questions about this feature, feel free to join us on [Slack](https://stree.ai/slack), where we’ll be happy to help you out.\\n\\nAnd if you’re interested in how this feature was implemented, you can look at the [pull request on GitHub](https://github.com/apache/pinot/pull/8708).\\n","code":"var Component=(()=>{var d=Object.create;var l=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,N=Object.prototype.hasOwnProperty;var k=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),g=(a,e)=>{for(var s in e)l(a,s,{get:e[s],enumerable:!0})},i=(a,e,s,t)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let c of m(e))!N.call(a,c)&&c!==s&&l(a,c,{get:()=>e[c],enumerable:!(t=h(e,c))||t.enumerable});return a};var y=(a,e,s)=>(s=a!=null?d(u(a)):{},i(e||!a||!a.__esModule?l(s,\\"default\\",{value:a,enumerable:!0}):s,a)),f=a=>i(l({},\\"__esModule\\",{value:!0}),a);var r=k((E,o)=>{o.exports=_jsx_runtime});var T={};g(T,{default:()=>v,frontmatter:()=>b});var n=y(r()),b={title:\\"Apache Pinot\\\\u2122 0.11 - Deduplication on Real-Time Tables\\",date:new Date(16749504e5),authors:[\\"needham\\"],summary:\\"Learn about the deduplication for the real-time tables feature in Apache Pinot\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"deduplication\\"]};function p(a){let e=Object.assign({p:\\"p\\",a:\\"a\\",h2:\\"h2\\",span:\\"span\\",ul:\\"ul\\",li:\\"li\\",pre:\\"pre\\",code:\\"code\\",img:\\"img\\"},a.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.p,{children:[\\"Last fall, the Apache Pinot community released version \\",(0,n.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/apache-pinot-0-11-released-d564684df5d4\\",children:\\"0.11.0\\"}),\\", which has lots of goodies for you to play with.\\"]}),(0,n.jsxs)(e.p,{children:[\\"In this post, we\\\\u2019re going to learn about the \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/data-import/dedup\\",children:\\"deduplication for the real-time tables feature\\"}),\\".\\"]}),(0,n.jsxs)(e.h2,{id:\\"why-do-we-need-deduplication-on-real-time-tables\\",children:[(0,n.jsx)(e.a,{href:\\"#why-do-we-need-deduplication-on-real-time-tables\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Why do we need deduplication on real-time tables?\\"]}),(0,n.jsx)(e.p,{children:\\"This feature was built to deal with duplicate data in the streaming platform.\\"}),(0,n.jsx)(e.p,{children:\\"Users have previously used the upsert feature to de-duplicate data, but this has the following limitations:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"It forces us to keep redundant records that we don\\\\u2019t want to keep, which increases overall storage costs.\\"}),(0,n.jsx)(e.li,{children:\\"We can\\\\u2019t yet use the StarTree index with upserts, so the speed benefits we get from using that indexing technique are lost.\\"})]}),(0,n.jsxs)(e.h2,{id:\\"how-does-dedup-differ-from-upserts\\",children:[(0,n.jsx)(e.a,{href:\\"#how-does-dedup-differ-from-upserts\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"How does dedup differ from upserts?\\"]}),(0,n.jsx)(e.p,{children:\\"Both upserts and dedup keep track of multiple documents that have the same primary key. They differ as follows:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"Upserts are used when we want to get the latest copy of a document for a given primary key. It\\\\u2019s likely that some or all of the other fields will be different. Pinot stores all documents it receives, but when querying it will only return the latest document for each primary key.\\"}),(0,n.jsx)(e.li,{children:\\"Dedup is used when we know that multiple documents with the same primary key are identical. Only the first event received for a given primary key is stored in Pinot\\\\u2014any future events with the same primary key are thrown away.\\"})]}),(0,n.jsx)(e.p,{children:\\"Let\\\\u2019s see how to use this functionality with help from a worked example.\\"}),(0,n.jsxs)(e.h2,{id:\\"setting-up-apache-kafka-and-apache-pinot\\",children:[(0,n.jsx)(e.a,{href:\\"#setting-up-apache-kafka-and-apache-pinot\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Setting up Apache Kafka and Apache Pinot\\"]}),(0,n.jsx)(e.p,{children:\\"We\\\\u2019re going to spin up Kafka and Pinot using the following Docker Compose config:\\"}),(0,n.jsx)(e.pre,{className:\\"language-yaml\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-yaml\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"version\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'3\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"services\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"zookeeper\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"image\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" zookeeper\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`3.8.0\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"hostname\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),` zookeeper\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"container_name\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" zookeeper\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),\\"dedup\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),`blog\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"ports\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'2181:2181\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"environment\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"ZOOKEEPER_CLIENT_PORT\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"2181\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"ZOOKEEPER_TICK_TIME\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"2000\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"networks\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),` dedup_blog\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"kafka\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"image\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" wurstmeister/kafka\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`latest\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"restart\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" unless\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),`stopped\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"container_name\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'kafka-dedup-blog\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"ports\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'9092:9092\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"expose\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'9093\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"depends_on\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),` zookeeper\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"environment\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"KAFKA_ZOOKEEPER_CONNECT\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" zookeeper\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),\\"dedup\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),\\"blog\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`2181/kafka\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"KAFKA_BROKER_ID\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"0\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"KAFKA_ADVERTISED_HOST_NAME\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" kafka\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),\\"dedup\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),`blog\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"KAFKA_ADVERTISED_LISTENERS\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" PLAINTEXT\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\"//kafka\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),\\"dedup\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),\\"blog\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"9093\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\"OUTSIDE\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\"//localhost\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"9092\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"KAFKA_LISTENERS\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" PLAINTEXT\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\"//0.0.0.0\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"9093\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\"OUTSIDE\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\"//0.0.0.0\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"9092\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"KAFKA_LISTENER_SECURITY_PROTOCOL_MAP\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" PLAINTEXT\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\"PLAINTEXT\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\"OUTSIDE\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`PLAINTEXT\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"networks\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),` dedup_blog\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"pinot-controller\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"image\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" apachepinot/pinot\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\"0.11.0\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),`arm64\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"command\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'QuickStart -type EMPTY\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"container_name\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'pinot-controller-dedup-blog\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"volumes\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),\\" ./config\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`/config\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"restart\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" unless\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),`stopped\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"ports\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'9000:9000\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"networks\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"-\\"}),` dedup_blog\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"networks\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"dedup_blog\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token atrule key\\",children:\\"name\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),` dedup_blog\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"We can spin up our infrastructure using the following command:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsx)(e.code,{className:\\"code-highlight language-bash\\",children:(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"docker-compose\\"}),` up\\n`]})})}),(0,n.jsxs)(e.h2,{id:\\"data-generation\\",children:[(0,n.jsx)(e.a,{href:\\"#data-generation\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Data Generation\\"]}),(0,n.jsx)(e.p,{children:\\"Let\\\\u2019s imagine that we want to ingest events generated by the following Python script:\\"}),(0,n.jsx)(e.pre,{className:\\"language-python\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-python\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"import\\"}),` datetime\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"import\\"}),` uuid\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"import\\"}),` random\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"import\\"}),` json\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"while\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"True\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    ts \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" datetime\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"datetime\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"now\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"strftime\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"%Y-%m-%dT%H:%M:%S.%fZ\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token builtin\\",children:\\"id\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token builtin\\",children:\\"str\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"uuid\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"uuid4\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    count \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" random\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"randint\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"0\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1000\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"print\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        json\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"dumps\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"tsString\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" ts\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"uuid\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token builtin\\",children:\\"id\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"3\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"count\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" count\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"We can view the data generated by this script by pasting the above code into a file called datagen.py and then running the following command:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsx)(e.code,{className:\\"code-highlight language-bash\\",children:(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"python datagen.py \\",(0,n.jsxs)(e.span,{className:\\"token operator\\",children:[(0,n.jsx)(e.span,{className:\\"token file-descriptor important\\",children:\\"2\\"}),\\">\\"]}),\\"/dev/null \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"head\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-n3\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"|\\"}),` jq\\n`]})})}),(0,n.jsx)(e.p,{children:\\"We\\\\u2019ll see the following output:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tsString\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"2023-01-03T10:59:17.355081Z\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"uuid\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"f94\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"count\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"541\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tsString\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"2023-01-03T10:59:17.355125Z\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"uuid\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"057\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"count\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"96\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tsString\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"2023-01-03T10:59:17.355141Z\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"uuid\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"d7b\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"count\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"288\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"If we generate only 25,000 events, we\\\\u2019ll get some duplicates, which we can see by running the following command:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"python datagen.py \\",(0,n.jsxs)(e.span,{className:\\"token operator\\",children:[(0,n.jsx)(e.span,{className:\\"token file-descriptor important\\",children:\\"2\\"}),\\">\\"]}),\\"/dev/null  \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"|\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"jq \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-r\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'.uuid\'\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"head\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-n25000\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"uniq\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-cd\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"The results of running that command are shown below:\\"}),(0,n.jsx)(e.pre,{className:\\"language-text\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-text\\",children:[(0,n.jsx)(e.span,{className:\\"code-line\\",children:`2 3a2\\n`}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`2 a04\\n`}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`2 433\\n`}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`2 291\\n`}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`2 d73\\n`})]})}),(0,n.jsx)(e.p,{children:\\"We\\\\u2019re going to pipe this data into a Kafka stream called events, like this:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"python datagen.py \\",(0,n.jsxs)(e.span,{className:\\"token operator\\",children:[(0,n.jsx)(e.span,{className:\\"token file-descriptor important\\",children:\\"2\\"}),\\">\\"]}),\\"/dev/null \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"|\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"jq \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-cr\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"--arg\\"}),\\" sep \\\\u{1F60A} \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'[.uuid, tostring] | join($sep)\'\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"|\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"kcat \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-P\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-b\\"}),\\" localhost:9092 \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-t\\"}),` events -K\\\\u{1F60A}\\n`]})]})}),(0,n.jsxs)(e.p,{children:[\\"The construction of the key/value structure comes from Robin Moffatt\\\\u2019s \\",(0,n.jsx)(e.a,{href:\\"https://rmoff.net/2020/09/30/setting-key-value-when-piping-from-jq-to-kafkacat/\\",children:\\"excellent blog post\\"}),\\". Since that blog post was written, kcat has started supporting multi byte separators, which is why we can use a smiley face to separate our key and value.\\"]}),(0,n.jsxs)(e.h2,{id:\\"pinot-schematable-config\\",children:[(0,n.jsx)(e.a,{href:\\"#pinot-schematable-config\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Pinot Schema/Table Config\\"]}),(0,n.jsx)(e.p,{children:\\"Next, we\\\\u2019re going to create a Pinot table and schema with the same name. Let\\\\u2019s first define a schema:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"events\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dimensionFieldSpecs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"uuid\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"metricFieldSpecs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"count\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"INT\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dateTimeFieldSpecs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"TIMESTAMP\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"format\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS:EPOCH\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"granularity\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"Note that the timestamp field is called ts and not tsString, as it is in the Kafka stream. We\\\\u2019re going to transform the DateTime string value held in that field into a proper timestamp using a transformation function.\\"}),(0,n.jsx)(e.p,{children:\\"Our table config is described below:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"events\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"REALTIME\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"segmentsConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"timeColumnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"events\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"replication\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"replicasPerPartition\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableIndexConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"loadMode\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"MMAP\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"streamConfigs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"streamType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"kafka\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.topic.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"events\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.broker.list\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"kafka-dedup-blog:9093\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.type\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"lowlevel\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.prop.auto.offset.reset\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"smallest\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.factory.class.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.class.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"ingestionConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformConfigs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"columnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformFunction\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:`\\"FromDateTime(tsString, \'YYYY-MM-dd\'\'T\'\'HH:mm:ss.SSSSSS\'\'Z\'\'\')\\"`}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tenants\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"metadata\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"Let\\\\u2019s create the table using the following command:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"--network\\"}),\\" dedup_blog \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-v\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token constant environment\\",children:\\"$PWD\\"}),\\"/pinot/config:/config \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   apachepinot/pinot:0.11.0-arm64 AddTable \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-schemaFile\\"}),\\" /config/schema.json \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-tableConfigFile\\"}),\\" /config/table.json \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-controllerHost\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"pinot-controller-dedup-blog\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-exec\\"}),`\\n`]})]})}),(0,n.jsxs)(e.p,{children:[\\"Now we can navigate to \\",(0,n.jsx)(e.a,{href:\\"http://localhost:9000/\\",children:\\"http://localhost:9000\\"}),\\" and run a query that will return a count of the number of each uuid:\\"]}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-sql\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" uuid\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),` events\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"group\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"by\\"}),` uuid\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"order\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"by\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"limit\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"10\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"The results of this query are shown below:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample Apache Pinot real-time query response stats including duplicates\\",src:\\"https://www.datocms-assets.com/75153/1673273173-image4.png\\",title:\\"Sample Apache Pinot real-time query response stats including duplicates\\"})}),(0,n.jsx)(e.p,{children:\\"We can see loads of duplicates!\\"}),(0,n.jsx)(e.p,{children:\\"Now let\\\\u2019s add a table and schema that uses the de-duplicate feature, starting with the schema:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"events_dedup\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"primaryKeyColumns\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"uuid\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dimensionFieldSpecs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"uuid\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"metricFieldSpecs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"count\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"INT\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dateTimeFieldSpecs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"TIMESTAMP\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"format\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS:EPOCH\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"granularity\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"The main difference between this schema and the events schema is that we need to specify a primary key. This key can be any number of fields, but in this case, we\\\\u2019re only using the uuid field.\\"}),(0,n.jsx)(e.p,{children:\\"Next, the table config:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"events_dedup\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"REALTIME\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"segmentsConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"timeColumnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"events_dedup\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"replication\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"replicasPerPartition\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableIndexConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"loadMode\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"MMAP\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"streamConfigs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"streamType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"kafka\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.topic.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"events\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.broker.list\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"kafka-dedup-blog:9093\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.type\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"lowlevel\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.prop.auto.offset.reset\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"smallest\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.factory.class.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.class.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"routing\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"instanceSelectorType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"strictReplicaGroup\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dedupConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dedupEnabled\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"true\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"hashFunction\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"NONE\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"ingestionConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformConfigs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"columnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformFunction\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:`\\"FromDateTime(tsString, \'YYYY-MM-dd\'\'T\'\'HH:mm:ss.SSSSSS\'\'Z\'\'\')\\"`}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tenants\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"metadata\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"The changes to notice here are:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.code,{children:\'\\"dedupConfig\\": {\\"dedupEnabled\\": true, \\"hashFunction\\": \\"NONE\\"}\'}),\\" - This enables the feature and indicates that we won\\\\u2019t use a hash function on our primary key.\\"]}),(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.code,{children:\'\\"routing\\": {\\"instanceSelectorType\\": \\"strictReplicaGroup\\"}\'}),\\" - This makes sure that all segments of the same partition are served from the same server to ensure data consistency across the segments.\\"]})]}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"--network\\"}),\\" dedup_blog \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-v\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token constant environment\\",children:\\"$PWD\\"}),\\"/pinot/config:/config \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    apachepinot/pinot:0.11.0-arm64 AddTable \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-schemaFile\\"}),\\" /config/schema-dedup.json \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-tableConfigFile\\"}),\\" /config/table-dedup.json \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-controllerHost\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"pinot-controller-dedup-blog\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-exec\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" uuid, count\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"*\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`    from events_dedup\\n`}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`    group by uuid\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    order by count\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"*\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    limit \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"10\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample Apache Pinot real-time query response stats deduplicated\\",src:\\"https://www.datocms-assets.com/75153/1673273248-image3.png\\",title:\\"Sample Apache Pinot real-time query response stats deduplicated\\"})}),(0,n.jsx)(e.p,{children:\\"We have every combination of hex values (16^3=4096) and no duplicates! Pinot\\\\u2019s de-duplication feature has done its job.\\"}),(0,n.jsxs)(e.h2,{id:\\"how-does-it-work\\",children:[(0,n.jsx)(e.a,{href:\\"#how-does-it-work\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"How does it work?\\\\xA0\\"]}),(0,n.jsx)(e.p,{children:\\"When we\\\\u2019re not using the deduplication feature, events are ingested from our streaming platform into Pinot, as shown in the diagram below:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Events ingested from a streaming platform into Apache Pinot without using the deduplication feature\\",src:\\"https://www.datocms-assets.com/75153/1673273272-pinot_0-11-de-duplication-diagram_1-v2.png\\",title:\\"Events ingested from a streaming platform into Apache Pinot without using the deduplication feature\\"})}),(0,n.jsx)(e.p,{children:\\"When de-dup is enabled, we have to check whether records can be ingested, as shown in the diagram below:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Events ingested from a streaming platform into Apache Pinot using the deduplication feature\\",src:\\"https://www.datocms-assets.com/75153/1673273289-pinot_0-11-de-duplication-diagram_2-v3.png\\",title:\\"Events ingested from a streaming platform into Apache Pinot using the deduplication feature\\"})}),(0,n.jsx)(e.p,{children:\\"De-dup works out whether a primary key has already been ingested by using an in memory map of (primary key -> corresponding segment reference).\\"}),(0,n.jsx)(e.p,{children:\\"We need to take that into account when using this feature, otherwise, we\\\\u2019ll end up using all the available memory on the Pinot Server. Below are some tips for using this feature:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"Try to use a simple primary key type and avoid composite keys. If you don\\\\u2019t have a simple primary key, consider using one of the available hash functions to reduce the space taken up.\\"}),(0,n.jsx)(e.li,{children:\\"Create more partitions in the streaming platform than you might otherwise create. The number of partitions determines the partition numbers of the Pinot table. The more partitions you have in the streaming platform, the more Pinot servers you can distribute the Pinot table to, and the more horizontally scalable the table will be.\\"})]}),(0,n.jsxs)(e.h2,{id:\\"summary\\",children:[(0,n.jsx)(e.a,{href:\\"#summary\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),(0,n.jsx)(e.p,{children:\\"This feature makes it easier to ensure that we don\\\\u2019t end up with duplicate data in our Apache Pinot estate.\\"}),(0,n.jsxs)(e.p,{children:[\\"So give it a try and let us know how you get on. If you have any questions about this feature, feel free to join us on \\",(0,n.jsx)(e.a,{href:\\"https://stree.ai/slack\\",children:\\"Slack\\"}),\\", where we\\\\u2019ll be happy to help you out.\\"]}),(0,n.jsxs)(e.p,{children:[\\"And if you\\\\u2019re interested in how this feature was implemented, you can look at the \\",(0,n.jsx)(e.a,{href:\\"https://github.com/apache/pinot/pull/8708\\",children:\\"pull request on GitHub\\"}),\\".\\"]})]})}function w(a={}){let{wrapper:e}=a.components||{};return e?(0,n.jsx)(e,Object.assign({},a,{children:(0,n.jsx)(p,a)})):p(a)}var v=w;return f(T);})();\\n;return Component;"},"_id":"blog/2023-01-29-Apache-Pinot-Deduplication-on-Real-Time-Tables.mdx","_raw":{"sourceFilePath":"blog/2023-01-29-Apache-Pinot-Deduplication-on-Real-Time-Tables.mdx","sourceFileName":"2023-01-29-Apache-Pinot-Deduplication-on-Real-Time-Tables.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2023-01-29-Apache-Pinot-Deduplication-on-Real-Time-Tables"},"type":"Blog","readingTime":{"text":"8 min read","minutes":7.395,"time":443700,"words":1479},"slug":"2023/01/29/Apache-Pinot-Deduplication-on-Real-Time-Tables","customSlug":"2023/01/29/Apache-Pinot-Deduplication-on-Real-Time-Tables","path":"blog/2023/01/29/Apache-Pinot-Deduplication-on-Real-Time-Tables","customPath":"blog/2023/01/29/Apache-Pinot-Deduplication-on-Real-Time-Tables","filePath":"blog/2023-01-29-Apache-Pinot-Deduplication-on-Real-Time-Tables.mdx","toc":[{"value":"Why do we need deduplication on real-time tables?","url":"#why-do-we-need-deduplication-on-real-time-tables","depth":2},{"value":"How does dedup differ from upserts?","url":"#how-does-dedup-differ-from-upserts","depth":2},{"value":"Setting up Apache Kafka and Apache Pinot","url":"#setting-up-apache-kafka-and-apache-pinot","depth":2},{"value":"Data Generation","url":"#data-generation","depth":2},{"value":"Pinot Schema/Table Config","url":"#pinot-schematable-config","depth":2},{"value":"How does it work?\xa0","url":"#how-does-it-work","depth":2},{"value":"Summary","url":"#summary","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Pinot™ 0.11 - Deduplication on Real-Time Tables","datePublished":"2023-01-29T00:00:00.000Z","dateModified":"2023-01-29T00:00:00.000Z","description":"Learn about the deduplication for the real-time tables feature in Apache Pinot","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2023-01-29-Apache-Pinot-Deduplication-on-Real-Time-Tables"}},{"title":"Apache Pinot™ 0.12 - Configurable Time Boundary","date":"2023-02-21T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","hybrid tables","time boundary"],"summary":"This post will explore the ability to configure the time boundary when working with hybrid tables.","authors":["needham"],"body":{"raw":"\\n[![Watch the video](https://i3.ytimg.com/vi/lB3RaKJ0Hbs/maxresdefault.jpg)](https://youtu.be/lB3RaKJ0Hbs)\\n\\nThe Apache Pinot community recently released version [0.12.0](https://docs.pinot.apache.org/basics/releases/0.12.0), which has lots of goodies for you to play with. This is the first in a series of blog posts showing off some of the new features in this release.\\n\\nThis post will explore the ability to configure the time boundary when working with hybrid tables.\\n\\n## What is a hybrid table?\\n\\nA hybrid table is the term used to describe a situation where we have an offline and real-time table with the same name. The offline table stores historical data, while the real-time data continuously ingests data from a streaming data platform.\\n\\n## How do you query a hybrid table?\\n\\nWhen you write a query against a hybrid table, the Pinot query engine needs to work out which records to read from the offline table and which to read from the real-time table.\\n\\nIt does this by computing the time boundary, determined by looking at the maximum end time of segments in the offline table and the segment ingestion frequency specified for the offline table.\\n\\n```\\ntimeBoundary = <Maximum end time of offline segments> - <Ingestion Frequency>\\n```\\n\\nThe ingestion frequency can either be 1 hour or 1 day, so one of these values will be used.\\n\\nWhen a query for a hybrid table is received by a Pinot Broker, the broker sends a time boundary annotated version of the query to the offline and real-time tables. Any records from or before the time boundary are read from the offline table; anything greater than the boundary comes from the real-time table.\\n\\n![Apache Pinot computing the time boundary](https://www.datocms-assets.com/75153/1676991003-image2.png \'Apache Pinot computing the time boundary\')\\n\\nFor example, if we executed the following query:\\n\\n```sql\\nSELECT count(*)\\nFROM events\\n```\\n\\nThe broker would send the following query to the offline table:\\n\\n```sql\\nSELECT count(*)\\nFROM events_OFFLINE\\nWHERE timeColumn <= $timeBoundary\\n```\\n\\nAnd the following query to the real-time table:\\n\\n```sql\\nSELECT count(*)\\nFROM events_REALTIME\\nWHERE timeColumn > $timeBoundary\\n```\\n\\nThe results of the two queries are merged by the broker before being returned to the client.\\n\\n## So, what’s the problem?\\n\\nIf we have some overlap in the data in our offline and real-time tables, this approach works well, but if we have no overlap, we will end up with unexpected results.\\n\\nFor example, let’s say that the most recent timestamp in the events offline table is 2023-01-09T18:41:17, our ingestion frequency is 1 hour, and the real-time table has data starting from 2023-01-09T18:41:18.\\n\\nThis will result in a boundary time of 2023-01-09T17:41:17, which means that any records with timestamps between 17:41 and 18:41 will be excluded from query results.\\n\\n## And the solution?\\n\\nThe 0.12 release sees the addition of the `tables/{tableName}/timeBoundary` API, which lets us set the time boundary to the maximum end time of all offline segments.\\n\\n```bash\\ncurl -X POST \\\\\\n  \\"http://localhost:9000/tables/{tableName}/timeBoundary\\" \\\\\\n  -H \\"accept: application/json\\"\\n```\\n\\nIn this case, that will result in a new boundary time of 2023-01-09T18:41:17, which is exactly what we need.\\n\\nWe’ll then be able to query the events table and have it read the offline table to get all records on or before 2023-01-09T18:41:17 and the real-time table for everything else.\\n\\n## Neat, anything else I should know?\\n\\nSomething to keep in mind when updating the time boundary is that it’s a one-off operation. It won’t be automatically updated if you add a new, more recent segment to the offline table.\\n\\nIn this scenario, you need to call the `tables/{tableName}/timeBoundary` API again.\\n\\nAnd if you want to revert to the previous behavior where the time boundary is computed by subtracting the ingestion frequency from the latest end time, you can do that too:\\n\\n```bash\\ncurl -X DELETE \\\\\\n  \\"http://localhost:9000/tables/{tableName}/timeBoundary\\" \\\\\\n  -H \\"accept: application/json\\"\\n```\\n\\n## Summary\\n\\nI love this feature, and it solves a problem I’ve struggled with when using my datasets. I hope you’ll find it just as useful.\\n\\nGive it a try, and let us know how you get on. If you have any questions about this feature, feel free to join us on [Slack](https://stree.ai/slack), where we’ll be happy to help you out.\\n","code":"var Component=(()=>{var d=Object.create;var i=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,b=Object.prototype.hasOwnProperty;var y=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),f=(n,e)=>{for(var t in e)i(n,t,{get:e[t],enumerable:!0})},o=(n,e,t,l)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let s of p(e))!b.call(n,s)&&s!==t&&i(n,s,{get:()=>e[s],enumerable:!(l=m(e,s))||l.enumerable});return n};var g=(n,e,t)=>(t=n!=null?d(u(n)):{},o(e||!n||!n.__esModule?i(t,\\"default\\",{value:n,enumerable:!0}):t,n)),N=n=>o(i({},\\"__esModule\\",{value:!0}),n);var c=y((T,r)=>{r.exports=_jsx_runtime});var x={};f(x,{default:()=>v,frontmatter:()=>w});var a=g(c()),w={title:\\"Apache Pinot\\\\u2122 0.12 - Configurable Time Boundary\\",date:new Date(16769376e5),authors:[\\"needham\\"],summary:\\"This post will explore the ability to configure the time boundary when working with hybrid tables.\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"hybrid tables\\",\\"time boundary\\"]};function h(n){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\",h2:\\"h2\\",span:\\"span\\",pre:\\"pre\\",code:\\"code\\"},n.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.p,{children:(0,a.jsx)(e.a,{href:\\"https://youtu.be/lB3RaKJ0Hbs\\",children:(0,a.jsx)(e.img,{alt:\\"Watch the video\\",src:\\"https://i3.ytimg.com/vi/lB3RaKJ0Hbs/maxresdefault.jpg\\"})})}),(0,a.jsxs)(e.p,{children:[\\"The Apache Pinot community recently released version \\",(0,a.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/releases/0.12.0\\",children:\\"0.12.0\\"}),\\", which has lots of goodies for you to play with. This is the first in a series of blog posts showing off some of the new features in this release.\\"]}),(0,a.jsx)(e.p,{children:\\"This post will explore the ability to configure the time boundary when working with hybrid tables.\\"}),(0,a.jsxs)(e.h2,{id:\\"what-is-a-hybrid-table\\",children:[(0,a.jsx)(e.a,{href:\\"#what-is-a-hybrid-table\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"What is a hybrid table?\\"]}),(0,a.jsx)(e.p,{children:\\"A hybrid table is the term used to describe a situation where we have an offline and real-time table with the same name. The offline table stores historical data, while the real-time data continuously ingests data from a streaming data platform.\\"}),(0,a.jsxs)(e.h2,{id:\\"how-do-you-query-a-hybrid-table\\",children:[(0,a.jsx)(e.a,{href:\\"#how-do-you-query-a-hybrid-table\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"How do you query a hybrid table?\\"]}),(0,a.jsx)(e.p,{children:\\"When you write a query against a hybrid table, the Pinot query engine needs to work out which records to read from the offline table and which to read from the real-time table.\\"}),(0,a.jsx)(e.p,{children:\\"It does this by computing the time boundary, determined by looking at the maximum end time of segments in the offline table and the segment ingestion frequency specified for the offline table.\\"}),(0,a.jsx)(e.pre,{className:\\"language-js\\",children:(0,a.jsx)(e.code,{className:\\"code-highlight language-js\\",children:(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"timeBoundary \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"<\\"}),(0,a.jsx)(e.span,{className:\\"token maybe-class-name\\",children:\\"Maximum\\"}),\\" end time \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"of\\"}),\\" offline segments\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\">\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"-\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"<\\"}),(0,a.jsx)(e.span,{className:\\"token maybe-class-name\\",children:\\"Ingestion\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token maybe-class-name\\",children:\\"Frequency\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\">\\"}),`\\n`]})})}),(0,a.jsx)(e.p,{children:\\"The ingestion frequency can either be 1 hour or 1 day, so one of these values will be used.\\"}),(0,a.jsx)(e.p,{children:\\"When a query for a hybrid table is received by a Pinot Broker, the broker sends a time boundary annotated version of the query to the offline and real-time tables. Any records from or before the time boundary are read from the offline table; anything greater than the boundary comes from the real-time table.\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Apache Pinot computing the time boundary\\",src:\\"https://www.datocms-assets.com/75153/1676991003-image2.png\\",title:\\"Apache Pinot computing the time boundary\\"})}),(0,a.jsx)(e.p,{children:\\"For example, if we executed the following query:\\"}),(0,a.jsx)(e.pre,{className:\\"language-sql\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-sql\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"SELECT\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),` events\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"The broker would send the following query to the offline table:\\"}),(0,a.jsx)(e.pre,{className:\\"language-sql\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-sql\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"SELECT\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),` events_OFFLINE\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),\\" timeColumn \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"<=\\"}),` $timeBoundary\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"And the following query to the real-time table:\\"}),(0,a.jsx)(e.pre,{className:\\"language-sql\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-sql\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"SELECT\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),` events_REALTIME\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),\\" timeColumn \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\">\\"}),` $timeBoundary\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"The results of the two queries are merged by the broker before being returned to the client.\\"}),(0,a.jsxs)(e.h2,{id:\\"so-whats-the-problem\\",children:[(0,a.jsx)(e.a,{href:\\"#so-whats-the-problem\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"So, what\\\\u2019s the problem?\\"]}),(0,a.jsx)(e.p,{children:\\"If we have some overlap in the data in our offline and real-time tables, this approach works well, but if we have no overlap, we will end up with unexpected results.\\"}),(0,a.jsx)(e.p,{children:\\"For example, let\\\\u2019s say that the most recent timestamp in the events offline table is 2023-01-09T18:41:17, our ingestion frequency is 1 hour, and the real-time table has data starting from 2023-01-09T18:41:18.\\"}),(0,a.jsx)(e.p,{children:\\"This will result in a boundary time of 2023-01-09T17:41:17, which means that any records with timestamps between 17:41 and 18:41 will be excluded from query results.\\"}),(0,a.jsxs)(e.h2,{id:\\"and-the-solution\\",children:[(0,a.jsx)(e.a,{href:\\"#and-the-solution\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"And the solution?\\"]}),(0,a.jsxs)(e.p,{children:[\\"The 0.12 release sees the addition of the \\",(0,a.jsx)(e.code,{children:\\"tables/{tableName}/timeBoundary\\"}),\\" API, which lets us set the time boundary to the maximum end time of all offline segments.\\"]}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"curl\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-X\\"}),\\" POST \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"http://localhost:9000/tables/{tableName}/timeBoundary\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-H\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"accept: application/json\\"\'}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"In this case, that will result in a new boundary time of 2023-01-09T18:41:17, which is exactly what we need.\\"}),(0,a.jsx)(e.p,{children:\\"We\\\\u2019ll then be able to query the events table and have it read the offline table to get all records on or before 2023-01-09T18:41:17 and the real-time table for everything else.\\"}),(0,a.jsxs)(e.h2,{id:\\"neat-anything-else-i-should-know\\",children:[(0,a.jsx)(e.a,{href:\\"#neat-anything-else-i-should-know\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Neat, anything else I should know?\\"]}),(0,a.jsx)(e.p,{children:\\"Something to keep in mind when updating the time boundary is that it\\\\u2019s a one-off operation. It won\\\\u2019t be automatically updated if you add a new, more recent segment to the offline table.\\"}),(0,a.jsxs)(e.p,{children:[\\"In this scenario, you need to call the \\",(0,a.jsx)(e.code,{children:\\"tables/{tableName}/timeBoundary\\"}),\\" API again.\\"]}),(0,a.jsx)(e.p,{children:\\"And if you want to revert to the previous behavior where the time boundary is computed by subtracting the ingestion frequency from the latest end time, you can do that too:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"curl\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-X\\"}),\\" DELETE \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"http://localhost:9000/tables/{tableName}/timeBoundary\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-H\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"accept: application/json\\"\'}),`\\n`]})]})}),(0,a.jsxs)(e.h2,{id:\\"summary\\",children:[(0,a.jsx)(e.a,{href:\\"#summary\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),(0,a.jsx)(e.p,{children:\\"I love this feature, and it solves a problem I\\\\u2019ve struggled with when using my datasets. I hope you\\\\u2019ll find it just as useful.\\"}),(0,a.jsxs)(e.p,{children:[\\"Give it a try, and let us know how you get on. If you have any questions about this feature, feel free to join us on \\",(0,a.jsx)(e.a,{href:\\"https://stree.ai/slack\\",children:\\"Slack\\"}),\\", where we\\\\u2019ll be happy to help you out.\\"]})]})}function k(n={}){let{wrapper:e}=n.components||{};return e?(0,a.jsx)(e,Object.assign({},n,{children:(0,a.jsx)(h,n)})):h(n)}var v=k;return N(x);})();\\n;return Component;"},"_id":"blog/2023-02-21-Apache-Pinot-0-12-Configurable-Time-Boundary.mdx","_raw":{"sourceFilePath":"blog/2023-02-21-Apache-Pinot-0-12-Configurable-Time-Boundary.mdx","sourceFileName":"2023-02-21-Apache-Pinot-0-12-Configurable-Time-Boundary.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2023-02-21-Apache-Pinot-0-12-Configurable-Time-Boundary"},"type":"Blog","readingTime":{"text":"4 min read","minutes":3.415,"time":204900,"words":683},"slug":"2023/02/21/Apache-Pinot-0-12-Configurable-Time-Boundary","customSlug":"2023/02/21/Apache-Pinot-0-12-Configurable-Time-Boundary","path":"blog/2023/02/21/Apache-Pinot-0-12-Configurable-Time-Boundary","customPath":"blog/2023/02/21/Apache-Pinot-0-12-Configurable-Time-Boundary","filePath":"blog/2023-02-21-Apache-Pinot-0-12-Configurable-Time-Boundary.mdx","toc":[{"value":"What is a hybrid table?","url":"#what-is-a-hybrid-table","depth":2},{"value":"How do you query a hybrid table?","url":"#how-do-you-query-a-hybrid-table","depth":2},{"value":"So, what’s the problem?","url":"#so-whats-the-problem","depth":2},{"value":"And the solution?","url":"#and-the-solution","depth":2},{"value":"Neat, anything else I should know?","url":"#neat-anything-else-i-should-know","depth":2},{"value":"Summary","url":"#summary","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Pinot™ 0.12 - Configurable Time Boundary","datePublished":"2023-02-21T00:00:00.000Z","dateModified":"2023-02-21T00:00:00.000Z","description":"This post will explore the ability to configure the time boundary when working with hybrid tables.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2023-02-21-Apache-Pinot-0-12-Configurable-Time-Boundary"}},{"title":"Apache Pinot™ 0.12 - Consumer Record Lag","date":"2023-03-30T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","consumer record lag","kafka"],"summary":"This post will explore a new API endpoint that lets you check how much Pinot is lagging when ingesting from Apache Kafka.","authors":["needham"],"body":{"raw":"\\n[![Watch the video](https://i3.ytimg.com/vi/JJEh_kBfJts/maxresdefault.jpg)](https://youtu.be/JJEh_kBfJts)\\n\\nThe Apache Pinot community recently released version [0.12.0](https://docs.pinot.apache.org/basics/releases/0.12.0), which has lots of goodies for you to play with. I’ve been exploring and writing about those features in a series of blog posts.\\n\\nThis post will explore a new API endpoint that lets you check how much Pinot is lagging when ingesting from Apache Kafka.\\n\\n## Why do we need this?\\n\\nA common question in the Pinot community is how to work out the consumption status of real-time tables.\\n\\nThis was a tricky one to answer, but Pinot 0.12 sees the addition of a new API that lets us see exactly what’s going on.\\n\\n## Worked Example\\n\\nLet’s have a look at how it works with help from a worked example.\\n\\nFirst, we’re going to create a Kafka topic with 5 partitions:\\n\\n```bash\\ndocker exec -it kafka-lag-blog kafka-topics.sh \\\\\\n--bootstrap-server localhost:9092 \\\\\\n--partitions 5 \\\\\\n--topic events \\\\\\n--create\\n```\\n\\nWe’re going to populate this topic with data from a data generator, which is shown below:\\n\\n```python\\nimport datetime, uuid, random, json, click, time\\n\\n@click.command()\\n@click.option(\'--sleep\', default=0.0, help=\'Sleep between each message\')\\ndef generate(sleep):\\n    while True:\\n        ts = datetime.datetime.now().strftime(\\"%Y-%m-%dT%H:%M:%S.%fZ\\")\\n        id = str(uuid.uuid4())\\n        count = random.randint(0, 1000)\\n        print(json.dumps({\\"tsString\\": ts, \\"uuid\\": id, \\"count\\": count}))\\n        time.sleep(sleep)\\n\\nif __name__ == \'__main__\':\\n    generate()\\n```\\n\\nWe can see an example of the messages generated by this script by running the following:\\n\\n```bash\\npython datagen.py --sleep 0.01 2>/dev/null | head -n3 | jq -c\\n```\\n\\nYou should see something like this:\\n\\n```json\\n{\\"tsString\\":\\"2023-03-17T12:10:03.854680Z\\",\\"uuid\\":\\"f3b7b5d3-b352-4cfb-a5e3-527f2c663143\\",\\"count\\":690}\\n{\\"tsString\\":\\"2023-03-17T12:10:03.864815Z\\",\\"uuid\\":\\"eac57622-4b58-4456-bb38-96d1ef5a1ed5\\",\\"count\\":522}\\n{\\"tsString\\":\\"2023-03-17T12:10:03.875723Z\\",\\"uuid\\":\\"65926a80-208a-408b-90d0-36cf74c8923a\\",\\"count\\":154}\\n```\\n\\nSo far, so good. Let’s now ingest this data into Kafka:\\n\\n```bash\\npython datagen.py --sleep 0.01 2>/dev/null |\\njq -cr --arg sep \xf8 \'[.uuid, tostring] | join($sep)\' |\\nkcat -P -b localhost:9092 -t events -K\\n```\\n\\nNext we’re going to create a Pinot schema and table. First, the schema config:\\n\\n```json\\n{\\n    \\"schemaName\\": \\"events\\",\\n    \\"dimensionFieldSpecs\\": [{ \\"name\\": \\"uuid\\", \\"dataType\\": \\"STRING\\" }],\\n    \\"metricFieldSpecs\\": [{ \\"name\\": \\"count\\", \\"dataType\\": \\"INT\\" }],\\n    \\"dateTimeFieldSpecs\\": [\\n        {\\n            \\"name\\": \\"ts\\",\\n            \\"dataType\\": \\"TIMESTAMP\\",\\n            \\"format\\": \\"1:MILLISECONDS:EPOCH\\",\\n            \\"granularity\\": \\"1:MILLISECONDS\\"\\n        }\\n    ]\\n}\\n```\\n\\nAnd now, the table config:\\n\\n```json\\n{\\n    \\"tableName\\": \\"events\\",\\n    \\"tableType\\": \\"REALTIME\\",\\n    \\"segmentsConfig\\": {\\n        \\"timeColumnName\\": \\"ts\\",\\n        \\"schemaName\\": \\"events\\",\\n        \\"replication\\": \\"1\\",\\n        \\"replicasPerPartition\\": \\"1\\"\\n    },\\n    \\"tableIndexConfig\\": {\\n        \\"loadMode\\": \\"MMAP\\",\\n        \\"streamConfigs\\": {\\n            \\"streamType\\": \\"kafka\\",\\n            \\"stream.kafka.topic.name\\": \\"events\\",\\n            \\"stream.kafka.broker.list\\": \\"kafka-lag-blog:9093\\",\\n            \\"stream.kafka.consumer.type\\": \\"lowlevel\\",\\n            \\"stream.kafka.consumer.prop.auto.offset.reset\\": \\"smallest\\",\\n            \\"stream.kafka.consumer.factory.class.name\\": \\"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\\",\\n            \\"stream.kafka.decoder.class.name\\": \\"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\\",\\n            \\"realtime.segment.flush.threshold.rows\\": \\"10000000\\"\\n        }\\n    },\\n    \\"ingestionConfig\\": {\\n        \\"transformConfigs\\": [\\n            {\\n                \\"columnName\\": \\"ts\\",\\n                \\"transformFunction\\": \\"FromDateTime(tsString, \'YYYY-MM-dd\'\'T\'\'HH:mm:ss.SSSSSS\'\'Z\'\'\')\\"\\n            }\\n        ]\\n    },\\n    \\"tenants\\": {},\\n    \\"metadata\\": {}\\n}\\n```\\n\\nWe can create both the table and schema using the _AddTable_ command:\\n\\n```bash\\ndocker run \\\\\\n  --network lag_blog \\\\\\n  -v $PWD/config:/config \\\\\\n  apachepinot/pinot:0.12.0-arm64 AddTable \\\\\\n  -schemaFile /config/schema.json \\\\\\n  -tableConfigFile /config/table.json \\\\\\n  -controllerHost \\"pinot-controller-lag-blog\\" \\\\\\n  -exec\\n```\\n\\nNow let’s call the /consumingSegmentsInfo endpoint to see what’s going on:\\n\\n`curl \\"http://localhost:9000/tables/events/consumingSegmentsInfo\\" 2>/dev/null | jq`\\n\\nThe output of calling this end point is shown below:\\n\\n```json\\n{\\n  \\"_segmentToConsumingInfoMap\\": {\\n    \\"events__0__0__20230317T1133Z\\": [\\n      {\\n        \\"serverName\\": \\"Server_172.29.0.4_8098\\",\\n        \\"consumerState\\": \\"CONSUMING\\",\\n        \\"lastConsumedTimestamp\\": 1679052823350,\\n        \\"partitionToOffsetMap\\": {\\n          \\"0\\": \\"969\\"\\n        },\\n        \\"partitionOffsetInfo\\": {\\n          \\"currentOffsetsMap\\": {\\n            \\"0\\": \\"969\\"\\n          },\\n          \\"latestUpstreamOffsetMap\\": {\\n            \\"0\\": \\"969\\"\\n          },\\n          \\"recordsLagMap\\": {\\n            \\"0\\": \\"0\\"\\n          },\\n          \\"availabilityLagMsMap\\": {\\n            \\"0\\": \\"26\\"\\n          }\\n        }\\n      }\\n    ],\\n…\\n}\\n```\\n\\nIf we look under _partitionOffsetInfo_, we can see what’s going on:\\n\\n-   currentOffsetsMap is Pinot’s current offset\\n-   latestUpstreamOffsetMap is Kafka’s offset\\n-   recordsLagMap is the record lag\\n-   availabilityLagMsMap is the time lag\\n\\nThis output is a bit unwieldy, so let’s create a bash function to tidy up the output into something that’s easier to consume:\\n\\n```python\\nfunction consuming_info() {\\n  curl \\"http://localhost:9000/tables/events/consumingSegmentsInfo\\" 2>/dev/null |\\n  jq -rc \'[._segmentToConsumingInfoMap | keys[] as $k | (.[$k] | .[] | {\\n    segment: $k,\\n    kafka: (.partitionOffsetInfo.currentOffsetsMap | keys[] as $k | (.[$k])),\\n    pinot: (.partitionOffsetInfo.latestUpstreamOffsetMap | keys[] as $k | (.[$k])),\\n    recordLag: (.partitionOffsetInfo.recordsLagMap | keys[] as $k | (.[$k])),\\n    timeLagMs: (.partitionOffsetInfo.availabilityLagMsMap | keys[] as $k | (.[$k]))\\n})] | (.[0] |keys_unsorted | @tsv), (.[]  |map(.) |@tsv)\'  | column -t\\n  printf \\"\\\\n\\"\\n\\n}\\n```\\n\\nLet’s call the function:\\n\\n`consuming\\\\_info`\\n\\nWe’ll see the following output:\\n\\n![Consumer record lag output](https://www.datocms-assets.com/75153/1680190272-image2.png \'Consumer record lag output\')\\n\\nNow let’s put it in a script and call the watch command so that it will be refreshed every couple of seconds:\\n\\n```python\\n!#/bin/bash\\n\\nfunction consuming_info() {\\n  curl \\"http://localhost:9000/tables/events/consumingSegmentsInfo\\" 2>/dev/null |\\n  jq -rc \'[._segmentToConsumingInfoMap | keys[] as $k | (.[$k] | .[] | {\\n    segment: $k,\\n    kafka: (.partitionOffsetInfo.currentOffsetsMap | keys[] as $k | (.[$k])),\\n    pinot: (.partitionOffsetInfo.latestUpstreamOffsetMap | keys[] as $k | (.[$k])),\\n    recordLag: (.partitionOffsetInfo.recordsLagMap | keys[] as $k | (.[$k])),\\n    timeLagMs: (.partitionOffsetInfo.availabilityLagMsMap | keys[] as $k | (.[$k]))\\n})] | (.[0] |keys_unsorted | @tsv), (.[]  |map(.) |@tsv)\'  | column -t\\n  printf \\"\\\\n\\"\\n}\\n\\nexport -f consuming_info\\nwatch bash -c consuming_info\\n\\n```\\n\\nGive permissions to run it as a script:\\n\\n`chmod u+x watch\\\\_consuming\\\\_info.sh`\\n\\nAnd finally, run it:\\n\\n`./watch\\\\_consuming\\\\_info.sh`\\n\\nThis will print out a new table every two seconds. Let’s now make things more interesting by removing the sleep from our ingestion command:\\n\\n```bash\\npython datagen.py  2>/dev/null |\\njq -cr --arg sep \xf8 \'[.uuid, tostring] | join($sep)\' |\\nkcat -P -b localhost:9092 -t events -K\xf8\\n```\\n\\nAnd now if we look at the watch output:\\n\\n![Apache Pinot Consumer Record Lag](https://www.datocms-assets.com/75153/1680190286-image1.png \'Apache Pinot Consumer Record Lag\')\\n\\nWe get some transitory lag, but it generally goes away by the next time the command is run.\\n\\n## Summary\\n\\nI love this feature, and it solves a problem I’ve struggled with when using my datasets. I hope you’ll find it just as useful.\\n\\nGive it a try, and let us know how you get on. If you have any questions about this feature, feel free to join us on [Slack](https://stree.ai/slack), where we’ll be happy to help you out.\\n","code":"var Component=(()=>{var d=Object.create;var t=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,N=Object.prototype.hasOwnProperty;var k=(a,n)=>()=>(n||a((n={exports:{}}).exports,n),n.exports),g=(a,n)=>{for(var s in n)t(a,s,{get:n[s],enumerable:!0})},o=(a,n,s,l)=>{if(n&&typeof n==\\"object\\"||typeof n==\\"function\\")for(let c of m(n))!N.call(a,c)&&c!==s&&t(a,c,{get:()=>n[c],enumerable:!(l=h(n,c))||l.enumerable});return a};var f=(a,n,s)=>(s=a!=null?d(u(a)):{},o(n||!a||!a.__esModule?t(s,\\"default\\",{value:a,enumerable:!0}):s,a)),y=a=>o(t({},\\"__esModule\\",{value:!0}),a);var r=k((I,i)=>{i.exports=_jsx_runtime});var M={};g(M,{default:()=>v,frontmatter:()=>b});var e=f(r()),b={title:\\"Apache Pinot\\\\u2122 0.12 - Consumer Record Lag\\",date:new Date(16801344e5),authors:[\\"needham\\"],summary:\\"This post will explore a new API endpoint that lets you check how much Pinot is lagging when ingesting from Apache Kafka.\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"consumer record lag\\",\\"kafka\\"]};function p(a){let n=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\",h2:\\"h2\\",span:\\"span\\",pre:\\"pre\\",code:\\"code\\",em:\\"em\\",ul:\\"ul\\",li:\\"li\\"},a.components);return(0,e.jsxs)(e.Fragment,{children:[(0,e.jsx)(n.p,{children:(0,e.jsx)(n.a,{href:\\"https://youtu.be/JJEh_kBfJts\\",children:(0,e.jsx)(n.img,{alt:\\"Watch the video\\",src:\\"https://i3.ytimg.com/vi/JJEh_kBfJts/maxresdefault.jpg\\"})})}),(0,e.jsxs)(n.p,{children:[\\"The Apache Pinot community recently released version \\",(0,e.jsx)(n.a,{href:\\"https://docs.pinot.apache.org/basics/releases/0.12.0\\",children:\\"0.12.0\\"}),\\", which has lots of goodies for you to play with. I\\\\u2019ve been exploring and writing about those features in a series of blog posts.\\"]}),(0,e.jsx)(n.p,{children:\\"This post will explore a new API endpoint that lets you check how much Pinot is lagging when ingesting from Apache Kafka.\\"}),(0,e.jsxs)(n.h2,{id:\\"why-do-we-need-this\\",children:[(0,e.jsx)(n.a,{href:\\"#why-do-we-need-this\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,e.jsx)(n.span,{className:\\"icon icon-link\\"})}),\\"Why do we need this?\\"]}),(0,e.jsx)(n.p,{children:\\"A common question in the Pinot community is how to work out the consumption status of real-time tables.\\"}),(0,e.jsx)(n.p,{children:\\"This was a tricky one to answer, but Pinot 0.12 sees the addition of a new API that lets us see exactly what\\\\u2019s going on.\\"}),(0,e.jsxs)(n.h2,{id:\\"worked-example\\",children:[(0,e.jsx)(n.a,{href:\\"#worked-example\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,e.jsx)(n.span,{className:\\"icon icon-link\\"})}),\\"Worked Example\\"]}),(0,e.jsx)(n.p,{children:\\"Let\\\\u2019s have a look at how it works with help from a worked example.\\"}),(0,e.jsx)(n.p,{children:\\"First, we\\\\u2019re going to create a Kafka topic with 5 partitions:\\"}),(0,e.jsx)(n.pre,{className:\\"language-bash\\",children:(0,e.jsxs)(n.code,{className:\\"code-highlight language-bash\\",children:[(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token function\\",children:\\"docker\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token builtin class-name\\",children:\\"exec\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-it\\"}),\\" kafka-lag-blog kafka-topics.sh \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"--bootstrap-server localhost:9092 \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"--partitions\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token number\\",children:\\"5\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"--topic\\"}),\\" events \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"--create\\"}),`\\n`]})]})}),(0,e.jsx)(n.p,{children:\\"We\\\\u2019re going to populate this topic with data from a data generator, which is shown below:\\"}),(0,e.jsx)(n.pre,{className:\\"language-python\\",children:(0,e.jsxs)(n.code,{className:\\"code-highlight language-python\\",children:[(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"import\\"}),\\" datetime\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" uuid\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" random\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" json\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" click\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),` time\\n`]}),(0,e.jsx)(n.span,{className:\\"code-line\\",children:`\\n`}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsxs)(n.span,{className:\\"token punctuation annotation decorator\\",children:[\\"@click\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"command\\"]}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsxs)(n.span,{className:\\"token punctuation annotation decorator\\",children:[\\"@click\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"option\\"]}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token string\\",children:\\"\'--sleep\'\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" default\\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"=\\"}),(0,e.jsx)(n.span,{className:\\"token number\\",children:\\"0.0\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token builtin\\",children:\\"help\\"}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"=\\"}),(0,e.jsx)(n.span,{className:\\"token string\\",children:\\"\'Sleep between each message\'\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"def\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token function\\",children:\\"generate\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"sleep\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"while\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token boolean\\",children:\\"True\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        ts \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"=\\"}),\\" datetime\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"datetime\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"now\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"strftime\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"%Y-%m-%dT%H:%M:%S.%fZ\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token builtin\\",children:\\"id\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token builtin\\",children:\\"str\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"uuid\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"uuid4\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        count \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"=\\"}),\\" random\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"randint\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token number\\",children:\\"0\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token number\\",children:\\"1000\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"print\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"json\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"dumps\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"tsString\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" ts\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"uuid\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token builtin\\",children:\\"id\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"count\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" count\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        time\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"sleep\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"sleep\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,e.jsx)(n.span,{className:\\"code-line\\",children:`\\n`}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"if\\"}),\\" __name__ \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"==\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\\"\'__main__\'\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    generate\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]})]})}),(0,e.jsx)(n.p,{children:\\"We can see an example of the messages generated by this script by running the following:\\"}),(0,e.jsx)(n.pre,{className:\\"language-bash\\",children:(0,e.jsx)(n.code,{className:\\"code-highlight language-bash\\",children:(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"python datagen.py \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"--sleep\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token number\\",children:\\"0.01\\"}),\\" \\",(0,e.jsxs)(n.span,{className:\\"token operator\\",children:[(0,e.jsx)(n.span,{className:\\"token file-descriptor important\\",children:\\"2\\"}),\\">\\"]}),\\"/dev/null \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token function\\",children:\\"head\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-n3\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" jq \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-c\\"}),`\\n`]})})}),(0,e.jsx)(n.p,{children:\\"You should see something like this:\\"}),(0,e.jsx)(n.pre,{className:\\"language-json\\",children:(0,e.jsxs)(n.code,{className:\\"code-highlight language-json\\",children:[(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"tsString\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"2023-03-17T12:10:03.854680Z\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"uuid\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"f3b7b5d3-b352-4cfb-a5e3-527f2c663143\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"count\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),(0,e.jsx)(n.span,{className:\\"token number\\",children:\\"690\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"tsString\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"2023-03-17T12:10:03.864815Z\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"uuid\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"eac57622-4b58-4456-bb38-96d1ef5a1ed5\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"count\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),(0,e.jsx)(n.span,{className:\\"token number\\",children:\\"522\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"tsString\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"2023-03-17T12:10:03.875723Z\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"uuid\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"65926a80-208a-408b-90d0-36cf74c8923a\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"count\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),(0,e.jsx)(n.span,{className:\\"token number\\",children:\\"154\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,e.jsx)(n.p,{children:\\"So far, so good. Let\\\\u2019s now ingest this data into Kafka:\\"}),(0,e.jsx)(n.pre,{className:\\"language-bash\\",children:(0,e.jsxs)(n.code,{className:\\"code-highlight language-bash\\",children:[(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"python datagen.py \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"--sleep\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token number\\",children:\\"0.01\\"}),\\" \\",(0,e.jsxs)(n.span,{className:\\"token operator\\",children:[(0,e.jsx)(n.span,{className:\\"token file-descriptor important\\",children:\\"2\\"}),\\">\\"]}),\\"/dev/null \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"jq \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-cr\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"--arg\\"}),\\" sep \\\\xF8 \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\\"\'[.uuid, tostring] | join($sep)\'\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"kcat \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-P\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-b\\"}),\\" localhost:9092 \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-t\\"}),\\" events \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-K\\"}),`\\n`]})]})}),(0,e.jsx)(n.p,{children:\\"Next we\\\\u2019re going to create a Pinot schema and table. First, the schema config:\\"}),(0,e.jsx)(n.pre,{className:\\"language-json\\",children:(0,e.jsxs)(n.code,{className:\\"code-highlight language-json\\",children:[(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"events\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"dimensionFieldSpecs\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"uuid\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"metricFieldSpecs\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"count\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"INT\\"\'}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"dateTimeFieldSpecs\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"TIMESTAMP\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"format\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS:EPOCH\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"granularity\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS\\"\'}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,e.jsx)(n.p,{children:\\"And now, the table config:\\"}),(0,e.jsx)(n.pre,{className:\\"language-json\\",children:(0,e.jsxs)(n.code,{className:\\"code-highlight language-json\\",children:[(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"tableName\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"events\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"tableType\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"REALTIME\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"segmentsConfig\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"timeColumnName\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"events\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"replication\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"1\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"replicasPerPartition\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"1\\"\'}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"tableIndexConfig\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"loadMode\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"MMAP\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"streamConfigs\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"streamType\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"kafka\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"stream.kafka.topic.name\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"events\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"stream.kafka.broker.list\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"kafka-lag-blog:9093\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.type\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"lowlevel\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.prop.auto.offset.reset\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"smallest\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.factory.class.name\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.class.name\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"realtime.segment.flush.threshold.rows\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"10000000\\"\'}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"ingestionConfig\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"transformConfigs\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"                \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"columnName\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"                \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"transformFunction\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:`\\"FromDateTime(tsString, \'YYYY-MM-dd\'\'T\'\'HH:mm:ss.SSSSSS\'\'Z\'\'\')\\"`}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"tenants\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"metadata\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,e.jsxs)(n.p,{children:[\\"We can create both the table and schema using the \\",(0,e.jsx)(n.em,{children:\\"AddTable\\"}),\\" command:\\"]}),(0,e.jsx)(n.pre,{className:\\"language-bash\\",children:(0,e.jsxs)(n.code,{className:\\"code-highlight language-bash\\",children:[(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"  \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"--network\\"}),\\" lag_blog \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"  \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-v\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token constant environment\\",children:\\"$PWD\\"}),\\"/config:/config \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"  apachepinot/pinot:0.12.0-arm64 AddTable \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"  \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-schemaFile\\"}),\\" /config/schema.json \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"  \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-tableConfigFile\\"}),\\" /config/table.json \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"  \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-controllerHost\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"pinot-controller-lag-blog\\"\'}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"  \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-exec\\"}),`\\n`]})]})}),(0,e.jsx)(n.p,{children:\\"Now let\\\\u2019s call the /consumingSegmentsInfo endpoint to see what\\\\u2019s going on:\\"}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.code,{children:\'curl \\"http://localhost:9000/tables/events/consumingSegmentsInfo\\" 2>/dev/null | jq\'})}),(0,e.jsx)(n.p,{children:\\"The output of calling this end point is shown below:\\"}),(0,e.jsx)(n.pre,{className:\\"language-json\\",children:(0,e.jsxs)(n.code,{className:\\"code-highlight language-json\\",children:[(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"  \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"_segmentToConsumingInfoMap\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"events__0__0__20230317T1133Z\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"      \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"serverName\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"Server_172.29.0.4_8098\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"consumerState\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"CONSUMING\\"\'}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"lastConsumedTimestamp\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token number\\",children:\\"1679052823350\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"partitionToOffsetMap\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"          \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"0\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"969\\"\'}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"partitionOffsetInfo\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"          \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"currentOffsetsMap\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"0\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"969\\"\'}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"          \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"          \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"latestUpstreamOffsetMap\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"0\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"969\\"\'}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"          \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"          \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"recordsLagMap\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"0\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"0\\"\'}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"          \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"          \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"availabilityLagMsMap\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"            \\",(0,e.jsx)(n.span,{className:\\"token property\\",children:\'\\"0\\"\'}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"26\\"\'}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"          \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"        \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"      \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsx)(n.span,{className:\\"code-line\\",children:`\\\\u2026\\n`}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,e.jsxs)(n.p,{children:[\\"If we look under \\",(0,e.jsx)(n.em,{children:\\"partitionOffsetInfo\\"}),\\", we can see what\\\\u2019s going on:\\"]}),(0,e.jsxs)(n.ul,{children:[(0,e.jsx)(n.li,{children:\\"currentOffsetsMap is Pinot\\\\u2019s current offset\\"}),(0,e.jsx)(n.li,{children:\\"latestUpstreamOffsetMap is Kafka\\\\u2019s offset\\"}),(0,e.jsx)(n.li,{children:\\"recordsLagMap is the record lag\\"}),(0,e.jsx)(n.li,{children:\\"availabilityLagMsMap is the time lag\\"})]}),(0,e.jsx)(n.p,{children:\\"This output is a bit unwieldy, so let\\\\u2019s create a bash function to tidy up the output into something that\\\\u2019s easier to consume:\\"}),(0,e.jsx)(n.pre,{className:\\"language-python\\",children:(0,e.jsxs)(n.code,{className:\\"code-highlight language-python\\",children:[(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"function consuming_info\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"  curl \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"http://localhost:9000/tables/events/consumingSegmentsInfo\\"\'}),\\" \\",(0,e.jsx)(n.span,{className:\\"token number\\",children:\\"2\\"}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\">\\"}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"/\\"}),\\"dev\\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"/\\"}),\\"null \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"  jq \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"-\\"}),\\"rc \'\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"_segmentToConsumingInfoMap \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" keys\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" $k \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"$k\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    segment\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" $k\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    kafka\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"partitionOffsetInfo\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"currentOffsetsMap \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" keys\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" $k \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"$k\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    pinot\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"partitionOffsetInfo\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"latestUpstreamOffsetMap \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" keys\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" $k \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"$k\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    recordLag\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"partitionOffsetInfo\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"recordsLagMap \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" keys\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" $k \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"$k\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    timeLagMs\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"partitionOffsetInfo\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"availabilityLagMsMap \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" keys\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" $k \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"$k\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token number\\",children:\\"0\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\"keys_unsorted \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" @tsv\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\"  \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),(0,e.jsx)(n.span,{className:\\"token builtin\\",children:\\"map\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\"@tsv\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),\\"\'  \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" column \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"-\\"}),`t\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"  printf \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"\\\\\\\\n\\"\'}),`\\n`]}),(0,e.jsx)(n.span,{className:\\"code-line\\",children:`\\n`}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,e.jsx)(n.p,{children:\\"Let\\\\u2019s call the function:\\"}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.code,{children:\\"consuming\\\\\\\\_info\\"})}),(0,e.jsx)(n.p,{children:\\"We\\\\u2019ll see the following output:\\"}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.img,{alt:\\"Consumer record lag output\\",src:\\"https://www.datocms-assets.com/75153/1680190272-image2.png\\",title:\\"Consumer record lag output\\"})}),(0,e.jsx)(n.p,{children:\\"Now let\\\\u2019s put it in a script and call the watch command so that it will be refreshed every couple of seconds:\\"}),(0,e.jsx)(n.pre,{className:\\"language-python\\",children:(0,e.jsxs)(n.code,{className:\\"code-highlight language-python\\",children:[(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"!\\",(0,e.jsx)(n.span,{className:\\"token comment\\",children:\\"#/bin/bash\\"}),`\\n`]}),(0,e.jsx)(n.span,{className:\\"code-line\\",children:`\\n`}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"function consuming_info\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"  curl \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"http://localhost:9000/tables/events/consumingSegmentsInfo\\"\'}),\\" \\",(0,e.jsx)(n.span,{className:\\"token number\\",children:\\"2\\"}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\">\\"}),(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"/\\"}),\\"dev\\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"/\\"}),\\"null \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"  jq \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"-\\"}),\\"rc \'\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"_segmentToConsumingInfoMap \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" keys\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" $k \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"$k\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    segment\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" $k\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    kafka\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"partitionOffsetInfo\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"currentOffsetsMap \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" keys\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" $k \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"$k\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    pinot\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"partitionOffsetInfo\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"latestUpstreamOffsetMap \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" keys\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" $k \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"$k\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    recordLag\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"partitionOffsetInfo\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"recordsLagMap \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" keys\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" $k \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"$k\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"    timeLagMs\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\":\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"partitionOffsetInfo\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"availabilityLagMsMap \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" keys\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" $k \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"$k\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token number\\",children:\\"0\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\"keys_unsorted \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" @tsv\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\"  \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),(0,e.jsx)(n.span,{className:\\"token builtin\\",children:\\"map\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\"@tsv\\",(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\")\\"}),\\"\'  \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),\\" column \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"-\\"}),`t\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"  printf \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\'\\"\\\\\\\\n\\"\'}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[(0,e.jsx)(n.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,e.jsx)(n.span,{className:\\"code-line\\",children:`\\n`}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"export \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"-\\"}),`f consuming_info\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"watch bash \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"-\\"}),`c consuming_info\\n`]}),(0,e.jsx)(n.span,{className:\\"code-line\\",children:`\\n`})]})}),(0,e.jsx)(n.p,{children:\\"Give permissions to run it as a script:\\"}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.code,{children:\\"chmod u+x watch\\\\\\\\_consuming\\\\\\\\_info.sh\\"})}),(0,e.jsx)(n.p,{children:\\"And finally, run it:\\"}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.code,{children:\\"./watch\\\\\\\\_consuming\\\\\\\\_info.sh\\"})}),(0,e.jsx)(n.p,{children:\\"This will print out a new table every two seconds. Let\\\\u2019s now make things more interesting by removing the sleep from our ingestion command:\\"}),(0,e.jsx)(n.pre,{className:\\"language-bash\\",children:(0,e.jsxs)(n.code,{className:\\"code-highlight language-bash\\",children:[(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"python datagen.py  \\",(0,e.jsxs)(n.span,{className:\\"token operator\\",children:[(0,e.jsx)(n.span,{className:\\"token file-descriptor important\\",children:\\"2\\"}),\\">\\"]}),\\"/dev/null \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"jq \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-cr\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"--arg\\"}),\\" sep \\\\xF8 \\",(0,e.jsx)(n.span,{className:\\"token string\\",children:\\"\'[.uuid, tostring] | join($sep)\'\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token operator\\",children:\\"|\\"}),`\\n`]}),(0,e.jsxs)(n.span,{className:\\"code-line\\",children:[\\"kcat \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-P\\"}),\\" \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-b\\"}),\\" localhost:9092 \\",(0,e.jsx)(n.span,{className:\\"token parameter variable\\",children:\\"-t\\"}),` events -K\\\\xF8\\n`]})]})}),(0,e.jsx)(n.p,{children:\\"And now if we look at the watch output:\\"}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.img,{alt:\\"Apache Pinot Consumer Record Lag\\",src:\\"https://www.datocms-assets.com/75153/1680190286-image1.png\\",title:\\"Apache Pinot Consumer Record Lag\\"})}),(0,e.jsx)(n.p,{children:\\"We get some transitory lag, but it generally goes away by the next time the command is run.\\"}),(0,e.jsxs)(n.h2,{id:\\"summary\\",children:[(0,e.jsx)(n.a,{href:\\"#summary\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,e.jsx)(n.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),(0,e.jsx)(n.p,{children:\\"I love this feature, and it solves a problem I\\\\u2019ve struggled with when using my datasets. I hope you\\\\u2019ll find it just as useful.\\"}),(0,e.jsxs)(n.p,{children:[\\"Give it a try, and let us know how you get on. If you have any questions about this feature, feel free to join us on \\",(0,e.jsx)(n.a,{href:\\"https://stree.ai/slack\\",children:\\"Slack\\"}),\\", where we\\\\u2019ll be happy to help you out.\\"]})]})}function w(a={}){let{wrapper:n}=a.components||{};return n?(0,e.jsx)(n,Object.assign({},a,{children:(0,e.jsx)(p,a)})):p(a)}var v=w;return y(M);})();\\n;return Component;"},"_id":"blog/2023-03-30-Apache-Pinot-0-12-Consumer-Record-Lag.mdx","_raw":{"sourceFilePath":"blog/2023-03-30-Apache-Pinot-0-12-Consumer-Record-Lag.mdx","sourceFileName":"2023-03-30-Apache-Pinot-0-12-Consumer-Record-Lag.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2023-03-30-Apache-Pinot-0-12-Consumer-Record-Lag"},"type":"Blog","readingTime":{"text":"5 min read","minutes":4.57,"time":274200,"words":914},"slug":"2023/03/30/Apache-Pinot-0-12-Consumer-Record-Lag","customSlug":"2023/03/30/Apache-Pinot-0-12-Consumer-Record-Lag","path":"blog/2023/03/30/Apache-Pinot-0-12-Consumer-Record-Lag","customPath":"blog/2023/03/30/Apache-Pinot-0-12-Consumer-Record-Lag","filePath":"blog/2023-03-30-Apache-Pinot-0-12-Consumer-Record-Lag.mdx","toc":[{"value":"Why do we need this?","url":"#why-do-we-need-this","depth":2},{"value":"Worked Example","url":"#worked-example","depth":2},{"value":"Summary","url":"#summary","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Pinot™ 0.12 - Consumer Record Lag","datePublished":"2023-03-30T00:00:00.000Z","dateModified":"2023-03-30T00:00:00.000Z","description":"This post will explore a new API endpoint that lets you check how much Pinot is lagging when ingesting from Apache Kafka.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2023-03-30-Apache-Pinot-0-12-Consumer-Record-Lag"}},{"title":"Geospatial Indexing in Apache Pinot","date":"2023-05-11T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","geospatial indexing"],"summary":"This post will explore a new API endpoint that lets you check how much Pinot is lagging when ingesting from Apache Kafka.","authors":["needham"],"body":{"raw":"\\n[![Watch the video](https://i3.ytimg.com/vi/J-4iHPolZz0/maxresdefault.jpg)](https://youtu.be/J-4iHPolZz0)\\n\\nIt’s been over 18 months since [geospatial indexes were added to Apache Pinot™](https://medium.com/apache-pinot-developer-blog/introduction-to-geospatial-queries-in-apache-pinot-b63e2362e2a9), giving you the ability to retrieve data based on geographic location—a common requirement in many analytics use cases. Using geospatial queries in combination with time series queries in Pinot, you can perform complex spatiotemporal analysis, such as analyzing changes in weather patterns over time or tracking the movement of objects, vehicles, or people. Pinot\'s support for geospatial data indexing means fast and efficient querying of large-scale, location-based datasets distributed across multiple nodes.\\n\\nIn that time, more indexing functionality has been added, so I wanted to take an opportunity to have a look at the current state of things.\\n\\n## What is geospatial indexing?\\n\\nGeospatial indexing is a technique used in database management systems to store and retrieve spatial data based on its geographic location. It involves creating an index that allows for efficient querying of location-based data, such as latitude and longitude coordinates or geographical shapes.\\n\\nGeospatial indexing organizes spatial data in such a way that enables fast and accurate retrieval of data based on its proximity to a specific location or geographic region. This indexing can be used to answer queries such as \\"What are the restaurants with a 30-minute delivery window to my current location?\\" or \\"What are the boundaries of this specific city or state?\\"\\n\\nGeospatial indexing is commonly used in geographic information systems (GIS), mapping applications, and location-based services such as ride-sharing apps, social media platforms, and navigation tools. It plays a crucial role in spatial data analysis, spatial data visualization, and decision-making processes.\\n\\n## How do geospatial indexes work in Apache Pinot?\\n\\nWe can index points using [H3](https://h3geo.org/), an open source library that originated at Uber. This library provides hexagon-based hierarchical gridding. Indexing a point means that the point is translated to a geoId, which corresponds to a hexagon. Its neighbors in H3 can be approximated by a ring of hexagons. Direct neighbors have a distance of 1, their neighbors are at a distance of 2, and so on.\\n\\nFor example, if the central hexagon covers the Westminster area of central London, neighbors at distance 1 are colored blue, those at distance 2 are in green, and those at distance 3 are in red.\\n\\n![Geospatial Indexing In Apache Pinot](https://www.datocms-assets.com/75153/1683813508-image5.png \'Geospatial Indexing In Apache Pinot\')\\n\\nLet’s learn how to use geospatial indexing with help from a dataset that captures the latest location of trains moving around the UK. We’re streaming this data into a `trains` topic in Apache Kafka\xae. Here’s one message from this stream:\\n\\n```bash\\nkcat -C -b localhost:9092 -t trains -c1| jq\\n\\n\\n{\\n  \\"trainCompany\\": \\"CrossCountry\\",\\n  \\"atocCode\\": \\"XC\\",\\n  \\"lat\\": 50.692726,\\n  \\"lon\\": -3.5040767,\\n  \\"ts\\": \\"2023-03-09 10:57:11.1678359431\\",\\n  \\"trainId\\": \\"202303096771054\\"\\n}\\n```\\n\\nWe’re going to ingest this data into Pinot, so let’s create a schema:\\n\\n```json\\n{\\n    \\"schemaName\\": \\"trains\\",\\n    \\"dimensionFieldSpecs\\": [\\n        { \\"name\\": \\"trainCompany\\", \\"dataType\\": \\"STRING\\" },\\n        { \\"name\\": \\"trainId\\", \\"dataType\\": \\"STRING\\" },\\n        { \\"name\\": \\"atocCode\\", \\"dataType\\": \\"STRING\\" },\\n        { \\"name\\": \\"point\\", \\"dataType\\": \\"BYTES\\" }\\n    ],\\n    \\"dateTimeFieldSpecs\\": [\\n        {\\n            \\"name\\": \\"ts\\",\\n            \\"dataType\\": \\"TIMESTAMP\\",\\n            \\"format\\": \\"1:MILLISECONDS:EPOCH\\",\\n            \\"granularity\\": \\"1:MILLISECONDS\\"\\n        }\\n    ]\\n}\\n```\\n\\nThe point column will store a point object that represents the current location of a train. We’ll see how that column gets populated from our table config, as shown below:\\n\\n```json\\n{\\n    \\"tableName\\": \\"trains\\",\\n    \\"tableType\\": \\"REALTIME\\",\\n    \\"segmentsConfig\\": {\\n        \\"timeColumnName\\": \\"ts\\",\\n        \\"schemaName\\": \\"trains\\",\\n        \\"replication\\": \\"1\\",\\n        \\"replicasPerPartition\\": \\"1\\"\\n    },\\n    \\"fieldConfigList\\": [\\n        {\\n            \\"name\\": \\"point\\",\\n            \\"encodingType\\": \\"RAW\\",\\n            \\"indexType\\": \\"H3\\",\\n            \\"properties\\": { \\"resolutions\\": \\"7\\" }\\n        }\\n    ],\\n    \\"tableIndexConfig\\": {\\n        \\"loadMode\\": \\"MMAP\\",\\n        \\"noDictionaryColumns\\": [\\"point\\"],\\n        \\"streamConfigs\\": {\\n            \\"streamType\\": \\"kafka\\",\\n            \\"stream.kafka.topic.name\\": \\"trains\\",\\n            \\"stream.kafka.broker.list\\": \\"kafka-geospatial:9093\\",\\n            \\"stream.kafka.consumer.type\\": \\"lowlevel\\",\\n            \\"stream.kafka.consumer.prop.auto.offset.reset\\": \\"smallest\\",\\n            \\"stream.kafka.consumer.factory.class.name\\": \\"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\\",\\n            \\"stream.kafka.decoder.class.name\\": \\"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\\"\\n        }\\n    },\\n    \\"ingestionConfig\\": {\\n        \\"transformConfigs\\": [\\n            {\\n                \\"columnName\\": \\"point\\",\\n                \\"transformFunction\\": \\"STPoint(lon, lat, 1)\\"\\n            }\\n        ]\\n    },\\n    \\"tenants\\": {},\\n    \\"metadata\\": {}\\n}\\n```\\n\\nThe point column is populated by the following function under `transformConfigs`:\\n\\n`STPoint(lon, lat, 1)`\\n\\nIn earlier versions of Pinot, you’d need to ensure that the schema included lat and lon columns, but that no longer applies.\\n\\nWe define the geospatial index on the point column under `fieldConfigList`. We can configure what H3 calls [resolutions](https://h3geo.org/docs/core-library/restable), which defines the size of a hexagon and their number. A resolution of 7 means that there will be 98,825,150 hexagons, each covering an area of 5.16 km\xb2. We also need to add the geospatial column to `tableIndexConfig.noDictionaryColumns`.\\n\\nWe can go ahead and create that table using the `AddTable` command and Pinot will automatically start ingesting data from Kafka.\\n\\n## When is the geospatial index used?\\n\\nThe geospatial index is used when a WHERE clause in a query calls the StDistance, StWithin, or StContains functions.\\n\\n`ST\\\\_Distance`\\n\\nLet’s say we want to find all the trains within a 10 km radius of Westminster. We could write a query to answer this question using the STDistance function. The query might look like this:\\n\\n```sql\\nselect ts, trainId, atocCode, trainCompany, ST\\\\_AsText(point),\\n       STDistance(\\n         point,\\n         toSphericalGeography(ST_GeomFromText(\'POINT (-0.13624 51.499507)\')))\\n  AS distance\\nfrom trains\\nWHERE distance < 10000\\nORDER BY distance, ts DESC\\nlimit 10\\n```\\n\\nThese results from running the query would follow:\\n\\n![Sample Geospatial Indexing In Apache Pinot Query Result](https://www.datocms-assets.com/75153/1683813581-image1.png \'Sample Geospatial Indexing In Apache Pinot Query Result\')\\n\\nLet’s now go into a bit more detail about what happens when we run the query.\\n\\nThe 10 km radius covers the area inside the white circle on the diagram below:\\n\\n![Geospatial Indexing In Apache Pinot Circle](https://www.datocms-assets.com/75153/1683813641-image7.png \'Geospatial Indexing In Apache Pinot Circle\')\\n\\nPinot’s query planner will first translate the distance of 10 km into a number of rings, in this case, two. It will then find all the hexagons located two rings away from the white one. Some of these hexagons will fit completely inside the white circle, and some will overlap with the circle.\\n\\nIf a hexagon fully fits, then we can get all the records inside this hexagon and return them. For those that partially fit, we’ll need to apply the distance predicate before working out which records to return.\\n\\n`ST\\\\_Within/ST\\\\_Contains`\\n\\nLet’s say that rather than specifying a distance, we instead want to draw a polygon and find the trains that fit inside that polygon. We could use either the `ST\\\\_Within` or `ST\\\\_Contains` functions to answer this question.\\n\\nThe query might look like this:\\n\\n```sql\\nselect ts, trainId, atocCode, trainCompany, ST\\\\_AsText(point)\\nfrom trains\\nWHERE StWithin(\\n      point,\\n      toSphericalGeography(ST_GeomFromText(\'POLYGON((\\n        -0.1296371966600418 51.508053828550544,\\n        -0.1538461446762085 51.497007194317064,\\n        -0.13032652437686923 51.488276935884414,\\n        -0.10458670556545259 51.497003019756846,\\n        -0.10864421725273131 51.50817152245844,\\n        -0.1296371966600418 51.508053828550544))\'))) = 1\\nORDER BY ts DESC\\nlimit 10\\n```\\n\\nThe results from running the query are shown below:\\n\\n![Sample Geospatial Indexing In Apache Pinot Query Result](https://www.datocms-assets.com/75153/1683813749-image4.png \'Sample Geospatial Indexing In Apache Pinot Query Result\')\\n\\nIf we change the query to show trains outside of a central London polygon, we’d see the following results:\\n\\n![Sample Geospatial Indexing In Apache Pinot Query Result](https://www.datocms-assets.com/75153/1683813705-image3.png \'Sample Geospatial Indexing In Apache Pinot Query Result\')\\n\\nSo what’s actually happening when we run this query?\\n\\nThe polygon covers the area inside the white shape as shown below:\\n\\n![Geospatial Indexing In Apache Pinot Polygon](https://www.datocms-assets.com/75153/1683813802-image2.png \'Geospatial Indexing In Apache Pinot Polygon\')\\n\\nPinot’s query planner will first find all the coordinates on the exterior of the polygon. It will then find the hexagons that fit within that geofence. Those hexagons get added to the potential cells list.\\n\\nThe query planner then takes each of those hexagons and checks whether they fit completely inside the original polygon. If they do, then they get added to the fully contained cells list. If we have any cells in both lists, we remove them from the potential cells list.\\n\\nNext, we find the records for the fully contained cells list and those for the potential cells list.\\n\\nIf we are finding records that fit inside the polygon, we return those in the fully contained list and apply the STWithin/StContains predicate to work out which records to return from the potential list.\\n\\nIf we are finding records outside the polygon, we will create a new fully contained list, which will actually contain the records that are outside the polygon. This list contains all of the records in the database except the ones in the potential list and those in the initial fully contained list.\\n\\nThis one was a bit tricky for me to get my head around, so let’s just quickly go through an example. Imagine that we store 10 records in our database and our potential and fully contained lists hold the following values:\\n\\n```python\\npotential = [0,1,2,3]\\nfullyContained = [4,5,6]\\n```\\n\\nFirst, compute newFullyContained to find all the records not in potential:\\n\\n`newFullyContained = [4,5,6,7,8,9]`\\n\\nThen we can remove the values in fullyContained, which gives us:\\n\\n`newFullyContained = [7,8,9]`\\n\\nWe will return all the records in `newFullyContained` and apply the `STWithin` or `StContains` predicate to work out which records to return from the potential list.\\n\\n## How do you know the index usage?\\n\\nWe can write queries that use `STDistance`, `STWithin`, and `STContains` without using a geospatial index, but if we’ve got one defined, we’ll want to get the peace of mind of its actual use.\\n\\nYou can check by prefixing a query with `EXPLAIN PLAN FOR`, which will return a list of the operators in the query plan.\\n\\nIf our query uses `STDistance`, we should expect to see the ​`​FILTER\\\\_H3\\\\_INDEX` operator. If it uses STWithin or STContains, we should expect to see the INCLUSION_FILTER_H3_INDEX operator.\\n\\nSee this example query plan:\\n\\n![Apache Pinot Geospatial Indexing Query Plan](https://www.datocms-assets.com/75153/1683813851-image6.png \'Apache Pinot Geospatial Indexing Query Plan\')\\n\\nThe [StarTree Developer Hub](https://dev.startree.ai/) contains a [geospatial indexing guide](https://dev.startree.ai/docs/pinot/recipes/geospatial-indexing#how-do-i-check-that-the-geospatial-index-is-being-used) that goes through this in more detail.\\n\\n## Summary\\n\\nI hope you found this blog post useful and now understand how geospatial indexes work and when to use them in Apache Pinot.\\n\\nGive them a try, and let us know how you get on! If you want to use, or are already using geospatial queries in Apache Pinot, we’d love to hear how — feel free to [contact us](/contact-us) and tell us more! To help get you started, [sign up for a free trial of fully managed Apache Pinot](/saas-signup). And if you run into any technical questions, feel free to find me on the [StarTree Community Slack](https://stree.ai/slack).\\n","code":"var Component=(()=>{var d=Object.create;var i=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,N=Object.prototype.hasOwnProperty;var k=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),g=(a,e)=>{for(var s in e)i(a,s,{get:e[s],enumerable:!0})},l=(a,e,s,c)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let t of m(e))!N.call(a,t)&&t!==s&&i(a,t,{get:()=>e[t],enumerable:!(c=h(e,t))||c.enumerable});return a};var y=(a,e,s)=>(s=a!=null?d(u(a)):{},l(e||!a||!a.__esModule?i(s,\\"default\\",{value:a,enumerable:!0}):s,a)),w=a=>l(i({},\\"__esModule\\",{value:!0}),a);var r=k((S,o)=>{o.exports=_jsx_runtime});var I={};g(I,{default:()=>b,frontmatter:()=>f});var n=y(r()),f={title:\\"Geospatial Indexing in Apache Pinot\\",date:new Date(16837632e5),authors:[\\"needham\\"],summary:\\"This post will explore a new API endpoint that lets you check how much Pinot is lagging when ingesting from Apache Kafka.\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"geospatial indexing\\"]};function p(a){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\",h2:\\"h2\\",span:\\"span\\",code:\\"code\\",pre:\\"pre\\"},a.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:(0,n.jsx)(e.a,{href:\\"https://youtu.be/J-4iHPolZz0\\",children:(0,n.jsx)(e.img,{alt:\\"Watch the video\\",src:\\"https://i3.ytimg.com/vi/J-4iHPolZz0/maxresdefault.jpg\\"})})}),(0,n.jsxs)(e.p,{children:[\\"It\\\\u2019s been over 18 months since \\",(0,n.jsx)(e.a,{href:\\"https://medium.com/apache-pinot-developer-blog/introduction-to-geospatial-queries-in-apache-pinot-b63e2362e2a9\\",children:\\"geospatial indexes were added to Apache Pinot\\\\u2122\\"}),\\", giving you the ability to retrieve data based on geographic location\\\\u2014a common requirement in many analytics use cases. Using geospatial queries in combination with time series queries in Pinot, you can perform complex spatiotemporal analysis, such as analyzing changes in weather patterns over time or tracking the movement of objects, vehicles, or people. Pinot\'s support for geospatial data indexing means fast and efficient querying of large-scale, location-based datasets distributed across multiple nodes.\\"]}),(0,n.jsx)(e.p,{children:\\"In that time, more indexing functionality has been added, so I wanted to take an opportunity to have a look at the current state of things.\\"}),(0,n.jsxs)(e.h2,{id:\\"what-is-geospatial-indexing\\",children:[(0,n.jsx)(e.a,{href:\\"#what-is-geospatial-indexing\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"What is geospatial indexing?\\"]}),(0,n.jsx)(e.p,{children:\\"Geospatial indexing is a technique used in database management systems to store and retrieve spatial data based on its geographic location. It involves creating an index that allows for efficient querying of location-based data, such as latitude and longitude coordinates or geographical shapes.\\"}),(0,n.jsx)(e.p,{children:\'Geospatial indexing organizes spatial data in such a way that enables fast and accurate retrieval of data based on its proximity to a specific location or geographic region. This indexing can be used to answer queries such as \\"What are the restaurants with a 30-minute delivery window to my current location?\\" or \\"What are the boundaries of this specific city or state?\\"\'}),(0,n.jsx)(e.p,{children:\\"Geospatial indexing is commonly used in geographic information systems (GIS), mapping applications, and location-based services such as ride-sharing apps, social media platforms, and navigation tools. It plays a crucial role in spatial data analysis, spatial data visualization, and decision-making processes.\\"}),(0,n.jsxs)(e.h2,{id:\\"how-do-geospatial-indexes-work-in-apache-pinot\\",children:[(0,n.jsx)(e.a,{href:\\"#how-do-geospatial-indexes-work-in-apache-pinot\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"How do geospatial indexes work in Apache Pinot?\\"]}),(0,n.jsxs)(e.p,{children:[\\"We can index points using \\",(0,n.jsx)(e.a,{href:\\"https://h3geo.org/\\",children:\\"H3\\"}),\\", an open source library that originated at Uber. This library provides hexagon-based hierarchical gridding. Indexing a point means that the point is translated to a geoId, which corresponds to a hexagon. Its neighbors in H3 can be approximated by a ring of hexagons. Direct neighbors have a distance of 1, their neighbors are at a distance of 2, and so on.\\"]}),(0,n.jsx)(e.p,{children:\\"For example, if the central hexagon covers the Westminster area of central London, neighbors at distance 1 are colored blue, those at distance 2 are in green, and those at distance 3 are in red.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Geospatial Indexing In Apache Pinot\\",src:\\"https://www.datocms-assets.com/75153/1683813508-image5.png\\",title:\\"Geospatial Indexing In Apache Pinot\\"})}),(0,n.jsxs)(e.p,{children:[\\"Let\\\\u2019s learn how to use geospatial indexing with help from a dataset that captures the latest location of trains moving around the UK. We\\\\u2019re streaming this data into a \\",(0,n.jsx)(e.code,{children:\\"trains\\"}),\\" topic in Apache Kafka\\\\xAE. Here\\\\u2019s one message from this stream:\\"]}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"kcat \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-C\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-b\\"}),\\" localhost:9092 \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-t\\"}),\\" trains -c1\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"|\\"}),` jq\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"trainCompany\\"\'}),(0,n.jsx)(e.span,{className:\\"token builtin class-name\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"CrossCountry\\"\'}),`,\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"atocCode\\"\'}),(0,n.jsx)(e.span,{className:\\"token builtin class-name\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"XC\\"\'}),`,\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"lat\\"\'}),(0,n.jsx)(e.span,{className:\\"token builtin class-name\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"50.692726\\"}),`,\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"lon\\"\'}),(0,n.jsx)(e.span,{className:\\"token builtin class-name\\",children:\\":\\"}),` -3.5040767,\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,n.jsx)(e.span,{className:\\"token builtin class-name\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"2023-03-09 10:57:11.1678359431\\"\'}),`,\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"trainId\\"\'}),(0,n.jsx)(e.span,{className:\\"token builtin class-name\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"202303096771054\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"We\\\\u2019re going to ingest this data into Pinot, so let\\\\u2019s create a schema:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"trains\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dimensionFieldSpecs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"trainCompany\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"trainId\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"atocCode\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"point\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"BYTES\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dateTimeFieldSpecs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"TIMESTAMP\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"format\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS:EPOCH\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"granularity\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"The point column will store a point object that represents the current location of a train. We\\\\u2019ll see how that column gets populated from our table config, as shown below:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"trains\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"REALTIME\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"segmentsConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"timeColumnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"trains\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"replication\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"replicasPerPartition\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"fieldConfigList\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"point\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"encodingType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"RAW\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"indexType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"H3\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"properties\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"resolutions\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"7\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableIndexConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"loadMode\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"MMAP\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"noDictionaryColumns\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"point\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"streamConfigs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"streamType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"kafka\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.topic.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"trains\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.broker.list\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"kafka-geospatial:9093\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.type\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"lowlevel\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.prop.auto.offset.reset\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"smallest\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.factory.class.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.class.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"ingestionConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformConfigs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"columnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"point\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformFunction\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STPoint(lon, lat, 1)\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tenants\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"metadata\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsxs)(e.p,{children:[\\"The point column is populated by the following function under \\",(0,n.jsx)(e.code,{children:\\"transformConfigs\\"}),\\":\\"]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.code,{children:\\"STPoint(lon, lat, 1)\\"})}),(0,n.jsx)(e.p,{children:\\"In earlier versions of Pinot, you\\\\u2019d need to ensure that the schema included lat and lon columns, but that no longer applies.\\"}),(0,n.jsxs)(e.p,{children:[\\"We define the geospatial index on the point column under \\",(0,n.jsx)(e.code,{children:\\"fieldConfigList\\"}),\\". We can configure what H3 calls \\",(0,n.jsx)(e.a,{href:\\"https://h3geo.org/docs/core-library/restable\\",children:\\"resolutions\\"}),\\", which defines the size of a hexagon and their number. A resolution of 7 means that there will be 98,825,150 hexagons, each covering an area of 5.16 km\\\\xB2. We also need to add the geospatial column to \\",(0,n.jsx)(e.code,{children:\\"tableIndexConfig.noDictionaryColumns\\"}),\\".\\"]}),(0,n.jsxs)(e.p,{children:[\\"We can go ahead and create that table using the \\",(0,n.jsx)(e.code,{children:\\"AddTable\\"}),\\" command and Pinot will automatically start ingesting data from Kafka.\\"]}),(0,n.jsxs)(e.h2,{id:\\"when-is-the-geospatial-index-used\\",children:[(0,n.jsx)(e.a,{href:\\"#when-is-the-geospatial-index-used\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"When is the geospatial index used?\\"]}),(0,n.jsx)(e.p,{children:\\"The geospatial index is used when a WHERE clause in a query calls the StDistance, StWithin, or StContains functions.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.code,{children:\\"ST\\\\\\\\_Distance\\"})}),(0,n.jsx)(e.p,{children:\\"Let\\\\u2019s say we want to find all the trains within a 10 km radius of Westminster. We could write a query to answer this question using the STDistance function. The query might look like this:\\"}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-sql\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" ts\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" trainId\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" atocCode\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" trainCompany\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" ST\\\\\\\\_AsText\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"point\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"       STDistance\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"         \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"point\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"         toSphericalGeography\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"ST_GeomFromText\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'POINT (-0.13624 51.499507)\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"AS\\"}),` distance\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),` trains\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),\\" distance \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"<\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"10000\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"ORDER\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),\\" distance\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" ts \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"DESC\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"limit\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"10\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"These results from running the query would follow:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample Geospatial Indexing In Apache Pinot Query Result\\",src:\\"https://www.datocms-assets.com/75153/1683813581-image1.png\\",title:\\"Sample Geospatial Indexing In Apache Pinot Query Result\\"})}),(0,n.jsx)(e.p,{children:\\"Let\\\\u2019s now go into a bit more detail about what happens when we run the query.\\"}),(0,n.jsx)(e.p,{children:\\"The 10 km radius covers the area inside the white circle on the diagram below:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Geospatial Indexing In Apache Pinot Circle\\",src:\\"https://www.datocms-assets.com/75153/1683813641-image7.png\\",title:\\"Geospatial Indexing In Apache Pinot Circle\\"})}),(0,n.jsx)(e.p,{children:\\"Pinot\\\\u2019s query planner will first translate the distance of 10 km into a number of rings, in this case, two. It will then find all the hexagons located two rings away from the white one. Some of these hexagons will fit completely inside the white circle, and some will overlap with the circle.\\"}),(0,n.jsx)(e.p,{children:\\"If a hexagon fully fits, then we can get all the records inside this hexagon and return them. For those that partially fit, we\\\\u2019ll need to apply the distance predicate before working out which records to return.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.code,{children:\\"ST\\\\\\\\_Within/ST\\\\\\\\_Contains\\"})}),(0,n.jsxs)(e.p,{children:[\\"Let\\\\u2019s say that rather than specifying a distance, we instead want to draw a polygon and find the trains that fit inside that polygon. We could use either the \\",(0,n.jsx)(e.code,{children:\\"ST\\\\\\\\_Within\\"}),\\" or \\",(0,n.jsx)(e.code,{children:\\"ST\\\\\\\\_Contains\\"}),\\" functions to answer this question.\\"]}),(0,n.jsx)(e.p,{children:\\"The query might look like this:\\"}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-sql\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" ts\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" trainId\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" atocCode\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" trainCompany\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" ST\\\\\\\\_AsText\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"point\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),` trains\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),\\" StWithin\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"point\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      toSphericalGeography\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"ST_GeomFromText\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:`\'POLYGON((\\n`})]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:(0,n.jsx)(e.span,{className:\\"token string\\",children:`        -0.1296371966600418 51.508053828550544,\\n`})}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:(0,n.jsx)(e.span,{className:\\"token string\\",children:`        -0.1538461446762085 51.497007194317064,\\n`})}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:(0,n.jsx)(e.span,{className:\\"token string\\",children:`        -0.13032652437686923 51.488276935884414,\\n`})}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:(0,n.jsx)(e.span,{className:\\"token string\\",children:`        -0.10458670556545259 51.497003019756846,\\n`})}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:(0,n.jsx)(e.span,{className:\\"token string\\",children:`        -0.10864421725273131 51.50817152245844,\\n`})}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"        -0.1296371966600418 51.508053828550544))\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"ORDER\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),\\" ts \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"DESC\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"limit\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"10\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"The results from running the query are shown below:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample Geospatial Indexing In Apache Pinot Query Result\\",src:\\"https://www.datocms-assets.com/75153/1683813749-image4.png\\",title:\\"Sample Geospatial Indexing In Apache Pinot Query Result\\"})}),(0,n.jsx)(e.p,{children:\\"If we change the query to show trains outside of a central London polygon, we\\\\u2019d see the following results:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Sample Geospatial Indexing In Apache Pinot Query Result\\",src:\\"https://www.datocms-assets.com/75153/1683813705-image3.png\\",title:\\"Sample Geospatial Indexing In Apache Pinot Query Result\\"})}),(0,n.jsx)(e.p,{children:\\"So what\\\\u2019s actually happening when we run this query?\\"}),(0,n.jsx)(e.p,{children:\\"The polygon covers the area inside the white shape as shown below:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Geospatial Indexing In Apache Pinot Polygon\\",src:\\"https://www.datocms-assets.com/75153/1683813802-image2.png\\",title:\\"Geospatial Indexing In Apache Pinot Polygon\\"})}),(0,n.jsx)(e.p,{children:\\"Pinot\\\\u2019s query planner will first find all the coordinates on the exterior of the polygon. It will then find the hexagons that fit within that geofence. Those hexagons get added to the potential cells list.\\"}),(0,n.jsx)(e.p,{children:\\"The query planner then takes each of those hexagons and checks whether they fit completely inside the original polygon. If they do, then they get added to the fully contained cells list. If we have any cells in both lists, we remove them from the potential cells list.\\"}),(0,n.jsx)(e.p,{children:\\"Next, we find the records for the fully contained cells list and those for the potential cells list.\\"}),(0,n.jsx)(e.p,{children:\\"If we are finding records that fit inside the polygon, we return those in the fully contained list and apply the STWithin/StContains predicate to work out which records to return from the potential list.\\"}),(0,n.jsx)(e.p,{children:\\"If we are finding records outside the polygon, we will create a new fully contained list, which will actually contain the records that are outside the polygon. This list contains all of the records in the database except the ones in the potential list and those in the initial fully contained list.\\"}),(0,n.jsx)(e.p,{children:\\"This one was a bit tricky for me to get my head around, so let\\\\u2019s just quickly go through an example. Imagine that we store 10 records in our database and our potential and fully contained lists hold the following values:\\"}),(0,n.jsx)(e.pre,{className:\\"language-python\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-python\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"potential \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"0\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"2\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"3\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"fullyContained \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"4\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"5\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"6\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"First, compute newFullyContained to find all the records not in potential:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.code,{children:\\"newFullyContained = [4,5,6,7,8,9]\\"})}),(0,n.jsx)(e.p,{children:\\"Then we can remove the values in fullyContained, which gives us:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.code,{children:\\"newFullyContained = [7,8,9]\\"})}),(0,n.jsxs)(e.p,{children:[\\"We will return all the records in \\",(0,n.jsx)(e.code,{children:\\"newFullyContained\\"}),\\" and apply the \\",(0,n.jsx)(e.code,{children:\\"STWithin\\"}),\\" or \\",(0,n.jsx)(e.code,{children:\\"StContains\\"}),\\" predicate to work out which records to return from the potential list.\\"]}),(0,n.jsxs)(e.h2,{id:\\"how-do-you-know-the-index-usage\\",children:[(0,n.jsx)(e.a,{href:\\"#how-do-you-know-the-index-usage\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"How do you know the index usage?\\"]}),(0,n.jsxs)(e.p,{children:[\\"We can write queries that use \\",(0,n.jsx)(e.code,{children:\\"STDistance\\"}),\\", \\",(0,n.jsx)(e.code,{children:\\"STWithin\\"}),\\", and \\",(0,n.jsx)(e.code,{children:\\"STContains\\"}),\\" without using a geospatial index, but if we\\\\u2019ve got one defined, we\\\\u2019ll want to get the peace of mind of its actual use.\\"]}),(0,n.jsxs)(e.p,{children:[\\"You can check by prefixing a query with \\",(0,n.jsx)(e.code,{children:\\"EXPLAIN PLAN FOR\\"}),\\", which will return a list of the operators in the query plan.\\"]}),(0,n.jsxs)(e.p,{children:[\\"If our query uses \\",(0,n.jsx)(e.code,{children:\\"STDistance\\"}),\\", we should expect to see the \\\\u200B\\",(0,n.jsx)(e.code,{children:\\"\\\\u200BFILTER\\\\\\\\_H3\\\\\\\\_INDEX\\"}),\\" operator. If it uses STWithin or STContains, we should expect to see the INCLUSION_FILTER_H3_INDEX operator.\\"]}),(0,n.jsx)(e.p,{children:\\"See this example query plan:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Apache Pinot Geospatial Indexing Query Plan\\",src:\\"https://www.datocms-assets.com/75153/1683813851-image6.png\\",title:\\"Apache Pinot Geospatial Indexing Query Plan\\"})}),(0,n.jsxs)(e.p,{children:[\\"The \\",(0,n.jsx)(e.a,{href:\\"https://dev.startree.ai/\\",children:\\"StarTree Developer Hub\\"}),\\" contains a \\",(0,n.jsx)(e.a,{href:\\"https://dev.startree.ai/docs/pinot/recipes/geospatial-indexing#how-do-i-check-that-the-geospatial-index-is-being-used\\",children:\\"geospatial indexing guide\\"}),\\" that goes through this in more detail.\\"]}),(0,n.jsxs)(e.h2,{id:\\"summary\\",children:[(0,n.jsx)(e.a,{href:\\"#summary\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),(0,n.jsx)(e.p,{children:\\"I hope you found this blog post useful and now understand how geospatial indexes work and when to use them in Apache Pinot.\\"}),(0,n.jsxs)(e.p,{children:[\\"Give them a try, and let us know how you get on! If you want to use, or are already using geospatial queries in Apache Pinot, we\\\\u2019d love to hear how \\\\u2014 feel free to \\",(0,n.jsx)(e.a,{href:\\"/contact-us\\",children:\\"contact us\\"}),\\" and tell us more! To help get you started, \\",(0,n.jsx)(e.a,{href:\\"/saas-signup\\",children:\\"sign up for a free trial of fully managed Apache Pinot\\"}),\\". And if you run into any technical questions, feel free to find me on the \\",(0,n.jsx)(e.a,{href:\\"https://stree.ai/slack\\",children:\\"StarTree Community Slack\\"}),\\".\\"]})]})}function x(a={}){let{wrapper:e}=a.components||{};return e?(0,n.jsx)(e,Object.assign({},a,{children:(0,n.jsx)(p,a)})):p(a)}var b=x;return w(I);})();\\n;return Component;"},"_id":"blog/2023-05-11-Geospatial-Indexing-in-Apache-Pinot.mdx","_raw":{"sourceFilePath":"blog/2023-05-11-Geospatial-Indexing-in-Apache-Pinot.mdx","sourceFileName":"2023-05-11-Geospatial-Indexing-in-Apache-Pinot.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2023-05-11-Geospatial-Indexing-in-Apache-Pinot"},"type":"Blog","readingTime":{"text":"9 min read","minutes":8.305,"time":498300,"words":1661},"slug":"2023/05/11/Geospatial-Indexing-in-Apache-Pinot","customSlug":"2023/05/11/Geospatial-Indexing-in-Apache-Pinot","path":"blog/2023/05/11/Geospatial-Indexing-in-Apache-Pinot","customPath":"blog/2023/05/11/Geospatial-Indexing-in-Apache-Pinot","filePath":"blog/2023-05-11-Geospatial-Indexing-in-Apache-Pinot.mdx","toc":[{"value":"What is geospatial indexing?","url":"#what-is-geospatial-indexing","depth":2},{"value":"How do geospatial indexes work in Apache Pinot?","url":"#how-do-geospatial-indexes-work-in-apache-pinot","depth":2},{"value":"When is the geospatial index used?","url":"#when-is-the-geospatial-index-used","depth":2},{"value":"How do you know the index usage?","url":"#how-do-you-know-the-index-usage","depth":2},{"value":"Summary","url":"#summary","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Geospatial Indexing in Apache Pinot","datePublished":"2023-05-11T00:00:00.000Z","dateModified":"2023-05-11T00:00:00.000Z","description":"This post will explore a new API endpoint that lets you check how much Pinot is lagging when ingesting from Apache Kafka.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2023-05-11-Geospatial-Indexing-in-Apache-Pinot"}},{"title":"StarTree Indexes in Apache Pinot Part-1 - Understanding the Impact on Query Performance","date":"2023-05-16T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","star-tree index"],"summary":"The blog post explains the star-tree index in Apache Pinot and its benefits compared to traditional materialized views. By implementing a star-tree index, query performance significantly improved, reducing query latency from 1,513 ms to just 4 ms and drastically reducing disk reads by 99.999%.","authors":["dabade"],"body":{"raw":"\\nStar-tree is a [specialized index](https://docs.pinot.apache.org/basics/indexing/star-tree-index) in [Apache Pinot™](https://startree.ai/resources/what-is-apache-pinot). This index dynamically builds a tree structure to maintain aggregates for a group of dimensions. With star-tree Index, the query latency becomes a function of just a tree traversal with computational complexity of log(_n_).\\n\\n[This comprehensive blog](https://startree.ai/blog/a-tale-of-three-real-time-olap-databases#query) explains in depth how the star-tree Index differs from traditional materialized views (MVs). In particular, read the section Star-Tree Index: Pinot’s intelligent materialized view. Particularly this one key passage:\\n\\n_Star-Tree Index: Pinot’s Intelligent Materialized View:_\\n\\n_The star-tree index provides an intelligent way to build materialized views within Pinot. Traditional MVs work by fully materializing the computation for each source record that matches the specified predicates. Although useful, this can result in non-trivial storage overhead. On the other hand, the star-tree index allows us to partially materialize the computations and provide the ability to tune the space-time tradeoff by providing a configurable threshold between pre-aggregation and data scans._\\n\\n![](https://www.datocms-assets.com/75153/1684246698-image5.png)\\n\\nIn this three-part blog series, we will compare and contrast query performance of a star-tree index with an inverted index, something that most of the OLAP databases end up using for such queries.\\n\\nIn this first part, we will showcase how a star-tree index brought down standalone query latency on a sizable dataset of ~633M records from 1,513ms to 4ms! — nearly 380x faster.\\n\\n![](https://www.datocms-assets.com/75153/1684246806-image7.png)\\n\\n## 1\\\\. The Dataset:\\n\\nWe used New York City Taxi Data for this comparison. Original source: [here](https://www.kaggle.com/c/nyc-taxi-trip-duration). Below are the high level details about this dataset.\\n\\n![](https://www.datocms-assets.com/75153/1684246816-image6.png)\\n\\n### Schema:\\n\\nThe dataset has 8 dimension fields and 11 metric columns as listed below.\\n\\n![](https://www.datocms-assets.com/75153/1684246732-image2.png)\\n\\n## 2\\\\. Query Pattern\\n\\nThe query pattern involved slicing and dicing the data (GROUPING) BY various dimensions (Date, Month and Year), aggregating different metrics (total trips, distance and passengers count) and FILTERING BY a time range that could go as wide as 1 year.\\n\\n![](https://www.datocms-assets.com/75153/1684246872-image10.png)\\n\\nNote: A key thing to note is that a single star-tree index covers a wide range of OLAP queries that comprise the dimensions, metrics and aggregate functions specified in it.\\n\\n### Star-Tree Index Config:\\n\\nTo support the various query patterns specified above, we defined the following star-tree index.\\n\\n```json\\n\\"starTreeIndexConfigs\\": [\\n        {\\n          \\"dimensionsSplitOrder\\": [\\n            \\"dropoff_date_str\\",\\n            \\"dropoff_month\\",\\n            \\"dropoff_year\\"\\n          ],\\n          \\"skipStarNodeCreationForDimensions\\": [],\\n          \\"functionColumnPairs\\": [\\n            \\"COUNT__*\\",\\n            \\"SUM__passenger_count\\",\\n            \\"SUM__total_amount\\",\\n            \\"SUM__trip_distance\\",\\n            \\"AVG__passenger_count\\",\\n            \\"AVG__total_amount\\",\\n            \\"AVG__trip_distance\\",\\n            \\"MIN__passenger_count\\",\\n            \\"MIN__total_amount\\",\\n            \\"MIN__trip_distance\\",\\n            \\"MAX__passenger_count\\",\\n            \\"MAX__total_amount\\",\\n            \\"MAX__trip_distance\\"\\n          ],\\n          \\"maxLeafRecords\\": 10000\\n        }\\n      ]\\n```\\n\\nThis one star-tree index can get us insights to questions such as:\\n\\n-   How many trips were completed in a given day, month or year?\\n-   How many passengers traveled in a given day, month or year?\\n-   What is the daily / monthly / annual average trip revenue?\\n-   What is the daily / monthly / annual average trip revenue, trip duration and distance traveled?\\n-   What is the daily / monthly / annual breakdown of total number of trips, total distance traveled and total revenue generated in 2015?\\n-   And many more…\\n\\nWe will use one such variant query for this illustration:\\n\\n-   What is the total number of trips, total distance traveled and total revenue generated by day in 2015?\\n\\nWe used a very small infrastructure footprint for this comparison test.\\n\\n![](https://www.datocms-assets.com/75153/1687549350-screen-shot-2023-06-22-at-1-32-51-pm.png)\\n\\n## 4\\\\. Query Results and Stats\\n\\n### Iteration #1: w/o any Apache Pinot optimizations:\\n\\nFirst, we ran the query without any optimizations offered in Apache Pinot.\\n\\n```sql\\n-- Iteration #1: w/o optimizations > 120s\\n\\nSELECT\\n      toDateTime(tpep_dropoff_datetime/1000, \'yyyy-MM-dd\') \\"Date\\",\\n      count(*) \\"Total # of Trips\\",\\n      sum(trip_distance) \\"Total distance traveled\\",\\n      sum(passenger_count) \\"Total # of Passengers\\",\\n      sum(total_amount) \\"Total Revenue\\"\\nFROM\\n      nyc_taxi_demo\\nWHERE\\n    \\"Date\\" BETWEEN \'2015-01-01\' AND \'2015-12-31\'\\nGROUP BY\\n    \\"Date\\"\\nORDER BY\\n    \\"Date\\" ASC\\nlimit 1000\\n```\\n\\nThis was a wide time range query (365 days). It required scanning across ~146M out of ~633M documents. In addition, it involved performing an expensive ToDateTime transformation on the tpep_dropoff_datetime entry in each of those ~146M documents during query time.\\n\\nResult: The query took 131,425 milliseconds (~131.4s; ~2m 11s) to complete.\\n\\n### Iteration #2: w/ Inverted Index\xa0\\n\\nIn this iteration, we used a derived column - dropoff_date_str - which performed the ToDateTime transformation for every record during ingestion time. Since the cardinality of this derived column was much lower (granularity was at Day level instead of milliseconds), this enabled us to use an inverted index on this column.\\n\\n```sql\\n-- Iteration #2: w/ Ingestion Time Transformation\\nSELECT\\n      dropoff_date_str \\"Date\\",\\n      count(*) \\"Total # of Trips\\",\\n      sum(trip_distance) \\"Total distance traveled\\",\\n      sum(passenger_count) \\"Total # of Passengers\\",\\n      sum(total_amount) \\"Total Revenue\\"\\nFROM\\n      nyc_taxi_demo\\nWHERE\\n    \\"Date\\" BETWEEN \'2015-01-01\' AND \'2015-12-31\'\\nGROUP BY\\n    \\"Date\\"\\nORDER BY\\n    \\"Date\\" ASC\\nlimit 1000\\noption(useStarTree=false, timeoutMs=20000)\\n```\\n\\n![](https://www.datocms-assets.com/75153/1684246716-image1.png)\\n\\nResult: The query completed in 1,513 milliseconds. (~1.5s); from ~131s to ~1.5s was a BIG improvement. However, results still took more than a second — which is a relatively long time for an OLAP database, especially if it is faced with multiple concurrent queries.\\n\\n### Iteration #3: w/ Star-Tree Index:\xa0\\n\\nIn this iteration, we ran the same query with star-tree index enabled.\\n\\n```sql\\n-- Iteration #3: w/ Ingestion Time Transformation + StarTree Index\\nSELECT\\n      dropoff_date_str \\"Date\\",\\n      count(*) \\"Total # of Trips\\",\\n      sum(trip_distance) \\"Total distance traveled\\",\\n      sum(passenger_count) \\"Total # of Passengers\\",\\n      sum(total_amount) \\"Total Revenue\\"\\nFROM\\n      nyc_taxi_demo\\nWHERE\\n    \\"Date\\" BETWEEN \'2015-01-01\' AND \'2015-12-31\'\\nGROUP BY\\n    \\"Date\\"\\nORDER BY\\n    \\"Date\\" ASC\\nlimit 1000\\noption(useStarTree=true)\\n```\\n\\n![](https://www.datocms-assets.com/75153/1684246852-image9.png)\\n\\nResult: The query completed in 4 milliseconds! Notice in particular that the numDocsScanned came down from ~146M to 409!\\n\\n### Comparison:\\n\\nLet’s take a closer look at the [query response stats](https://docs.pinot.apache.org/users/api/querying-pinot-using-standard-sql/response-format) across all three iterations to understand the “how” part of this magic of indexing in Apache Pinot.\\n\\n![](https://www.datocms-assets.com/75153/1684246748-image3.png)\\n\\n1.  The dataset has 633,694,594 records (documents) spread across 130 segments.\\n2.  Query Stats:\\n\\n    1.  w/o any index optimizations (Iteration #1), the query scanned ALL 633,694,594 records (check numEntriesScannedInFilter) during processing. Also, numEntriesScannedPostFilter was 584,147,312 (numDocsScanned = ~146M). All 130 segments were processed which was very inefficient.\\n    2.  w/ Inverted Index (Iteration #2), numEntriesScannedInFilter was 0; numEntriesScannedPostFilter was 584,147,312 (numDocsScanned = ~146M) which meant that the query selectivity was low (the query had to scan a lot of records during post filter phase; about 92% of overall records). This is an indication of when a star-tree index could help.\\n    3.  w/ Star-tree Index (Iteration #3), numEntriesScannedInFilter was 0; numEntriesScannedPostFilter was only 2,045 (numDocsScanned = 409). The star-tree index helped improve query performance tremendously by providing high query selectivity.\\n\\n## 5\\\\. Impact Summary:\\n\\n![](https://www.datocms-assets.com/75153/1684246766-image4.png)\\n\\n1.  356,968x improvement (or 99.999% drop) in num docs scanned from ~146M to 409.\\n2.  378.5x improvement (~99.736% drop) in query latency from 1,513 ms to 4 ms.\\n\\n### Key Benefits of the Star-Tree Index:\\n\\n-   User controllable: Tune space vs. time overhead\\n-   Flexible: create any number of indexes. The right index is chosen based on the query structure.\\n-   Transparent: Unlike traditional MVs, users don’t need to know about the existence of a star-tree index. The same query will be accelerated with a star-tree index in place.\\n-   Dynamic: Very easy to generate a new index at any point of time.\\n-   Disk IO is the most expensive operation in query processing. Latency is linear to the number of disk reads a query has to perform. Star-Tree Index brings the number of disk reads down exponentially.\\n\\n    -   In this example, star-tree Index reduced the disk reads by 99.999% from ~584 Million entries (~146 Million documents or records) in case of an inverted index to 2,045 entries (409 documents or records). Query latency came down from 1,513 ms to 4 ms!\\n\\n[In part 2 of this series,](https://startree.ai/blog/star-tree-indexes-in-apache-pinot-part-2-understanding-the-impact-during-high-concurrency) we will perform throughput tests to measure the impact of star-tree index under high load.\\n","code":"var Component=(()=>{var h=Object.create;var i=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,N=Object.prototype.hasOwnProperty;var k=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),g=(a,e)=>{for(var s in e)i(a,s,{get:e[s],enumerable:!0})},r=(a,e,s,c)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let t of m(e))!N.call(a,t)&&t!==s&&i(a,t,{get:()=>e[t],enumerable:!(c=p(e,t))||c.enumerable});return a};var y=(a,e,s)=>(s=a!=null?h(u(a)):{},r(e||!a||!a.__esModule?i(s,\\"default\\",{value:a,enumerable:!0}):s,a)),f=a=>r(i({},\\"__esModule\\",{value:!0}),a);var o=k((T,l)=>{l.exports=_jsx_runtime});var v={};g(v,{default:()=>_,frontmatter:()=>w});var n=y(o()),w={title:\\"StarTree Indexes in Apache Pinot Part-1 - Understanding the Impact on Query Performance\\",date:new Date(16841952e5),authors:[\\"dabade\\"],summary:\\"The blog post explains the star-tree index in Apache Pinot and its benefits compared to traditional materialized views. By implementing a star-tree index, query performance significantly improved, reducing query latency from 1,513 ms to just 4 ms and drastically reducing disk reads by 99.999%.\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"star-tree index\\"]};function d(a){let e=Object.assign({p:\\"p\\",a:\\"a\\",em:\\"em\\",img:\\"img\\",h2:\\"h2\\",span:\\"span\\",h3:\\"h3\\",pre:\\"pre\\",code:\\"code\\",ul:\\"ul\\",li:\\"li\\",ol:\\"ol\\"},a.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.p,{children:[\\"Star-tree is a \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/indexing/star-tree-index\\",children:\\"specialized index\\"}),\\" in \\",(0,n.jsx)(e.a,{href:\\"https://startree.ai/resources/what-is-apache-pinot\\",children:\\"Apache Pinot\\\\u2122\\"}),\\". This index dynamically builds a tree structure to maintain aggregates for a group of dimensions. With star-tree Index, the query latency becomes a function of just a tree traversal with computational complexity of log(\\",(0,n.jsx)(e.em,{children:\\"n\\"}),\\").\\"]}),(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.a,{href:\\"https://startree.ai/blog/a-tale-of-three-real-time-olap-databases#query\\",children:\\"This comprehensive blog\\"}),\\" explains in depth how the star-tree Index differs from traditional materialized views (MVs). In particular, read the section Star-Tree Index: Pinot\\\\u2019s intelligent materialized view. Particularly this one key passage:\\"]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.em,{children:\\"Star-Tree Index: Pinot\\\\u2019s Intelligent Materialized View:\\"})}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.em,{children:\\"The star-tree index provides an intelligent way to build materialized views within Pinot. Traditional MVs work by fully materializing the computation for each source record that matches the specified predicates. Although useful, this can result in non-trivial storage overhead. On the other hand, the star-tree index allows us to partially materialize the computations and provide the ability to tune the space-time tradeoff by providing a configurable threshold between pre-aggregation and data scans.\\"})}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"\\",src:\\"https://www.datocms-assets.com/75153/1684246698-image5.png\\"})}),(0,n.jsx)(e.p,{children:\\"In this three-part blog series, we will compare and contrast query performance of a star-tree index with an inverted index, something that most of the OLAP databases end up using for such queries.\\"}),(0,n.jsx)(e.p,{children:\\"In this first part, we will showcase how a star-tree index brought down standalone query latency on a sizable dataset of ~633M records from 1,513ms to 4ms! \\\\u2014 nearly 380x faster.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"\\",src:\\"https://www.datocms-assets.com/75153/1684246806-image7.png\\"})}),(0,n.jsxs)(e.h2,{id:\\"1-the-dataset\\",children:[(0,n.jsx)(e.a,{href:\\"#1-the-dataset\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"1. The Dataset:\\"]}),(0,n.jsxs)(e.p,{children:[\\"We used New York City Taxi Data for this comparison. Original source: \\",(0,n.jsx)(e.a,{href:\\"https://www.kaggle.com/c/nyc-taxi-trip-duration\\",children:\\"here\\"}),\\". Below are the high level details about this dataset.\\"]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"\\",src:\\"https://www.datocms-assets.com/75153/1684246816-image6.png\\"})}),(0,n.jsxs)(e.h3,{id:\\"schema\\",children:[(0,n.jsx)(e.a,{href:\\"#schema\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Schema:\\"]}),(0,n.jsx)(e.p,{children:\\"The dataset has 8 dimension fields and 11 metric columns as listed below.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"\\",src:\\"https://www.datocms-assets.com/75153/1684246732-image2.png\\"})}),(0,n.jsxs)(e.h2,{id:\\"2-query-pattern\\",children:[(0,n.jsx)(e.a,{href:\\"#2-query-pattern\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"2. Query Pattern\\"]}),(0,n.jsx)(e.p,{children:\\"The query pattern involved slicing and dicing the data (GROUPING) BY various dimensions (Date, Month and Year), aggregating different metrics (total trips, distance and passengers count) and FILTERING BY a time range that could go as wide as 1 year.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"\\",src:\\"https://www.datocms-assets.com/75153/1684246872-image10.png\\"})}),(0,n.jsx)(e.p,{children:\\"Note: A key thing to note is that a single star-tree index covers a wide range of OLAP queries that comprise the dimensions, metrics and aggregate functions specified in it.\\"}),(0,n.jsxs)(e.h3,{id:\\"star-tree-index-config\\",children:[(0,n.jsx)(e.a,{href:\\"#star-tree-index-config\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Star-Tree Index Config:\\"]}),(0,n.jsx)(e.p,{children:\\"To support the various query patterns specified above, we defined the following star-tree index.\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"starTreeIndexConfigs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"          \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dimensionsSplitOrder\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"dropoff_date_str\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"dropoff_month\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"dropoff_year\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"          \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"          \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"skipStarNodeCreationForDimensions\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"          \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"functionColumnPairs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"COUNT__*\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"SUM__passenger_count\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"SUM__total_amount\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"SUM__trip_distance\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"AVG__passenger_count\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"AVG__total_amount\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"AVG__trip_distance\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"MIN__passenger_count\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"MIN__total_amount\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"MIN__trip_distance\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"MAX__passenger_count\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"MAX__total_amount\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"MAX__trip_distance\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"          \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"          \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"maxLeafRecords\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"10000\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"This one star-tree index can get us insights to questions such as:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"How many trips were completed in a given day, month or year?\\"}),(0,n.jsx)(e.li,{children:\\"How many passengers traveled in a given day, month or year?\\"}),(0,n.jsx)(e.li,{children:\\"What is the daily / monthly / annual average trip revenue?\\"}),(0,n.jsx)(e.li,{children:\\"What is the daily / monthly / annual average trip revenue, trip duration and distance traveled?\\"}),(0,n.jsx)(e.li,{children:\\"What is the daily / monthly / annual breakdown of total number of trips, total distance traveled and total revenue generated in 2015?\\"}),(0,n.jsx)(e.li,{children:\\"And many more\\\\u2026\\"})]}),(0,n.jsx)(e.p,{children:\\"We will use one such variant query for this illustration:\\"}),(0,n.jsx)(e.ul,{children:(0,n.jsx)(e.li,{children:\\"What is the total number of trips, total distance traveled and total revenue generated by day in 2015?\\"})}),(0,n.jsx)(e.p,{children:\\"We used a very small infrastructure footprint for this comparison test.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"\\",src:\\"https://www.datocms-assets.com/75153/1687549350-screen-shot-2023-06-22-at-1-32-51-pm.png\\"})}),(0,n.jsxs)(e.h2,{id:\\"4-query-results-and-stats\\",children:[(0,n.jsx)(e.a,{href:\\"#4-query-results-and-stats\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"4. Query Results and Stats\\"]}),(0,n.jsxs)(e.h3,{id:\\"iteration-1-wo-any-apache-pinot-optimizations\\",children:[(0,n.jsx)(e.a,{href:\\"#iteration-1-wo-any-apache-pinot-optimizations\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Iteration #1: w/o any Apache Pinot optimizations:\\"]}),(0,n.jsx)(e.p,{children:\\"First, we ran the query without any optimizations offered in Apache Pinot.\\"}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"language-sql code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token comment\\",children:\\"-- Iteration #1: w/o optimizations > 120s\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"SELECT\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      toDateTime\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"tpep_dropoff_datetime\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"/\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1000\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'yyyy-MM-dd\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Date\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Total # of Trips\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"sum\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"trip_distance\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Total distance traveled\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"sum\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"passenger_count\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Total # of Passengers\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"sum\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"total_amount\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Total Revenue\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`      nyc_taxi_demo\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Date\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"BETWEEN\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'2015-01-01\'\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"AND\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'2015-12-31\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"GROUP\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Date\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"ORDER\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Date\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"ASC\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"limit\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1000\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"This was a wide time range query (365 days). It required scanning across ~146M out of ~633M documents. In addition, it involved performing an expensive ToDateTime transformation on the tpep_dropoff_datetime entry in each of those ~146M documents during query time.\\"}),(0,n.jsx)(e.p,{children:\\"Result: The query took 131,425 milliseconds (~131.4s; ~2m 11s) to complete.\\"}),(0,n.jsxs)(e.h3,{id:\\"iteration-2-w-inverted-index\\",children:[(0,n.jsx)(e.a,{href:\\"#iteration-2-w-inverted-index\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Iteration #2: w/ Inverted Index\\\\xA0\\"]}),(0,n.jsx)(e.p,{children:\\"In this iteration, we used a derived column - dropoff_date_str - which performed the ToDateTime transformation for every record during ingestion time. Since the cardinality of this derived column was much lower (granularity was at Day level instead of milliseconds), this enabled us to use an inverted index on this column.\\"}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"language-sql code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token comment\\",children:\\"-- Iteration #2: w/ Ingestion Time Transformation\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"SELECT\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      dropoff_date_str \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Date\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Total # of Trips\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"sum\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"trip_distance\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Total distance traveled\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"sum\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"passenger_count\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Total # of Passengers\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"sum\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"total_amount\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Total Revenue\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`      nyc_taxi_demo\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Date\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"BETWEEN\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'2015-01-01\'\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"AND\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'2015-12-31\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"GROUP\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Date\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"ORDER\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Date\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"ASC\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"limit\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1000\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"option\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"useStarTree\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" timeoutMs\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"20000\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"\\",src:\\"https://www.datocms-assets.com/75153/1684246716-image1.png\\"})}),(0,n.jsx)(e.p,{children:\\"Result: The query completed in 1,513 milliseconds. (~1.5s); from ~131s to ~1.5s was a BIG improvement. However, results still took more than a second \\\\u2014 which is a relatively long time for an OLAP database, especially if it is faced with multiple concurrent queries.\\"}),(0,n.jsxs)(e.h3,{id:\\"iteration-3-w-star-tree-index\\",children:[(0,n.jsx)(e.a,{href:\\"#iteration-3-w-star-tree-index\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Iteration #3: w/ Star-Tree Index:\\\\xA0\\"]}),(0,n.jsx)(e.p,{children:\\"In this iteration, we ran the same query with star-tree index enabled.\\"}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"language-sql code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token comment\\",children:\\"-- Iteration #3: w/ Ingestion Time Transformation + StarTree Index\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"SELECT\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      dropoff_date_str \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Date\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Total # of Trips\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"sum\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"trip_distance\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Total distance traveled\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"sum\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"passenger_count\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Total # of Passengers\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"sum\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"total_amount\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Total Revenue\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FROM\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`      nyc_taxi_demo\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"WHERE\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Date\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"BETWEEN\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'2015-01-01\'\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"AND\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'2015-12-31\'\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"GROUP\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Date\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"ORDER\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"BY\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"Date\\"\'}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"ASC\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"limit\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"1000\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"option\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"useStarTree\\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"true\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"\\",src:\\"https://www.datocms-assets.com/75153/1684246852-image9.png\\"})}),(0,n.jsx)(e.p,{children:\\"Result: The query completed in 4 milliseconds! Notice in particular that the numDocsScanned came down from ~146M to 409!\\"}),(0,n.jsxs)(e.h3,{id:\\"comparison\\",children:[(0,n.jsx)(e.a,{href:\\"#comparison\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Comparison:\\"]}),(0,n.jsxs)(e.p,{children:[\\"Let\\\\u2019s take a closer look at the \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/users/api/querying-pinot-using-standard-sql/response-format\\",children:\\"query response stats\\"}),\\" across all three iterations to understand the \\\\u201Chow\\\\u201D part of this magic of indexing in Apache Pinot.\\"]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"\\",src:\\"https://www.datocms-assets.com/75153/1684246748-image3.png\\"})}),(0,n.jsxs)(e.ol,{children:[(0,n.jsx)(e.li,{children:(0,n.jsx)(e.p,{children:\\"The dataset has 633,694,594 records (documents) spread across 130 segments.\\"})}),(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.p,{children:\\"Query Stats:\\"}),(0,n.jsxs)(e.ol,{children:[(0,n.jsx)(e.li,{children:\\"w/o any index optimizations (Iteration #1), the query scanned ALL 633,694,594 records (check numEntriesScannedInFilter) during processing. Also, numEntriesScannedPostFilter was 584,147,312 (numDocsScanned = ~146M). All 130 segments were processed which was very inefficient.\\"}),(0,n.jsx)(e.li,{children:\\"w/ Inverted Index (Iteration #2), numEntriesScannedInFilter was 0; numEntriesScannedPostFilter was 584,147,312 (numDocsScanned = ~146M) which meant that the query selectivity was low (the query had to scan a lot of records during post filter phase; about 92% of overall records). This is an indication of when a star-tree index could help.\\"}),(0,n.jsx)(e.li,{children:\\"w/ Star-tree Index (Iteration #3), numEntriesScannedInFilter was 0; numEntriesScannedPostFilter was only 2,045 (numDocsScanned = 409). The star-tree index helped improve query performance tremendously by providing high query selectivity.\\"})]})]})]}),(0,n.jsxs)(e.h2,{id:\\"5-impact-summary\\",children:[(0,n.jsx)(e.a,{href:\\"#5-impact-summary\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"5. Impact Summary:\\"]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"\\",src:\\"https://www.datocms-assets.com/75153/1684246766-image4.png\\"})}),(0,n.jsxs)(e.ol,{children:[(0,n.jsx)(e.li,{children:\\"356,968x improvement (or 99.999% drop) in num docs scanned from ~146M to 409.\\"}),(0,n.jsx)(e.li,{children:\\"378.5x improvement (~99.736% drop) in query latency from 1,513 ms to 4 ms.\\"})]}),(0,n.jsxs)(e.h3,{id:\\"key-benefits-of-the-star-tree-index\\",children:[(0,n.jsx)(e.a,{href:\\"#key-benefits-of-the-star-tree-index\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Key Benefits of the Star-Tree Index:\\"]}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:(0,n.jsx)(e.p,{children:\\"User controllable: Tune space vs. time overhead\\"})}),(0,n.jsx)(e.li,{children:(0,n.jsx)(e.p,{children:\\"Flexible: create any number of indexes. The right index is chosen based on the query structure.\\"})}),(0,n.jsx)(e.li,{children:(0,n.jsx)(e.p,{children:\\"Transparent: Unlike traditional MVs, users don\\\\u2019t need to know about the existence of a star-tree index. The same query will be accelerated with a star-tree index in place.\\"})}),(0,n.jsx)(e.li,{children:(0,n.jsx)(e.p,{children:\\"Dynamic: Very easy to generate a new index at any point of time.\\"})}),(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.p,{children:\\"Disk IO is the most expensive operation in query processing. Latency is linear to the number of disk reads a query has to perform. Star-Tree Index brings the number of disk reads down exponentially.\\"}),(0,n.jsx)(e.ul,{children:(0,n.jsx)(e.li,{children:\\"In this example, star-tree Index reduced the disk reads by 99.999% from ~584 Million entries (~146 Million documents or records) in case of an inverted index to 2,045 entries (409 documents or records). Query latency came down from 1,513 ms to 4 ms!\\"})})]})]}),(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.a,{href:\\"https://startree.ai/blog/star-tree-indexes-in-apache-pinot-part-2-understanding-the-impact-during-high-concurrency\\",children:\\"In part 2 of this series,\\"}),\\" we will perform throughput tests to measure the impact of star-tree index under high load.\\"]})]})}function x(a={}){let{wrapper:e}=a.components||{};return e?(0,n.jsx)(e,Object.assign({},a,{children:(0,n.jsx)(d,a)})):d(a)}var _=x;return f(v);})();\\n;return Component;"},"_id":"blog/2023-05-16-star-tree-indexes-in-apache-pinot-part-1-understanding-the-impact-on-query-performance.mdx","_raw":{"sourceFilePath":"blog/2023-05-16-star-tree-indexes-in-apache-pinot-part-1-understanding-the-impact-on-query-performance.mdx","sourceFileName":"2023-05-16-star-tree-indexes-in-apache-pinot-part-1-understanding-the-impact-on-query-performance.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2023-05-16-star-tree-indexes-in-apache-pinot-part-1-understanding-the-impact-on-query-performance"},"type":"Blog","readingTime":{"text":"7 min read","minutes":6.25,"time":375000,"words":1250},"slug":"2023/05/16/star-tree-indexes-in-apache-pinot-part-1-understanding-the-impact-on-query-performance","customSlug":"2023/05/16/star-tree-indexes-in-apache-pinot-part-1-understanding-the-impact-on-query-performance","path":"blog/2023/05/16/star-tree-indexes-in-apache-pinot-part-1-understanding-the-impact-on-query-performance","customPath":"blog/2023/05/16/star-tree-indexes-in-apache-pinot-part-1-understanding-the-impact-on-query-performance","filePath":"blog/2023-05-16-star-tree-indexes-in-apache-pinot-part-1-understanding-the-impact-on-query-performance.mdx","toc":[{"value":"1. The Dataset:","url":"#1-the-dataset","depth":2},{"value":"Schema:","url":"#schema","depth":3},{"value":"2. Query Pattern","url":"#2-query-pattern","depth":2},{"value":"Star-Tree Index Config:","url":"#star-tree-index-config","depth":3},{"value":"4. Query Results and Stats","url":"#4-query-results-and-stats","depth":2},{"value":"Iteration #1: w/o any Apache Pinot optimizations:","url":"#iteration-1-wo-any-apache-pinot-optimizations","depth":3},{"value":"Iteration #2: w/ Inverted Index\xa0","url":"#iteration-2-w-inverted-index","depth":3},{"value":"Iteration #3: w/ Star-Tree Index:\xa0","url":"#iteration-3-w-star-tree-index","depth":3},{"value":"Comparison:","url":"#comparison","depth":3},{"value":"5. Impact Summary:","url":"#5-impact-summary","depth":2},{"value":"Key Benefits of the Star-Tree Index:","url":"#key-benefits-of-the-star-tree-index","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"StarTree Indexes in Apache Pinot Part-1 - Understanding the Impact on Query Performance","datePublished":"2023-05-16T00:00:00.000Z","dateModified":"2023-05-16T00:00:00.000Z","description":"The blog post explains the star-tree index in Apache Pinot and its benefits compared to traditional materialized views. By implementing a star-tree index, query performance significantly improved, reducing query latency from 1,513 ms to just 4 ms and drastically reducing disk reads by 99.999%.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2023-05-16-star-tree-indexes-in-apache-pinot-part-1-understanding-the-impact-on-query-performance"}},{"title":"Apache Pinot Tutorial for Getting Started - A Step-by-Step Guide","date":"2023-05-18T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","data explorer","getting started","streaming","kafka"],"summary":"This blog post is a guide to getting started with Apache Pinot, including installing and running the necessary components of a Pinot cluster. It also explains how to set up schemas, tables, and load data into Pinot, as well as how to run queries using the Pinot Data Explorer. The next article in the series will cover consuming event streaming data with Apache Pinot and Apache Kafka.","authors":["herman"],"body":{"raw":"\\nHow do you get started with [Apache Pinot™](https://startree.ai/resources/what-is-apache-pinot)? Good question! To save you the hassle of trying to tackle this on your own, here’s a handy guide that overviews all of the components that make up Pinot and how to set Pinot up.\\n\\n## The Obligatory What is Apache Pinot and StarTree Section\\n\\n[Pinot](https://startree.ai/what-is-apache-pinot) is an open source, free-to-use, real-time, and distributed OLAP datastore, purpose built to provide ultra low-latency analytics at extremely high throughput.\\n\\nStarTree offers a fully managed version of the Apache Pinot [real-time analytics](https://startree.ai/resources/what-is-real-time-analytics) system and other tools around it, such as a real-time anomaly detection and root cause analysis tool, which you can [try for free](https://startree.ai/saas-signup).\\n\\n## What do you need to run Apache Pinot?\\n\\nThe Docker image that we will use runs multiple services. To accommodate this, we recommend at a minimum the following resources in order to run the sample:\\n\\n-   CPUs: four or more\\n-   Memory: 8 GB or more\\n-   Swap: 2 GB or more\\n-   Disk space: 10 GB or more\\n\\nNote: When importing custom data or event streaming, you may need more resources. Additionally, note that if not set, Docker will use resources from the host environment as needed and available.\\n\\n## Step-by-step installation of Apache Pinot\\n\\nFor this intro tutorial, we will use Docker. Alternatively, you can run Pinot locally if you wish.\\n\\nThe instructions use a Windows 11 computer, but they will work on Macs as well. Also note that I am using VS Code with the Docker extension installed.\\n\\n### Step 1:\xa0\\n\\nMake sure you have [Docker installed](https://docs.docker.com/get-docker/) on your machine.\\n\\n_Docker is a set of platform as a service (PaaS) products that use OS-level virtualization to deliver software in packages called containers._\\n\\n### Step 2:\\n\\nNow, let’s download the Docker image. On a Windows machine, start a new PowerShell command window. Note that this is not the same as a Windows PowerShell command window, as shown below.\\n\\n![Download Docker image on Windows with PowerShell command window](https://www.datocms-assets.com/75153/1684419409-image7.png \'Download Docker image on Windows with PowerShell command window\')\\n\\nUse the following command to get (pull) the image we are looking for:\\n\\n```bash\\ndocker pull apachepinot/pinot:0.12.0\\n```\\n\\nYou can also download the latest version like so:\\n\\n```bash\\ndocker pull apachepinot/pinot:latest\\n```\\n\\nHere, apachepinot is the name of the repository in Docker Hub, pinot is the name of the image, and :latest or :0.12.0 is the version for the image.\xa0 Note that we will be using the 0.12.0 version for this blog post.\\n\\n_Docker Hub is the world’s largest repository of container images in the world._\\n\\nYou can verify the image was downloaded or pulled by running the following command:\\n\\n```bash\\ndocker images\\n```\\n\\nIt should show you the image like so:\\n\\n![Docker images command](https://www.datocms-assets.com/75153/1684420004-image3.png \'Docker images command\')\\n\\n### Step 3:\\n\\nLet’s run a container using the Docker image that we downloaded:\\n\\n```bash\\ndocker run -it --entrypoint /bin/bash -p 9000:9000 apachepinot/pinot:0.12.0\\n```\\n\\n![Running a container with downloaded Docker image](https://www.datocms-assets.com/75153/1684420103-image4.png \'Running a container with downloaded Docker image\')\\n\\nThe docker run command runs the image. The \\\\-p 9000:00 option maps the docker container port 9000 to the local machine port 9000. This allows us to access the Pinot UI, which defaults to port 9000 to be accessible from the localhost. We are using the –entrypoint to override the default entrypoint and replace it with Bash. We want to override the default behavior so that we can start each component one at a time. The next parameter apachepinot/pinot:0.12.0 is the Docker image we pulled above.\\n\\nAfter running the command, we’ll find ourselves in the Docker container instance running Bash shell. We can use ls to list the contents of the Docker container as shown above.\\n\\nIf you’re using VS Code, with the Docker extension installed, you can click on the Docker extension and see our container and its content:\\n\\n![VS Code Docker extension open to see container and content](https://www.datocms-assets.com/75153/1684421493-image11.png \'VS Code Docker extension open to see container and content\')\\n\\nClick on the Docker icon in the left menu, and apachepinot/pinot:0.12.0. This should take a few seconds to connect to the running container. Now, you can navigate to the files and see what we have under the opt folder.\\n\\n### Step 4:\\n\\nLet’s run the components that are essential to running a Pinot cluster. Change directory to the bin folder and list the contents like so:\\n\\n![Running components, directory changed to bin folder and contents listed](https://www.datocms-assets.com/75153/1684421611-image10.png \'Running components, directory changed to bin folder and contents listed\')\\n\\nIn order to start the Pinot cluster, we will need to run the following essential components:\\n\\n-   Apache ZooKeeper™\\n-   Controller\\n-   Broker\\n-   Server\\n\\nStart ZooKeeper using the following command:\\n\\n```bash\\n./pinot-admin.sh StartZookeeper &\\n```\\n\\npinot-admin.sh is a shell script for starting the various components. The & allows us to continue using the Bash shell. ZooKeeper is responsible for the configuration for the Pinot cluster and needs to be started first.\\n\\nWe can start the remaining components using these commands one at a time:\\n\\n```bash\\n./pinot-admin.sh StartController &\\n./pinot-admin.sh StartBroker &\\n./pinot-admin.sh StartServer &\\n```\\n\\nThe controller controls the cluster health and coordinates with ZooKeeper for configuration and status changes. The broker is responsible for query distribution and result collation, sometimes called Scatter-Gather. Servers manage individual table segments and perform the actual read/writes. To get a better understanding of each component, read this [intro to Apache Pinot](https://startree.ai/blog/introduction-to-apache-pinot-a-beginners-guide).\\n\\nAt this time, we should have a running Pinot cluster. We can verify via the Pinot Data Explorer by browsing to localhost:9000. You should see something like this:\\n\\n![Pinot data explorer](https://www.datocms-assets.com/75153/1684419932-image2.png \'Pinot data explorer\')\\n\\nWhat just happened?\\n\\nLet’s dive in.\\n\\nWe have started the four essential components of Pinot, however, you will note that there is not yet any data in our fresh new instance.\\n\\nBefore we create a table and load data, notice the four navigation menus on the left-hand side. You can look at the cluster status, run queries, inspect ZooKeeper, or launch the Swagger endpoints for the REST API that Pinot supports.\\n\\nOn the cluster, we notice that we have the essentials deployed: controller, broker, and server. Currently, there are no tables and no minions—dispatchable components used for task management—exist, though Notice also that multi-tenancy support is available in the cluster manager.\\n\\n### Step 5:\\n\\nNow that we have our Apache Pinot cluster ready, let’s load some data. Of course, before we do that, we have to create a schema.\\n\\nLet’s navigate to the folder:\\n\\n```bash\\ncd /opt/pinot/examples/batch/baseballStats\\n```\\n\\nYou will notice that there are the following files listed here:\\n\\n```\\nbaseballStats_offline_table_config.json\\nbaseballStats_schema.json\\ningestionJobSpec.yaml\\nsparkIngestionJobSpec.yaml\\nrawdata\\n```\\n\\nFrom the names, we can see that there is a schema file, a table config file, an ingestion job, and Apache Spark™ ingestion job files as well as a raw data folder.\\n\\nThe content of the schema file contains both metric and dimension like so (abbreviated):\\n\\n```json\\n{\\n \\"metricFieldSpecs\\": [\\n {\\n \\"dataType\\": \\"INT\\",\\n \\"name\\": \\"playerStint\\"\\n },\\n …\\n {\\n \\"dataType\\": \\"INT\\",\\n \\"name\\": \\"baseOnBalls\\"\\n },\\n ],\\n \\"dimensionFieldSpecs\\": [\\n {\\n \\"dataType\\": \\"STRING\\",\\n \\"name\\": \\"playerID\\"\\n },\\n ….\\n {\\n \\"dataType\\": \\"STRING\\",\\n \\"name\\": \\"playerName\\"\\n }\\n ],\\n \\"schemaName\\": \\"baseballStats\\"\\n}\\n```\\n\\nTo create a schema and table for the baseball stats file, run the following command from the /app/pinot/bin folder:\\n\\n```bash\\n./pinot-admin.sh AddTable -schemaFile /opt/pinot/examples/batch/baseballStats/baseballStats_schema.json -tableConfigFile /opt/pinot/examples/batch/baseballStats/baseballStats_offline_table_config.json -exec\\n```\\n\\nYou should now see the schema and table created:\\n\\n![Apache Pinot tables created](https://www.datocms-assets.com/75153/1684421406-image12.png \'Apache Pinot tables created\')\\n\\nNext, we’ll want to load some data into the table that we created. We have some sample data in the folder rawdata that we can use to load. We will need a YAML file to perform the actual ingestion job and can use the following command to import data:\\n\\n```bash\\n./pinot-admin.sh LaunchDataIngestionJob -jobSpecFile /opt/pinot/examples/batch/baseballStats/ingestionJobSpec.yaml\\n\\n```\\n\\nIf you run into trouble on this step like I did, edit the ingestJobSpec.yaml file using Docker Desktop to change the inputDirURI from relative to absolute path. Then rerun the above command.\\n\\n![Editing the .yaml file with Docker Desktop](https://www.datocms-assets.com/75153/1684419802-image1.png \'Editing the .yaml file with Docker Desktop\')\\n\\nYou should now be able to see the table has been populated like so:\\n\\n![Apache Pinot table populated](https://www.datocms-assets.com/75153/1684421215-image8.png \'Apache Pinot table populated\')\\n\\nNow, let’s run some queries. From localhost:9000, select the Query Console in the left-hand menu. Then type in some of these queries:\\n\\n```sql\\nselect * from baseballStats limit 10\\nselect sum(runs), playerName from baseballStats group by playerName order by sum(runs) desc\\n```\\n\\nYou should see results like so:\\n\\n![Apache Pinot query console](https://www.datocms-assets.com/75153/1684421163-image6.png \'Apache Pinot query console\')\\n\\nAnd there you have it!\\n\\n## What’s under the hood?\\n\\nIf you’re curious to go a step further and see what the segments look like and what the actual data on disk looks like, keep reading! In the Tables section of localhost:9000, you can scroll down to find a segment:\\n\\n![Apache Pinot data on disk segment](https://www.datocms-assets.com/75153/1684421358-image9.png \'Apache Pinot data on disk segment\')\\n\\nClicking on this gives the specifics of the segment:\\n\\n![Segment specifics in Pinot UI](https://www.datocms-assets.com/75153/1684420155-image5.png \'Segment specifics in Pinot UI\')\\n\\nPinot allows you to easily inspect your segments and tables in one easy-to-use UI. You can find what’s where and keep an eye on size, location, number of documents, etc.\\n\\n## Conclusion\\n\\nCongratulations!\\n\\nTogether, we’ve:\\n\\n-   Installed and ran Apache Pinot components\\n-   Created a table schema and a table\\n-   Loaded data in a table\\n-   Ran a few queries\\n-   Explored the Pinot UI\\n\\nIn my next article, we’ll consume event streaming data using Apache Pinot and Apache Kafka\xae.\\n\\nIn the meantime, run more queries, load more data, and don’t forget to [join the Community Slack](https://communityinviter.com/apps/startreedata/startree-community) for support if you get stuck!\\n","code":"var Component=(()=>{var d=Object.create;var o=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var k=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),N=(n,e)=>{for(var t in e)o(n,t,{get:e[t],enumerable:!0})},l=(n,e,t,i)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let s of m(e))!g.call(n,s)&&s!==t&&o(n,s,{get:()=>e[s],enumerable:!(i=p(e,s))||i.enumerable});return n};var w=(n,e,t)=>(t=n!=null?d(u(n)):{},l(e||!n||!n.__esModule?o(t,\\"default\\",{value:n,enumerable:!0}):t,n)),b=n=>l(o({},\\"__esModule\\",{value:!0}),n);var r=k((x,c)=>{c.exports=_jsx_runtime});var S={};N(S,{default:()=>v,frontmatter:()=>f});var a=w(r()),f={title:\\"Apache Pinot Tutorial for Getting Started - A Step-by-Step Guide\\",date:new Date(1684368e6),authors:[\\"herman\\"],summary:\\"This blog post is a guide to getting started with Apache Pinot, including installing and running the necessary components of a Pinot cluster. It also explains how to set up schemas, tables, and load data into Pinot, as well as how to run queries using the Pinot Data Explorer. The next article in the series will cover consuming event streaming data with Apache Pinot and Apache Kafka.\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"data explorer\\",\\"getting started\\",\\"streaming\\",\\"kafka\\"]};function h(n){let e=Object.assign({p:\\"p\\",a:\\"a\\",h2:\\"h2\\",span:\\"span\\",ul:\\"ul\\",li:\\"li\\",h3:\\"h3\\",em:\\"em\\",img:\\"img\\",pre:\\"pre\\",code:\\"code\\"},n.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(e.p,{children:[\\"How do you get started with \\",(0,a.jsx)(e.a,{href:\\"https://startree.ai/resources/what-is-apache-pinot\\",children:\\"Apache Pinot\\\\u2122\\"}),\\"? Good question! To save you the hassle of trying to tackle this on your own, here\\\\u2019s a handy guide that overviews all of the components that make up Pinot and how to set Pinot up.\\"]}),(0,a.jsxs)(e.h2,{id:\\"the-obligatory-what-is-apache-pinot-and-startree-section\\",children:[(0,a.jsx)(e.a,{href:\\"#the-obligatory-what-is-apache-pinot-and-startree-section\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"The Obligatory What is Apache Pinot and StarTree Section\\"]}),(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.a,{href:\\"https://startree.ai/what-is-apache-pinot\\",children:\\"Pinot\\"}),\\" is an open source, free-to-use, real-time, and distributed OLAP datastore, purpose built to provide ultra low-latency analytics at extremely high throughput.\\"]}),(0,a.jsxs)(e.p,{children:[\\"StarTree offers a fully managed version of the Apache Pinot \\",(0,a.jsx)(e.a,{href:\\"https://startree.ai/resources/what-is-real-time-analytics\\",children:\\"real-time analytics\\"}),\\" system and other tools around it, such as a real-time anomaly detection and root cause analysis tool, which you can \\",(0,a.jsx)(e.a,{href:\\"https://startree.ai/saas-signup\\",children:\\"try for free\\"}),\\".\\"]}),(0,a.jsxs)(e.h2,{id:\\"what-do-you-need-to-run-apache-pinot\\",children:[(0,a.jsx)(e.a,{href:\\"#what-do-you-need-to-run-apache-pinot\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"What do you need to run Apache Pinot?\\"]}),(0,a.jsx)(e.p,{children:\\"The Docker image that we will use runs multiple services. To accommodate this, we recommend at a minimum the following resources in order to run the sample:\\"}),(0,a.jsxs)(e.ul,{children:[(0,a.jsx)(e.li,{children:\\"CPUs: four or more\\"}),(0,a.jsx)(e.li,{children:\\"Memory: 8 GB or more\\"}),(0,a.jsx)(e.li,{children:\\"Swap: 2 GB or more\\"}),(0,a.jsx)(e.li,{children:\\"Disk space: 10 GB or more\\"})]}),(0,a.jsx)(e.p,{children:\\"Note: When importing custom data or event streaming, you may need more resources. Additionally, note that if not set, Docker will use resources from the host environment as needed and available.\\"}),(0,a.jsxs)(e.h2,{id:\\"step-by-step-installation-of-apache-pinot\\",children:[(0,a.jsx)(e.a,{href:\\"#step-by-step-installation-of-apache-pinot\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Step-by-step installation of Apache Pinot\\"]}),(0,a.jsx)(e.p,{children:\\"For this intro tutorial, we will use Docker. Alternatively, you can run Pinot locally if you wish.\\"}),(0,a.jsx)(e.p,{children:\\"The instructions use a Windows 11 computer, but they will work on Macs as well. Also note that I am using VS Code with the Docker extension installed.\\"}),(0,a.jsxs)(e.h3,{id:\\"step-1\\",children:[(0,a.jsx)(e.a,{href:\\"#step-1\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Step 1:\\\\xA0\\"]}),(0,a.jsxs)(e.p,{children:[\\"Make sure you have \\",(0,a.jsx)(e.a,{href:\\"https://docs.docker.com/get-docker/\\",children:\\"Docker installed\\"}),\\" on your machine.\\"]}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.em,{children:\\"Docker is a set of platform as a service (PaaS) products that use OS-level virtualization to deliver software in packages called containers.\\"})}),(0,a.jsxs)(e.h3,{id:\\"step-2\\",children:[(0,a.jsx)(e.a,{href:\\"#step-2\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Step 2:\\"]}),(0,a.jsx)(e.p,{children:\\"Now, let\\\\u2019s download the Docker image. On a Windows machine, start a new PowerShell command window. Note that this is not the same as a Windows PowerShell command window, as shown below.\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Download Docker image on Windows with PowerShell command window\\",src:\\"https://www.datocms-assets.com/75153/1684419409-image7.png\\",title:\\"Download Docker image on Windows with PowerShell command window\\"})}),(0,a.jsx)(e.p,{children:\\"Use the following command to get (pull) the image we are looking for:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsx)(e.code,{className:\\"language-bash code-highlight\\",children:(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),` pull apachepinot/pinot:0.12.0\\n`]})})}),(0,a.jsx)(e.p,{children:\\"You can also download the latest version like so:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsx)(e.code,{className:\\"language-bash code-highlight\\",children:(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),` pull apachepinot/pinot:latest\\n`]})})}),(0,a.jsx)(e.p,{children:\\"Here, apachepinot is the name of the repository in Docker Hub, pinot is the name of the image, and :latest or :0.12.0 is the version for the image.\\\\xA0 Note that we will be using the 0.12.0 version for this blog post.\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.em,{children:\\"Docker Hub is the world\\\\u2019s largest repository of container images in the world.\\"})}),(0,a.jsx)(e.p,{children:\\"You can verify the image was downloaded or pulled by running the following command:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsx)(e.code,{className:\\"language-bash code-highlight\\",children:(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),` images\\n`]})})}),(0,a.jsx)(e.p,{children:\\"It should show you the image like so:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Docker images command\\",src:\\"https://www.datocms-assets.com/75153/1684420004-image3.png\\",title:\\"Docker images command\\"})}),(0,a.jsxs)(e.h3,{id:\\"step-3\\",children:[(0,a.jsx)(e.a,{href:\\"#step-3\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Step 3:\\"]}),(0,a.jsx)(e.p,{children:\\"Let\\\\u2019s run a container using the Docker image that we downloaded:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsx)(e.code,{className:\\"language-bash code-highlight\\",children:(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,a.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-it\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"--entrypoint\\"}),\\" /bin/bash \\",(0,a.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-p\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"9000\\"}),`:9000 apachepinot/pinot:0.12.0\\n`]})})}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Running a container with downloaded Docker image\\",src:\\"https://www.datocms-assets.com/75153/1684420103-image4.png\\",title:\\"Running a container with downloaded Docker image\\"})}),(0,a.jsx)(e.p,{children:\\"The docker run command runs the image. The -p 9000:00 option maps the docker container port 9000 to the local machine port 9000. This allows us to access the Pinot UI, which defaults to port 9000 to be accessible from the localhost. We are using the \\\\u2013entrypoint to override the default entrypoint and replace it with Bash. We want to override the default behavior so that we can start each component one at a time. The next parameter apachepinot/pinot:0.12.0 is the Docker image we pulled above.\\"}),(0,a.jsx)(e.p,{children:\\"After running the command, we\\\\u2019ll find ourselves in the Docker container instance running Bash shell. We can use ls to list the contents of the Docker container as shown above.\\"}),(0,a.jsx)(e.p,{children:\\"If you\\\\u2019re using VS Code, with the Docker extension installed, you can click on the Docker extension and see our container and its content:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"VS Code Docker extension open to see container and content\\",src:\\"https://www.datocms-assets.com/75153/1684421493-image11.png\\",title:\\"VS Code Docker extension open to see container and content\\"})}),(0,a.jsx)(e.p,{children:\\"Click on the Docker icon in the left menu, and apachepinot/pinot:0.12.0. This should take a few seconds to connect to the running container. Now, you can navigate to the files and see what we have under the opt folder.\\"}),(0,a.jsxs)(e.h3,{id:\\"step-4\\",children:[(0,a.jsx)(e.a,{href:\\"#step-4\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Step 4:\\"]}),(0,a.jsx)(e.p,{children:\\"Let\\\\u2019s run the components that are essential to running a Pinot cluster. Change directory to the bin folder and list the contents like so:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Running components, directory changed to bin folder and contents listed\\",src:\\"https://www.datocms-assets.com/75153/1684421611-image10.png\\",title:\\"Running components, directory changed to bin folder and contents listed\\"})}),(0,a.jsx)(e.p,{children:\\"In order to start the Pinot cluster, we will need to run the following essential components:\\"}),(0,a.jsxs)(e.ul,{children:[(0,a.jsx)(e.li,{children:\\"Apache ZooKeeper\\\\u2122\\"}),(0,a.jsx)(e.li,{children:\\"Controller\\"}),(0,a.jsx)(e.li,{children:\\"Broker\\"}),(0,a.jsx)(e.li,{children:\\"Server\\"})]}),(0,a.jsx)(e.p,{children:\\"Start ZooKeeper using the following command:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsx)(e.code,{className:\\"language-bash code-highlight\\",children:(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"./pinot-admin.sh StartZookeeper \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"&\\"}),`\\n`]})})}),(0,a.jsx)(e.p,{children:\\"pinot-admin.sh is a shell script for starting the various components. The & allows us to continue using the Bash shell. ZooKeeper is responsible for the configuration for the Pinot cluster and needs to be started first.\\"}),(0,a.jsx)(e.p,{children:\\"We can start the remaining components using these commands one at a time:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"language-bash code-highlight\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"./pinot-admin.sh StartController \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"&\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"./pinot-admin.sh StartBroker \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"&\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"./pinot-admin.sh StartServer \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"&\\"}),`\\n`]})]})}),(0,a.jsxs)(e.p,{children:[\\"The controller controls the cluster health and coordinates with ZooKeeper for configuration and status changes. The broker is responsible for query distribution and result collation, sometimes called Scatter-Gather. Servers manage individual table segments and perform the actual read/writes. To get a better understanding of each component, read this \\",(0,a.jsx)(e.a,{href:\\"https://startree.ai/blog/introduction-to-apache-pinot-a-beginners-guide\\",children:\\"intro to Apache Pinot\\"}),\\".\\"]}),(0,a.jsx)(e.p,{children:\\"At this time, we should have a running Pinot cluster. We can verify via the Pinot Data Explorer by browsing to localhost:9000. You should see something like this:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Pinot data explorer\\",src:\\"https://www.datocms-assets.com/75153/1684419932-image2.png\\",title:\\"Pinot data explorer\\"})}),(0,a.jsx)(e.p,{children:\\"What just happened?\\"}),(0,a.jsx)(e.p,{children:\\"Let\\\\u2019s dive in.\\"}),(0,a.jsx)(e.p,{children:\\"We have started the four essential components of Pinot, however, you will note that there is not yet any data in our fresh new instance.\\"}),(0,a.jsx)(e.p,{children:\\"Before we create a table and load data, notice the four navigation menus on the left-hand side. You can look at the cluster status, run queries, inspect ZooKeeper, or launch the Swagger endpoints for the REST API that Pinot supports.\\"}),(0,a.jsx)(e.p,{children:\\"On the cluster, we notice that we have the essentials deployed: controller, broker, and server. Currently, there are no tables and no minions\\\\u2014dispatchable components used for task management\\\\u2014exist, though Notice also that multi-tenancy support is available in the cluster manager.\\"}),(0,a.jsxs)(e.h3,{id:\\"step-5\\",children:[(0,a.jsx)(e.a,{href:\\"#step-5\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Step 5:\\"]}),(0,a.jsx)(e.p,{children:\\"Now that we have our Apache Pinot cluster ready, let\\\\u2019s load some data. Of course, before we do that, we have to create a schema.\\"}),(0,a.jsx)(e.p,{children:\\"Let\\\\u2019s navigate to the folder:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsx)(e.code,{className:\\"language-bash code-highlight\\",children:(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token builtin class-name\\",children:\\"cd\\"}),` /opt/pinot/examples/batch/baseballStats\\n`]})})}),(0,a.jsx)(e.p,{children:\\"You will notice that there are the following files listed here:\\"}),(0,a.jsx)(e.pre,{className:\\"language-js\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-js\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"baseballStats_offline_table_config\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,a.jsx)(e.span,{className:\\"token property-access\\",children:\\"json\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"baseballStats_schema\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,a.jsx)(e.span,{className:\\"token property-access\\",children:\\"json\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"ingestionJobSpec\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,a.jsx)(e.span,{className:\\"token property-access\\",children:\\"yaml\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"sparkIngestionJobSpec\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,a.jsx)(e.span,{className:\\"token property-access\\",children:\\"yaml\\"}),`\\n`]}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:`rawdata\\n`})]})}),(0,a.jsx)(e.p,{children:\\"From the names, we can see that there is a schema file, a table config file, an ingestion job, and Apache Spark\\\\u2122 ingestion job files as well as a raw data folder.\\"}),(0,a.jsx)(e.p,{children:\\"The content of the schema file contains both metric and dimension like so (abbreviated):\\"}),(0,a.jsx)(e.pre,{className:\\"language-json\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"metricFieldSpecs\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"INT\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"playerStint\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:` \\\\u2026\\n`}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"INT\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"baseOnBalls\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dimensionFieldSpecs\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"playerID\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:` \\\\u2026.\\n`}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"playerName\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"baseballStats\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"To create a schema and table for the baseball stats file, run the following command from the /app/pinot/bin folder:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsx)(e.code,{className:\\"language-bash code-highlight\\",children:(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"./pinot-admin.sh AddTable \\",(0,a.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-schemaFile\\"}),\\" /opt/pinot/examples/batch/baseballStats/baseballStats_schema.json \\",(0,a.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-tableConfigFile\\"}),\\" /opt/pinot/examples/batch/baseballStats/baseballStats_offline_table_config.json \\",(0,a.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-exec\\"}),`\\n`]})})}),(0,a.jsx)(e.p,{children:\\"You should now see the schema and table created:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Apache Pinot tables created\\",src:\\"https://www.datocms-assets.com/75153/1684421406-image12.png\\",title:\\"Apache Pinot tables created\\"})}),(0,a.jsx)(e.p,{children:\\"Next, we\\\\u2019ll want to load some data into the table that we created. We have some sample data in the folder rawdata that we can use to load. We will need a YAML file to perform the actual ingestion job and can use the following command to import data:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"language-bash code-highlight\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"./pinot-admin.sh LaunchDataIngestionJob \\",(0,a.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-jobSpecFile\\"}),` /opt/pinot/examples/batch/baseballStats/ingestionJobSpec.yaml\\n`]}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:`\\n`})]})}),(0,a.jsx)(e.p,{children:\\"If you run into trouble on this step like I did, edit the ingestJobSpec.yaml file using Docker Desktop to change the inputDirURI from relative to absolute path. Then rerun the above command.\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Editing the .yaml file with Docker Desktop\\",src:\\"https://www.datocms-assets.com/75153/1684419802-image1.png\\",title:\\"Editing the .yaml file with Docker Desktop\\"})}),(0,a.jsx)(e.p,{children:\\"You should now be able to see the table has been populated like so:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Apache Pinot table populated\\",src:\\"https://www.datocms-assets.com/75153/1684421215-image8.png\\",title:\\"Apache Pinot table populated\\"})}),(0,a.jsx)(e.p,{children:\\"Now, let\\\\u2019s run some queries. From localhost:9000, select the Query Console in the left-hand menu. Then type in some of these queries:\\"}),(0,a.jsx)(e.pre,{className:\\"language-sql\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-sql\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),\\" baseballStats \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"limit\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"10\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"sum\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"runs\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" playerName \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),\\" baseballStats \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"group\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"by\\"}),\\" playerName \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"order\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"by\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"sum\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"runs\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"desc\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"You should see results like so:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Apache Pinot query console\\",src:\\"https://www.datocms-assets.com/75153/1684421163-image6.png\\",title:\\"Apache Pinot query console\\"})}),(0,a.jsx)(e.p,{children:\\"And there you have it!\\"}),(0,a.jsxs)(e.h2,{id:\\"whats-under-the-hood\\",children:[(0,a.jsx)(e.a,{href:\\"#whats-under-the-hood\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"What\\\\u2019s under the hood?\\"]}),(0,a.jsx)(e.p,{children:\\"If you\\\\u2019re curious to go a step further and see what the segments look like and what the actual data on disk looks like, keep reading! In the Tables section of localhost:9000, you can scroll down to find a segment:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Apache Pinot data on disk segment\\",src:\\"https://www.datocms-assets.com/75153/1684421358-image9.png\\",title:\\"Apache Pinot data on disk segment\\"})}),(0,a.jsx)(e.p,{children:\\"Clicking on this gives the specifics of the segment:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Segment specifics in Pinot UI\\",src:\\"https://www.datocms-assets.com/75153/1684420155-image5.png\\",title:\\"Segment specifics in Pinot UI\\"})}),(0,a.jsx)(e.p,{children:\\"Pinot allows you to easily inspect your segments and tables in one easy-to-use UI. You can find what\\\\u2019s where and keep an eye on size, location, number of documents, etc.\\"}),(0,a.jsxs)(e.h2,{id:\\"conclusion\\",children:[(0,a.jsx)(e.a,{href:\\"#conclusion\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Conclusion\\"]}),(0,a.jsx)(e.p,{children:\\"Congratulations!\\"}),(0,a.jsx)(e.p,{children:\\"Together, we\\\\u2019ve:\\"}),(0,a.jsxs)(e.ul,{children:[(0,a.jsx)(e.li,{children:\\"Installed and ran Apache Pinot components\\"}),(0,a.jsx)(e.li,{children:\\"Created a table schema and a table\\"}),(0,a.jsx)(e.li,{children:\\"Loaded data in a table\\"}),(0,a.jsx)(e.li,{children:\\"Ran a few queries\\"}),(0,a.jsx)(e.li,{children:\\"Explored the Pinot UI\\"})]}),(0,a.jsx)(e.p,{children:\\"In my next article, we\\\\u2019ll consume event streaming data using Apache Pinot and Apache Kafka\\\\xAE.\\"}),(0,a.jsxs)(e.p,{children:[\\"In the meantime, run more queries, load more data, and don\\\\u2019t forget to \\",(0,a.jsx)(e.a,{href:\\"https://communityinviter.com/apps/startreedata/startree-community\\",children:\\"join the Community Slack\\"}),\\" for support if you get stuck!\\"]})]})}function y(n={}){let{wrapper:e}=n.components||{};return e?(0,a.jsx)(e,Object.assign({},n,{children:(0,a.jsx)(h,n)})):h(n)}var v=y;return b(S);})();\\n;return Component;"},"_id":"blog/2023-05-18-apache-pinot-tutorial-for-getting-started-a-step-by-step-guide.mdx","_raw":{"sourceFilePath":"blog/2023-05-18-apache-pinot-tutorial-for-getting-started-a-step-by-step-guide.mdx","sourceFileName":"2023-05-18-apache-pinot-tutorial-for-getting-started-a-step-by-step-guide.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2023-05-18-apache-pinot-tutorial-for-getting-started-a-step-by-step-guide"},"type":"Blog","readingTime":{"text":"8 min read","minutes":7.91,"time":474600,"words":1582},"slug":"2023/05/18/apache-pinot-tutorial-for-getting-started-a-step-by-step-guide","customSlug":"2023/05/18/apache-pinot-tutorial-for-getting-started-a-step-by-step-guide","path":"blog/2023/05/18/apache-pinot-tutorial-for-getting-started-a-step-by-step-guide","customPath":"blog/2023/05/18/apache-pinot-tutorial-for-getting-started-a-step-by-step-guide","filePath":"blog/2023-05-18-apache-pinot-tutorial-for-getting-started-a-step-by-step-guide.mdx","toc":[{"value":"The Obligatory What is Apache Pinot and StarTree Section","url":"#the-obligatory-what-is-apache-pinot-and-startree-section","depth":2},{"value":"What do you need to run Apache Pinot?","url":"#what-do-you-need-to-run-apache-pinot","depth":2},{"value":"Step-by-step installation of Apache Pinot","url":"#step-by-step-installation-of-apache-pinot","depth":2},{"value":"Step 1:\xa0","url":"#step-1","depth":3},{"value":"Step 2:","url":"#step-2","depth":3},{"value":"Step 3:","url":"#step-3","depth":3},{"value":"Step 4:","url":"#step-4","depth":3},{"value":"Step 5:","url":"#step-5","depth":3},{"value":"What’s under the hood?","url":"#whats-under-the-hood","depth":2},{"value":"Conclusion","url":"#conclusion","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Pinot Tutorial for Getting Started - A Step-by-Step Guide","datePublished":"2023-05-18T00:00:00.000Z","dateModified":"2023-05-18T00:00:00.000Z","description":"This blog post is a guide to getting started with Apache Pinot, including installing and running the necessary components of a Pinot cluster. It also explains how to set up schemas, tables, and load data into Pinot, as well as how to run queries using the Pinot Data Explorer. The next article in the series will cover consuming event streaming data with Apache Pinot and Apache Kafka.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2023-05-18-apache-pinot-tutorial-for-getting-started-a-step-by-step-guide"}},{"title":"Change Data Capture with Apache Pinot - How Does It Work?","date":"2023-05-23T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","CDC","Debezium"],"summary":"This blog post discusses the use of Change Data Capture (CDC) in Apache Pinot and the data format used in Debezium for efficient querying and analytics. It explains the elements of the format and its usage in indexing JSON fields. It also mentions the availability of CDC connectors in Debezium for various streaming systems.","authors":["dulay"],"body":{"raw":"\\nChange Data Capture (CDC) is the process of capturing and communicating changes made to records in a data store, including INSERTs, UPDATEs, and DELETEs transactions to records.\\n\\nCDC implementations vary across different types of transactional databases, whether SQL or NoSQL. However, the means to ingest and analyze that data in [Apache Pinot™](https://startree.ai/resources/what-is-apache-pinot) will generally remain the same.\\n\\nAs your applications interact with their data stores, they automatically log the transaction in a construct called a write-ahead log (WAL) in real time. In fact, each transaction reflects an event that has been recorded, naturally giving the WAL event streaming properties. This approach is typically used by relational OLTP databases like PostgreSQL.\\n\\nNOTE: NoSQL databases also have the ability to perform CDC but may use other mechanisms than a WAL. CDC for NoSQL databases is outside the scope of this post.\\n\\nThe WAL is an append-only, immutable stream of events designed to replicate its data to another instance of the data store for high availability in disaster recovery scenarios (see diagram below). The transactions occurring on the left data store (primary) get replicated to the data store to the right (secondary). The applications connect to the primary data store and replicate its data to the secondary data store. If the primary data store goes down, the application switches to the secondary data store.\\n\\n![Primary data store transactions being replicated to a secondary data store](https://www.datocms-assets.com/75153/1684857872-image3.png \'Primary data store transactions being replicated to a secondary data store\')\\n\\nThe following diagram shows an example of a WAL in a data store. New transactions get appended to the end of the WAL. The old transactions are on the left, and the newer transactions are on the right.\\n\\n![WAL in a data store with new transactions appended to the end of the WAL](https://www.datocms-assets.com/75153/1684857250-image5.png \'WAL in a data store with new transactions appended to the end of the WAL\')\\n\\nChange data capture enables you to listen to this WAL by capturing these transactions and sending them downstream for processing. The data processing occurs in a different system where we can view the latest version of each record in other applications. Because of the real-time nature of the data, the subscribing applications to the stream of transactions receive real-time transaction events.\\n\\n## Pre-Image, Post-Image, or Diffs?\\n\\nAn important consideration for CDC is what specific elements of change it captures. Not all CDC implementations are the same. Some provide only the _post-image_ — the complete state to which the record changes after an update. Some only provide the _diffs_ (or _deltas_) — the specific changes made to the record at the time of the update, not the complete current state of the record. And others can provide the pre-image as well — what the state of the record was before the changes were applied.\\n\\nDifferent transactional databases may only provide one or two of these elements. Usually, it will provide the complete post-image or the diffs (or deltas) to the record. In other cases, a CDC implementation might provide all three data elements — pre-, post-, _and_ diffs. It is very important for you to understand what specific CDC data elements your transactional database provides because of how it limits the kind of analytics you can perform.\\n\\n## How to Capture Change Data with Debezium\\n\\nCapturing change events requires specific knowledge of the database from which the changes are occurring; and there are many transactional databases. Debezium, an open source project, provides a set of connectors that can subscribe to WALs in many different data stores, such as PostgreSQL, SQL Server, and MongoDB. Their implementation involves the Kafka Connect framework, an open source framework that enables integrations to Apache Kafka\xae. Two types of connectors exist: source and sink. Debezium connectors are source-only connectors.\\n\\nKafka connectors must run in a Kafka Connect cluster, a highly available and distributed system for running connectors. Kafka connectors cannot run on their own and require a server. The Debezium project provides a Debezium server that can also run Debezium connectors capable of writing to other event streaming platforms besides Kafka, for instance, Amazon Kinesis. The diagram below shows a Debezium connector reading the WAL and writing to a Debezium server. The Debezium server can then write to either Kafka or Kinesis.\\n\\n![Diagram showing a Debezium connector reading the WAL and writing to a Debezium server](https://www.datocms-assets.com/75153/1684857201-image4.png \'Diagram showing a Debezium connector reading the WAL and writing to a Debezium server\')\\n\\n## Debezium Data Format\\n\\nFor details on the Debezium format, [check out the tutorial](https://debezium.io/documentation/reference/stable/tutorial.html). Below, you’ll find an example of a transaction event encoded in JSON coming from the Debezium connector.\\n\\n```json\\n{\\n  \\"schema\\": {...},\\n  \\"payload\\": {\\n    \\"before\\": {\\n      \\"user_id\\": 1004,\\n      \\"first_name\\": \\"Anne\\",\\n      \\"last_name\\": \\"Kretchmar\\",\\n      \\"email\\": \\"annek@noanswer.org\\"\\n    },\\n    \\"after\\": {\\n      \\"user_id\\": 1004,\\n      \\"first_name\\": \\"Anne Marie\\",\\n      \\"last_name\\": \\"Kretchmar\\",\\n      \\"email\\": \\"annek@noanswer.org\\"\\n    },\\n    \\"source\\": {\\n      \\"name\\": \\"2.2.0.Final\\",\\n      \\"name\\": \\"dbserver1\\",\\n      \\"server_id\\": 223344,\\n      \\"ts_sec\\": 1486501486,\\n      \\"gtid\\": null,\\n      \\"file\\": \\"mysql-bin.000003\\",\\n      \\"pos\\": 364,\\n      \\"row\\": 0,\\n      \\"snapshot\\": null,\\n      \\"thread\\": 3,\\n      \\"db\\": \\"inventory\\",\\n      \\"table\\": \\"customers\\"\\n    },\\n    \\"op\\": \\"u\\",\\n    \\"ts_ms\\": 1486501486308\\n  }\\n}\\n```\\n\\nA few elements to note:\\n\\n-   The schema element never changes and defines the schema of the payload\\n-   The payload element holds three different elements:\\n\\n    -   before: shows the state of the record before it was changed; if this is null, then you can assume that the transaction is an INSERT\\n    -   after: shows the state of the record after the record was changed; if this is null, then you can assume that the transaction is a DELETE\\n    -   source: constitutes metadata that describes the source of the data\\n\\n-   The op element defines the actual transaction\\n\\n    -   Values:\\n\\n        -   c for CREATE (or INSERT)\\n        -   r for READ (in the case of a snapshot)\\n        -   u for UPDATE\\n        -   d for DELETE\\n\\n-   The ts_ms element refers to the timestamp in milliseconds of when the transaction occurred\\n\\nIn the op element of the format, you may use a possible r value to determine if the record originated from a snapshot of the entire table in the data store. When the Debezium connector first starts, you could encounter existing records. You can configure the connector to first take a snapshot of the entire table to send as events downstream to its eventual destination. This will affect the treatment of records in the destination, in our case, Apache Pinot.\\n\\nIn Apache Pinot, we will have to create a schema that corresponds to the Debezium format. This could be defined a number of ways. I chose to bring the comments in the after field so users can access the latest values for any customer. I also kept the op at the top level. Since there are no metrics, that context in the schema is an empty array. I also preserved the after and before fields. Notice they are of type STRING. In Apache Pinot, you can assign a JSON index to any field containing multi-level JSON data. Apache Pinot will index all the values in the JSON payload so that any query referencing data in those JSON fields would be fast. This will allow users to see previous values of the record in cases where the operation was a change.\xa0 Lastly, I have a date time field to indicate when the last change was made.\\n\\n```json\\n{\\n    \\"schemaName\\": \\"customers\\",\\n    \\"dimensionFieldSpecs\\": [\\n        {\\n            \\"name\\": \\"user_id\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"first_name\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"last_name\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"email\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"op\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"before\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"after\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"source\\",\\n            \\"dataType\\": \\"STRING\\"\\n        }\\n    ],\\n    \\"metricFieldSpecs\\": [],\\n    \\"dateTimeFieldSpecs\\": [\\n        {\\n            \\"name\\": \\"ts_ms\\",\\n            \\"dataType\\": \\"LONG\\",\\n            \\"format\\": \\"1:MILLISECONDS:SIMPLE_DATE_FORMAT:yyyy-MM-dd\'T\'HH:mm:ss.SSS\'Z\'\\",\\n            \\"granularity\\": \\"1:MILLISECONDS\\"\\n        }\\n    ],\\n    \\"primaryKeyColumns\\": [\\"user_id\\"]\\n}\\n```\\n\\nYou may have an alternative schema depending on your use case. You don’t need any of the fields I preserved. If at the end you only want the latest version, you can do that easily by only preserving the columns that matter to you.\\n\\n## Materialized Views\\n\\nWhen looking up your record in Pinot, you only need to provide a WHERE clause with the primary key. Pinot will only return one record—the latest version of the record, not the history of the record—as a true materialized view should. Otherwise, you would have to provide more logic in the SQL statement that selects for the latest record. This adds latency to the query and may make downstream aggregations less accurate. Pinot provides a materialized view by implementing upsert for real-time tables with a primary key.\\n\\n## Upsert in Apache Pinot\\n\\nUnlike any other real-time OLAP, [Pinot offers native support for upsert](https://docs.pinot.apache.org/basics/data-import/upsert) for real-time ingestion. Upsert logic says, “If the record exists, update it or otherwise insert it.”\\n\\nYou need upsert capabilities for dimensional data to simply SELECT for the record’s primary key when retrieving it. Without upsert, you will need to find the latest version of a record by comparing the latest timestamps, which leaves room for error.\\n\\nThis JSON document shows a schema snippet in Pinot that contains a primaryKeyColumns property. By applying this property, Pinot automatically enables the upsert feature. Upsert is completely transparent to the sender and therefore no specific programming is required.\\n\\n```json\\n{\\n    \\"primaryKeyColumns\\": [\\"user_id\\"]\\n}\\n```\\n\\nYou can further configure the behavior of the upsert to allow for different behaviors: FULL or PARTIAL.\\n\\nA FULL upsert means that a new record will replace the older record completely if they share the same primary key.\\n\\nPARTIAL only allows updates to specific columns and employs additional strategies.\\n\\n![Table describing the strategy and descriptions of stream ingestion with upsert](https://www.datocms-assets.com/75153/1684857317-image6.png \'Table describing the strategy and descriptions of stream ingestion with upsert\')\\n\\nSource: [Stream Ingestion with Upsert](https://docs.pinot.apache.org/basics/data-import/upsert)\\n\\nHere is a sample snippet of a table configuration containing the property that configures the upsert strategy:\\n\\n```json\\n\\"upsertConfig\\": { \\"mode\\": \\"FULL\\" },\\n```\\n\\nUpsert simplifies client queries in an extremely powerful way. More importantly, upsert assures the accuracy of any aggregations applied to updated columns, which proves especially important when the analytics lead to critical decisions.\\n\\n## Summary\\n\\nChange data capture is the best way to capture changes in a database. Other options require comparing snapshots or applying complex modified timestamp logic. Other solutions only emulate real-time, but change data capture embodies the only genuine real-time event streaming solution.\\n\\n[Debezium provides many other CDC connectors](https://debezium.io/documentation/reference/stable/index.html) that you can find in their documentation. If you do not have a Kafka Connect cluster or do not use Kafka at all, you can use the Debezium server to run the CDC connectors and write to an alternative streaming system, such as Amazon Kinesis, Pub/Sub from Google Cloud, Apache\xae Pulsar™, Azure Event Hubs, and RabbitMQ.\\n\\nLastly, Apache Pinot enables upsert for any client sinking into it, which means the client does not need to implement upsert logic. Any client can generate a materialized view in Pinot. This makes the resulting table faster to query and provides more accurate analytics.\\n\\nTo try Pinot in the cloud, [visit startree.ai for a free trial](https://startree.ai/saas-signup).\\n","code":"var Component=(()=>{var d=Object.create;var r=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,N=Object.prototype.hasOwnProperty;var k=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),y=(n,e)=>{for(var s in e)r(n,s,{get:e[s],enumerable:!0})},i=(n,e,s,c)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let t of m(e))!N.call(n,t)&&t!==s&&r(n,t,{get:()=>e[t],enumerable:!(c=h(e,t))||c.enumerable});return n};var g=(n,e,s)=>(s=n!=null?d(u(n)):{},i(e||!n||!n.__esModule?r(s,\\"default\\",{value:n,enumerable:!0}):s,n)),f=n=>i(r({},\\"__esModule\\",{value:!0}),n);var l=k((C,o)=>{o.exports=_jsx_runtime});var T={};y(T,{default:()=>v,frontmatter:()=>w});var a=g(l()),w={title:\\"Change Data Capture with Apache Pinot - How Does It Work?\\",date:new Date(16848e8),authors:[\\"dulay\\"],summary:\\"This blog post discusses the use of Change Data Capture (CDC) in Apache Pinot and the data format used in Debezium for efficient querying and analytics. It explains the elements of the format and its usage in indexing JSON fields. It also mentions the availability of CDC connectors in Debezium for various streaming systems.\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"CDC\\",\\"Debezium\\"]};function p(n){let e=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\",h2:\\"h2\\",span:\\"span\\",em:\\"em\\",pre:\\"pre\\",code:\\"code\\",ul:\\"ul\\",li:\\"li\\"},n.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.p,{children:\\"Change Data Capture (CDC) is the process of capturing and communicating changes made to records in a data store, including INSERTs, UPDATEs, and DELETEs transactions to records.\\"}),(0,a.jsxs)(e.p,{children:[\\"CDC implementations vary across different types of transactional databases, whether SQL or NoSQL. However, the means to ingest and analyze that data in \\",(0,a.jsx)(e.a,{href:\\"https://startree.ai/resources/what-is-apache-pinot\\",children:\\"Apache Pinot\\\\u2122\\"}),\\" will generally remain the same.\\"]}),(0,a.jsx)(e.p,{children:\\"As your applications interact with their data stores, they automatically log the transaction in a construct called a write-ahead log (WAL) in real time. In fact, each transaction reflects an event that has been recorded, naturally giving the WAL event streaming properties. This approach is typically used by relational OLTP databases like PostgreSQL.\\"}),(0,a.jsx)(e.p,{children:\\"NOTE: NoSQL databases also have the ability to perform CDC but may use other mechanisms than a WAL. CDC for NoSQL databases is outside the scope of this post.\\"}),(0,a.jsx)(e.p,{children:\\"The WAL is an append-only, immutable stream of events designed to replicate its data to another instance of the data store for high availability in disaster recovery scenarios (see diagram below). The transactions occurring on the left data store (primary) get replicated to the data store to the right (secondary). The applications connect to the primary data store and replicate its data to the secondary data store. If the primary data store goes down, the application switches to the secondary data store.\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Primary data store transactions being replicated to a secondary data store\\",src:\\"https://www.datocms-assets.com/75153/1684857872-image3.png\\",title:\\"Primary data store transactions being replicated to a secondary data store\\"})}),(0,a.jsx)(e.p,{children:\\"The following diagram shows an example of a WAL in a data store. New transactions get appended to the end of the WAL. The old transactions are on the left, and the newer transactions are on the right.\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"WAL in a data store with new transactions appended to the end of the WAL\\",src:\\"https://www.datocms-assets.com/75153/1684857250-image5.png\\",title:\\"WAL in a data store with new transactions appended to the end of the WAL\\"})}),(0,a.jsx)(e.p,{children:\\"Change data capture enables you to listen to this WAL by capturing these transactions and sending them downstream for processing. The data processing occurs in a different system where we can view the latest version of each record in other applications. Because of the real-time nature of the data, the subscribing applications to the stream of transactions receive real-time transaction events.\\"}),(0,a.jsxs)(e.h2,{id:\\"pre-image-post-image-or-diffs\\",children:[(0,a.jsx)(e.a,{href:\\"#pre-image-post-image-or-diffs\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Pre-Image, Post-Image, or Diffs?\\"]}),(0,a.jsxs)(e.p,{children:[\\"An important consideration for CDC is what specific elements of change it captures. Not all CDC implementations are the same. Some provide only the \\",(0,a.jsx)(e.em,{children:\\"post-image\\"}),\\" \\\\u2014 the complete state to which the record changes after an update. Some only provide the \\",(0,a.jsx)(e.em,{children:\\"diffs\\"}),\\" (or \\",(0,a.jsx)(e.em,{children:\\"deltas\\"}),\\") \\\\u2014 the specific changes made to the record at the time of the update, not the complete current state of the record. And others can provide the pre-image as well \\\\u2014 what the state of the record was before the changes were applied.\\"]}),(0,a.jsxs)(e.p,{children:[\\"Different transactional databases may only provide one or two of these elements. Usually, it will provide the complete post-image or the diffs (or deltas) to the record. In other cases, a CDC implementation might provide all three data elements \\\\u2014 pre-, post-, \\",(0,a.jsx)(e.em,{children:\\"and\\"}),\\" diffs. It is very important for you to understand what specific CDC data elements your transactional database provides because of how it limits the kind of analytics you can perform.\\"]}),(0,a.jsxs)(e.h2,{id:\\"how-to-capture-change-data-with-debezium\\",children:[(0,a.jsx)(e.a,{href:\\"#how-to-capture-change-data-with-debezium\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"How to Capture Change Data with Debezium\\"]}),(0,a.jsx)(e.p,{children:\\"Capturing change events requires specific knowledge of the database from which the changes are occurring; and there are many transactional databases. Debezium, an open source project, provides a set of connectors that can subscribe to WALs in many different data stores, such as PostgreSQL, SQL Server, and MongoDB. Their implementation involves the Kafka Connect framework, an open source framework that enables integrations to Apache Kafka\\\\xAE. Two types of connectors exist: source and sink. Debezium connectors are source-only connectors.\\"}),(0,a.jsx)(e.p,{children:\\"Kafka connectors must run in a Kafka Connect cluster, a highly available and distributed system for running connectors. Kafka connectors cannot run on their own and require a server. The Debezium project provides a Debezium server that can also run Debezium connectors capable of writing to other event streaming platforms besides Kafka, for instance, Amazon Kinesis. The diagram below shows a Debezium connector reading the WAL and writing to a Debezium server. The Debezium server can then write to either Kafka or Kinesis.\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Diagram showing a Debezium connector reading the WAL and writing to a Debezium server\\",src:\\"https://www.datocms-assets.com/75153/1684857201-image4.png\\",title:\\"Diagram showing a Debezium connector reading the WAL and writing to a Debezium server\\"})}),(0,a.jsxs)(e.h2,{id:\\"debezium-data-format\\",children:[(0,a.jsx)(e.a,{href:\\"#debezium-data-format\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Debezium Data Format\\"]}),(0,a.jsxs)(e.p,{children:[\\"For details on the Debezium format, \\",(0,a.jsx)(e.a,{href:\\"https://debezium.io/documentation/reference/stable/tutorial.html\\",children:\\"check out the tutorial\\"}),\\". Below, you\\\\u2019ll find an example of a transaction event encoded in JSON coming from the Debezium connector.\\"]}),(0,a.jsx)(e.pre,{className:\\"language-json\\",children:(0,a.jsxs)(e.code,{className:\\"language-json code-highlight\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"schema\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\"...\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"payload\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"before\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"user_id\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"1004\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"first_name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"Anne\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"last_name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"Kretchmar\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"email\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"annek@noanswer.org\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"after\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"user_id\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"1004\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"first_name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"Anne Marie\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"last_name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"Kretchmar\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"email\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"annek@noanswer.org\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"source\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"2.2.0.Final\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"dbserver1\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"server_id\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"223344\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"ts_sec\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"1486501486\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"gtid\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword null\\",children:\\"null\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"file\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"mysql-bin.000003\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"pos\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"364\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"row\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"0\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"snapshot\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword null\\",children:\\"null\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"thread\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"3\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"db\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"inventory\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"table\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"customers\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"op\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"u\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"ts_ms\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"1486501486308\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"A few elements to note:\\"}),(0,a.jsxs)(e.ul,{children:[(0,a.jsx)(e.li,{children:(0,a.jsx)(e.p,{children:\\"The schema element never changes and defines the schema of the payload\\"})}),(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.p,{children:\\"The payload element holds three different elements:\\"}),(0,a.jsxs)(e.ul,{children:[(0,a.jsx)(e.li,{children:\\"before: shows the state of the record before it was changed; if this is null, then you can assume that the transaction is an INSERT\\"}),(0,a.jsx)(e.li,{children:\\"after: shows the state of the record after the record was changed; if this is null, then you can assume that the transaction is a DELETE\\"}),(0,a.jsx)(e.li,{children:\\"source: constitutes metadata that describes the source of the data\\"})]})]}),(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.p,{children:\\"The op element defines the actual transaction\\"}),(0,a.jsx)(e.ul,{children:(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.p,{children:\\"Values:\\"}),(0,a.jsxs)(e.ul,{children:[(0,a.jsx)(e.li,{children:\\"c for CREATE (or INSERT)\\"}),(0,a.jsx)(e.li,{children:\\"r for READ (in the case of a snapshot)\\"}),(0,a.jsx)(e.li,{children:\\"u for UPDATE\\"}),(0,a.jsx)(e.li,{children:\\"d for DELETE\\"})]})]})})]}),(0,a.jsx)(e.li,{children:(0,a.jsx)(e.p,{children:\\"The ts_ms element refers to the timestamp in milliseconds of when the transaction occurred\\"})})]}),(0,a.jsx)(e.p,{children:\\"In the op element of the format, you may use a possible r value to determine if the record originated from a snapshot of the entire table in the data store. When the Debezium connector first starts, you could encounter existing records. You can configure the connector to first take a snapshot of the entire table to send as events downstream to its eventual destination. This will affect the treatment of records in the destination, in our case, Apache Pinot.\\"}),(0,a.jsx)(e.p,{children:\\"In Apache Pinot, we will have to create a schema that corresponds to the Debezium format. This could be defined a number of ways. I chose to bring the comments in the after field so users can access the latest values for any customer. I also kept the op at the top level. Since there are no metrics, that context in the schema is an empty array. I also preserved the after and before fields. Notice they are of type STRING. In Apache Pinot, you can assign a JSON index to any field containing multi-level JSON data. Apache Pinot will index all the values in the JSON payload so that any query referencing data in those JSON fields would be fast. This will allow users to see previous values of the record in cases where the operation was a change.\\\\xA0 Lastly, I have a date time field to indicate when the last change was made.\\"}),(0,a.jsx)(e.pre,{className:\\"language-json\\",children:(0,a.jsxs)(e.code,{className:\\"language-json code-highlight\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"customers\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dimensionFieldSpecs\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"user_id\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"first_name\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"last_name\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"email\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"op\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"before\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"after\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"source\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"metricFieldSpecs\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dateTimeFieldSpecs\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"ts_ms\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"LONG\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"format\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:`\\"1:MILLISECONDS:SIMPLE_DATE_FORMAT:yyyy-MM-dd\'T\'HH:mm:ss.SSS\'Z\'\\"`}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"granularity\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"primaryKeyColumns\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"user_id\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"You may have an alternative schema depending on your use case. You don\\\\u2019t need any of the fields I preserved. If at the end you only want the latest version, you can do that easily by only preserving the columns that matter to you.\\"}),(0,a.jsxs)(e.h2,{id:\\"materialized-views\\",children:[(0,a.jsx)(e.a,{href:\\"#materialized-views\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Materialized Views\\"]}),(0,a.jsx)(e.p,{children:\\"When looking up your record in Pinot, you only need to provide a WHERE clause with the primary key. Pinot will only return one record\\\\u2014the latest version of the record, not the history of the record\\\\u2014as a true materialized view should. Otherwise, you would have to provide more logic in the SQL statement that selects for the latest record. This adds latency to the query and may make downstream aggregations less accurate. Pinot provides a materialized view by implementing upsert for real-time tables with a primary key.\\"}),(0,a.jsxs)(e.h2,{id:\\"upsert-in-apache-pinot\\",children:[(0,a.jsx)(e.a,{href:\\"#upsert-in-apache-pinot\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Upsert in Apache Pinot\\"]}),(0,a.jsxs)(e.p,{children:[\\"Unlike any other real-time OLAP, \\",(0,a.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/data-import/upsert\\",children:\\"Pinot offers native support for upsert\\"}),\\" for real-time ingestion. Upsert logic says, \\\\u201CIf the record exists, update it or otherwise insert it.\\\\u201D\\"]}),(0,a.jsx)(e.p,{children:\\"You need upsert capabilities for dimensional data to simply SELECT for the record\\\\u2019s primary key when retrieving it. Without upsert, you will need to find the latest version of a record by comparing the latest timestamps, which leaves room for error.\\"}),(0,a.jsx)(e.p,{children:\\"This JSON document shows a schema snippet in Pinot that contains a primaryKeyColumns property. By applying this property, Pinot automatically enables the upsert feature. Upsert is completely transparent to the sender and therefore no specific programming is required.\\"}),(0,a.jsx)(e.pre,{className:\\"language-json\\",children:(0,a.jsxs)(e.code,{className:\\"language-json code-highlight\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"primaryKeyColumns\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"user_id\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"You can further configure the behavior of the upsert to allow for different behaviors: FULL or PARTIAL.\\"}),(0,a.jsx)(e.p,{children:\\"A FULL upsert means that a new record will replace the older record completely if they share the same primary key.\\"}),(0,a.jsx)(e.p,{children:\\"PARTIAL only allows updates to specific columns and employs additional strategies.\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Table describing the strategy and descriptions of stream ingestion with upsert\\",src:\\"https://www.datocms-assets.com/75153/1684857317-image6.png\\",title:\\"Table describing the strategy and descriptions of stream ingestion with upsert\\"})}),(0,a.jsxs)(e.p,{children:[\\"Source: \\",(0,a.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/data-import/upsert\\",children:\\"Stream Ingestion with Upsert\\"})]}),(0,a.jsx)(e.p,{children:\\"Here is a sample snippet of a table configuration containing the property that configures the upsert strategy:\\"}),(0,a.jsx)(e.pre,{className:\\"language-json\\",children:(0,a.jsx)(e.code,{className:\\"language-json code-highlight\\",children:(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"upsertConfig\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"mode\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"FULL\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]})})}),(0,a.jsx)(e.p,{children:\\"Upsert simplifies client queries in an extremely powerful way. More importantly, upsert assures the accuracy of any aggregations applied to updated columns, which proves especially important when the analytics lead to critical decisions.\\"}),(0,a.jsxs)(e.h2,{id:\\"summary\\",children:[(0,a.jsx)(e.a,{href:\\"#summary\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),(0,a.jsx)(e.p,{children:\\"Change data capture is the best way to capture changes in a database. Other options require comparing snapshots or applying complex modified timestamp logic. Other solutions only emulate real-time, but change data capture embodies the only genuine real-time event streaming solution.\\"}),(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.a,{href:\\"https://debezium.io/documentation/reference/stable/index.html\\",children:\\"Debezium provides many other CDC connectors\\"}),\\" that you can find in their documentation. If you do not have a Kafka Connect cluster or do not use Kafka at all, you can use the Debezium server to run the CDC connectors and write to an alternative streaming system, such as Amazon Kinesis, Pub/Sub from Google Cloud, Apache\\\\xAE Pulsar\\\\u2122, Azure Event Hubs, and RabbitMQ.\\"]}),(0,a.jsx)(e.p,{children:\\"Lastly, Apache Pinot enables upsert for any client sinking into it, which means the client does not need to implement upsert logic. Any client can generate a materialized view in Pinot. This makes the resulting table faster to query and provides more accurate analytics.\\"}),(0,a.jsxs)(e.p,{children:[\\"To try Pinot in the cloud, \\",(0,a.jsx)(e.a,{href:\\"https://startree.ai/saas-signup\\",children:\\"visit startree.ai for a free trial\\"}),\\".\\"]})]})}function b(n={}){let{wrapper:e}=n.components||{};return e?(0,a.jsx)(e,Object.assign({},n,{children:(0,a.jsx)(p,n)})):p(n)}var v=b;return f(T);})();\\n;return Component;"},"_id":"blog/2023-05-23-change-data-capture-with-apache-pinot-how-does-it-work.mdx","_raw":{"sourceFilePath":"blog/2023-05-23-change-data-capture-with-apache-pinot-how-does-it-work.mdx","sourceFileName":"2023-05-23-change-data-capture-with-apache-pinot-how-does-it-work.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2023-05-23-change-data-capture-with-apache-pinot-how-does-it-work"},"type":"Blog","readingTime":{"text":"10 min read","minutes":9.105,"time":546300,"words":1821},"slug":"2023/05/23/change-data-capture-with-apache-pinot-how-does-it-work","customSlug":"2023/05/23/change-data-capture-with-apache-pinot-how-does-it-work","path":"blog/2023/05/23/change-data-capture-with-apache-pinot-how-does-it-work","customPath":"blog/2023/05/23/change-data-capture-with-apache-pinot-how-does-it-work","filePath":"blog/2023-05-23-change-data-capture-with-apache-pinot-how-does-it-work.mdx","toc":[{"value":"Pre-Image, Post-Image, or Diffs?","url":"#pre-image-post-image-or-diffs","depth":2},{"value":"How to Capture Change Data with Debezium","url":"#how-to-capture-change-data-with-debezium","depth":2},{"value":"Debezium Data Format","url":"#debezium-data-format","depth":2},{"value":"Materialized Views","url":"#materialized-views","depth":2},{"value":"Upsert in Apache Pinot","url":"#upsert-in-apache-pinot","depth":2},{"value":"Summary","url":"#summary","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Change Data Capture with Apache Pinot - How Does It Work?","datePublished":"2023-05-23T00:00:00.000Z","dateModified":"2023-05-23T00:00:00.000Z","description":"This blog post discusses the use of Change Data Capture (CDC) in Apache Pinot and the data format used in Debezium for efficient querying and analytics. It explains the elements of the format and its usage in indexing JSON fields. It also mentions the availability of CDC connectors in Debezium for various streaming systems.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2023-05-23-change-data-capture-with-apache-pinot-how-does-it-work"}},{"title":"How to Ingest Streaming Data from Kafka to Apache Pinot™","date":"2022-05-30T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","kafka","streaming","json"],"summary":"The blog post explains how to use Apache Kafka topics in Apache Pinot to ingest streaming data, with step-by-step instructions provided for installation and setup. It focuses on ingesting Wikipedia events into Kafka and connecting it to Pinot to create a real-time table. The post highlights Pinot\'s capabilities in ingesting and transforming JSON data into OLAP tables and encourages reader engagement through the community Slack.","authors":["herman"],"body":{"raw":"\\nWe previously walked through getting started with [Apache Pinot™](https://startree.ai/resources/what-is-apache-pinot) using batch data, and now we will learn how to ingest streaming data using Apache Kafka\xae topics.\\n\\nAs the story goes, Apache Pinot was created at LinkedIn to provide a platform that could ingest a high number of incoming events (kafka) and provide “fresh” (sub second) analytics to a large number (20+ million) of users, fast (sub second latency). So, really, consuming events is part of the reason why Pinot was created.\\n\\n### The obligatory “What is Apache Pinot and StarTree?” section\\n\\n[Pinot](https://docs.pinot.apache.org/) is a real-time, distributed, open source, and free-to-use OLAP datastore, purpose-built to provide ultra low-latency analytics at extremely high throughput. It is open source and free to use.\\n\\nHow does StarTree come in? StarTree offers a [fully managed version of the Apache Pinot real-time analytics system](https://startree.ai/saas-signup) , plus other tools around it that you can try for free. The system includes\xa0 [StarTree Dataset Manager](https://dev.startree.ai/docs/startree-enterprise-edition/startree-dataset-manager/) and [StarTree ThirdEye](https://dev.startree.ai/docs/procedures/get-started-with-thirdeye/), a UI based data ingestion tool, and a real-time anomaly detection and root cause analysis tool, respectively.\\n\\n## How to install Kafka alongside Pinot\xa0\\n\\n### Prerequisite\\n\\nComplete the steps outlined in the [introduction to Apache Pinot](https://startree.ai/blog/apache-pinot-tutorial-for-getting-started-a-step-by-step-guide).\\n\\n### Step 1: Install Kafka on your Pinot Docker image\\n\\nMake sure you have completed the first article in the series.\\n\\nWe will be installing Apache Kafka onto our already existing Pinot docker image. To start the Docker image, run the following command:\\n\\ndocker run -it --entrypoint /bin/bash -p 9000:9000 apachepinot/pinot:0.12.0\\n\\n![PowerShell 7.3.4 docker run Apache Pinot](https://www.datocms-assets.com/75153/1685462020-image1.png \'PowerShell 7.3.4 docker run Apache Pinot\')\\n\\nWe want to override the ENTRYPOINT and run Bash script within the Docker image. If you already have a container running, you can skip this step. I tend to tear down containers after use, so in my case, I created a brand new container.\\n\\nNow, start each of the components one at a time like we did in the previous session:\\n\\nbin/pinot-admin.sh StartZookeeper &\\n\\nbin/pinot-admin.sh StartController &\\n\\nbin/pinot-admin.sh StartBroker &\\n\\nbin/pinot-admin.sh StartServer &\\n\\nRun each of the commands one at a time. The & allows you to continue using the same Bash shell session. If you like, you can create different shells for each service:\\n\\n1.  Get the container ID by running docker ps\\n2.  Run `docker exec -it DOCKER_CONTAINER_ID bash` where DOCKER_CONTAINER_ID is the ID received from step 1.\\n3.  Run the pinot-admin.sh command to start the desired service\\n\\nIt should look like this:\\n\\n![Docker with container ID, Image, Command, and Created](https://www.datocms-assets.com/75153/1685462274-image7.png \'Docker with container ID, Image, Command, and Created\')\\n\\nYou can now browse to [http://localhost:9000/#/zookeeper](http://localhost:9000/#/zookeeper) to see the running cluster:\\n\\n![Empty Zookeeper Browser](https://www.datocms-assets.com/75153/1685462203-image5.png \'Empty Zookeeper Browser\')\\n\\n### Step 2: Install Kafka on the Docker container\\n\\nNext, let\'s install Kafka. We will be installing Kafka on the existing docker container. For this step, download the TAR file, extract the contents, and start Kafka.\\n\\n_Apache Kafka is an open source software platform that provides a unified, high-throughput, low-latency platform for handling real-time data feeds._\\n\\nUse the following command to download the Kafka image:\\n\\n```bash\\ncd ..\\ncurl https://downloads.apache.org/kafka/3.4.0/kafka_2.12-3.4.0.tgz --output kafka.tgz --output kafka.tgz\\n```\\n\\nIt should look this:\\n\\n![Code with Apache Pinot speed results](https://www.datocms-assets.com/75153/1685462322-image8.png \'Code with Apache Pinot speed results\')\\n\\nNote that we’ve changed the directory to keep the Kafka folder separate from the Pinot folder.\\n\\nNow, let’s expand the downloaded TAR file, rename the folder for convenience, and delete the downloaded file:\\n\\n```bash\\ntar -xvf kafka.tgz\\nmv kafka_2.12-3.4.0 kafka\\nrm -rf kafka.tgz\\n```\\n\\nIt should look like this:\\n\\n![Code with Apache Kafka](https://www.datocms-assets.com/75153/1685462061-image2.png \'Code with Apache Kafka\')\\n\\n![Code with kafka version](https://www.datocms-assets.com/75153/1685462480-image12.png \'Code with kafka version\')\\n\\nNow, Kafka and Pinot reside locally on our Docker container with Pinot up and running. Let’s run the Kafka service. Kafka will use the existing ZooKeeper for configuration management.\\n\\nUse the following command to run Kafka:\\n\\n```bash\\ncd kafka\\n./bin/kafka-server-start.sh config/server.properties\\n```\\n\\nIt should look like this:\\n\\n![Code with cd kafka](https://www.datocms-assets.com/75153/1685462400-image10.png \'Code with cd kafka\')\\n\\nTo verify that Kafka is running, let’s look at our ZooKeeper configs by browsing to [http://localhost:9000/#/zookeeper:](http://localhost:9000/#/zookeeper)\\n\\n![Zookeeper Browser](https://www.datocms-assets.com/75153/1685462099-image3.png \'Zookeeper Browser\')\\n\\nYou may have to refresh the page and find many more configuration items appear thanexpectedt. These are Kafka configurations.\\n\\n### Step 3: Ingest data into Kafka\\n\\nIn this step, we will ingest data into Kafka. We will be using Wikipedia events since they are easily accessible. We will use a node script to ingest the Wikipedia events, then add them to a Kafka Topic.\\n\\nLet’s first create some folders like this:\\n\\ncd /opt\\n\\nmkdir realtime\\n\\ncd realtime\\n\\nmkdir events\\n\\nIt should look like this:\\n\\n![Code with realtime](https://www.datocms-assets.com/75153/1685462150-image4.png \'Code with realtime\')\\n\\nYou may have to start a new PowerShell window and connect to Docker for this. Now, let’s install Node.js and any dependencies we might need for the event consumption script:\\n\\n```bash\\ncurl -fsSL https://deb.nodesource.com/setup_14.x | bash -\\napt install nodejs\\n```\\n\\nNode.js takes a few minutes to install. Next, we will create a script to consume the events called wikievents.js. Cut and paste the following code to this file:\\n\\n```javascript\\nvar EventSource = require(\'eventsource\');\\nvar fs = require(\'fs\');\\nvar path = require(\'path\');\\nconst { Kafka } = require(\'kafkajs\');\\n\\nvar url = \'https://stream.wikimedia.org/v2/stream/recentchange\';\\n\\nconst kafka = new Kafka({\\n    clientId: \'wikievents\',\\n    brokers: [\'localhost:9092\']\\n});\\n\\nconst producer = kafka.producer();\\n\\nasync function start() {\\n    await producer.connect();\\n    startEvents();\\n}\\n\\nfunction startEvents() {\\n    console.log(`Connecting to EventStreams at ${url}`);\\n    var eventSource = new EventSource(url);\\n\\n    eventSource.onopen = function () {\\n        console.log(\'--- Opened connection.\');\\n    };\\n\\n    eventSource.onerror = function (event) {\\n        console.error(\'--- Encountered error\', event);\\n    };\\n\\n    eventSource.onmessage = async function (event) {\\n        const data = JSON.parse(event.data);\\n        const eventPath = path.join(__dirname, \'./events\', data.wiki);\\n        fs.existsSync(eventPath) || fs.mkdirSync(eventPath);\\n        fs.writeFileSync(path.join(eventPath, data.meta.id + \'.json\'), event.data);\\n        await producer.send({\\n            topic: \'wikipedia-events\',\\n            messages: [\\n                {\\n                    key: data.meta.id,\\n                    value: event.data\\n                }\\n            ]\\n        });\\n    };\\n}\\n\\nstart();\\n```\\n\\nYou can use vi to create the file and save it. You can also use Docker Desktop to edit the file.\\n\\nTo install the two modules referenced in the file above, kafkajs and eventsource, run the following command:\\n\\n```bash\\nnpm i eventsource kafkajs\\n```\\n\\nLet’s run the program. This will result in the download of many files, so I recommend running the program for just a few minutes. You can stop the run by using Ctrl-C.\\n\\n```bash\\nnode wikievents.js\\n```\\n\\nUse Ctrl-C to stop the program. Navigate to the events folder to see some new folders created with the various language events downloaded from Wikipedia.\\n\\n![Wikievents node in code](https://www.datocms-assets.com/75153/1685462366-image9.png \'Wikievents node in code\')\\n\\nNavigate to the enwiki folder and review some of the downloaded JSON files.\\n\\n![Code with realtime wikievents](https://www.datocms-assets.com/75153/1685462441-image11.png \'Code with realtime wikievents\')\\n\\nAt http://localhost:9000/#/zookeeper, you can find the Kafka topic by locating the ZooKeeper config and expanding config > topics. You may have to refresh your browser.\\n\\n![Zookeeper browser in Apache Pinot topics](https://www.datocms-assets.com/75153/1685462510-image13.png \'Zookeeper browser in Apache Pinot topics\')\\n\\nHere, you should see the wikipedia-events topic that we created using the Node.js script. So far, so good.\\n\\n### Step 4: Connect Kafka to Pinot\\n\\nWith Kafka installed and configured to receive events, we can connect it to Pinot.\\n\\nTo create a real-time table in Pinot that can consume the Kafka topic, create a schema and a configuration table. The schema configuration is very much like the schema that we created for our batch example. You can use vi to create a file named realtime.schema.json and cut and paste the content below.\\n\\nHere’s the JSON for the wikievents schema:\\n\\n```json\\n{\\n    \\"schemaName\\": \\"wikievents\\",\\n    \\"dimensionFieldSpecs\\": [\\n        {\\n            \\"name\\": \\"id\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"wiki\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"user\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"title\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"comment\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"stream\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"domain\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"topic\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"type\\",\\n            \\"dataType\\": \\"STRING\\"\\n        },\\n        {\\n            \\"name\\": \\"metaJson\\",\\n            \\"dataType\\": \\"STRING\\"\\n        }\\n    ],\\n    \\"dateTimeFieldSpecs\\": [\\n        {\\n            \\"name\\": \\"timestamp\\",\\n            \\"dataType\\": \\"LONG\\",\\n            \\"format\\": \\"1:MILLISECONDS:EPOCH\\",\\n            \\"granularity\\": \\"1:MILLISECONDS\\"\\n        }\\n    ]\\n}\\n```\\n\\nCreating the table config file is where the magic happens. Use vi (or your favorite editor) to create realtime.tableconfig.json and cut and paste the following content:\\n\\n```json\\n{\\n    \\"tableName\\": \\"wikievents_REALTIME\\",\\n    \\"tableType\\": \\"REALTIME\\",\\n    \\"segmentsConfig\\": {\\n        \\"timeColumnName\\": \\"timestamp\\",\\n        \\"schemaName\\": \\"wikievents\\",\\n        \\"replication\\": \\"1\\",\\n        \\"replicasPerPartition\\": \\"1\\"\\n    },\\n    \\"tenants\\": {\\n        \\"broker\\": \\"DefaultTenant\\",\\n        \\"server\\": \\"DefaultTenant\\",\\n        \\"tagOverrideConfig\\": {}\\n    },\\n    \\"tableIndexConfig\\": {\\n        \\"invertedIndexColumns\\": [],\\n        \\"rangeIndexColumns\\": [],\\n        \\"autoGeneratedInvertedIndex\\": false,\\n        \\"createInvertedIndexDuringSegmentGeneration\\": false,\\n        \\"sortedColumn\\": [],\\n        \\"bloomFilterColumns\\": [],\\n        \\"loadMode\\": \\"MMAP\\",\\n        \\"streamConfigs\\": {\\n            \\"streamType\\": \\"kafka\\",\\n            \\"stream.kafka.topic.name\\": \\"wikipedia-events\\",\\n            \\"stream.kafka.broker.list\\": \\"localhost:9092\\",\\n            \\"stream.kafka.consumer.type\\": \\"lowlevel\\",\\n            \\"stream.kafka.consumer.prop.auto.offset.reset\\": \\"smallest\\",\\n            \\"stream.kafka.consumer.factory.class.name\\": \\"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\\",\\n            \\"stream.kafka.decoder.class.name\\": \\"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\\",\\n            \\"realtime.segment.flush.threshold.rows\\": \\"0\\",\\n            \\"realtime.segment.flush.threshold.time\\": \\"24h\\",\\n            \\"realtime.segment.flush.segment.size\\": \\"100M\\"\\n        },\\n        \\"noDictionaryColumns\\": [],\\n        \\"onHeapDictionaryColumns\\": [],\\n        \\"varLengthDictionaryColumns\\": [],\\n        \\"enableDefaultStarTree\\": false,\\n        \\"enableDynamicStarTreeCreation\\": false,\\n        \\"aggregateMetrics\\": false,\\n        \\"nullHandlingEnabled\\": false\\n    },\\n    \\"metadata\\": {},\\n    \\"quota\\": {},\\n    \\"routing\\": {},\\n    \\"query\\": {},\\n    \\"ingestionConfig\\": {\\n        \\"transformConfigs\\": [\\n            {\\n                \\"columnName\\": \\"metaJson\\",\\n                \\"transformFunction\\": \\"JSONFORMAT(meta)\\"\\n            },\\n            {\\n                \\"columnName\\": \\"id\\",\\n                \\"transformFunction\\": \\"JSONPATH(metaJson, \'$.id\')\\"\\n            },\\n            {\\n                \\"columnName\\": \\"stream\\",\\n                \\"transformFunction\\": \\"JSONPATH(metaJson, \'$.stream\')\\"\\n            },\\n            {\\n                \\"columnName\\": \\"domain\\",\\n                \\"transformFunction\\": \\"JSONPATH(metaJson, \'$.domain\')\\"\\n            },\\n            {\\n                \\"columnName\\": \\"topic\\",\\n                \\"transformFunction\\": \\"JSONPATH(metaJson, \'$.topic\')\\"\\n            }\\n        ]\\n    },\\n    \\"isDimTable\\": false\\n}\\n```\\n\\nNotice the section called streamConfigs, where we define the source as a Kafka stream, located at localhost:9092, and consume the topic wikipedia-events. That’s all it takes to consume a Kafka Topic into Pinot.\\n\\nDon’t believe me? Give it a try!\\n\\nCreate the table by running the following command:\\n\\n```bash\\n/opt/pinot/bin/pinot-admin.sh AddTable -schemaFile /opt/realtime/realtime.schema.json -tableConfigFile /opt/realtime/realtime.tableconfig.json -exec\\n```\\n\\nNow, browse to the following location [http://localhost:9000/#/tables,](http://localhost:9000/#/tables) and you should see the newly created table. However, where’s the real-time data, you say?\\n\\nRun the node wikievents.js command, then query the newly created wikievents table to see the totalDocs increase in real time:\\n\\n![Apache Pinot query console](https://www.datocms-assets.com/75153/1685462248-image6.png \'Apache Pinot query console\')\\n\\nTo avoid running out of space on your computer, make sure to stop the wikievents.js script when you’re done :-D\\n\\n## Conclusion\\n\\nCongratulations! Using only the table config, we simultaneously consumed Kafka topics directly into Pinot tables and queried events. We also transformed JSON to map to the Pinot table. In the transformConfigs portion of the Pinot table config file, we consumed the nested block meta into a field called metaJson. In the subsequent steps, we referenced the metaJson field with jsonPath to extract fields such as id, stream, domain, and topic.\\n\\nNot only does Pinot support easy ingestion from Kafka topics, but it also provides a robust way to transform JSON to OLAP tables.\\n\\nIn summary, we have:\\n\\n-   Installed and run Kafka\\n-   Consumed events from Wikipedia into Kafka\\n-   Created a real-time table schema and a table in Pinot\\n-   Streamed events from Wikipedia into Pinot tables via Kafka topics\\n-   Run multiple queries\\n-   Performed JSON transformations\\n\\nIn some upcoming blog posts, we will explore more advanced topics, such as indexes and transformations, not to mention real-time anomaly detection with [ThirdEye](https://dev.startree.ai/docs/procedures/get-started-with-thirdeye/).\\n\\nIn the meantime, run more queries, load more data, and don’t forget to [join the community Slack for support](https://dev.startree.ai/slack-invite) if you get stuck or would like to request a topic for me to write about—you know where to find us!\\n","code":"var Component=(()=>{var d=Object.create;var t=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,N=Object.prototype.hasOwnProperty;var k=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),g=(a,e)=>{for(var s in e)t(a,s,{get:e[s],enumerable:!0})},o=(a,e,s,l)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let c of m(e))!N.call(a,c)&&c!==s&&t(a,c,{get:()=>e[c],enumerable:!(l=h(e,c))||l.enumerable});return a};var f=(a,e,s)=>(s=a!=null?d(u(a)):{},o(e||!a||!a.__esModule?t(s,\\"default\\",{value:a,enumerable:!0}):s,a)),y=a=>o(t({},\\"__esModule\\",{value:!0}),a);var r=k((T,i)=>{i.exports=_jsx_runtime});var I={};g(I,{default:()=>b,frontmatter:()=>w});var n=f(r()),w={title:\\"How to Ingest Streaming Data from Kafka to Apache Pinot\\\\u2122\\",date:new Date(16538688e5),authors:[\\"herman\\"],summary:\\"The blog post explains how to use Apache Kafka topics in Apache Pinot to ingest streaming data, with step-by-step instructions provided for installation and setup. It focuses on ingesting Wikipedia events into Kafka and connecting it to Pinot to create a real-time table. The post highlights Pinot\'s capabilities in ingesting and transforming JSON data into OLAP tables and encourages reader engagement through the community Slack.\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"kafka\\",\\"streaming\\",\\"json\\"]};function p(a){let e=Object.assign({p:\\"p\\",a:\\"a\\",h3:\\"h3\\",span:\\"span\\",h2:\\"h2\\",img:\\"img\\",ol:\\"ol\\",li:\\"li\\",code:\\"code\\",em:\\"em\\",pre:\\"pre\\",ul:\\"ul\\"},a.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.p,{children:[\\"We previously walked through getting started with \\",(0,n.jsx)(e.a,{href:\\"https://startree.ai/resources/what-is-apache-pinot\\",children:\\"Apache Pinot\\\\u2122\\"}),\\" using batch data, and now we will learn how to ingest streaming data using Apache Kafka\\\\xAE topics.\\"]}),(0,n.jsx)(e.p,{children:\\"As the story goes, Apache Pinot was created at LinkedIn to provide a platform that could ingest a high number of incoming events (kafka) and provide \\\\u201Cfresh\\\\u201D (sub second) analytics to a large number (20+ million) of users, fast (sub second latency). So, really, consuming events is part of the reason why Pinot was created.\\"}),(0,n.jsxs)(e.h3,{id:\\"the-obligatory-what-is-apache-pinot-and-startree-section\\",children:[(0,n.jsx)(e.a,{href:\\"#the-obligatory-what-is-apache-pinot-and-startree-section\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"The obligatory \\\\u201CWhat is Apache Pinot and StarTree?\\\\u201D section\\"]}),(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/\\",children:\\"Pinot\\"}),\\" is a real-time, distributed, open source, and free-to-use OLAP datastore, purpose-built to provide ultra low-latency analytics at extremely high throughput. It is open source and free to use.\\"]}),(0,n.jsxs)(e.p,{children:[\\"How does StarTree come in? StarTree offers a \\",(0,n.jsx)(e.a,{href:\\"https://startree.ai/saas-signup\\",children:\\"fully managed version of the Apache Pinot real-time analytics system\\"}),\\" , plus other tools around it that you can try for free. The system includes\\\\xA0 \\",(0,n.jsx)(e.a,{href:\\"https://dev.startree.ai/docs/startree-enterprise-edition/startree-dataset-manager/\\",children:\\"StarTree Dataset Manager\\"}),\\" and \\",(0,n.jsx)(e.a,{href:\\"https://dev.startree.ai/docs/procedures/get-started-with-thirdeye/\\",children:\\"StarTree ThirdEye\\"}),\\", a UI based data ingestion tool, and a real-time anomaly detection and root cause analysis tool, respectively.\\"]}),(0,n.jsxs)(e.h2,{id:\\"how-to-install-kafka-alongside-pinot\\",children:[(0,n.jsx)(e.a,{href:\\"#how-to-install-kafka-alongside-pinot\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"How to install Kafka alongside Pinot\\\\xA0\\"]}),(0,n.jsxs)(e.h3,{id:\\"prerequisite\\",children:[(0,n.jsx)(e.a,{href:\\"#prerequisite\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Prerequisite\\"]}),(0,n.jsxs)(e.p,{children:[\\"Complete the steps outlined in the \\",(0,n.jsx)(e.a,{href:\\"https://startree.ai/blog/apache-pinot-tutorial-for-getting-started-a-step-by-step-guide\\",children:\\"introduction to Apache Pinot\\"}),\\".\\"]}),(0,n.jsxs)(e.h3,{id:\\"step-1-install-kafka-on-your-pinot-docker-image\\",children:[(0,n.jsx)(e.a,{href:\\"#step-1-install-kafka-on-your-pinot-docker-image\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Step 1: Install Kafka on your Pinot Docker image\\"]}),(0,n.jsx)(e.p,{children:\\"Make sure you have completed the first article in the series.\\"}),(0,n.jsx)(e.p,{children:\\"We will be installing Apache Kafka onto our already existing Pinot docker image. To start the Docker image, run the following command:\\"}),(0,n.jsx)(e.p,{children:\\"docker run -it --entrypoint /bin/bash -p 9000:9000 apachepinot/pinot:0.12.0\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"PowerShell 7.3.4 docker run Apache Pinot\\",src:\\"https://www.datocms-assets.com/75153/1685462020-image1.png\\",title:\\"PowerShell 7.3.4 docker run Apache Pinot\\"})}),(0,n.jsx)(e.p,{children:\\"We want to override the ENTRYPOINT and run Bash script within the Docker image. If you already have a container running, you can skip this step. I tend to tear down containers after use, so in my case, I created a brand new container.\\"}),(0,n.jsx)(e.p,{children:\\"Now, start each of the components one at a time like we did in the previous session:\\"}),(0,n.jsx)(e.p,{children:\\"bin/pinot-admin.sh StartZookeeper &\\"}),(0,n.jsx)(e.p,{children:\\"bin/pinot-admin.sh StartController &\\"}),(0,n.jsx)(e.p,{children:\\"bin/pinot-admin.sh StartBroker &\\"}),(0,n.jsx)(e.p,{children:\\"bin/pinot-admin.sh StartServer &\\"}),(0,n.jsx)(e.p,{children:\\"Run each of the commands one at a time. The & allows you to continue using the same Bash shell session. If you like, you can create different shells for each service:\\"}),(0,n.jsxs)(e.ol,{children:[(0,n.jsx)(e.li,{children:\\"Get the container ID by running docker ps\\"}),(0,n.jsxs)(e.li,{children:[\\"Run \\",(0,n.jsx)(e.code,{children:\\"docker exec -it DOCKER_CONTAINER_ID bash\\"}),\\" where DOCKER_CONTAINER_ID is the ID received from step 1.\\"]}),(0,n.jsx)(e.li,{children:\\"Run the pinot-admin.sh command to start the desired service\\"})]}),(0,n.jsx)(e.p,{children:\\"It should look like this:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Docker with container ID, Image, Command, and Created\\",src:\\"https://www.datocms-assets.com/75153/1685462274-image7.png\\",title:\\"Docker with container ID, Image, Command, and Created\\"})}),(0,n.jsxs)(e.p,{children:[\\"You can now browse to \\",(0,n.jsx)(e.a,{href:\\"http://localhost:9000/#/zookeeper\\",children:\\"http://localhost:9000/#/zookeeper\\"}),\\" to see the running cluster:\\"]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Empty Zookeeper Browser\\",src:\\"https://www.datocms-assets.com/75153/1685462203-image5.png\\",title:\\"Empty Zookeeper Browser\\"})}),(0,n.jsxs)(e.h3,{id:\\"step-2-install-kafka-on-the-docker-container\\",children:[(0,n.jsx)(e.a,{href:\\"#step-2-install-kafka-on-the-docker-container\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Step 2: Install Kafka on the Docker container\\"]}),(0,n.jsx)(e.p,{children:\\"Next, let\'s install Kafka. We will be installing Kafka on the existing docker container. For this step, download the TAR file, extract the contents, and start Kafka.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.em,{children:\\"Apache Kafka is an open source software platform that provides a unified, high-throughput, low-latency platform for handling real-time data feeds.\\"})}),(0,n.jsx)(e.p,{children:\\"Use the following command to download the Kafka image:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"language-bash code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token class-name builtin\\",children:\\"cd\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"..\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"curl\\"}),\\" https://downloads.apache.org/kafka/3.4.0/kafka_2.12-3.4.0.tgz \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"--output\\"}),\\" kafka.tgz \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"--output\\"}),` kafka.tgz\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"It should look this:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Code with Apache Pinot speed results\\",src:\\"https://www.datocms-assets.com/75153/1685462322-image8.png\\",title:\\"Code with Apache Pinot speed results\\"})}),(0,n.jsx)(e.p,{children:\\"Note that we\\\\u2019ve changed the directory to keep the Kafka folder separate from the Pinot folder.\\"}),(0,n.jsx)(e.p,{children:\\"Now, let\\\\u2019s expand the downloaded TAR file, rename the folder for convenience, and delete the downloaded file:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"language-bash code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"tar\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-xvf\\"}),` kafka.tgz\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"mv\\"}),` kafka_2.12-3.4.0 kafka\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"rm\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-rf\\"}),` kafka.tgz\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"It should look like this:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Code with Apache Kafka\\",src:\\"https://www.datocms-assets.com/75153/1685462061-image2.png\\",title:\\"Code with Apache Kafka\\"})}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Code with kafka version\\",src:\\"https://www.datocms-assets.com/75153/1685462480-image12.png\\",title:\\"Code with kafka version\\"})}),(0,n.jsx)(e.p,{children:\\"Now, Kafka and Pinot reside locally on our Docker container with Pinot up and running. Let\\\\u2019s run the Kafka service. Kafka will use the existing ZooKeeper for configuration management.\\"}),(0,n.jsx)(e.p,{children:\\"Use the following command to run Kafka:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"language-bash code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token class-name builtin\\",children:\\"cd\\"}),` kafka\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`./bin/kafka-server-start.sh config/server.properties\\n`})]})}),(0,n.jsx)(e.p,{children:\\"It should look like this:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Code with cd kafka\\",src:\\"https://www.datocms-assets.com/75153/1685462400-image10.png\\",title:\\"Code with cd kafka\\"})}),(0,n.jsxs)(e.p,{children:[\\"To verify that Kafka is running, let\\\\u2019s look at our ZooKeeper configs by browsing to \\",(0,n.jsx)(e.a,{href:\\"http://localhost:9000/#/zookeeper\\",children:\\"http://localhost:9000/#/zookeeper:\\"})]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Zookeeper Browser\\",src:\\"https://www.datocms-assets.com/75153/1685462099-image3.png\\",title:\\"Zookeeper Browser\\"})}),(0,n.jsx)(e.p,{children:\\"You may have to refresh the page and find many more configuration items appear thanexpectedt. These are Kafka configurations.\\"}),(0,n.jsxs)(e.h3,{id:\\"step-3-ingest-data-into-kafka\\",children:[(0,n.jsx)(e.a,{href:\\"#step-3-ingest-data-into-kafka\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Step 3: Ingest data into Kafka\\"]}),(0,n.jsx)(e.p,{children:\\"In this step, we will ingest data into Kafka. We will be using Wikipedia events since they are easily accessible. We will use a node script to ingest the Wikipedia events, then add them to a Kafka Topic.\\"}),(0,n.jsx)(e.p,{children:\\"Let\\\\u2019s first create some folders like this:\\"}),(0,n.jsx)(e.p,{children:\\"cd /opt\\"}),(0,n.jsx)(e.p,{children:\\"mkdir realtime\\"}),(0,n.jsx)(e.p,{children:\\"cd realtime\\"}),(0,n.jsx)(e.p,{children:\\"mkdir events\\"}),(0,n.jsx)(e.p,{children:\\"It should look like this:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Code with realtime\\",src:\\"https://www.datocms-assets.com/75153/1685462150-image4.png\\",title:\\"Code with realtime\\"})}),(0,n.jsx)(e.p,{children:\\"You may have to start a new PowerShell window and connect to Docker for this. Now, let\\\\u2019s install Node.js and any dependencies we might need for the event consumption script:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsxs)(e.code,{className:\\"language-bash code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"curl\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-fsSL\\"}),\\" https://deb.nodesource.com/setup_14.x \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"|\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"bash\\"}),` -\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"apt\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"install\\"}),` nodejs\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"Node.js takes a few minutes to install. Next, we will create a script to consume the events called wikievents.js. Cut and paste the following code to this file:\\"}),(0,n.jsx)(e.pre,{className:\\"language-javascript\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-javascript\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"var\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token maybe-class-name\\",children:\\"EventSource\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"require\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'eventsource\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"var\\"}),\\" fs \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"require\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'fs\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"var\\"}),\\" path \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"require\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'path\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"const\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token maybe-class-name\\",children:\\"Kafka\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"require\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'kafkajs\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"var\\"}),\\" url \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'https://stream.wikimedia.org/v2/stream/recentchange\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"const\\"}),\\" kafka \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"new\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token class-name\\",children:\\"Kafka\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property literal-property\\",children:\\"clientId\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'wikievents\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property literal-property\\",children:\\"brokers\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'localhost:9092\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"const\\"}),\\" producer \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" kafka\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method\\",children:\\"producer\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"async\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"function\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"start\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token keyword control-flow\\",children:\\"await\\"}),\\" producer\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method\\",children:\\"connect\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"startEvents\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"function\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"startEvents\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token class-name console\\",children:\\"console\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method\\",children:\\"log\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsxs)(e.span,{className:\\"token template-string\\",children:[(0,n.jsx)(e.span,{className:\\"token string template-punctuation\\",children:\\"`\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"Connecting to EventStreams at \\"}),(0,n.jsxs)(e.span,{className:\\"token interpolation\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation interpolation-punctuation\\",children:\\"${\\"}),\\"url\\",(0,n.jsx)(e.span,{className:\\"token punctuation interpolation-punctuation\\",children:\\"}\\"})]}),(0,n.jsx)(e.span,{className:\\"token string template-punctuation\\",children:\\"`\\"})]}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"var\\"}),\\" eventSource \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"new\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token class-name\\",children:\\"EventSource\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"url\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    eventSource\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method function-variable method-variable\\",children:\\"onopen\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"function\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token class-name console\\",children:\\"console\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method\\",children:\\"log\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'--- Opened connection.\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    eventSource\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method function-variable method-variable\\",children:\\"onerror\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"function\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token parameter\\",children:\\"event\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token class-name console\\",children:\\"console\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method\\",children:\\"error\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'--- Encountered error\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" event\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    eventSource\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method function-variable method-variable\\",children:\\"onmessage\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"async\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"function\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token parameter\\",children:\\"event\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"const\\"}),\\" data \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token class-name known-class-name\\",children:\\"JSON\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method\\",children:\\"parse\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"event\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token property-access\\",children:\\"data\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"const\\"}),\\" eventPath \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" path\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method\\",children:\\"join\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"__dirname\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'./events\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" data\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token property-access\\",children:\\"wiki\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        fs\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method\\",children:\\"existsSync\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"eventPath\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"||\\"}),\\" fs\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method\\",children:\\"mkdirSync\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"eventPath\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        fs\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method\\",children:\\"writeFileSync\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"path\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method\\",children:\\"join\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"eventPath\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" data\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token property-access\\",children:\\"meta\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token property-access\\",children:\\"id\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"+\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'.json\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" event\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token property-access\\",children:\\"data\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token keyword control-flow\\",children:\\"await\\"}),\\" producer\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token function property-access method\\",children:\\"send\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property literal-property\\",children:\\"topic\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\\"\'wikipedia-events\'\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property literal-property\\",children:\\"messages\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                    \\",(0,n.jsx)(e.span,{className:\\"token property literal-property\\",children:\\"key\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" data\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token property-access\\",children:\\"meta\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token property-access\\",children:\\"id\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                    \\",(0,n.jsx)(e.span,{className:\\"token property literal-property\\",children:\\"value\\"}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" event\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),(0,n.jsx)(e.span,{className:\\"token property-access\\",children:\\"data\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"start\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"You can use vi to create the file and save it. You can also use Docker Desktop to edit the file.\\"}),(0,n.jsx)(e.p,{children:\\"To install the two modules referenced in the file above, kafkajs and eventsource, run the following command:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsx)(e.code,{className:\\"language-bash code-highlight\\",children:(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"npm\\"}),` i eventsource kafkajs\\n`]})})}),(0,n.jsx)(e.p,{children:\\"Let\\\\u2019s run the program. This will result in the download of many files, so I recommend running the program for just a few minutes. You can stop the run by using Ctrl-C.\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsx)(e.code,{className:\\"language-bash code-highlight\\",children:(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"node\\"}),` wikievents.js\\n`]})})}),(0,n.jsx)(e.p,{children:\\"Use Ctrl-C to stop the program. Navigate to the events folder to see some new folders created with the various language events downloaded from Wikipedia.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Wikievents node in code\\",src:\\"https://www.datocms-assets.com/75153/1685462366-image9.png\\",title:\\"Wikievents node in code\\"})}),(0,n.jsx)(e.p,{children:\\"Navigate to the enwiki folder and review some of the downloaded JSON files.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Code with realtime wikievents\\",src:\\"https://www.datocms-assets.com/75153/1685462441-image11.png\\",title:\\"Code with realtime wikievents\\"})}),(0,n.jsxs)(e.p,{children:[\\"At \\",(0,n.jsx)(e.a,{href:\\"http://localhost:9000/#/zookeeper\\",children:\\"http://localhost:9000/#/zookeeper\\"}),\\", you can find the Kafka topic by locating the ZooKeeper config and expanding config > topics. You may have to refresh your browser.\\"]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Zookeeper browser in Apache Pinot topics\\",src:\\"https://www.datocms-assets.com/75153/1685462510-image13.png\\",title:\\"Zookeeper browser in Apache Pinot topics\\"})}),(0,n.jsx)(e.p,{children:\\"Here, you should see the wikipedia-events topic that we created using the Node.js script. So far, so good.\\"}),(0,n.jsxs)(e.h3,{id:\\"step-4-connect-kafka-to-pinot\\",children:[(0,n.jsx)(e.a,{href:\\"#step-4-connect-kafka-to-pinot\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Step 4: Connect Kafka to Pinot\\"]}),(0,n.jsx)(e.p,{children:\\"With Kafka installed and configured to receive events, we can connect it to Pinot.\\"}),(0,n.jsx)(e.p,{children:\\"To create a real-time table in Pinot that can consume the Kafka topic, create a schema and a configuration table. The schema configuration is very much like the schema that we created for our batch example. You can use vi to create a file named realtime.schema.json and cut and paste the content below.\\"}),(0,n.jsx)(e.p,{children:\\"Here\\\\u2019s the JSON for the wikievents schema:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"wikievents\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dimensionFieldSpecs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"id\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"wiki\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"user\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"title\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"comment\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"stream\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"domain\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"topic\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"type\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"metaJson\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dateTimeFieldSpecs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"timestamp\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"LONG\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"format\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS:EPOCH\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"granularity\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"Creating the table config file is where the magic happens. Use vi (or your favorite editor) to create realtime.tableconfig.json and cut and paste the following content:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"wikievents_REALTIME\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"REALTIME\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"segmentsConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"timeColumnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"timestamp\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"wikievents\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"replication\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"replicasPerPartition\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"1\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tenants\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"broker\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"DefaultTenant\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"server\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"DefaultTenant\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tagOverrideConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableIndexConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"invertedIndexColumns\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"rangeIndexColumns\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"autoGeneratedInvertedIndex\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"createInvertedIndexDuringSegmentGeneration\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"sortedColumn\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"bloomFilterColumns\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"loadMode\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"MMAP\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"streamConfigs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"streamType\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"kafka\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.topic.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"wikipedia-events\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.broker.list\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"localhost:9092\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.type\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"lowlevel\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.prop.auto.offset.reset\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"smallest\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.factory.class.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.class.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"realtime.segment.flush.threshold.rows\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"0\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"realtime.segment.flush.threshold.time\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"24h\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"realtime.segment.flush.segment.size\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"100M\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"noDictionaryColumns\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"onHeapDictionaryColumns\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"varLengthDictionaryColumns\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"enableDefaultStarTree\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"enableDynamicStarTreeCreation\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"aggregateMetrics\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"nullHandlingEnabled\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"metadata\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"quota\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"routing\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"query\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"ingestionConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformConfigs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"columnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"metaJson\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformFunction\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"JSONFORMAT(meta)\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"columnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"id\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformFunction\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:`\\"JSONPATH(metaJson, \'$.id\')\\"`}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"columnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"stream\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformFunction\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:`\\"JSONPATH(metaJson, \'$.stream\')\\"`}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"columnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"domain\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformFunction\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:`\\"JSONPATH(metaJson, \'$.domain\')\\"`}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"columnName\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"topic\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"                \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"transformFunction\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:`\\"JSONPATH(metaJson, \'$.topic\')\\"`}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"isDimTable\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"Notice the section called streamConfigs, where we define the source as a Kafka stream, located at localhost:9092, and consume the topic wikipedia-events. That\\\\u2019s all it takes to consume a Kafka Topic into Pinot.\\"}),(0,n.jsx)(e.p,{children:\\"Don\\\\u2019t believe me? Give it a try!\\"}),(0,n.jsx)(e.p,{children:\\"Create the table by running the following command:\\"}),(0,n.jsx)(e.pre,{className:\\"language-bash\\",children:(0,n.jsx)(e.code,{className:\\"language-bash code-highlight\\",children:(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"/opt/pinot/bin/pinot-admin.sh AddTable \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-schemaFile\\"}),\\" /opt/realtime/realtime.schema.json \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-tableConfigFile\\"}),\\" /opt/realtime/realtime.tableconfig.json \\",(0,n.jsx)(e.span,{className:\\"token parameter variable\\",children:\\"-exec\\"}),`\\n`]})})}),(0,n.jsxs)(e.p,{children:[\\"Now, browse to the following location \\",(0,n.jsx)(e.a,{href:\\"http://localhost:9000/#/tables\\",children:\\"http://localhost:9000/#/tables,\\"}),\\" and you should see the newly created table. However, where\\\\u2019s the real-time data, you say?\\"]}),(0,n.jsx)(e.p,{children:\\"Run the node wikievents.js command, then query the newly created wikievents table to see the totalDocs increase in real time:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Apache Pinot query console\\",src:\\"https://www.datocms-assets.com/75153/1685462248-image6.png\\",title:\\"Apache Pinot query console\\"})}),(0,n.jsx)(e.p,{children:\\"To avoid running out of space on your computer, make sure to stop the wikievents.js script when you\\\\u2019re done :-D\\"}),(0,n.jsxs)(e.h2,{id:\\"conclusion\\",children:[(0,n.jsx)(e.a,{href:\\"#conclusion\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Conclusion\\"]}),(0,n.jsx)(e.p,{children:\\"Congratulations! Using only the table config, we simultaneously consumed Kafka topics directly into Pinot tables and queried events. We also transformed JSON to map to the Pinot table. In the transformConfigs portion of the Pinot table config file, we consumed the nested block meta into a field called metaJson. In the subsequent steps, we referenced the metaJson field with jsonPath to extract fields such as id, stream, domain, and topic.\\"}),(0,n.jsx)(e.p,{children:\\"Not only does Pinot support easy ingestion from Kafka topics, but it also provides a robust way to transform JSON to OLAP tables.\\"}),(0,n.jsx)(e.p,{children:\\"In summary, we have:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"Installed and run Kafka\\"}),(0,n.jsx)(e.li,{children:\\"Consumed events from Wikipedia into Kafka\\"}),(0,n.jsx)(e.li,{children:\\"Created a real-time table schema and a table in Pinot\\"}),(0,n.jsx)(e.li,{children:\\"Streamed events from Wikipedia into Pinot tables via Kafka topics\\"}),(0,n.jsx)(e.li,{children:\\"Run multiple queries\\"}),(0,n.jsx)(e.li,{children:\\"Performed JSON transformations\\"})]}),(0,n.jsxs)(e.p,{children:[\\"In some upcoming blog posts, we will explore more advanced topics, such as indexes and transformations, not to mention real-time anomaly detection with \\",(0,n.jsx)(e.a,{href:\\"https://dev.startree.ai/docs/procedures/get-started-with-thirdeye/\\",children:\\"ThirdEye\\"}),\\".\\"]}),(0,n.jsxs)(e.p,{children:[\\"In the meantime, run more queries, load more data, and don\\\\u2019t forget to \\",(0,n.jsx)(e.a,{href:\\"https://dev.startree.ai/slack-invite\\",children:\\"join the community Slack for support\\"}),\\" if you get stuck or would like to request a topic for me to write about\\\\u2014you know where to find us!\\"]})]})}function v(a={}){let{wrapper:e}=a.components||{};return e?(0,n.jsx)(e,Object.assign({},a,{children:(0,n.jsx)(p,a)})):p(a)}var b=v;return y(I);})();\\n;return Component;"},"_id":"blog/2023-05-30-how-to-ingest-streaming-data-from-kafka-to-apache-pinot.mdx","_raw":{"sourceFilePath":"blog/2023-05-30-how-to-ingest-streaming-data-from-kafka-to-apache-pinot.mdx","sourceFileName":"2023-05-30-how-to-ingest-streaming-data-from-kafka-to-apache-pinot.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2023-05-30-how-to-ingest-streaming-data-from-kafka-to-apache-pinot"},"type":"Blog","readingTime":{"text":"9 min read","minutes":8.935,"time":536100,"words":1787},"slug":"2023/05/30/how-to-ingest-streaming-data-from-kafka-to-apache-pinot","customSlug":"2023/05/30/how-to-ingest-streaming-data-from-kafka-to-apache-pinot","path":"blog/2023/05/30/how-to-ingest-streaming-data-from-kafka-to-apache-pinot","customPath":"blog/2023/05/30/how-to-ingest-streaming-data-from-kafka-to-apache-pinot","filePath":"blog/2023-05-30-how-to-ingest-streaming-data-from-kafka-to-apache-pinot.mdx","toc":[{"value":"The obligatory “What is Apache Pinot and StarTree?” section","url":"#the-obligatory-what-is-apache-pinot-and-startree-section","depth":3},{"value":"How to install Kafka alongside Pinot\xa0","url":"#how-to-install-kafka-alongside-pinot","depth":2},{"value":"Prerequisite","url":"#prerequisite","depth":3},{"value":"Step 1: Install Kafka on your Pinot Docker image","url":"#step-1-install-kafka-on-your-pinot-docker-image","depth":3},{"value":"Step 2: Install Kafka on the Docker container","url":"#step-2-install-kafka-on-the-docker-container","depth":3},{"value":"Step 3: Ingest data into Kafka","url":"#step-3-ingest-data-into-kafka","depth":3},{"value":"Step 4: Connect Kafka to Pinot","url":"#step-4-connect-kafka-to-pinot","depth":3},{"value":"Conclusion","url":"#conclusion","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"How to Ingest Streaming Data from Kafka to Apache Pinot™","datePublished":"2022-05-30T00:00:00.000Z","dateModified":"2022-05-30T00:00:00.000Z","description":"The blog post explains how to use Apache Kafka topics in Apache Pinot to ingest streaming data, with step-by-step instructions provided for installation and setup. It focuses on ingesting Wikipedia events into Kafka and connecting it to Pinot to create a real-time table. The post highlights Pinot\'s capabilities in ingesting and transforming JSON data into OLAP tables and encourages reader engagement through the community Slack.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2023-05-30-how-to-ingest-streaming-data-from-kafka-to-apache-pinot"}},{"title":"Real-Time Mastodon Usage with Apache Kafka, Apache Pinot, and Streamlit","date":"2023-06-01T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","blog post","analyzing user activity","server popularity","Mastodon","Kafka Connect","Parquet","Seaborn","DuckDB","potential","Apache Pinot","realtime data streaming","dashboard","instructions","ingesting","Apache Avro messages","Pinot table","querying data"],"summary":"The blog post discusses analyzing user activity and server popularity on Mastodon using Kafka Connect, Parquet, Seaborn, and DuckDB. It explores the potential of using Apache Pinot for real-time data streaming and creating a dashboard. The post provides instructions on ingesting Apache Avro messages into Pinot, creating a Pinot table, and querying the data.","authors":["needham"],"body":{"raw":"\\nI recently came across a fascinating blog post written by Simon Aubury that shows [how to analyze user activity, server popularity, and language usage on Mastodon](https://simonaubury.com/posts/202302_mastodon_duckdb/), a decentralized social networking platform that has become quite popular in the last six months.\\n\\n## The Existing Solution: Kafka Connect, Parquet, Seaborn and DuckDB\xa0\\n\\nTo start, Simon wrote a listener to collect the messages, which he then published into Apache Kafka\xae. He then wrote a Kafka Connect configuration that consumes messages from Kafka and flushes them after every 1,000 messages into Apache Parquet files stored in an Amazon S3 bucket.\\n\\nFinally, he queried those Parquet files using DuckDB and created some charts using the Seaborn library, as reflected in the architecture diagram below:\\n\\n![Flowchart of data collection to data processing](https://www.datocms-assets.com/75153/1685637607-image1.png \'Flowchart of data collection to data processing\')\\n\\nFig: [Data Collection Architecture](https://simonaubury.com/posts/202302_mastodon_duckdb/)\\n\\nThe awesome visualizations that Simon created make me wonder whether we can change what happens downstream of Kafka to make our queries even more real-time. Let’s find out!\\n\\n## Going Real-Time with Apache Pinot™\\n\\nNow [Apache Pinot](https://startree.ai/resources/what-is-apache-pinot) comes into the picture. Instead of using Kafka Connect to batch Mastodon toots into groups of 1,000 messages to generate Parquet files, we can stream the data immediately and directly, toot-by-toot into Pinot and then build a real-time dashboard using Streamlit:\\n\\n![Data collection in Mastodon, followed by processing in Apache Kafka, Apache Pinot, and Streamlit](https://www.datocms-assets.com/75153/1685637507-image4.png \'Data collection in Mastodon, followed by processing in Apache Kafka, Apache Pinot, and Streamlit\')\\n\\n## Setup\\n\\nTo follow along, first clone my fork of Simon’s GitHub repository:\\n\\n```bash\\ngit clone git@github.com:mneedham/mastodon-stream.git\\ncd mastodon-stream\\n```\\n\\nThen launch all of the components using Docker Compose:\\n\\n```bash\\ndocker-compose up\\n```\\n\\n## Pinot Schema and Table\\n\\nSimilar to what Simon did with DuckDB, we’ll ingest the Mastodon events into a table. Pinot tables have a schema that’s defined in a schema file.\\n\\nTo come up with a schema file, we need to know the structure of the ingested events. For example:\\n\\n```json\\n{\\n    \\"m_id\\": 110146691030544274,\\n    \\"created_at\\": 1680705124,\\n    \\"created_at_str\\": \\"2023 04 05 15:32:04\\",\\n    \\"app\\": \\"\\",\\n    \\"url\\": \\"https://mastodon.social/@Xingcat/110146690810165414\\",\\n    \\"base_url\\": \\"https://techhub.social\\",\\n    \\"language\\": \\"en\\",\\n    \\"favourites\\": 0,\\n    \\"username\\": \\"Xingcat\\",\\n    \\"bot\\": false,\\n    \\"tags\\": 0,\\n    \\"characters\\": 196,\\n    \\"words\\": 36,\\n    \\"mastodon_text\\": \\"Another, “I don’t know what this is yet,” paintings. Many, many layers that look like distressed metal or some sort of rock crosscut. Liking it so far, need to figure out what it’ll wind up being.\\"\\n}\\n```\\n\\nMapping these fields directly to columns is easiest and will result in a schema file that looks like this:\\n\\n```json\\n{\\n    \\"schemaName\\": \\"mastodon\\",\\n    \\"dimensionFieldSpecs\\": [\\n        { \\"name\\": \\"m_id\\", \\"dataType\\": \\"LONG\\" },\\n        { \\"name\\": \\"created_at_str\\", \\"dataType\\": \\"STRING\\" },\\n        { \\"name\\": \\"app\\", \\"dataType\\": \\"STRING\\" },\\n        { \\"name\\": \\"url\\", \\"dataType\\": \\"STRING\\" },\\n        { \\"name\\": \\"base_url\\", \\"dataType\\": \\"STRING\\" },\\n        { \\"name\\": \\"language\\", \\"dataType\\": \\"STRING\\" },\\n        { \\"name\\": \\"username\\", \\"dataType\\": \\"STRING\\" },\\n        { \\"name\\": \\"bot\\", \\"dataType\\": \\"BOOLEAN\\" },\\n        { \\"name\\": \\"mastodon_text\\", \\"dataType\\": \\"STRING\\" }\\n    ],\\n    \\"metricFieldSpecs\\": [\\n        { \\"name\\": \\"favourites\\", \\"dataType\\": \\"INT\\" },\\n        { \\"name\\": \\"words\\", \\"dataType\\": \\"INT\\" },\\n        { \\"name\\": \\"characters\\", \\"dataType\\": \\"INT\\" },\\n        { \\"name\\": \\"tags\\", \\"dataType\\": \\"INT\\" }\\n    ],\\n    \\"dateTimeFieldSpecs\\": [\\n        {\\n            \\"name\\": \\"created_at\\",\\n            \\"dataType\\": \\"LONG\\",\\n            \\"format\\": \\"1:MILLISECONDS:EPOCH\\",\\n            \\"granularity\\": \\"1:MILLISECONDS\\"\\n        }\\n    ]\\n}\\n```\\n\\nNext up: our table config, shown below:\\n\\n```json\\n{\\n    \\"tableName\\": \\"mastodon\\",\\n    \\"tableType\\": \\"REALTIME\\",\\n    \\"segmentsConfig\\": {\\n        \\"timeColumnName\\": \\"created_at\\",\\n        \\"timeType\\": \\"MILLISECONDS\\",\\n        \\"schemaName\\": \\"mastodon\\",\\n        \\"replicasPerPartition\\": \\"1\\"\\n    },\\n    \\"tenants\\": {},\\n    \\"tableIndexConfig\\": {\\n        \\"loadMode\\": \\"MMAP\\",\\n        \\"streamConfigs\\": {\\n            \\"streamType\\": \\"kafka\\",\\n            \\"stream.kafka.consumer.type\\": \\"lowLevel\\",\\n            \\"stream.kafka.topic.name\\": \\"mastodon-topic\\",\\n            \\"stream.kafka.decoder.class.name\\": \\"org.apache.pinot.plugin.inputformat.avro.confluent.KafkaConfluentSchemaRegistryAvroMessageDecoder\\",\\n            \\"stream.kafka.consumer.factory.class.name\\": \\"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\\",\\n            \\"stream.kafka.decoder.prop.format\\": \\"AVRO\\",\\n            \\"stream.kafka.decoder.prop.schema.registry.rest.url\\": \\"http://schema-registry:8081\\",\\n            \\"stream.kafka.decoder.prop.schema.registry.schema.name\\": \\"mastodon-topic-value\\",\\n            \\"stream.kafka.broker.list\\": \\"broker:9093\\",\\n            \\"stream.kafka.consumer.prop.auto.offset.reset\\": \\"smallest\\"\\n        }\\n    },\\n    \\"metadata\\": {\\n        \\"customConfigs\\": {}\\n    },\\n    \\"routing\\": {\\n        \\"instanceSelectorType\\": \\"strictReplicaGroup\\"\\n    }\\n}\\n```\\n\\nThe following configs represent the most important ones for ingesting Apache Avro™ messages into Pinot:\\n\\n```json\\n\\"stream.kafka.decoder.class.name\\": \\"org.apache.pinot.plugin.inputformat.avro.confluent.KafkaConfluentSchemaRegistryAvroMessageDecoder\\",\\n\\"stream.kafka.decoder.prop.format\\": \\"AVRO\\",\\n\\"stream.kafka.decoder.prop.schema.registry.rest.url\\": \\"http://schema-registry:8081\\",\\n\\"stream.kafka.decoder.prop.schema.registry.schema.name\\": \\"mastodon-topic-value\\",\\n```\\n\\nThe KafkaConfluentSchemaRegistryAvroMessageDecoder decoder calls the Schema Registry with the schema name to get back the schema that it will use to decode messages.\\n\\nWe can create the Pinot table by running the following command:\\n\\n```bash\\ndocker run \\\\\\n   --network mastodon \\\\\\n   -v $PWD/pinot:/config \\\\\\n   apachepinot/pinot:0.12.0-arm64 AddTable \\\\\\n     -schemaFile /config/schema.json \\\\\\n     -tableConfigFile /config/table.json \\\\\\n     -controllerHost \\"pinot-controller\\" \\\\\\n    -exec\\n```\\n\\nWe can then navigate to the table page of the Pinot UI:\\n\\n[http://localhost:9000/#/tenants/table/mastodon_REALTIME](http://localhost:9000/#/tenants/table/mastodon_REALTIME)\\n\\nHere, we’ll see the following:\\n\\n![Apache Pinot table config and schema](https://www.datocms-assets.com/75153/1685637837-image6.png \'Apache Pinot table config and schema\')\\n\\n## Ingest Data into Kafka\\n\\nNow, we need to start ingesting data into Kafka. Simon created a script that accomplishes this for us, so we just need to indicate which Mastodon servers to query.\\n\\n```bash\\npython mastodonlisten.py --baseURL https://data-folks.masto.host \\\\\\n  --public --enableKafka --quiet\\npython mastodonlisten.py --baseURL https://fosstodon.org/ \\\\\\n  --public --enableKafka --quiet\\npython mastodonlisten.py --baseURL https://mstdn.social/ \\\\\\n  --public --enableKafka --quiet\\n```\\n\\nWe can then check the ingestion of messages with the [kcat](https://docs.confluent.io/platform/current/clients/kafkacat-usage.html) command line tool:\\n\\n```bash\\nkcat -C -b localhost:9092 -t mastodon-topic \\\\\\n  -s value=avro -r http://localhost:8081 -e\\n```\\n\\n## Query Pinot\\n\\nNow, let’s go to the Pinot UI to see what data we’ve got to play with:\\n\\n[http://localhost:9000](http://localhost:9000/)\\n\\nWe’ll see the following preview of the data in the mastodon table:\\n\\n![SQL Editor, query response stats, and query result in Apache Pinot](https://www.datocms-assets.com/75153/1685637772-image5.png \'SQL Editor, query response stats, and query result in Apache Pinot\')\\n\\nWe can then write a query to find the number of messages posted in the last five minutes:\\n\\n```sql\\nselect count(*) as \\"Num toots\\"\\n, count(distinct(username)) as \\"Num users\\"\\n, count(distinct(url)) as \\"Num urls\\"\\nfrom mastodon\\nwhere created_at*1000 > ago(\'PT1M\')\\norder by 1 DESC;\\n```\\n\\n![Query results for toots, users, and urls](https://www.datocms-assets.com/75153/1685637909-image8.png \'Query results for toots, users, and urls\')\\n\\nWe can also query Pinot via the Python client, which we can install by running the following:\\n\\n```bash\\npip install pinotdb\\n```\\n\\nOnce we’ve done that, let’s open the Python REPL and run the following code:\\n\\n```python\\nfrom pinotdb import connect\\nimport pandas as pd\\n\\nconn = connect(host=\'localhost\', port=8099, path=\'/query/sql\', scheme=\'http\')\\n\\ncurs = conn.cursor()\\n\\nst.header(\\"Daily Mastodon Usage\\")\\nquery = \\"\\"\\"\\nselect count(*) as \\"Num toots\\"\\n, count(distinct(username)) as \\"Num users\\"\\n, count(distinct(url)) as \\"Num urls\\"\\nfrom mastodon\\nwhere created_at*1000 > ago(\'PT1M\')\\norder by 1 DESC;\\n\\"\\"\\"\\ncurs.execute(query)\\n\\ndf = pd.DataFrame(curs, columns=[item[0] for item in curs.description])\\n```\\n\\nThis produces the resulting DataFrame:\\n\\n```\\n   Num toots  Num users  Num urls\\n0        552        173       192\\n```\\n\\n## Streamlit\\n\\nNext, we’ll create a Streamlit dashboard to package up these queries. We’ll visualize the results using Plotly, which you can install using:\\n\\npip install streamlit plotly\\n\\nI’ve created a Streamlit app in the file [app.py](https://github.com/mneedham/mastodon-stream/blob/main/app.py), which you can find in the GitHub repository. Let’s have a look at the kinds of visualizations that we can generate.\\n\\nFirst, we’ll create metrics to show the number of toots, users, and URLs in the last _n_ minutes. _n_ will be configurable from the app as shown in the screenshot below:\\n\\n![Chart of real-time Mastodon usage](https://www.datocms-assets.com/75153/1685637876-image7.png \'Chart of real-time Mastodon usage\')\\n\\nFrom the screenshot, we can identify mastodon.cloud as the most active server, though it produces only 1,800 messages in 10 minutes or three messages per second. The values in green indicate the change in values compared to the previous 10 minutes.\\n\\nWe can also create a chart showing the number of messages per minute for the last 10 minutes:\\n\\n![Time of day Mastodon usage](https://www.datocms-assets.com/75153/1685637945-image9.png \'Time of day Mastodon usage\')\\n\\nBased on this chart, we can see that we’re creating anywhere from 200–900 messages per second. Part of the reason lies in the fact that the Mastodon servers sometimes disconnect our listener, and at the moment, I have to manually reconnect.\\n\\nFinally, we can look at the toot length by language:\\n\\n![Chart of toot length by language usage](https://www.datocms-assets.com/75153/1685637644-image2.png \'Chart of toot length by language usage\')\\n\\nWe see much bigger ranges here than Simon saw in his analysis. He saw a maximum length of 200 characters, whereas we see some messages of up to 4,200 characters.\\n\\n## Summary\\n\\nWe hope you enjoyed following along as we explored this fun use case for [real-time analytics](https://startree.ai/resources/what-is-real-time-analytics). As you can see, even though we’re pulling the data from many of the popular Mastodon servers, it’s still not all that much data!\\n\\nGive the code a try and let us know how it goes. If you have any questions, feel free to [join us on Slack](https://stree.ai/slack), where we’ll gladly do our best to help you out.\\n","code":"var Component=(()=>{var d=Object.create;var t=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var N=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var k=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),g=(n,e)=>{for(var s in e)t(n,s,{get:e[s],enumerable:!0})},o=(n,e,s,l)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let c of m(e))!u.call(n,c)&&c!==s&&t(n,c,{get:()=>e[c],enumerable:!(l=h(e,c))||l.enumerable});return n};var y=(n,e,s)=>(s=n!=null?d(N(n)):{},o(e||!n||!n.__esModule?t(s,\\"default\\",{value:n,enumerable:!0}):s,n)),f=n=>o(t({},\\"__esModule\\",{value:!0}),n);var i=k((P,r)=>{r.exports=_jsx_runtime});var T={};g(T,{default:()=>v,frontmatter:()=>b});var a=y(i()),b={title:\\"Real-Time Mastodon Usage with Apache Kafka, Apache Pinot, and Streamlit\\",date:new Date(16855776e5),authors:[\\"needham\\"],summary:\\"The blog post discusses analyzing user activity and server popularity on Mastodon using Kafka Connect, Parquet, Seaborn, and DuckDB. It explores the potential of using Apache Pinot for real-time data streaming and creating a dashboard. The post provides instructions on ingesting Apache Avro messages into Pinot, creating a Pinot table, and querying the data.\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"blog post\\",\\"analyzing user activity\\",\\"server popularity\\",\\"Mastodon\\",\\"Kafka Connect\\",\\"Parquet\\",\\"Seaborn\\",\\"DuckDB\\",\\"potential\\",\\"Apache Pinot\\",\\"realtime data streaming\\",\\"dashboard\\",\\"instructions\\",\\"ingesting\\",\\"Apache Avro messages\\",\\"Pinot table\\",\\"querying data\\"]};function p(n){let e=Object.assign({p:\\"p\\",a:\\"a\\",h2:\\"h2\\",span:\\"span\\",img:\\"img\\",pre:\\"pre\\",code:\\"code\\",em:\\"em\\"},n.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(e.p,{children:[\\"I recently came across a fascinating blog post written by Simon Aubury that shows \\",(0,a.jsx)(e.a,{href:\\"https://simonaubury.com/posts/202302_mastodon_duckdb/\\",children:\\"how to analyze user activity, server popularity, and language usage on Mastodon\\"}),\\", a decentralized social networking platform that has become quite popular in the last six months.\\"]}),(0,a.jsxs)(e.h2,{id:\\"the-existing-solution-kafka-connect-parquet-seaborn-and-duckdb\\",children:[(0,a.jsx)(e.a,{href:\\"#the-existing-solution-kafka-connect-parquet-seaborn-and-duckdb\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"The Existing Solution: Kafka Connect, Parquet, Seaborn and DuckDB\\\\xA0\\"]}),(0,a.jsx)(e.p,{children:\\"To start, Simon wrote a listener to collect the messages, which he then published into Apache Kafka\\\\xAE. He then wrote a Kafka Connect configuration that consumes messages from Kafka and flushes them after every 1,000 messages into Apache Parquet files stored in an Amazon S3 bucket.\\"}),(0,a.jsx)(e.p,{children:\\"Finally, he queried those Parquet files using DuckDB and created some charts using the Seaborn library, as reflected in the architecture diagram below:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Flowchart of data collection to data processing\\",src:\\"https://www.datocms-assets.com/75153/1685637607-image1.png\\",title:\\"Flowchart of data collection to data processing\\"})}),(0,a.jsxs)(e.p,{children:[\\"Fig: \\",(0,a.jsx)(e.a,{href:\\"https://simonaubury.com/posts/202302_mastodon_duckdb/\\",children:\\"Data Collection Architecture\\"})]}),(0,a.jsx)(e.p,{children:\\"The awesome visualizations that Simon created make me wonder whether we can change what happens downstream of Kafka to make our queries even more real-time. Let\\\\u2019s find out!\\"}),(0,a.jsxs)(e.h2,{id:\\"going-real-time-with-apache-pinot\\",children:[(0,a.jsx)(e.a,{href:\\"#going-real-time-with-apache-pinot\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Going Real-Time with Apache Pinot\\\\u2122\\"]}),(0,a.jsxs)(e.p,{children:[\\"Now \\",(0,a.jsx)(e.a,{href:\\"https://startree.ai/resources/what-is-apache-pinot\\",children:\\"Apache Pinot\\"}),\\" comes into the picture. Instead of using Kafka Connect to batch Mastodon toots into groups of 1,000 messages to generate Parquet files, we can stream the data immediately and directly, toot-by-toot into Pinot and then build a real-time dashboard using Streamlit:\\"]}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Data collection in Mastodon, followed by processing in Apache Kafka, Apache Pinot, and Streamlit\\",src:\\"https://www.datocms-assets.com/75153/1685637507-image4.png\\",title:\\"Data collection in Mastodon, followed by processing in Apache Kafka, Apache Pinot, and Streamlit\\"})}),(0,a.jsxs)(e.h2,{id:\\"setup\\",children:[(0,a.jsx)(e.a,{href:\\"#setup\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Setup\\"]}),(0,a.jsx)(e.p,{children:\\"To follow along, first clone my fork of Simon\\\\u2019s GitHub repository:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"git\\"}),` clone git@github.com:mneedham/mastodon-stream.git\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token builtin class-name\\",children:\\"cd\\"}),` mastodon-stream\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"Then launch all of the components using Docker Compose:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsx)(e.code,{className:\\"code-highlight language-bash\\",children:(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"docker-compose\\"}),` up\\n`]})})}),(0,a.jsxs)(e.h2,{id:\\"pinot-schema-and-table\\",children:[(0,a.jsx)(e.a,{href:\\"#pinot-schema-and-table\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Pinot Schema and Table\\"]}),(0,a.jsx)(e.p,{children:\\"Similar to what Simon did with DuckDB, we\\\\u2019ll ingest the Mastodon events into a table. Pinot tables have a schema that\\\\u2019s defined in a schema file.\\"}),(0,a.jsx)(e.p,{children:\\"To come up with a schema file, we need to know the structure of the ingested events. For example:\\"}),(0,a.jsx)(e.pre,{className:\\"language-json\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"m_id\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"110146691030544274\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"created_at\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"1680705124\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"created_at_str\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"2023 04 05 15:32:04\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"app\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"url\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"https://mastodon.social/@Xingcat/110146690810165414\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"base_url\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"https://techhub.social\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"language\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"en\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"favourites\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"0\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"username\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"Xingcat\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"bot\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token boolean\\",children:\\"false\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"tags\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"0\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"characters\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"196\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"words\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"36\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"mastodon_text\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"Another, \\\\u201CI don\\\\u2019t know what this is yet,\\\\u201D paintings. Many, many layers that look like distressed metal or some sort of rock crosscut. Liking it so far, need to figure out what it\\\\u2019ll wind up being.\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"Mapping these fields directly to columns is easiest and will result in a schema file that looks like this:\\"}),(0,a.jsx)(e.pre,{className:\\"language-json\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"mastodon\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dimensionFieldSpecs\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"m_id\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"LONG\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"created_at_str\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"app\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"url\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"base_url\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"language\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"username\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"bot\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"BOOLEAN\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"mastodon_text\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"STRING\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"metricFieldSpecs\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"favourites\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"INT\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"words\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"INT\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"characters\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"INT\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"tags\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"INT\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dateTimeFieldSpecs\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"created_at\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"dataType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"LONG\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"format\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS:EPOCH\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"granularity\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"1:MILLISECONDS\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"Next up: our table config, shown below:\\"}),(0,a.jsx)(e.pre,{className:\\"language-json\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableName\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"mastodon\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"REALTIME\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"segmentsConfig\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"timeColumnName\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"created_at\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"timeType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"MILLISECONDS\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"schemaName\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"mastodon\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"replicasPerPartition\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"1\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"tenants\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableIndexConfig\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"loadMode\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"MMAP\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"streamConfigs\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"streamType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"kafka\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.type\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"lowLevel\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.topic.name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"mastodon-topic\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.class.name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.inputformat.avro.confluent.KafkaConfluentSchemaRegistryAvroMessageDecoder\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.factory.class.name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.prop.format\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"AVRO\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.prop.schema.registry.rest.url\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"http://schema-registry:8081\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.prop.schema.registry.schema.name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"mastodon-topic-value\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.broker.list\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"broker:9093\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.consumer.prop.auto.offset.reset\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"smallest\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"metadata\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"customConfigs\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"routing\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"instanceSelectorType\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"strictReplicaGroup\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"The following configs represent the most important ones for ingesting Apache Avro\\\\u2122 messages into Pinot:\\"}),(0,a.jsx)(e.pre,{className:\\"language-json\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.class.name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.inputformat.avro.confluent.KafkaConfluentSchemaRegistryAvroMessageDecoder\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.prop.format\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"AVRO\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.prop.schema.registry.rest.url\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"http://schema-registry:8081\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.prop.schema.registry.schema.name\\"\'}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"mastodon-topic-value\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"The KafkaConfluentSchemaRegistryAvroMessageDecoder decoder calls the Schema Registry with the schema name to get back the schema that it will use to decode messages.\\"}),(0,a.jsx)(e.p,{children:\\"We can create the Pinot table by running the following command:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"docker\\"}),\\" run \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--network\\"}),\\" mastodon \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-v\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token constant environment\\",children:\\"$PWD\\"}),\\"/pinot:/config \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   apachepinot/pinot:0.12.0-arm64 AddTable \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-schemaFile\\"}),\\" /config/schema.json \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-tableConfigFile\\"}),\\" /config/table.json \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"     \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-controllerHost\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"pinot-controller\\"\'}),\\" \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-exec\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"We can then navigate to the table page of the Pinot UI:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.a,{href:\\"http://localhost:9000/#/tenants/table/mastodon_REALTIME\\",children:\\"http://localhost:9000/#/tenants/table/mastodon_REALTIME\\"})}),(0,a.jsx)(e.p,{children:\\"Here, we\\\\u2019ll see the following:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Apache Pinot table config and schema\\",src:\\"https://www.datocms-assets.com/75153/1685637837-image6.png\\",title:\\"Apache Pinot table config and schema\\"})}),(0,a.jsxs)(e.h2,{id:\\"ingest-data-into-kafka\\",children:[(0,a.jsx)(e.a,{href:\\"#ingest-data-into-kafka\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Ingest Data into Kafka\\"]}),(0,a.jsx)(e.p,{children:\\"Now, we need to start ingesting data into Kafka. Simon created a script that accomplishes this for us, so we just need to indicate which Mastodon servers to query.\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"python mastodonlisten.py \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--baseURL\\"}),\\" https://data-folks.masto.host \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--public\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--enableKafka\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--quiet\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"python mastodonlisten.py \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--baseURL\\"}),\\" https://fosstodon.org/ \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--public\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--enableKafka\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--quiet\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"python mastodonlisten.py \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--baseURL\\"}),\\" https://mstdn.social/ \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--public\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--enableKafka\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"--quiet\\"}),`\\n`]})]})}),(0,a.jsxs)(e.p,{children:[\\"We can then check the ingestion of messages with the \\",(0,a.jsx)(e.a,{href:\\"https://docs.confluent.io/platform/current/clients/kafkacat-usage.html\\",children:\\"kcat\\"}),\\" command line tool:\\"]}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-bash\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"kcat \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-C\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-b\\"}),\\" localhost:9092 \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-t\\"}),\\" mastodon-topic \\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"\\\\\\\\\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-s\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token variable assign-left\\",children:\\"value\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\"avro \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-r\\"}),\\" http://localhost:8081 \\",(0,a.jsx)(e.span,{className:\\"token variable parameter\\",children:\\"-e\\"}),`\\n`]})]})}),(0,a.jsxs)(e.h2,{id:\\"query-pinot\\",children:[(0,a.jsx)(e.a,{href:\\"#query-pinot\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Query Pinot\\"]}),(0,a.jsx)(e.p,{children:\\"Now, let\\\\u2019s go to the Pinot UI to see what data we\\\\u2019ve got to play with:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.a,{href:\\"http://localhost:9000/\\",children:\\"http://localhost:9000\\"})}),(0,a.jsx)(e.p,{children:\\"We\\\\u2019ll see the following preview of the data in the mastodon table:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"SQL Editor, query response stats, and query result in Apache Pinot\\",src:\\"https://www.datocms-assets.com/75153/1685637772-image5.png\\",title:\\"SQL Editor, query response stats, and query result in Apache Pinot\\"})}),(0,a.jsx)(e.p,{children:\\"We can then write a query to find the number of messages posted in the last five minutes:\\"}),(0,a.jsx)(e.pre,{className:\\"language-sql\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-sql\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"Num toots\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"distinct\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"username\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"Num users\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"distinct\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"url\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"as\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"Num urls\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),` mastodon\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"where\\"}),\\" created_at\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"*\\"}),(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"1000\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\">\\"}),\\" ago\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\\"\'PT1M\'\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"order\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"by\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"1\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"DESC\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\";\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Query results for toots, users, and urls\\",src:\\"https://www.datocms-assets.com/75153/1685637909-image8.png\\",title:\\"Query results for toots, users, and urls\\"})}),(0,a.jsx)(e.p,{children:\\"We can also query Pinot via the Python client, which we can install by running the following:\\"}),(0,a.jsx)(e.pre,{className:\\"language-bash\\",children:(0,a.jsx)(e.code,{className:\\"code-highlight language-bash\\",children:(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"pip \\",(0,a.jsx)(e.span,{className:\\"token function\\",children:\\"install\\"}),` pinotdb\\n`]})})}),(0,a.jsx)(e.p,{children:\\"Once we\\\\u2019ve done that, let\\\\u2019s open the Python REPL and run the following code:\\"}),(0,a.jsx)(e.pre,{className:\\"language-python\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-python\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),\\" pinotdb \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"import\\"}),` connect\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"import\\"}),\\" pandas \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"as\\"}),` pd\\n`]}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"conn \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" connect\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"host\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\\"\'localhost\'\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" port\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"8099\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" path\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\\"\'/query/sql\'\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" scheme\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\\"\'http\'\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"curs \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" conn\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"cursor\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"st\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"header\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,a.jsx)(e.span,{className:\\"token string\\",children:\'\\"Daily Mastodon Usage\\"\'}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"query \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token string triple-quoted-string\\",children:`\\"\\"\\"\\n`})]}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:(0,a.jsx)(e.span,{className:\\"token string triple-quoted-string\\",children:`select count(*) as \\"Num toots\\"\\n`})}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:(0,a.jsx)(e.span,{className:\\"token string triple-quoted-string\\",children:`, count(distinct(username)) as \\"Num users\\"\\n`})}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:(0,a.jsx)(e.span,{className:\\"token string triple-quoted-string\\",children:`, count(distinct(url)) as \\"Num urls\\"\\n`})}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:(0,a.jsx)(e.span,{className:\\"token string triple-quoted-string\\",children:`from mastodon\\n`})}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:(0,a.jsx)(e.span,{className:\\"token string triple-quoted-string\\",children:`where created_at*1000 > ago(\'PT1M\')\\n`})}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:(0,a.jsx)(e.span,{className:\\"token string triple-quoted-string\\",children:`order by 1 DESC;\\n`})}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token string triple-quoted-string\\",children:\'\\"\\"\\"\'}),`\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"curs\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"execute\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"query\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,a.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"df \\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" pd\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"DataFrame\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"curs\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" columns\\",(0,a.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),\\"item\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"[\\"}),(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"0\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),\\" \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"for\\"}),\\" item \\",(0,a.jsx)(e.span,{className:\\"token keyword\\",children:\\"in\\"}),\\" curs\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"description\\",(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\"]\\"}),(0,a.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]})]})}),(0,a.jsx)(e.p,{children:\\"This produces the resulting DataFrame:\\"}),(0,a.jsx)(e.pre,{className:\\"language-js\\",children:(0,a.jsxs)(e.code,{className:\\"code-highlight language-js\\",children:[(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[\\"   \\",(0,a.jsx)(e.span,{className:\\"token maybe-class-name\\",children:\\"Num\\"}),\\" toots  \\",(0,a.jsx)(e.span,{className:\\"token maybe-class-name\\",children:\\"Num\\"}),\\" users  \\",(0,a.jsx)(e.span,{className:\\"token maybe-class-name\\",children:\\"Num\\"}),` urls\\n`]}),(0,a.jsxs)(e.span,{className:\\"code-line\\",children:[(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"0\\"}),\\"        \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"552\\"}),\\"        \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"173\\"}),\\"       \\",(0,a.jsx)(e.span,{className:\\"token number\\",children:\\"192\\"}),`\\n`]})]})}),(0,a.jsxs)(e.h2,{id:\\"streamlit\\",children:[(0,a.jsx)(e.a,{href:\\"#streamlit\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Streamlit\\"]}),(0,a.jsx)(e.p,{children:\\"Next, we\\\\u2019ll create a Streamlit dashboard to package up these queries. We\\\\u2019ll visualize the results using Plotly, which you can install using:\\"}),(0,a.jsx)(e.p,{children:\\"pip install streamlit plotly\\"}),(0,a.jsxs)(e.p,{children:[\\"I\\\\u2019ve created a Streamlit app in the file \\",(0,a.jsx)(e.a,{href:\\"https://github.com/mneedham/mastodon-stream/blob/main/app.py\\",children:\\"app.py\\"}),\\", which you can find in the GitHub repository. Let\\\\u2019s have a look at the kinds of visualizations that we can generate.\\"]}),(0,a.jsxs)(e.p,{children:[\\"First, we\\\\u2019ll create metrics to show the number of toots, users, and URLs in the last \\",(0,a.jsx)(e.em,{children:\\"n\\"}),\\" minutes. \\",(0,a.jsx)(e.em,{children:\\"n\\"}),\\" will be configurable from the app as shown in the screenshot below:\\"]}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Chart of real-time Mastodon usage\\",src:\\"https://www.datocms-assets.com/75153/1685637876-image7.png\\",title:\\"Chart of real-time Mastodon usage\\"})}),(0,a.jsx)(e.p,{children:\\"From the screenshot, we can identify mastodon.cloud as the most active server, though it produces only 1,800 messages in 10 minutes or three messages per second. The values in green indicate the change in values compared to the previous 10 minutes.\\"}),(0,a.jsx)(e.p,{children:\\"We can also create a chart showing the number of messages per minute for the last 10 minutes:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Time of day Mastodon usage\\",src:\\"https://www.datocms-assets.com/75153/1685637945-image9.png\\",title:\\"Time of day Mastodon usage\\"})}),(0,a.jsx)(e.p,{children:\\"Based on this chart, we can see that we\\\\u2019re creating anywhere from 200\\\\u2013900 messages per second. Part of the reason lies in the fact that the Mastodon servers sometimes disconnect our listener, and at the moment, I have to manually reconnect.\\"}),(0,a.jsx)(e.p,{children:\\"Finally, we can look at the toot length by language:\\"}),(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{alt:\\"Chart of toot length by language usage\\",src:\\"https://www.datocms-assets.com/75153/1685637644-image2.png\\",title:\\"Chart of toot length by language usage\\"})}),(0,a.jsx)(e.p,{children:\\"We see much bigger ranges here than Simon saw in his analysis. He saw a maximum length of 200 characters, whereas we see some messages of up to 4,200 characters.\\"}),(0,a.jsxs)(e.h2,{id:\\"summary\\",children:[(0,a.jsx)(e.a,{href:\\"#summary\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,a.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),(0,a.jsxs)(e.p,{children:[\\"We hope you enjoyed following along as we explored this fun use case for \\",(0,a.jsx)(e.a,{href:\\"https://startree.ai/resources/what-is-real-time-analytics\\",children:\\"real-time analytics\\"}),\\". As you can see, even though we\\\\u2019re pulling the data from many of the popular Mastodon servers, it\\\\u2019s still not all that much data!\\"]}),(0,a.jsxs)(e.p,{children:[\\"Give the code a try and let us know how it goes. If you have any questions, feel free to \\",(0,a.jsx)(e.a,{href:\\"https://stree.ai/slack\\",children:\\"join us on Slack\\"}),\\", where we\\\\u2019ll gladly do our best to help you out.\\"]})]})}function w(n={}){let{wrapper:e}=n.components||{};return e?(0,a.jsx)(e,Object.assign({},n,{children:(0,a.jsx)(p,n)})):p(n)}var v=w;return f(T);})();\\n;return Component;"},"_id":"blog/2023-06-01-real-time-mastodon-usage-with-apache-kafka-apache-pinot-and-streamlit.mdx","_raw":{"sourceFilePath":"blog/2023-06-01-real-time-mastodon-usage-with-apache-kafka-apache-pinot-and-streamlit.mdx","sourceFileName":"2023-06-01-real-time-mastodon-usage-with-apache-kafka-apache-pinot-and-streamlit.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2023-06-01-real-time-mastodon-usage-with-apache-kafka-apache-pinot-and-streamlit"},"type":"Blog","readingTime":{"text":"7 min read","minutes":6.755,"time":405300,"words":1351},"slug":"2023/06/01/real-time-mastodon-usage-with-apache-kafka-apache-pinot-and-streamlit","customSlug":"2023/06/01/real-time-mastodon-usage-with-apache-kafka-apache-pinot-and-streamlit","path":"blog/2023/06/01/real-time-mastodon-usage-with-apache-kafka-apache-pinot-and-streamlit","customPath":"blog/2023/06/01/real-time-mastodon-usage-with-apache-kafka-apache-pinot-and-streamlit","filePath":"blog/2023-06-01-real-time-mastodon-usage-with-apache-kafka-apache-pinot-and-streamlit.mdx","toc":[{"value":"The Existing Solution: Kafka Connect, Parquet, Seaborn and DuckDB\xa0","url":"#the-existing-solution-kafka-connect-parquet-seaborn-and-duckdb","depth":2},{"value":"Going Real-Time with Apache Pinot™","url":"#going-real-time-with-apache-pinot","depth":2},{"value":"Setup","url":"#setup","depth":2},{"value":"Pinot Schema and Table","url":"#pinot-schema-and-table","depth":2},{"value":"Ingest Data into Kafka","url":"#ingest-data-into-kafka","depth":2},{"value":"Query Pinot","url":"#query-pinot","depth":2},{"value":"Streamlit","url":"#streamlit","depth":2},{"value":"Summary","url":"#summary","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Real-Time Mastodon Usage with Apache Kafka, Apache Pinot, and Streamlit","datePublished":"2023-06-01T00:00:00.000Z","dateModified":"2023-06-01T00:00:00.000Z","description":"The blog post discusses analyzing user activity and server popularity on Mastodon using Kafka Connect, Parquet, Seaborn, and DuckDB. It explores the potential of using Apache Pinot for real-time data streaming and creating a dashboard. The post provides instructions on ingesting Apache Avro messages into Pinot, creating a Pinot table, and querying the data.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2023-06-01-real-time-mastodon-usage-with-apache-kafka-apache-pinot-and-streamlit"}},{"title":"Star-Tree Index in Apache Pinot - Part 3 - Understanding the Impact in Real Customer Scenarios","date":"2023-07-12T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","blog post","implementing","startree index","query performance","AdTech platform","reducing latency","cybersecurity threat detection","multiplayer game leaderboard tracking","improved query performance","cost savings","real production use cases","StarTree Cloud","realtime analytics","95% to 99% improvement"],"summary":"The blog post discusses how implementing a star-tree index significantly improved query performance for an AdTech platform by reducing latency. This index has also been successful in cybersecurity threat detection and multiplayer game leaderboard tracking, resulting in improved query performance and cost savings. Real production use cases showed a 95% to 99% improvement in query performance using StarTree Cloud for real-time analytics.","authors":["dabade","nijjer"],"body":{"raw":"\\nIn [part 1 of this blog series](https://startree.ai/blog/star-tree-indexes-in-apache-pinot-part-1-understanding-the-impact-on-query-performance), we looked at how a star-tree index brought down standalone query latency on a sizable dataset of ~633M records from 1,513ms to 4ms! — nearly 380x faster.\\n\\nIn [part 2 of this blog series](https://startree.ai/blog/star-tree-indexes-in-apache-pinot-part-2-understanding-the-impact-during-high-concurrency), we imitated a real production scenario by firing hundreds of concurrent queries using JMeter and showcased how using a star-tree index helped achieve a >95% drop in p90th / p95th / p99th latencies and 126x increase in Throughput.\\n\\nIn this part, we will cover some real customer stories that have seen 95% to 99% improvement in query performance using Star-Tree Index.\\n\\n## AdTech Use Case\\n\\nThis was for a leading AdTech platform and a somewhat typical use case; users of the platform (advertisers, publishers, and influencers) wanted to see fresh metrics on how their activities (such as online content, ad, and email campaigns) were performing in real-time so they could tweak things as needed. The application team wanted to provide a rich analytical interface to these users so that not only can they see the current performance but also do custom slicing and dicing of data over a period of time. For example, compare their current campaign performance to one they ran two weeks back, do cohort analysis, and so on.\\n\\n### Why was the existing system not working?\\n\\nTheir existing tech stack was a mix of OSS and custom-built in-house code, which was both operationally difficult to manage and costly to maintain. Yet more importantly, it wasn’t able to meet the basic throughput and latency requirements required by the platform to sustain user growth as well as provide richer analytic capabilities in the product.\\n\\n### The Problem and Challenges?\\n\\nWhen the StarTree Sales Engineering team was engaged, the requirements were very clear:\\n\\n-   Throughput: Support 50+ QPS during POC and 200+ for production)\\n-   Latency: P95th latency of 2s, including query that needed aggregation of ~ 2 billion rows\\n-   Scalability: Ability to scale efficiently with future growth in QPS in a non-linear manner\\n\\nThe biggest challenge was the size of data — 20+ TB and growing — and on top of that, a complex aggregation query driving the summary view for users so they can drill further in to get more details.\\n\\nThis particular query needed to aggregate close to 2 Billion records at read time and then would be fired for every active user interacting with the platform (so high concurrent QPS). In this case, despite applying all relevant indexes available in their existing system, out-of-the-box query performance was still in the 6-8 seconds range, which is expected given that bulk of the work for the query is happening in the aggregation phase and not during the filtering phase (indexing helps with this).\\n\\nIn other OLAP systems they explored, the only option available to handle this use case was doing ingestion time rollups. In other words, changing the data to higher granularity. However, this obviously means losing access to raw data and also potentially re-bootstrapping if new use cases come down the road that need raw data access.\\n\\nThis is exactly the type of scenario that the [Star-Tree Index](https://docs.pinot.apache.org/basics/indexing/star-tree-index), unique to Apache Pinot, is designed to address - handle large aggregation queries at scale that need sub-second performance. The best part is you can apply it anytime without any need to reprocess the data or plan any system downtime. (Segment reload to apply table config changes run as a background task in Apache Pinot.) In this specific case, the same query latencies with the star-tree index applied went down to 15 ms. This implicitly meant that with the same infrastructure footprint, StarTree was able to support ~70 QPS (Queries Per Second) vs < 1 QPS for this most complex query; while still keeping the raw data intact.\\n\\n### Data Size and Infra Footprint for the Pilot:\xa0\\n\\n-   Total # of records: ~2 Trillion\\n-   Data Size: ~20 TB\\n-   Capacity: 72 vCPUs across 9 Pinot servers (8 vCPU, 64GB per node).\\n\\n### Impact Summary:\\n\\n-   99.76% reduction in latency vs. no Star-Tree Index (6.3 seconds to 15 ms)\\n-   99.99999% reduction in amount of data scanned/aggregated per query (> 1.8B docs to < 2,400)\\n\\n![Visualization of the impact of start-tree index for an AdTech use case with Apache Pinot](https://www.datocms-assets.com/75153/1689174701-image1.png)\\n\\n## CyberSecurity Use Case:\\n\\nA cybersecurity company that provides their customers with a real-time threat detection platform with AI, allowing them to analyze network flow logs in real-time with a sophisticated reporting/analytical UI. The initial landing page inside the customer portal is a summary view of everything the platform was monitoring in the user\'s environment and then provides the capability to drill down into specifics of each. For example, filter requests by a specific application or IP Address.\\n\\n### Why was the existing system not working?\\n\\nTheir existing tech stack was a mix of Athena/Presto, which couldn’t meet the throughput and latency requirements with growing data volume across their customers. Additionally, operational overhead around managing some of these systems in-house led to increased cost.\\n\\n### The Problem and Challenges?\\n\\nSome of the key requirements that StarTree Cloud cluster had to meet:\\n\\n-   Throughput: Up to 200 QPS (200 projected by end of year)\\n-   Latency: < 1 second P99\\n-   High ingestion rate: 300k events/sec\\n-   ROI: Provide better cost efficiencies\\n\\nSimilar to Use case #1, the customer wanted to retain data at the lowest granularity (so no ingestion roll-ups), and given the time column granularity similar challenge with running the complex aggregation query to power off the summary view. Additionally, the requirement to get double-digit throughput(QPS) for the POC with the most efficient compute footprint made it quite challenging.\\n\\nGiven the overhead while doing complex aggregations, efficient filtering (indexes) wasn’t enough - in this case, with 3 \\\\* 4-core/32GB nodes query took more than 15 seconds. We immediately switched the table config to add star-tree index to the table config and do a segment reload, and the results were phenomenal — query latency was reduced to 10ms.\\n\\n### Data Size and Infra Footprint for the Pilot:\xa0\\n\\n-   Total # of records: ~8 Billion\\n-   Data Size: 500+ GB\\n-   Capacity: 12 vCPUs across 3 Pinot servers (4-core/32GB)\\n\\n### Impact Summary:\\n\\n-   99.94% reduction in query latency (achieving 100 QPS for the same query with no extra hardware)\\n-   99.9998% reduction in data scanned/aggregated per query\\n-   Happy Customer \uD83D\uDE03\\n\\n![Visualization of the impact of star-tree index for a Cybersecurity use case with Apache Pinot](https://www.datocms-assets.com/75153/1689175033-image4.png)\\n\\n## Multiplayer Game Leaderboard Use Case\\n\\nA global leader in the interactive entertainment field has an A/B Testing / Experimentation use case that tracks players’ activities to measure the player engagement on the new features being rolled out.\\n\\n### The Problem and Challenges?\\n\\nSome of the key requirements that StarTree Cloud cluster had to meet:\\n\\n-   Throughput: = 200 QPS\\n-   Latencies: < 1 second P99\\n-   Ingestion rate: 50K events/sec\\n\\nGiven the overhead while doing complex aggregations, efficient filtering (indexes) wasn’t enough - in this case, with 1 \\\\* 4-core/32GB nodes query took 163 milliseconds. After switching to a star-tree index, the query latency was reduced to 7ms (a reduction of 95.7%).\\n\\n### Data Size and Infra Footprint for the Pilot:\xa0\\n\\n-   Total # of records: ~34 Million\\n-   Data Size: 500+ GB\\n-   Capacity: 4 vCPUs - 1 Pinot server (4-cores / 32 GB)\\n\\n### Impact Summary:\\n\\n-   95.70% improvement in query performance as a result of 99.9962% reduction in number of documents and entries scanned.\\n\\n![Visualization of the impact of star-tree index for a Gaming use case with Apache Pinot](https://www.datocms-assets.com/75153/1689175176-image2.png)\\n\\n## Quick Recap: Star-Tree Index Performance Improvements\\n\\n![Recap Table of the Impact that star-tree index had on three real-world customers using Apache Pinot™](https://www.datocms-assets.com/75153/1689175271-image3.png)\\n\\n-   99.99% reduction in data scanned/aggregated per query\\n-   95 to 99% improvement in query performance\\n\\nDisk IO is the most expensive operation in query processing. The star-tree index reduces Disk IO significantly. Instead of scanning raw documents from the disk and computing aggregates on the fly, star-tree index scans pre-aggregated documents for the combination of dimensions specified in the query from the disk.\\n\\nIn part 1 of the series, we saw that the star-tree index reduced the disk reads by 99.999% from 584 Million entries (in case of an inverted index) to 2,045. Query latency came down 99.67% from 1,513 ms to 4 ms! This, in itself, was a HUGE benefit.\\n\\nIn addition to the drastic improvement in query latency, the memory and CPU usage decreased significantly, freeing up resources for taking up more concurrent workloads. The cumulative effect was the 126 x increase in QPS on this small 4 vCPU Pinot Server, as we saw in part 2 blog of this series.\\n\\nAnd finally, in this part 3 of the blog series, we covered three real production use cases that have seen 95% to 99% improvement in query performance using Star-Tree Index.\\n\\n## Intrigued by What You’ve Read?\\n\\nThe next step is to load your data into an open-source [Apache Pinot](https://docs.pinot.apache.org/basics/getting-started) cluster or, if you prefer, a fully-managed database-as-a-service (DBaaS). Sign up today for a [StarTree Cloud account](https://startree.ai/saas-signup), free for 30 days. If you have more questions, sign up for the [StarTree Community Slack](https://communityinviter.com/apps/startreedata/startree-community).\\n\\n[GET STARTED ON STARTREE CLOUD](https://startree.ai/saas-signup)\\n","code":"var Component=(()=>{var l=Object.create;var r=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var f=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),y=(a,e)=>{for(var i in e)r(a,i,{get:e[i],enumerable:!0})},o=(a,e,i,s)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let n of m(e))!g.call(a,n)&&n!==i&&r(a,n,{get:()=>e[n],enumerable:!(s=p(e,n))||s.enumerable});return a};var w=(a,e,i)=>(i=a!=null?l(u(a)):{},o(e||!a||!a.__esModule?r(i,\\"default\\",{value:a,enumerable:!0}):i,a)),b=a=>o(r({},\\"__esModule\\",{value:!0}),a);var d=f((I,c)=>{c.exports=_jsx_runtime});var k={};y(k,{default:()=>T,frontmatter:()=>x});var t=w(d()),x={title:\\"Star-Tree Index in Apache Pinot - Part 3 - Understanding the Impact in Real Customer Scenarios\\",date:new Date(168912e7),authors:[\\"dabade\\",\\"nijjer\\"],summary:\\"The blog post discusses how implementing a star-tree index significantly improved query performance for an AdTech platform by reducing latency. This index has also been successful in cybersecurity threat detection and multiplayer game leaderboard tracking, resulting in improved query performance and cost savings. Real production use cases showed a 95% to 99% improvement in query performance using StarTree Cloud for real-time analytics.\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"blog post\\",\\"implementing\\",\\"startree index\\",\\"query performance\\",\\"AdTech platform\\",\\"reducing latency\\",\\"cybersecurity threat detection\\",\\"multiplayer game leaderboard tracking\\",\\"improved query performance\\",\\"cost savings\\",\\"real production use cases\\",\\"StarTree Cloud\\",\\"realtime analytics\\",\\"95% to 99% improvement\\"]};function h(a){let e=Object.assign({p:\\"p\\",a:\\"a\\",h2:\\"h2\\",span:\\"span\\",h3:\\"h3\\",ul:\\"ul\\",li:\\"li\\",img:\\"img\\"},a.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(e.p,{children:[\\"In \\",(0,t.jsx)(e.a,{href:\\"https://startree.ai/blog/star-tree-indexes-in-apache-pinot-part-1-understanding-the-impact-on-query-performance\\",children:\\"part 1 of this blog series\\"}),\\", we looked at how a star-tree index brought down standalone query latency on a sizable dataset of ~633M records from 1,513ms to 4ms! \\\\u2014 nearly 380x faster.\\"]}),(0,t.jsxs)(e.p,{children:[\\"In \\",(0,t.jsx)(e.a,{href:\\"https://startree.ai/blog/star-tree-indexes-in-apache-pinot-part-2-understanding-the-impact-during-high-concurrency\\",children:\\"part 2 of this blog series\\"}),\\", we imitated a real production scenario by firing hundreds of concurrent queries using JMeter and showcased how using a star-tree index helped achieve a >95% drop in p90th / p95th / p99th latencies and 126x increase in Throughput.\\"]}),(0,t.jsx)(e.p,{children:\\"In this part, we will cover some real customer stories that have seen 95% to 99% improvement in query performance using Star-Tree Index.\\"}),(0,t.jsxs)(e.h2,{id:\\"adtech-use-case\\",children:[(0,t.jsx)(e.a,{href:\\"#adtech-use-case\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"AdTech Use Case\\"]}),(0,t.jsx)(e.p,{children:\\"This was for a leading AdTech platform and a somewhat typical use case; users of the platform (advertisers, publishers, and influencers) wanted to see fresh metrics on how their activities (such as online content, ad, and email campaigns) were performing in real-time so they could tweak things as needed. The application team wanted to provide a rich analytical interface to these users so that not only can they see the current performance but also do custom slicing and dicing of data over a period of time. For example, compare their current campaign performance to one they ran two weeks back, do cohort analysis, and so on.\\"}),(0,t.jsxs)(e.h3,{id:\\"why-was-the-existing-system-not-working\\",children:[(0,t.jsx)(e.a,{href:\\"#why-was-the-existing-system-not-working\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Why was the existing system not working?\\"]}),(0,t.jsx)(e.p,{children:\\"Their existing tech stack was a mix of OSS and custom-built in-house code, which was both operationally difficult to manage and costly to maintain. Yet more importantly, it wasn\\\\u2019t able to meet the basic throughput and latency requirements required by the platform to sustain user growth as well as provide richer analytic capabilities in the product.\\"}),(0,t.jsxs)(e.h3,{id:\\"the-problem-and-challenges\\",children:[(0,t.jsx)(e.a,{href:\\"#the-problem-and-challenges\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"The Problem and Challenges?\\"]}),(0,t.jsx)(e.p,{children:\\"When the StarTree Sales Engineering team was engaged, the requirements were very clear:\\"}),(0,t.jsxs)(e.ul,{children:[(0,t.jsx)(e.li,{children:\\"Throughput: Support 50+ QPS during POC and 200+ for production)\\"}),(0,t.jsx)(e.li,{children:\\"Latency: P95th latency of 2s, including query that needed aggregation of ~ 2 billion rows\\"}),(0,t.jsx)(e.li,{children:\\"Scalability: Ability to scale efficiently with future growth in QPS in a non-linear manner\\"})]}),(0,t.jsx)(e.p,{children:\\"The biggest challenge was the size of data \\\\u2014 20+ TB and growing \\\\u2014 and on top of that, a complex aggregation query driving the summary view for users so they can drill further in to get more details.\\"}),(0,t.jsx)(e.p,{children:\\"This particular query needed to aggregate close to 2 Billion records at read time and then would be fired for every active user interacting with the platform (so high concurrent QPS). In this case, despite applying all relevant indexes available in their existing system, out-of-the-box query performance was still in the 6-8 seconds range, which is expected given that bulk of the work for the query is happening in the aggregation phase and not during the filtering phase (indexing helps with this).\\"}),(0,t.jsx)(e.p,{children:\\"In other OLAP systems they explored, the only option available to handle this use case was doing ingestion time rollups. In other words, changing the data to higher granularity. However, this obviously means losing access to raw data and also potentially re-bootstrapping if new use cases come down the road that need raw data access.\\"}),(0,t.jsxs)(e.p,{children:[\\"This is exactly the type of scenario that the \\",(0,t.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/indexing/star-tree-index\\",children:\\"Star-Tree Index\\"}),\\", unique to Apache Pinot, is designed to address - handle large aggregation queries at scale that need sub-second performance. The best part is you can apply it anytime without any need to reprocess the data or plan any system downtime. (Segment reload to apply table config changes run as a background task in Apache Pinot.) In this specific case, the same query latencies with the star-tree index applied went down to 15 ms. This implicitly meant that with the same infrastructure footprint, StarTree was able to support ~70 QPS (Queries Per Second) vs < 1 QPS for this most complex query; while still keeping the raw data intact.\\"]}),(0,t.jsxs)(e.h3,{id:\\"data-size-and-infra-footprint-for-the-pilot\\",children:[(0,t.jsx)(e.a,{href:\\"#data-size-and-infra-footprint-for-the-pilot\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Data Size and Infra Footprint for the Pilot:\\\\xA0\\"]}),(0,t.jsxs)(e.ul,{children:[(0,t.jsx)(e.li,{children:\\"Total # of records: ~2 Trillion\\"}),(0,t.jsx)(e.li,{children:\\"Data Size: ~20 TB\\"}),(0,t.jsx)(e.li,{children:\\"Capacity: 72 vCPUs across 9 Pinot servers (8 vCPU, 64GB per node).\\"})]}),(0,t.jsxs)(e.h3,{id:\\"impact-summary\\",children:[(0,t.jsx)(e.a,{href:\\"#impact-summary\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Impact Summary:\\"]}),(0,t.jsxs)(e.ul,{children:[(0,t.jsx)(e.li,{children:\\"99.76% reduction in latency vs. no Star-Tree Index (6.3 seconds to 15 ms)\\"}),(0,t.jsx)(e.li,{children:\\"99.99999% reduction in amount of data scanned/aggregated per query (> 1.8B docs to < 2,400)\\"})]}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"Visualization of the impact of start-tree index for an AdTech use case with Apache Pinot\\",src:\\"https://www.datocms-assets.com/75153/1689174701-image1.png\\"})}),(0,t.jsxs)(e.h2,{id:\\"cybersecurity-use-case\\",children:[(0,t.jsx)(e.a,{href:\\"#cybersecurity-use-case\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"CyberSecurity Use Case:\\"]}),(0,t.jsx)(e.p,{children:\\"A cybersecurity company that provides their customers with a real-time threat detection platform with AI, allowing them to analyze network flow logs in real-time with a sophisticated reporting/analytical UI. The initial landing page inside the customer portal is a summary view of everything the platform was monitoring in the user\'s environment and then provides the capability to drill down into specifics of each. For example, filter requests by a specific application or IP Address.\\"}),(0,t.jsxs)(e.h3,{id:\\"why-was-the-existing-system-not-working-1\\",children:[(0,t.jsx)(e.a,{href:\\"#why-was-the-existing-system-not-working-1\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Why was the existing system not working?\\"]}),(0,t.jsx)(e.p,{children:\\"Their existing tech stack was a mix of Athena/Presto, which couldn\\\\u2019t meet the throughput and latency requirements with growing data volume across their customers. Additionally, operational overhead around managing some of these systems in-house led to increased cost.\\"}),(0,t.jsxs)(e.h3,{id:\\"the-problem-and-challenges-1\\",children:[(0,t.jsx)(e.a,{href:\\"#the-problem-and-challenges-1\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"The Problem and Challenges?\\"]}),(0,t.jsx)(e.p,{children:\\"Some of the key requirements that StarTree Cloud cluster had to meet:\\"}),(0,t.jsxs)(e.ul,{children:[(0,t.jsx)(e.li,{children:\\"Throughput: Up to 200 QPS (200 projected by end of year)\\"}),(0,t.jsx)(e.li,{children:\\"Latency: < 1 second P99\\"}),(0,t.jsx)(e.li,{children:\\"High ingestion rate: 300k events/sec\\"}),(0,t.jsx)(e.li,{children:\\"ROI: Provide better cost efficiencies\\"})]}),(0,t.jsx)(e.p,{children:\\"Similar to Use case #1, the customer wanted to retain data at the lowest granularity (so no ingestion roll-ups), and given the time column granularity similar challenge with running the complex aggregation query to power off the summary view. Additionally, the requirement to get double-digit throughput(QPS) for the POC with the most efficient compute footprint made it quite challenging.\\"}),(0,t.jsx)(e.p,{children:\\"Given the overhead while doing complex aggregations, efficient filtering (indexes) wasn\\\\u2019t enough - in this case, with 3 * 4-core/32GB nodes query took more than 15 seconds. We immediately switched the table config to add star-tree index to the table config and do a segment reload, and the results were phenomenal \\\\u2014 query latency was reduced to 10ms.\\"}),(0,t.jsxs)(e.h3,{id:\\"data-size-and-infra-footprint-for-the-pilot-1\\",children:[(0,t.jsx)(e.a,{href:\\"#data-size-and-infra-footprint-for-the-pilot-1\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Data Size and Infra Footprint for the Pilot:\\\\xA0\\"]}),(0,t.jsxs)(e.ul,{children:[(0,t.jsx)(e.li,{children:\\"Total # of records: ~8 Billion\\"}),(0,t.jsx)(e.li,{children:\\"Data Size: 500+ GB\\"}),(0,t.jsx)(e.li,{children:\\"Capacity: 12 vCPUs across 3 Pinot servers (4-core/32GB)\\"})]}),(0,t.jsxs)(e.h3,{id:\\"impact-summary-1\\",children:[(0,t.jsx)(e.a,{href:\\"#impact-summary-1\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Impact Summary:\\"]}),(0,t.jsxs)(e.ul,{children:[(0,t.jsx)(e.li,{children:\\"99.94% reduction in query latency (achieving 100 QPS for the same query with no extra hardware)\\"}),(0,t.jsx)(e.li,{children:\\"99.9998% reduction in data scanned/aggregated per query\\"}),(0,t.jsx)(e.li,{children:\\"Happy Customer \\\\u{1F603}\\"})]}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"Visualization of the impact of star-tree index for a Cybersecurity use case with Apache Pinot\\",src:\\"https://www.datocms-assets.com/75153/1689175033-image4.png\\"})}),(0,t.jsxs)(e.h2,{id:\\"multiplayer-game-leaderboard-use-case\\",children:[(0,t.jsx)(e.a,{href:\\"#multiplayer-game-leaderboard-use-case\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Multiplayer Game Leaderboard Use Case\\"]}),(0,t.jsx)(e.p,{children:\\"A global leader in the interactive entertainment field has an A/B Testing / Experimentation use case that tracks players\\\\u2019 activities to measure the player engagement on the new features being rolled out.\\"}),(0,t.jsxs)(e.h3,{id:\\"the-problem-and-challenges-2\\",children:[(0,t.jsx)(e.a,{href:\\"#the-problem-and-challenges-2\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"The Problem and Challenges?\\"]}),(0,t.jsx)(e.p,{children:\\"Some of the key requirements that StarTree Cloud cluster had to meet:\\"}),(0,t.jsxs)(e.ul,{children:[(0,t.jsx)(e.li,{children:\\"Throughput: = 200 QPS\\"}),(0,t.jsx)(e.li,{children:\\"Latencies: < 1 second P99\\"}),(0,t.jsx)(e.li,{children:\\"Ingestion rate: 50K events/sec\\"})]}),(0,t.jsx)(e.p,{children:\\"Given the overhead while doing complex aggregations, efficient filtering (indexes) wasn\\\\u2019t enough - in this case, with 1 * 4-core/32GB nodes query took 163 milliseconds. After switching to a star-tree index, the query latency was reduced to 7ms (a reduction of 95.7%).\\"}),(0,t.jsxs)(e.h3,{id:\\"data-size-and-infra-footprint-for-the-pilot-2\\",children:[(0,t.jsx)(e.a,{href:\\"#data-size-and-infra-footprint-for-the-pilot-2\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Data Size and Infra Footprint for the Pilot:\\\\xA0\\"]}),(0,t.jsxs)(e.ul,{children:[(0,t.jsx)(e.li,{children:\\"Total # of records: ~34 Million\\"}),(0,t.jsx)(e.li,{children:\\"Data Size: 500+ GB\\"}),(0,t.jsx)(e.li,{children:\\"Capacity: 4 vCPUs - 1 Pinot server (4-cores / 32 GB)\\"})]}),(0,t.jsxs)(e.h3,{id:\\"impact-summary-2\\",children:[(0,t.jsx)(e.a,{href:\\"#impact-summary-2\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Impact Summary:\\"]}),(0,t.jsx)(e.ul,{children:(0,t.jsx)(e.li,{children:\\"95.70% improvement in query performance as a result of 99.9962% reduction in number of documents and entries scanned.\\"})}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"Visualization of the impact of star-tree index for a Gaming use case with Apache Pinot\\",src:\\"https://www.datocms-assets.com/75153/1689175176-image2.png\\"})}),(0,t.jsxs)(e.h2,{id:\\"quick-recap-star-tree-index-performance-improvements\\",children:[(0,t.jsx)(e.a,{href:\\"#quick-recap-star-tree-index-performance-improvements\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Quick Recap: Star-Tree Index Performance Improvements\\"]}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"Recap Table of the Impact that star-tree index had on three real-world customers using Apache Pinot\\\\u2122\\",src:\\"https://www.datocms-assets.com/75153/1689175271-image3.png\\"})}),(0,t.jsxs)(e.ul,{children:[(0,t.jsx)(e.li,{children:\\"99.99% reduction in data scanned/aggregated per query\\"}),(0,t.jsx)(e.li,{children:\\"95 to 99% improvement in query performance\\"})]}),(0,t.jsx)(e.p,{children:\\"Disk IO is the most expensive operation in query processing. The star-tree index reduces Disk IO significantly. Instead of scanning raw documents from the disk and computing aggregates on the fly, star-tree index scans pre-aggregated documents for the combination of dimensions specified in the query from the disk.\\"}),(0,t.jsx)(e.p,{children:\\"In part 1 of the series, we saw that the star-tree index reduced the disk reads by 99.999% from 584 Million entries (in case of an inverted index) to 2,045. Query latency came down 99.67% from 1,513 ms to 4 ms! This, in itself, was a HUGE benefit.\\"}),(0,t.jsx)(e.p,{children:\\"In addition to the drastic improvement in query latency, the memory and CPU usage decreased significantly, freeing up resources for taking up more concurrent workloads. The cumulative effect was the 126 x increase in QPS on this small 4 vCPU Pinot Server, as we saw in part 2 blog of this series.\\"}),(0,t.jsx)(e.p,{children:\\"And finally, in this part 3 of the blog series, we covered three real production use cases that have seen 95% to 99% improvement in query performance using Star-Tree Index.\\"}),(0,t.jsxs)(e.h2,{id:\\"intrigued-by-what-youve-read\\",children:[(0,t.jsx)(e.a,{href:\\"#intrigued-by-what-youve-read\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Intrigued by What You\\\\u2019ve Read?\\"]}),(0,t.jsxs)(e.p,{children:[\\"The next step is to load your data into an open-source \\",(0,t.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/getting-started\\",children:\\"Apache Pinot\\"}),\\" cluster or, if you prefer, a fully-managed database-as-a-service (DBaaS). Sign up today for a \\",(0,t.jsx)(e.a,{href:\\"https://startree.ai/saas-signup\\",children:\\"StarTree Cloud account\\"}),\\", free for 30 days. If you have more questions, sign up for the \\",(0,t.jsx)(e.a,{href:\\"https://communityinviter.com/apps/startreedata/startree-community\\",children:\\"StarTree Community Slack\\"}),\\".\\"]}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.a,{href:\\"https://startree.ai/saas-signup\\",children:\\"GET STARTED ON STARTREE CLOUD\\"})})]})}function v(a={}){let{wrapper:e}=a.components||{};return e?(0,t.jsx)(e,Object.assign({},a,{children:(0,t.jsx)(h,a)})):h(a)}var T=v;return b(k);})();\\n;return Component;"},"_id":"blog/2023-07-12-star-tree-index-in-apache-pinot-part-3-understanding-the-impact-in-real-customer.mdx","_raw":{"sourceFilePath":"blog/2023-07-12-star-tree-index-in-apache-pinot-part-3-understanding-the-impact-in-real-customer.mdx","sourceFileName":"2023-07-12-star-tree-index-in-apache-pinot-part-3-understanding-the-impact-in-real-customer.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2023-07-12-star-tree-index-in-apache-pinot-part-3-understanding-the-impact-in-real-customer"},"type":"Blog","readingTime":{"text":"8 min read","minutes":7.675,"time":460500,"words":1535},"slug":"2023/07/12/star-tree-index-in-apache-pinot-part-3-understanding-the-impact-in-real-customer","customSlug":"2023/07/12/star-tree-index-in-apache-pinot-part-3-understanding-the-impact-in-real-customer","path":"blog/2023/07/12/star-tree-index-in-apache-pinot-part-3-understanding-the-impact-in-real-customer","customPath":"blog/2023/07/12/star-tree-index-in-apache-pinot-part-3-understanding-the-impact-in-real-customer","filePath":"blog/2023-07-12-star-tree-index-in-apache-pinot-part-3-understanding-the-impact-in-real-customer.mdx","toc":[{"value":"AdTech Use Case","url":"#adtech-use-case","depth":2},{"value":"Why was the existing system not working?","url":"#why-was-the-existing-system-not-working","depth":3},{"value":"The Problem and Challenges?","url":"#the-problem-and-challenges","depth":3},{"value":"Data Size and Infra Footprint for the Pilot:\xa0","url":"#data-size-and-infra-footprint-for-the-pilot","depth":3},{"value":"Impact Summary:","url":"#impact-summary","depth":3},{"value":"CyberSecurity Use Case:","url":"#cybersecurity-use-case","depth":2},{"value":"Why was the existing system not working?","url":"#why-was-the-existing-system-not-working","depth":3},{"value":"The Problem and Challenges?","url":"#the-problem-and-challenges","depth":3},{"value":"Data Size and Infra Footprint for the Pilot:\xa0","url":"#data-size-and-infra-footprint-for-the-pilot","depth":3},{"value":"Impact Summary:","url":"#impact-summary","depth":3},{"value":"Multiplayer Game Leaderboard Use Case","url":"#multiplayer-game-leaderboard-use-case","depth":2},{"value":"The Problem and Challenges?","url":"#the-problem-and-challenges","depth":3},{"value":"Data Size and Infra Footprint for the Pilot:\xa0","url":"#data-size-and-infra-footprint-for-the-pilot","depth":3},{"value":"Impact Summary:","url":"#impact-summary","depth":3},{"value":"Quick Recap: Star-Tree Index Performance Improvements","url":"#quick-recap-star-tree-index-performance-improvements","depth":2},{"value":"Intrigued by What You’ve Read?","url":"#intrigued-by-what-youve-read","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Star-Tree Index in Apache Pinot - Part 3 - Understanding the Impact in Real Customer Scenarios","datePublished":"2023-07-12T00:00:00.000Z","dateModified":"2023-07-12T00:00:00.000Z","description":"The blog post discusses how implementing a star-tree index significantly improved query performance for an AdTech platform by reducing latency. This index has also been successful in cybersecurity threat detection and multiplayer game leaderboard tracking, resulting in improved query performance and cost savings. Real production use cases showed a 95% to 99% improvement in query performance using StarTree Cloud for real-time analytics.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2023-07-12-star-tree-index-in-apache-pinot-part-3-understanding-the-impact-in-real-customer"}},{"title":"Segment Compaction for Upsert Enabled Tables in Apache Pinot","date":"2023-08-04T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","blog post","feature contribution","segment compaction","Apache Pinot project","older records","storage space","configuration","impact","freeing up storage"],"summary":"The blog post discusses the feature contribution of segment compaction to Apache Pinot project, addressing the issue of older records consuming unnecessary storage space. It explains the configuration and impact of segment compaction in freeing up storage. The author expresses gratitude and offers support for questions or feedback on segment compaction.","authors":["zych"],"body":{"raw":"\\nI’m happy to share that my 1st feature contribution to the Apache Pinot project ([Segment compaction for upsert enabled real-time tables](https://github.com/apache/pinot/pull/10463)) was merged recently! In this post, I will briefly discuss the problem segment compaction addresses, how to configure it, and what it looks like in action. If you’re unfamiliar with Pinot’s Upsert features, I recommend reviewing [Full Upserts in Pinot](https://dev.startree.ai/docs/pinot/recipes/upserts-full) to get started and [Stream Ingestion with Upsert](https://docs.pinot.apache.org/basics/data-import/upsert) for more information.\\n\\n## Context and Configuration\\n\\nAs Pinot’s Upsert stores all versions of the record ingested into immutable segments on disk, older records unnecessarily consume valuable storage space when they’re no longer used in query results. Pinot’s Segment Compaction reclaims this valuable storage space by introducing a periodic process that replaces the completed segments with compacted segments which only contain the latest version of the records. I recommend reviewing the Minion documentation if you’re unfamiliar with Pinot’s ability to run periodic processes.\\n\\nWith task scheduling enabled and an available Minion, you can configure segment compaction by adding the following to your table’s config.\\n\\n```json\\n\\"task\\": {\\n  \\"taskTypeConfigsMap\\": {\\n    \\"UpsertCompactionTask\\": {\\n      \\"schedule\\": \\"0 */5 * ? * *\\",\\n      \\"bufferTimePeriod\\": \\"7d\\",\\n      \\"invalidRecordsThresholdPercent\\": \\"30\\",\\n      \\"invalidRecordsThresholdCount\\": \\"100000\\"\\n    }\\n  }\\n}\\n```\\n\\nAll the configs above (excluding schedule) determine which completed segments are selected for compaction.\\n\\nbufferTimePeriod is the amount of time that has elapsed since the segment was consuming. In the example above, this has been set to “7d” which means that any segment that was completed over 7 days ago may be eligible for compaction. However, if you want to ensure that segments are compacted without any additional delay this config can be set to “0d”.\\n\\ninvalidRecordsThresholdPercent is a limit to the amount of older records allowed in the completed segment represented as a percentage of the total number of records in the segment (i.e. old records / total records). In the example above, this has been set to “30” which means that if more than 30% of the records in the completed segment are old, then the segment may be selected for compaction. As segment compaction is an expensive operation, it is not recommended to set this config (or invalidRecordsThresholdCount) too close to 1. This config is optional on the condition that invalidRecordsThresholdCount has been set and can be used in conjunction with invalidRecordsThresholdCount.\\n\\ninvalidRecordsThresholdCount is also a limit similar to invalidRecordsThresholdPercent, but allows you to express the threshold as a record count. In the example above, this has been set to “100000” which means that if the segment contains more than 100K records then it may be selected for compaction.\\n\\n## Example Use Case\\n\\nI’ve created a data set that includes 24M records. The data set contains 240K unique keys that have each been duplicated 100 times.\\n\\n![alt](https://miro.medium.com/v2/resize:fit:4800/0*gEyUq_Tp4Fycgp2r)\\n\\nAfter ingesting the data set there are 6 segments (5 completed segments + 1 consuming segment) with a total estimated size of 22.8MB. Submitting the query “set skipUpsert=true; select count(\\\\*) from transcript_upsert” before compaction produces the following query result.\\n\\n![alt](https://miro.medium.com/v2/resize:fit:1064/0*GE3P1fqAcsr0Xs5A)\\n\\nAfter the compaction tasks are complete, the Minion Task Manager UI reports the following.\\n\\n![alt](https://miro.medium.com/v2/resize:fit:2000/0*SMxDZNndFwpoeNMI)\\n\\nSegment compaction generates a task for each segment to be compacted. 5 tasks were generated in this case because 90% of the records (3.6–4.5M records) are old in all 5 of the completed segments, therefore exceeding the configured thresholds. If a completed segment only contains old records, it is deleted immediately and a task isn’t generated to compact it.\\n\\n![alt](https://miro.medium.com/v2/resize:fit:1068/0*LB1itt-wCohpz42i)\\n\\nSubmitting the query again we now see that count matches the set of 240K unique keys.\\n\\n![alt](https://miro.medium.com/v2/resize:fit:2000/0*cmx4zxoMsD4-tR_u)\\n\\nOnce compaction has completed and the original segments have been replaced with their compacted counterparts we see that the total number of segments remained the same, but the total estimated size dropped to only 2.77MB! Since compaction can yield very small segments, one improvement would be to merge smaller segments into larger ones as this would improve query latency.\\n\\n## Conclusion\\n\\nIn this brief overview of Segment Compaction I covered the problem it addresses, how you can configure it, and demonstrated its ability to reclaim storage space. I’d like to thank Ankit Sultana, Seunghyun Lee, and especially Jackie Jiang for their feedback and support throughout the design and development stages. If you have any questions or feedback, I’m available on the Apache Pinot Slack.\\n","code":"var Component=(()=>{var h=Object.create;var o=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var f=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),b=(n,e)=>{for(var a in e)o(n,a,{get:e[a],enumerable:!0})},r=(n,e,a,i)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let s of m(e))!g.call(n,s)&&s!==a&&o(n,s,{get:()=>e[s],enumerable:!(i=p(e,s))||i.enumerable});return n};var y=(n,e,a)=>(a=n!=null?h(u(n)):{},r(e||!n||!n.__esModule?o(a,\\"default\\",{value:n,enumerable:!0}):a,n)),k=n=>r(o({},\\"__esModule\\",{value:!0}),n);var l=f((T,c)=>{c.exports=_jsx_runtime});var x={};b(x,{default:()=>w,frontmatter:()=>N});var t=y(l()),N={title:\\"Segment Compaction for Upsert Enabled Tables in Apache Pinot\\",date:\\"2023-08-04\\",authors:[\\"zych\\"],summary:\\"The blog post discusses the feature contribution of segment compaction to Apache Pinot project, addressing the issue of older records consuming unnecessary storage space. It explains the configuration and impact of segment compaction in freeing up storage. The author expresses gratitude and offers support for questions or feedback on segment compaction.\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"blog post\\",\\"feature contribution\\",\\"segment compaction\\",\\"Apache Pinot project\\",\\"older records\\",\\"storage space\\",\\"configuration\\",\\"impact\\",\\"freeing up storage\\"]};function d(n){let e=Object.assign({p:\\"p\\",a:\\"a\\",h2:\\"h2\\",span:\\"span\\",pre:\\"pre\\",code:\\"code\\",img:\\"img\\"},n.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(e.p,{children:[\\"I\\\\u2019m happy to share that my 1st feature contribution to the Apache Pinot project (\\",(0,t.jsx)(e.a,{href:\\"https://github.com/apache/pinot/pull/10463\\",children:\\"Segment compaction for upsert enabled real-time tables\\"}),\\") was merged recently! In this post, I will briefly discuss the problem segment compaction addresses, how to configure it, and what it looks like in action. If you\\\\u2019re unfamiliar with Pinot\\\\u2019s Upsert features, I recommend reviewing \\",(0,t.jsx)(e.a,{href:\\"https://dev.startree.ai/docs/pinot/recipes/upserts-full\\",children:\\"Full Upserts in Pinot\\"}),\\" to get started and \\",(0,t.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/data-import/upsert\\",children:\\"Stream Ingestion with Upsert\\"}),\\" for more information.\\"]}),(0,t.jsxs)(e.h2,{id:\\"context-and-configuration\\",children:[(0,t.jsx)(e.a,{href:\\"#context-and-configuration\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Context and Configuration\\"]}),(0,t.jsx)(e.p,{children:\\"As Pinot\\\\u2019s Upsert stores all versions of the record ingested into immutable segments on disk, older records unnecessarily consume valuable storage space when they\\\\u2019re no longer used in query results. Pinot\\\\u2019s Segment Compaction reclaims this valuable storage space by introducing a periodic process that replaces the completed segments with compacted segments which only contain the latest version of the records. I recommend reviewing the Minion documentation if you\\\\u2019re unfamiliar with Pinot\\\\u2019s ability to run periodic processes.\\"}),(0,t.jsx)(e.p,{children:\\"With task scheduling enabled and an available Minion, you can configure segment compaction by adding the following to your table\\\\u2019s config.\\"}),(0,t.jsx)(e.pre,{className:\\"language-json\\",children:(0,t.jsxs)(e.code,{className:\\"language-json code-highlight\\",children:[(0,t.jsxs)(e.span,{className:\\"code-line\\",children:[(0,t.jsx)(e.span,{className:\\"token property\\",children:\'\\"task\\"\'}),(0,t.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,t.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,t.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,t.jsx)(e.span,{className:\\"token property\\",children:\'\\"taskTypeConfigsMap\\"\'}),(0,t.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,t.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,t.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,t.jsx)(e.span,{className:\\"token property\\",children:\'\\"UpsertCompactionTask\\"\'}),(0,t.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,t.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,t.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,t.jsx)(e.span,{className:\\"token property\\",children:\'\\"schedule\\"\'}),(0,t.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,t.jsx)(e.span,{className:\\"token string\\",children:\'\\"0 */5 * ? * *\\"\'}),(0,t.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,t.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,t.jsx)(e.span,{className:\\"token property\\",children:\'\\"bufferTimePeriod\\"\'}),(0,t.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,t.jsx)(e.span,{className:\\"token string\\",children:\'\\"7d\\"\'}),(0,t.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,t.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,t.jsx)(e.span,{className:\\"token property\\",children:\'\\"invalidRecordsThresholdPercent\\"\'}),(0,t.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,t.jsx)(e.span,{className:\\"token string\\",children:\'\\"30\\"\'}),(0,t.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,t.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,t.jsx)(e.span,{className:\\"token property\\",children:\'\\"invalidRecordsThresholdCount\\"\'}),(0,t.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,t.jsx)(e.span,{className:\\"token string\\",children:\'\\"100000\\"\'}),`\\n`]}),(0,t.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,t.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,t.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,t.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,t.jsxs)(e.span,{className:\\"code-line\\",children:[(0,t.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,t.jsx)(e.p,{children:\\"All the configs above (excluding schedule) determine which completed segments are selected for compaction.\\"}),(0,t.jsx)(e.p,{children:\\"bufferTimePeriod is the amount of time that has elapsed since the segment was consuming. In the example above, this has been set to \\\\u201C7d\\\\u201D which means that any segment that was completed over 7 days ago may be eligible for compaction. However, if you want to ensure that segments are compacted without any additional delay this config can be set to \\\\u201C0d\\\\u201D.\\"}),(0,t.jsx)(e.p,{children:\\"invalidRecordsThresholdPercent is a limit to the amount of older records allowed in the completed segment represented as a percentage of the total number of records in the segment (i.e. old records / total records). In the example above, this has been set to \\\\u201C30\\\\u201D which means that if more than 30% of the records in the completed segment are old, then the segment may be selected for compaction. As segment compaction is an expensive operation, it is not recommended to set this config (or invalidRecordsThresholdCount) too close to 1. This config is optional on the condition that invalidRecordsThresholdCount has been set and can be used in conjunction with invalidRecordsThresholdCount.\\"}),(0,t.jsx)(e.p,{children:\\"invalidRecordsThresholdCount is also a limit similar to invalidRecordsThresholdPercent, but allows you to express the threshold as a record count. In the example above, this has been set to \\\\u201C100000\\\\u201D which means that if the segment contains more than 100K records then it may be selected for compaction.\\"}),(0,t.jsxs)(e.h2,{id:\\"example-use-case\\",children:[(0,t.jsx)(e.a,{href:\\"#example-use-case\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Example Use Case\\"]}),(0,t.jsx)(e.p,{children:\\"I\\\\u2019ve created a data set that includes 24M records. The data set contains 240K unique keys that have each been duplicated 100 times.\\"}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"alt\\",src:\\"https://miro.medium.com/v2/resize:fit:4800/0*gEyUq_Tp4Fycgp2r\\"})}),(0,t.jsx)(e.p,{children:\\"After ingesting the data set there are 6 segments (5 completed segments + 1 consuming segment) with a total estimated size of 22.8MB. Submitting the query \\\\u201Cset skipUpsert=true; select count(*) from transcript_upsert\\\\u201D before compaction produces the following query result.\\"}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"alt\\",src:\\"https://miro.medium.com/v2/resize:fit:1064/0*GE3P1fqAcsr0Xs5A\\"})}),(0,t.jsx)(e.p,{children:\\"After the compaction tasks are complete, the Minion Task Manager UI reports the following.\\"}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"alt\\",src:\\"https://miro.medium.com/v2/resize:fit:2000/0*SMxDZNndFwpoeNMI\\"})}),(0,t.jsx)(e.p,{children:\\"Segment compaction generates a task for each segment to be compacted. 5 tasks were generated in this case because 90% of the records (3.6\\\\u20134.5M records) are old in all 5 of the completed segments, therefore exceeding the configured thresholds. If a completed segment only contains old records, it is deleted immediately and a task isn\\\\u2019t generated to compact it.\\"}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"alt\\",src:\\"https://miro.medium.com/v2/resize:fit:1068/0*LB1itt-wCohpz42i\\"})}),(0,t.jsx)(e.p,{children:\\"Submitting the query again we now see that count matches the set of 240K unique keys.\\"}),(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"alt\\",src:\\"https://miro.medium.com/v2/resize:fit:2000/0*cmx4zxoMsD4-tR_u\\"})}),(0,t.jsx)(e.p,{children:\\"Once compaction has completed and the original segments have been replaced with their compacted counterparts we see that the total number of segments remained the same, but the total estimated size dropped to only 2.77MB! Since compaction can yield very small segments, one improvement would be to merge smaller segments into larger ones as this would improve query latency.\\"}),(0,t.jsxs)(e.h2,{id:\\"conclusion\\",children:[(0,t.jsx)(e.a,{href:\\"#conclusion\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Conclusion\\"]}),(0,t.jsx)(e.p,{children:\\"In this brief overview of Segment Compaction I covered the problem it addresses, how you can configure it, and demonstrated its ability to reclaim storage space. I\\\\u2019d like to thank Ankit Sultana, Seunghyun Lee, and especially Jackie Jiang for their feedback and support throughout the design and development stages. If you have any questions or feedback, I\\\\u2019m available on the Apache Pinot Slack.\\"})]})}function v(n={}){let{wrapper:e}=n.components||{};return e?(0,t.jsx)(e,Object.assign({},n,{children:(0,t.jsx)(d,n)})):d(n)}var w=v;return k(x);})();\\n;return Component;"},"_id":"blog/2023-08-04-segment-compaction-for-upsert-enabled-tables-in-apache-pinot-3f30657aa077.mdx","_raw":{"sourceFilePath":"blog/2023-08-04-segment-compaction-for-upsert-enabled-tables-in-apache-pinot-3f30657aa077.mdx","sourceFileName":"2023-08-04-segment-compaction-for-upsert-enabled-tables-in-apache-pinot-3f30657aa077.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2023-08-04-segment-compaction-for-upsert-enabled-tables-in-apache-pinot-3f30657aa077"},"type":"Blog","readingTime":{"text":"4 min read","minutes":3.565,"time":213900,"words":713},"slug":"2023/08/04/segment-compaction-for-upsert-enabled-tables-in-apache-pinot-3f30657aa077","customSlug":"2023/08/04/segment-compaction-for-upsert-enabled-tables-in-apache-pinot-3f30657aa077","path":"blog/2023/08/04/segment-compaction-for-upsert-enabled-tables-in-apache-pinot-3f30657aa077","customPath":"blog/2023/08/04/segment-compaction-for-upsert-enabled-tables-in-apache-pinot-3f30657aa077","filePath":"blog/2023-08-04-segment-compaction-for-upsert-enabled-tables-in-apache-pinot-3f30657aa077.mdx","toc":[{"value":"Context and Configuration","url":"#context-and-configuration","depth":2},{"value":"Example Use Case","url":"#example-use-case","depth":2},{"value":"Conclusion","url":"#conclusion","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Segment Compaction for Upsert Enabled Tables in Apache Pinot","datePublished":"2023-08-04T00:00:00.000Z","dateModified":"2023-08-04T00:00:00.000Z","description":"The blog post discusses the feature contribution of segment compaction to Apache Pinot project, addressing the issue of older records consuming unnecessary storage space. It explains the configuration and impact of segment compaction in freeing up storage. The author expresses gratitude and offers support for questions or feedback on segment compaction.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2023-08-04-segment-compaction-for-upsert-enabled-tables-in-apache-pinot-3f30657aa077"}},{"title":"Announcing Apache Pinot 1.0™","date":"2023-09-19T00:00:00.000Z","tags":["Pinot","Data","Analytics","User-Facing Analytics","joins","compression","null support","pluggable index","spark integration"],"summary":"Introducing Apache Pinot 1.0 Release","authors":["dulay","shrivastava","pawar"],"body":{"raw":"\\n## What Makes a “1.0 Release?”\\n\\nApache Pinot has continuously evolved since the project’s inception within LinkedIn in 2013. Back then it was developed at a single company with a single use case in mind: to power “who viewed my profile?” Over the ensuing decade the Apache Pinot community expanded to be embraced by many other organizations, and those organizations have expanded its capabilities to address new use cases. Apache Pinot in 2023 is continuously evolving to address emerging needs in the real-time analytics community. Let’s look at how much innovation has gone into Apache Pinot over the years:\\n\\n-   Upserts — data-in-motion tends to stay in motion, and one of the cornerstone capabilities of Apache Pinot is upsert support to handle upsert mutations in real-time.\\n-   Query-time Native JOINs — it was important to get this right, so that they were performant and scalable, allowing high QPS. This we will discuss in more detail below.\\n-   Pluggable architecture — a broad user base requires the ability to extend the database with new customizable index types, routing strategies and storage options\\n-   Handling Semi-Structured/Unstructured Data — Pinot can easily index JSON and text data types at scale.\\n-   Improving ANSI SQL Compliance — to that end, we’ve added better NULL handling, window functions, and as stated above, the capability for native JOINs.\\n\\nWith all of these features and capabilities, Apache Pinot moves farther and farther from mere database status, and becomes more of a complete platform that can tackle entire new classes of use cases that were beyond its capabilities in earlier days.\\n\\nFirst let’s look at what Apache Pinot 1.0 itself is delivering. The first foundational pillar of what makes something worthy of a “1.0” release is software quality. Over the past year, since September 2022, engineers across the Apache Pinot community have closed over 300 issues to provide new features, optimize performance, expand test coverage, and squash bugs.\\n\\nFeatures are also a key thing that makes a new release worthy of “1.0” status. The most critical part of the 1.0 release is undoubtedly the [Multi-Stage Query Engine](https://docs.pinot.apache.org/developers/advanced/v2-multi-stage-query-engine), which permits Apache Pinot users to do [performant and scalable query-time JOINs](https://startree.ai/blog/apache-pinot-native-join-support).\\n\\nThe original engine works very well for simpler filter-and-aggregate queries, but the broker could become a bottleneck for more complex queries. The new engine also resolves this by introducing intermediary compute stages on the query servers, and brings Apache Pinot closer to full ANSI SQL semantics. While this query engine has been available within Apache Pinot already (since release 0.11.0), with the release of Apache Pinot 1.0 this feature is functionally complete.\\n\\n(While you can read more below, check out the accompanying blog by Apache Pinot PMC Neha Pawar about using query-time JOINs [here](https://startree.ai/blog/query-time-joins-in-apache-pinot-1-0)).\\n\\nThis post is a summary of the high points, but you can find a full list of everything included in the release notes. And if you’d like a [video treatment of many of the main features in 1.0](https://youtu.be/2cwRHM4J7kI?si=hEtl6W2eNlMkWqag), including some helpful animations, watch here:\\n\\n<VideoEmbed src=\\"https://www.youtube.com/embed/2cwRHM4J7kI\\" title=\\"YouTube video player\\" />\\n\\nOtherwise, let’s have a look at some of the highlighted changes:\\n\\n-   Join Support - Part of the Multi-Stage Query Engine\\n-   Improved Upserts - Deletion and Compaction Support\\n-   Encode User-Specified Compressed Log Processor (CLP) During Ingestion\\n-   NULL Support\\n-   Pluggable Index Types [Index Service Provider Interface (SPI)]\\n-   Improved Pinot-Spark Integration - Spark3 Compatibility\\n\\n## Join Support\\n\\nApache Pinot 1.0 introduces native query-time JOIN support equipping Pinot to handle a broad spectrum of JOIN scenarios providing full coverage from user-facing analytics all the way up to ad hoc analytics. Underpinning this innovation is the multi-stage query engine, introduced a year ago, which efficiently manages complex analytical queries, including JOIN operations. This engine alleviates computational burdens by offloading tasks from brokers to a dedicated intermediate compute stage. Additionally, a new planner supporting full SQL semantics enhances Pinot\'s analytical capabilities.\\n\\nJOIN optimization strategies play a pivotal role in Apache Pinot 1.0. These include predicate push-down to individual tables and using indexing and pruning to reduce scanning which speeds up query processing, smart data layout considerations to minimize data shuffling, and query hints for fine-tuning JOIN operations. With support for all JOIN types and three JOIN algorithms, including broadcast join, shuffle distributed hash join, and lookup join, Apache Pinot delivers versatility and scalability. By significantly reducing query latency and simplifying architecture, Apache Pinot 1.0 is a game-changer for real-time OLAP systems.\\n\\nFor more detailed information on JOINs, please visit this blog [post](https://startree.ai/blog/query-time-joins-in-apache-pinot-1-0).\\n\\nDiscover How Uber is using Joins in Apache Pinot For a real-world use case, Uber is already using the new join capabilities of Apache Pinot at scale in production. You can watch this video to learn more.\\n\\n<VideoEmbed src=\\"https://www.youtube.com/embed/z4Chhref1BM\\" title=\\"YouTube video player\\" />\\n\\n## Upsert Improvements\\n\\nSupport for upserts is one of the key capabilities Apache Pinot offers that differentiates it from other real-time analytics databases. It is a vital feature when real-time streaming data is prone to frequent updates. While upserts have been available in Apache Pinot since 0.6.0, with 1.0 they include two major new enhancements: segment compaction and delete support for upsert tables.\\n\\n### Segment Compaction for Upsert Tables\\n\\nPinot’s Upsert tables store all versions of a record ingested into immutable segments on disk. Older records unnecessarily consume valuable storage space when they’re no longer used in query results. Pinot’s Segment Compaction reclaims this valuable storage space by introducing a periodic process that replaces completed segments with compacted segments which only contain the latest version of the records.\\n\\n```json\\n\\"task\\": {\\n  \\"taskTypeConfigsMap\\": {\\n    \\"UpsertCompactionTask\\": {\\n      \\"schedule\\": \\"0 */5 * ? * *\\",\\n      \\"bufferTimePeriod\\": \\"7d\\",\\n      \\"invalidRecordsThresholdPercent\\": \\"30\\",\\n      \\"invalidRecordsThresholdCount\\": \\"100000\\"\\n    }\\n  }\\n}\\n```\\n\\nThe example above, bufferTimePeriod is set to “7d” which means that any segment that was completed over 7 days ago may be eligible for compaction. However, if you want to ensure that segments are compacted without any additional delay this config can be set to “0d”.\\n\\ninvalidRecordsThresholdPercent is an optional limit to the amount of older records allowed in the completed segment represented as a percentage of the total number of records in the segment (i.e. old records / total records). In the example, this property is set to “30” which means that if more than 30% of the records in the completed segment are old, then the segment may be selected for compaction.\\n\\ninvalidRecordsThresholdCount is also a limit similar to the previous property, but allows you to express the threshold as a record count. In the example above, this property is set to “100000” which means that if the segment contains more than 100K records then it may be selected for compaction.\\n\\n[Read more](https://robert-zych.medium.com/segment-compaction-for-upsert-enabled-tables-in-apache-pinot-3f30657aa077) about the design of this feature.\\n\\n### DELETE Support for Upsert Tables\\n\\nApache Pinot upsert tables now support deleting records. Supporting delete with upsert avoids the need for the user to explicitly filter out invalid records in the query. SELECT _FROM table WHERE deleted_column != true becomes as simple as SELECT _ FROM table. Pinot will only return the latest non-deleted records from the table. This feature opens up the support to ingest Change Data Capture (CDC) data like Debezium where the changes from a source (typically, mutable) will contain DELETE events.\\n\\nDeletes itself is implemented as a soft-delete in Apache Pinot with a dedicated boolean column that serves as a delete marker for the record. Pinot automatically filters out records that are marked in this column. For more details, please see the [documentation](https://docs.pinot.apache.org/basics/data-import/upsert#delete-column).\\n\\n## NULL Value Support\\n\\nThis feature enables Postgres compatible NULL semantics in Apache Pinot queries. The NULL semantics are important for usability for full SQL compatibility which many BI applications like Tableau rely upon when invoking queries to render dashboards. Previously in Pinot, we could not represent NULL. The workaround was to use special values like Integer.MIN_VALUE to represent NULL. Now Pinot 1.0 has full support to represent NULL values. By adding NULL support, Pinot 1.0 has increased the Tableau certification pass rate by 90%.\\n\\nHere are some examples of how NULLs will work in Pinot 1.0.\\n\\n### Aggregations\\n\\nGiven the following table below, aggregating columns with NULL values will have this behavior.\\n\\n| col1 | col2 |\\n| ---- | ---- |\\n| 1    | NULL |\\n| 2    | NULL |\\n| 3    | 1    |\\n\\nSince col1 does not contain NULL values, all the values are included in the aggregation.\\n\\n```sql\\nselect sum(col1) -- returns 6\\nselect count(col1) -- returns 3\\n```\\n\\nIn the select statement below, the NULL values in col2 are not included in the aggregation.\\n\\n```sql\\nselect sum(col2) -- returns 1\\nselect count(col2) -- returns 1\\n```\\n\\n### Group By\\n\\nPinot now supports grouping by NULL. In the example below, we are grouping by col1 which contains a NULL value. Given the table below, grouping by columns with NULL value will have this behavior.\\n\\n| col1 |\\n| ---- |\\n| a    |\\n| NULL |\\n| b    |\\n| a    |\\n\\nThe following select statement will output the following result.\\n\\nselect col1, count(\\\\*) from table group by col1\\n\\n| col1 | count() |\\n| ---- | ------- |\\n| a    | 2       |\\n| b    | 1       |\\n| NULL | 1       |\\n\\n### Sorting\\n\\nPinot now allows you to specify the location of NULL values when sorting records. The default is to act as though NULLs are larger than non-NULLs.\\n\\nGiven this list of values, sorting them will result in the following.\\n\\n`values: 1, 2, 3, NULL`\\n\\nExample 1:\\n\\nNULL values sort BEFORE all non-NULL values.\\n\\nSQL:\\n\\n```sql\\nselect col from table order by col NULLS FIRST\\n```\\n\\n`RESULT: NULL, 1, 2, 3`\\n\\nExample 2:\\n\\nNULL values sort AFTER all non-NULL values.\\n\\nSQL:\\n\\n```sql\\nselect col from table order by col ASC NULLS LAST\\n```\\n\\n`RESULT: 1, 2, 3, NULL`\\n\\nExample 3:\\n\\nDefault behavior is NULL LAST.\\n\\nSQL:\\n\\n```sql\\nselect col from table order by col\\n```\\n\\n`RESULT: 1, 2, 3, NULL`\\n\\n## Index Pluggability\\n\\nToday, Pinot supports multiple index types, like forward index, bloom filter, and range index. Before Pinot 1.0, index types were all statically defined, which means that in order to create a new index type, you’d need to rebuild Pinot from source. Ideally that shouldn’t be the case.\\n\\nTo increase speed of development, [Index Service Provider Interface (SPI)](https://github.com/apache/pinot/issues/10183), or index-spi, reduces friction by adding the ability to include new index types at runtime in Pinot. This opens the ability of adding third party indexes by including an external jar in the classpath and adding some configuration. This opens up Pinot indexing to lower-friction innovation from the community.\\n\\nFor now, SPI-accessible indexes are limited to single field index types. Features like the star-tree index or other multi-column approaches are not yet supported.\\n\\n## Apache Pinot Spark 3 Connector and Passing Pinot Options\\n\\nApache Spark users can now take advantage of Pinot’s ability to provide high scalability, low latency, and high concurrency within the context of a Spark 3 cluster using the [Apache Pinot Spark 3 Connector](https://github.com/apache/pinot/blob/master/pinot-connectors/pinot-spark-3-connector/README.md).\\n\\nThis connector supports Apache Spark (2.x and 3.x) as a processor to create and push segment files to the database and can read realtime, offline, and hybrid tables from Pinot.\\n\\nNow you can merge your streaming and batch datasets together in Spark to provide a full view of real-time and historical data for your machine learning algorithms and feature stores.\\n\\nPerformance Features\\n\\n-   Distributed, parallel scan\\n-   Streaming reads using gRPC (optional)\\n-   Column and filter push down to optimize performance\\n-   Support for Pinot’s Query Options that include: maxExecutionThreads, enableNullHandling, skipUpsert, etc.\\n\\nUsability Features\\n\\n-   SQL support instead of PQL\\n-   Overlap between realtime and offline segments is queried exactly once for hybrid tables\\n-   Schema discovery - If schema is not specified, the [connector reads the table schema](https://github.com/apache/pinot/blob/master/pinot-connectors/pinot-spark-3-connector/documentation/read_model.md) from the Pinot controller, and then converts to the Spark schema.\\n\\nHere is an example that reads a Pinot table, by setting the format to “pinot” spark will automatically load the Pinot connector and read the “airlinesStats” table. The queryOptions property allows you to provide [Pinot Query Options](https://docs.pinot.apache.org/users/user-guide-query/query-options).\\n\\n```scala\\nval data = spark.read\\n  .format(\\"pinot\\")\\n  .option(\\"table\\", \\"airlineStats\\")\\n  .option(\\"tableType\\", \\"offline\\")\\n  .option(\\"queryOptions\\", \\"enableNullHandling=true,maxExecutionThreads=1\\")\\n  .load()\\n  .sql(\\"SELECT * FROM airlineStats WHERE DEST = ‘SFO’\\")\\n\\ndata.show(100)\\n```\\n\\n## Petabyte-Scale Log Storage and Search in Pinot with CLP\\n\\nCompressed Log Processor (CLP) is a tool capable of losslessly compressing text logs and searching them in their compressed state. It achieves a better compression ratio than general purpose compressors alone, while retaining the ability to search the compressed log events without incurring the performance penalty of fully decompressing them. Part of CLP’s algorithm was deployed within [Uber](https://www.uber.com/blog/reducing-logging-cost-by-two-orders-of-magnitude-using-clp/) to compress unstructured Spark logs, as they are generated, achieving an unprecedented compression of 169\xd7.\\n\\nLog events generated as JSON objects with user-defined schemas, meaning each event may have different keys. Such user-defined schemas make these events challenging to store in a table with a set schema. With Log Storage and Search in Pinot with CLP, users would be able to:\\n\\n-   Store their log events losslessly (without dropping fields)\\n-   Store their logs with some amount of compression\\n-   Query their logs efficiently\\n\\nThe CLP ingestion pipeline can be used on log events from a stream, such as JSON log events ingested from Kafka. The plugin takes two inputs: a JSON record and a list of fields to encode with CLP.\\n\\nThe fields to encode can be configured as shown:\\n\\n```json\\n{\\n    ...\\n    \\"tableIndexConfig\\": {\\n        ...\\n        \\"streamConfigs\\": {\\n            ...\\n            \\"stream.kafka.decoder.class.name\\": \\"org.apache.pinot.plugin.inputformat.clplog.CLPLogMessageDecoder\\",\\n            \\"stream.kafka.decoder.prop.fieldsForClpEncoding\\": \\"<field-name-1>,<field-name-2>\\"\\n        }\\n    }\\n}\\n```\\n\\n`<field-names-1 and 2>` are a comma-separated list of fields you wish to encode with CLP.\\n\\nYou can read the design [document](https://docs.google.com/document/d/1nHZb37re4mUwEA258x3a2pgX13EWLWMJ0uLEDk1dUyU/edit) for more details into why and how this feature was implemented.\\n\\n## Summary\\n\\nApache Pinot’s evolution is expressly due to the humans behind the code, and in reaching 1.0 release status it is proper and fitting to give credit to the open source project’s key committers. Since its early days, over [three hundred contributors](https://github.com/apache/pinot/graphs/contributors) have produced more than 1.3 million source lines of code (SLOC).\\n\\n![Image test](https://pinot.apache.org/blogs/apache-pinot-1-0-name-cloud.png)\\n\\nThe introduction of Apache Pinot 1.0 represents an exceptional stride forward in real-time online analytical processing (OLAP) capabilities, marking a watershed moment in the evolution of real-time analytics systems. This release redefines the limits of what can be achieved in the realm of instant data analysis, presenting a game-changing solution for organizations seeking high throughput and low latency in their OLAP queries. If you would like to get started with Apache Pinot 1.0, you can check out the documentation, and download it now.\\n\\n## Resources\\n\\nIf you want to try out Apache Pinot, the following resources will help you get started:\\n\\n[Download page](https://pinot.apache.org/download/)\\n\\n[Getting started](https://docs.pinot.apache.org/getting-started)\\n\\n[Join our Slack channel](https://communityinviter.com/apps/apache-pinot/apache-pinot)\\n\\n[See our upcoming events](https://www.meetup.com/apache-pinot)\\n\\n[Follow us on social media](https://twitter.com/ApachePinot)\\n","code":"var Component=(()=>{var h=Object.create;var s=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var f=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),y=(a,e)=>{for(var t in e)s(a,t,{get:e[t],enumerable:!0})},r=(a,e,t,o)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let i of u(e))!g.call(a,i)&&i!==t&&s(a,i,{get:()=>e[i],enumerable:!(o=p(e,i))||o.enumerable});return a};var N=(a,e,t)=>(t=a!=null?h(m(a)):{},r(e||!a||!a.__esModule?s(t,\\"default\\",{value:a,enumerable:!0}):t,a)),b=a=>r(s({},\\"__esModule\\",{value:!0}),a);var c=f((x,l)=>{l.exports=_jsx_runtime});var P={};y(P,{default:()=>v,frontmatter:()=>k});var n=N(c()),k={title:\\"Announcing Apache Pinot 1.0\\\\u2122\\",date:\\"2023-09-19\\",authors:[\\"dulay\\",\\"shrivastava\\",\\"pawar\\"],summary:\\"Introducing Apache Pinot 1.0 Release\\",tags:[\\"Pinot\\",\\"Data\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"joins\\",\\"compression\\",\\"null support\\",\\"pluggable index\\",\\"spark integration\\"]};function d(a){let e=Object.assign({h2:\\"h2\\",a:\\"a\\",span:\\"span\\",p:\\"p\\",ul:\\"ul\\",li:\\"li\\",h3:\\"h3\\",pre:\\"pre\\",code:\\"code\\",table:\\"table\\",thead:\\"thead\\",tr:\\"tr\\",th:\\"th\\",tbody:\\"tbody\\",td:\\"td\\",img:\\"img\\"},a.components),{VideoEmbed:t}=e;return t||L(\\"VideoEmbed\\",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.h2,{id:\\"what-makes-a-10-release\\",children:[(0,n.jsx)(e.a,{href:\\"#what-makes-a-10-release\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"What Makes a \\\\u201C1.0 Release?\\\\u201D\\"]}),(0,n.jsx)(e.p,{children:\\"Apache Pinot has continuously evolved since the project\\\\u2019s inception within LinkedIn in 2013. Back then it was developed at a single company with a single use case in mind: to power \\\\u201Cwho viewed my profile?\\\\u201D Over the ensuing decade the Apache Pinot community expanded to be embraced by many other organizations, and those organizations have expanded its capabilities to address new use cases. Apache Pinot in 2023 is continuously evolving to address emerging needs in the real-time analytics community. Let\\\\u2019s look at how much innovation has gone into Apache Pinot over the years:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"Upserts \\\\u2014 data-in-motion tends to stay in motion, and one of the cornerstone capabilities of Apache Pinot is upsert support to handle upsert mutations in real-time.\\"}),(0,n.jsx)(e.li,{children:\\"Query-time Native JOINs \\\\u2014 it was important to get this right, so that they were performant and scalable, allowing high QPS. This we will discuss in more detail below.\\"}),(0,n.jsx)(e.li,{children:\\"Pluggable architecture \\\\u2014 a broad user base requires the ability to extend the database with new customizable index types, routing strategies and storage options\\"}),(0,n.jsx)(e.li,{children:\\"Handling Semi-Structured/Unstructured Data \\\\u2014 Pinot can easily index JSON and text data types at scale.\\"}),(0,n.jsx)(e.li,{children:\\"Improving ANSI SQL Compliance \\\\u2014 to that end, we\\\\u2019ve added better NULL handling, window functions, and as stated above, the capability for native JOINs.\\"})]}),(0,n.jsx)(e.p,{children:\\"With all of these features and capabilities, Apache Pinot moves farther and farther from mere database status, and becomes more of a complete platform that can tackle entire new classes of use cases that were beyond its capabilities in earlier days.\\"}),(0,n.jsx)(e.p,{children:\\"First let\\\\u2019s look at what Apache Pinot 1.0 itself is delivering. The first foundational pillar of what makes something worthy of a \\\\u201C1.0\\\\u201D release is software quality. Over the past year, since September 2022, engineers across the Apache Pinot community have closed over 300 issues to provide new features, optimize performance, expand test coverage, and squash bugs.\\"}),(0,n.jsxs)(e.p,{children:[\\"Features are also a key thing that makes a new release worthy of \\\\u201C1.0\\\\u201D status. The most critical part of the 1.0 release is undoubtedly the \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/developers/advanced/v2-multi-stage-query-engine\\",children:\\"Multi-Stage Query Engine\\"}),\\", which permits Apache Pinot users to do \\",(0,n.jsx)(e.a,{href:\\"https://startree.ai/blog/apache-pinot-native-join-support\\",children:\\"performant and scalable query-time JOINs\\"}),\\".\\"]}),(0,n.jsx)(e.p,{children:\\"The original engine works very well for simpler filter-and-aggregate queries, but the broker could become a bottleneck for more complex queries. The new engine also resolves this by introducing intermediary compute stages on the query servers, and brings Apache Pinot closer to full ANSI SQL semantics. While this query engine has been available within Apache Pinot already (since release 0.11.0), with the release of Apache Pinot 1.0 this feature is functionally complete.\\"}),(0,n.jsxs)(e.p,{children:[\\"(While you can read more below, check out the accompanying blog by Apache Pinot PMC Neha Pawar about using query-time JOINs \\",(0,n.jsx)(e.a,{href:\\"https://startree.ai/blog/query-time-joins-in-apache-pinot-1-0\\",children:\\"here\\"}),\\").\\"]}),(0,n.jsxs)(e.p,{children:[\\"This post is a summary of the high points, but you can find a full list of everything included in the release notes. And if you\\\\u2019d like a \\",(0,n.jsx)(e.a,{href:\\"https://youtu.be/2cwRHM4J7kI?si=hEtl6W2eNlMkWqag\\",children:\\"video treatment of many of the main features in 1.0\\"}),\\", including some helpful animations, watch here:\\"]}),(0,n.jsx)(t,{src:\\"https://www.youtube.com/embed/2cwRHM4J7kI\\",title:\\"YouTube video player\\"}),(0,n.jsx)(e.p,{children:\\"Otherwise, let\\\\u2019s have a look at some of the highlighted changes:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"Join Support - Part of the Multi-Stage Query Engine\\"}),(0,n.jsx)(e.li,{children:\\"Improved Upserts - Deletion and Compaction Support\\"}),(0,n.jsx)(e.li,{children:\\"Encode User-Specified Compressed Log Processor (CLP) During Ingestion\\"}),(0,n.jsx)(e.li,{children:\\"NULL Support\\"}),(0,n.jsx)(e.li,{children:\\"Pluggable Index Types [Index Service Provider Interface (SPI)]\\"}),(0,n.jsx)(e.li,{children:\\"Improved Pinot-Spark Integration - Spark3 Compatibility\\"})]}),(0,n.jsxs)(e.h2,{id:\\"join-support\\",children:[(0,n.jsx)(e.a,{href:\\"#join-support\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Join Support\\"]}),(0,n.jsx)(e.p,{children:\\"Apache Pinot 1.0 introduces native query-time JOIN support equipping Pinot to handle a broad spectrum of JOIN scenarios providing full coverage from user-facing analytics all the way up to ad hoc analytics. Underpinning this innovation is the multi-stage query engine, introduced a year ago, which efficiently manages complex analytical queries, including JOIN operations. This engine alleviates computational burdens by offloading tasks from brokers to a dedicated intermediate compute stage. Additionally, a new planner supporting full SQL semantics enhances Pinot\'s analytical capabilities.\\"}),(0,n.jsx)(e.p,{children:\\"JOIN optimization strategies play a pivotal role in Apache Pinot 1.0. These include predicate push-down to individual tables and using indexing and pruning to reduce scanning which speeds up query processing, smart data layout considerations to minimize data shuffling, and query hints for fine-tuning JOIN operations. With support for all JOIN types and three JOIN algorithms, including broadcast join, shuffle distributed hash join, and lookup join, Apache Pinot delivers versatility and scalability. By significantly reducing query latency and simplifying architecture, Apache Pinot 1.0 is a game-changer for real-time OLAP systems.\\"}),(0,n.jsxs)(e.p,{children:[\\"For more detailed information on JOINs, please visit this blog \\",(0,n.jsx)(e.a,{href:\\"https://startree.ai/blog/query-time-joins-in-apache-pinot-1-0\\",children:\\"post\\"}),\\".\\"]}),(0,n.jsx)(e.p,{children:\\"Discover How Uber is using Joins in Apache Pinot For a real-world use case, Uber is already using the new join capabilities of Apache Pinot at scale in production. You can watch this video to learn more.\\"}),(0,n.jsx)(t,{src:\\"https://www.youtube.com/embed/z4Chhref1BM\\",title:\\"YouTube video player\\"}),(0,n.jsxs)(e.h2,{id:\\"upsert-improvements\\",children:[(0,n.jsx)(e.a,{href:\\"#upsert-improvements\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Upsert Improvements\\"]}),(0,n.jsx)(e.p,{children:\\"Support for upserts is one of the key capabilities Apache Pinot offers that differentiates it from other real-time analytics databases. It is a vital feature when real-time streaming data is prone to frequent updates. While upserts have been available in Apache Pinot since 0.6.0, with 1.0 they include two major new enhancements: segment compaction and delete support for upsert tables.\\"}),(0,n.jsxs)(e.h3,{id:\\"segment-compaction-for-upsert-tables\\",children:[(0,n.jsx)(e.a,{href:\\"#segment-compaction-for-upsert-tables\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Segment Compaction for Upsert Tables\\"]}),(0,n.jsx)(e.p,{children:\\"Pinot\\\\u2019s Upsert tables store all versions of a record ingested into immutable segments on disk. Older records unnecessarily consume valuable storage space when they\\\\u2019re no longer used in query results. Pinot\\\\u2019s Segment Compaction reclaims this valuable storage space by introducing a periodic process that replaces completed segments with compacted segments which only contain the latest version of the records.\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"task\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"taskTypeConfigsMap\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"UpsertCompactionTask\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"schedule\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"0 */5 * ? * *\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"bufferTimePeriod\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"7d\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"invalidRecordsThresholdPercent\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"30\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"      \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"invalidRecordsThresholdCount\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"100000\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"The example above, bufferTimePeriod is set to \\\\u201C7d\\\\u201D which means that any segment that was completed over 7 days ago may be eligible for compaction. However, if you want to ensure that segments are compacted without any additional delay this config can be set to \\\\u201C0d\\\\u201D.\\"}),(0,n.jsx)(e.p,{children:\\"invalidRecordsThresholdPercent is an optional limit to the amount of older records allowed in the completed segment represented as a percentage of the total number of records in the segment (i.e. old records / total records). In the example, this property is set to \\\\u201C30\\\\u201D which means that if more than 30% of the records in the completed segment are old, then the segment may be selected for compaction.\\"}),(0,n.jsx)(e.p,{children:\\"invalidRecordsThresholdCount is also a limit similar to the previous property, but allows you to express the threshold as a record count. In the example above, this property is set to \\\\u201C100000\\\\u201D which means that if the segment contains more than 100K records then it may be selected for compaction.\\"}),(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.a,{href:\\"https://robert-zych.medium.com/segment-compaction-for-upsert-enabled-tables-in-apache-pinot-3f30657aa077\\",children:\\"Read more\\"}),\\" about the design of this feature.\\"]}),(0,n.jsxs)(e.h3,{id:\\"delete-support-for-upsert-tables\\",children:[(0,n.jsx)(e.a,{href:\\"#delete-support-for-upsert-tables\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"DELETE Support for Upsert Tables\\"]}),(0,n.jsx)(e.p,{children:\\"Apache Pinot upsert tables now support deleting records. Supporting delete with upsert avoids the need for the user to explicitly filter out invalid records in the query. SELECT _FROM table WHERE deleted_column != true becomes as simple as SELECT _ FROM table. Pinot will only return the latest non-deleted records from the table. This feature opens up the support to ingest Change Data Capture (CDC) data like Debezium where the changes from a source (typically, mutable) will contain DELETE events.\\"}),(0,n.jsxs)(e.p,{children:[\\"Deletes itself is implemented as a soft-delete in Apache Pinot with a dedicated boolean column that serves as a delete marker for the record. Pinot automatically filters out records that are marked in this column. For more details, please see the \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/basics/data-import/upsert#delete-column\\",children:\\"documentation\\"}),\\".\\"]}),(0,n.jsxs)(e.h2,{id:\\"null-value-support\\",children:[(0,n.jsx)(e.a,{href:\\"#null-value-support\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"NULL Value Support\\"]}),(0,n.jsx)(e.p,{children:\\"This feature enables Postgres compatible NULL semantics in Apache Pinot queries. The NULL semantics are important for usability for full SQL compatibility which many BI applications like Tableau rely upon when invoking queries to render dashboards. Previously in Pinot, we could not represent NULL. The workaround was to use special values like Integer.MIN_VALUE to represent NULL. Now Pinot 1.0 has full support to represent NULL values. By adding NULL support, Pinot 1.0 has increased the Tableau certification pass rate by 90%.\\"}),(0,n.jsx)(e.p,{children:\\"Here are some examples of how NULLs will work in Pinot 1.0.\\"}),(0,n.jsxs)(e.h3,{id:\\"aggregations\\",children:[(0,n.jsx)(e.a,{href:\\"#aggregations\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Aggregations\\"]}),(0,n.jsx)(e.p,{children:\\"Given the following table below, aggregating columns with NULL values will have this behavior.\\"}),(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\\"col1\\"}),(0,n.jsx)(e.th,{children:\\"col2\\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"1\\"}),(0,n.jsx)(e.td,{children:\\"NULL\\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"2\\"}),(0,n.jsx)(e.td,{children:\\"NULL\\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"3\\"}),(0,n.jsx)(e.td,{children:\\"1\\"})]})]})]}),(0,n.jsx)(e.p,{children:\\"Since col1 does not contain NULL values, all the values are included in the aggregation.\\"}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"language-sql code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"sum\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"col1\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token comment\\",children:\\"-- returns 6\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"col1\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token comment\\",children:\\"-- returns 3\\"}),`\\n`]})]})}),(0,n.jsx)(e.p,{children:\\"In the select statement below, the NULL values in col2 are not included in the aggregation.\\"}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsxs)(e.code,{className:\\"language-sql code-highlight\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"sum\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"col2\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token comment\\",children:\\"-- returns 1\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token function\\",children:\\"count\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),\\"col2\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token comment\\",children:\\"-- returns 1\\"}),`\\n`]})]})}),(0,n.jsxs)(e.h3,{id:\\"group-by\\",children:[(0,n.jsx)(e.a,{href:\\"#group-by\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Group By\\"]}),(0,n.jsx)(e.p,{children:\\"Pinot now supports grouping by NULL. In the example below, we are grouping by col1 which contains a NULL value. Given the table below, grouping by columns with NULL value will have this behavior.\\"}),(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsx)(e.tr,{children:(0,n.jsx)(e.th,{children:\\"col1\\"})})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsx)(e.tr,{children:(0,n.jsx)(e.td,{children:\\"a\\"})}),(0,n.jsx)(e.tr,{children:(0,n.jsx)(e.td,{children:\\"NULL\\"})}),(0,n.jsx)(e.tr,{children:(0,n.jsx)(e.td,{children:\\"b\\"})}),(0,n.jsx)(e.tr,{children:(0,n.jsx)(e.td,{children:\\"a\\"})})]})]}),(0,n.jsx)(e.p,{children:\\"The following select statement will output the following result.\\"}),(0,n.jsx)(e.p,{children:\\"select col1, count(*) from table group by col1\\"}),(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\\"col1\\"}),(0,n.jsx)(e.th,{children:\\"count()\\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"a\\"}),(0,n.jsx)(e.td,{children:\\"2\\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"b\\"}),(0,n.jsx)(e.td,{children:\\"1\\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\\"NULL\\"}),(0,n.jsx)(e.td,{children:\\"1\\"})]})]})]}),(0,n.jsxs)(e.h3,{id:\\"sorting\\",children:[(0,n.jsx)(e.a,{href:\\"#sorting\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Sorting\\"]}),(0,n.jsx)(e.p,{children:\\"Pinot now allows you to specify the location of NULL values when sorting records. The default is to act as though NULLs are larger than non-NULLs.\\"}),(0,n.jsx)(e.p,{children:\\"Given this list of values, sorting them will result in the following.\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.code,{children:\\"values: 1, 2, 3, NULL\\"})}),(0,n.jsx)(e.p,{children:\\"Example 1:\\"}),(0,n.jsx)(e.p,{children:\\"NULL values sort BEFORE all non-NULL values.\\"}),(0,n.jsx)(e.p,{children:\\"SQL:\\"}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsx)(e.code,{className:\\"language-sql code-highlight\\",children:(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" col \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"table\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"order\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"by\\"}),\\" col NULLS \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"FIRST\\"}),`\\n`]})})}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.code,{children:\\"RESULT: NULL, 1, 2, 3\\"})}),(0,n.jsx)(e.p,{children:\\"Example 2:\\"}),(0,n.jsx)(e.p,{children:\\"NULL values sort AFTER all non-NULL values.\\"}),(0,n.jsx)(e.p,{children:\\"SQL:\\"}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsx)(e.code,{className:\\"language-sql code-highlight\\",children:(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" col \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"table\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"order\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"by\\"}),\\" col \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"ASC\\"}),\\" NULLS \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"LAST\\"}),`\\n`]})})}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.code,{children:\\"RESULT: 1, 2, 3, NULL\\"})}),(0,n.jsx)(e.p,{children:\\"Example 3:\\"}),(0,n.jsx)(e.p,{children:\\"Default behavior is NULL LAST.\\"}),(0,n.jsx)(e.p,{children:\\"SQL:\\"}),(0,n.jsx)(e.pre,{className:\\"language-sql\\",children:(0,n.jsx)(e.code,{className:\\"language-sql code-highlight\\",children:(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"select\\"}),\\" col \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"from\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"table\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"order\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"by\\"}),` col\\n`]})})}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.code,{children:\\"RESULT: 1, 2, 3, NULL\\"})}),(0,n.jsxs)(e.h2,{id:\\"index-pluggability\\",children:[(0,n.jsx)(e.a,{href:\\"#index-pluggability\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Index Pluggability\\"]}),(0,n.jsx)(e.p,{children:\\"Today, Pinot supports multiple index types, like forward index, bloom filter, and range index. Before Pinot 1.0, index types were all statically defined, which means that in order to create a new index type, you\\\\u2019d need to rebuild Pinot from source. Ideally that shouldn\\\\u2019t be the case.\\"}),(0,n.jsxs)(e.p,{children:[\\"To increase speed of development, \\",(0,n.jsx)(e.a,{href:\\"https://github.com/apache/pinot/issues/10183\\",children:\\"Index Service Provider Interface (SPI)\\"}),\\", or index-spi, reduces friction by adding the ability to include new index types at runtime in Pinot. This opens the ability of adding third party indexes by including an external jar in the classpath and adding some configuration. This opens up Pinot indexing to lower-friction innovation from the community.\\"]}),(0,n.jsx)(e.p,{children:\\"For now, SPI-accessible indexes are limited to single field index types. Features like the star-tree index or other multi-column approaches are not yet supported.\\"}),(0,n.jsxs)(e.h2,{id:\\"apache-pinot-spark-3-connector-and-passing-pinot-options\\",children:[(0,n.jsx)(e.a,{href:\\"#apache-pinot-spark-3-connector-and-passing-pinot-options\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Apache Pinot Spark 3 Connector and Passing Pinot Options\\"]}),(0,n.jsxs)(e.p,{children:[\\"Apache Spark users can now take advantage of Pinot\\\\u2019s ability to provide high scalability, low latency, and high concurrency within the context of a Spark 3 cluster using the \\",(0,n.jsx)(e.a,{href:\\"https://github.com/apache/pinot/blob/master/pinot-connectors/pinot-spark-3-connector/README.md\\",children:\\"Apache Pinot Spark 3 Connector\\"}),\\".\\"]}),(0,n.jsx)(e.p,{children:\\"This connector supports Apache Spark (2.x and 3.x) as a processor to create and push segment files to the database and can read realtime, offline, and hybrid tables from Pinot.\\"}),(0,n.jsx)(e.p,{children:\\"Now you can merge your streaming and batch datasets together in Spark to provide a full view of real-time and historical data for your machine learning algorithms and feature stores.\\"}),(0,n.jsx)(e.p,{children:\\"Performance Features\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"Distributed, parallel scan\\"}),(0,n.jsx)(e.li,{children:\\"Streaming reads using gRPC (optional)\\"}),(0,n.jsx)(e.li,{children:\\"Column and filter push down to optimize performance\\"}),(0,n.jsx)(e.li,{children:\\"Support for Pinot\\\\u2019s Query Options that include: maxExecutionThreads, enableNullHandling, skipUpsert, etc.\\"})]}),(0,n.jsx)(e.p,{children:\\"Usability Features\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"SQL support instead of PQL\\"}),(0,n.jsx)(e.li,{children:\\"Overlap between realtime and offline segments is queried exactly once for hybrid tables\\"}),(0,n.jsxs)(e.li,{children:[\\"Schema discovery - If schema is not specified, the \\",(0,n.jsx)(e.a,{href:\\"https://github.com/apache/pinot/blob/master/pinot-connectors/pinot-spark-3-connector/documentation/read_model.md\\",children:\\"connector reads the table schema\\"}),\\" from the Pinot controller, and then converts to the Spark schema.\\"]})]}),(0,n.jsxs)(e.p,{children:[\\"Here is an example that reads a Pinot table, by setting the format to \\\\u201Cpinot\\\\u201D spark will automatically load the Pinot connector and read the \\\\u201CairlinesStats\\\\u201D table. The queryOptions property allows you to provide \\",(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/users/user-guide-query/query-options\\",children:\\"Pinot Query Options\\"}),\\".\\"]}),(0,n.jsx)(e.pre,{className:\\"language-scala\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-scala\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token keyword\\",children:\\"val\\"}),\\" data \\",(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\"=\\"}),\\" spark\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),`read\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"format\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"pinot\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"option\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"table\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"airlineStats\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"option\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"tableType\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"offline\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"option\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"queryOptions\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"enableNullHandling=true,maxExecutionThreads=1\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"load\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"  \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"sql\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"SELECT * FROM airlineStats WHERE DEST = \\\\u2018SFO\\\\u2019\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"data\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\".\\"}),\\"show\\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"(\\"}),(0,n.jsx)(e.span,{className:\\"token number\\",children:\\"100\\"}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\")\\"}),`\\n`]})]})}),(0,n.jsxs)(e.h2,{id:\\"petabyte-scale-log-storage-and-search-in-pinot-with-clp\\",children:[(0,n.jsx)(e.a,{href:\\"#petabyte-scale-log-storage-and-search-in-pinot-with-clp\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Petabyte-Scale Log Storage and Search in Pinot with CLP\\"]}),(0,n.jsxs)(e.p,{children:[\\"Compressed Log Processor (CLP) is a tool capable of losslessly compressing text logs and searching them in their compressed state. It achieves a better compression ratio than general purpose compressors alone, while retaining the ability to search the compressed log events without incurring the performance penalty of fully decompressing them. Part of CLP\\\\u2019s algorithm was deployed within \\",(0,n.jsx)(e.a,{href:\\"https://www.uber.com/blog/reducing-logging-cost-by-two-orders-of-magnitude-using-clp/\\",children:\\"Uber\\"}),\\" to compress unstructured Spark logs, as they are generated, achieving an unprecedented compression of 169\\\\xD7.\\"]}),(0,n.jsx)(e.p,{children:\\"Log events generated as JSON objects with user-defined schemas, meaning each event may have different keys. Such user-defined schemas make these events challenging to store in a table with a set schema. With Log Storage and Search in Pinot with CLP, users would be able to:\\"}),(0,n.jsxs)(e.ul,{children:[(0,n.jsx)(e.li,{children:\\"Store their log events losslessly (without dropping fields)\\"}),(0,n.jsx)(e.li,{children:\\"Store their logs with some amount of compression\\"}),(0,n.jsx)(e.li,{children:\\"Query their logs efficiently\\"})]}),(0,n.jsx)(e.p,{children:\\"The CLP ingestion pipeline can be used on log events from a stream, such as JSON log events ingested from Kafka. The plugin takes two inputs: a JSON record and a list of fields to encode with CLP.\\"}),(0,n.jsx)(e.p,{children:\\"The fields to encode can be configured as shown:\\"}),(0,n.jsx)(e.pre,{className:\\"language-json\\",children:(0,n.jsxs)(e.code,{className:\\"code-highlight language-json\\",children:[(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`    ...\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"tableIndexConfig\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`        ...\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"streamConfigs\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"{\\"}),`\\n`]}),(0,n.jsx)(e.span,{className:\\"code-line\\",children:`            ...\\n`}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.class.name\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"org.apache.pinot.plugin.inputformat.clplog.CLPLogMessageDecoder\\"\'}),(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\",\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"            \\",(0,n.jsx)(e.span,{className:\\"token property\\",children:\'\\"stream.kafka.decoder.prop.fieldsForClpEncoding\\"\'}),(0,n.jsx)(e.span,{className:\\"token operator\\",children:\\":\\"}),\\" \\",(0,n.jsx)(e.span,{className:\\"token string\\",children:\'\\"<field-name-1>,<field-name-2>\\"\'}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"        \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[\\"    \\",(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]}),(0,n.jsxs)(e.span,{className:\\"code-line\\",children:[(0,n.jsx)(e.span,{className:\\"token punctuation\\",children:\\"}\\"}),`\\n`]})]})}),(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.code,{children:\\"<field-names-1 and 2>\\"}),\\" are a comma-separated list of fields you wish to encode with CLP.\\"]}),(0,n.jsxs)(e.p,{children:[\\"You can read the design \\",(0,n.jsx)(e.a,{href:\\"https://docs.google.com/document/d/1nHZb37re4mUwEA258x3a2pgX13EWLWMJ0uLEDk1dUyU/edit\\",children:\\"document\\"}),\\" for more details into why and how this feature was implemented.\\"]}),(0,n.jsxs)(e.h2,{id:\\"summary\\",children:[(0,n.jsx)(e.a,{href:\\"#summary\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),(0,n.jsxs)(e.p,{children:[\\"Apache Pinot\\\\u2019s evolution is expressly due to the humans behind the code, and in reaching 1.0 release status it is proper and fitting to give credit to the open source project\\\\u2019s key committers. Since its early days, over \\",(0,n.jsx)(e.a,{href:\\"https://github.com/apache/pinot/graphs/contributors\\",children:\\"three hundred contributors\\"}),\\" have produced more than 1.3 million source lines of code (SLOC).\\"]}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:\\"Image test\\",src:\\"https://pinot.apache.org/blogs/apache-pinot-1-0-name-cloud.png\\"})}),(0,n.jsx)(e.p,{children:\\"The introduction of Apache Pinot 1.0 represents an exceptional stride forward in real-time online analytical processing (OLAP) capabilities, marking a watershed moment in the evolution of real-time analytics systems. This release redefines the limits of what can be achieved in the realm of instant data analysis, presenting a game-changing solution for organizations seeking high throughput and low latency in their OLAP queries. If you would like to get started with Apache Pinot 1.0, you can check out the documentation, and download it now.\\"}),(0,n.jsxs)(e.h2,{id:\\"resources\\",children:[(0,n.jsx)(e.a,{href:\\"#resources\\",\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Resources\\"]}),(0,n.jsx)(e.p,{children:\\"If you want to try out Apache Pinot, the following resources will help you get started:\\"}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.a,{href:\\"https://pinot.apache.org/download/\\",children:\\"Download page\\"})}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.a,{href:\\"https://docs.pinot.apache.org/getting-started\\",children:\\"Getting started\\"})}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.a,{href:\\"https://communityinviter.com/apps/apache-pinot/apache-pinot\\",children:\\"Join our Slack channel\\"})}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.a,{href:\\"https://www.meetup.com/apache-pinot\\",children:\\"See our upcoming events\\"})}),(0,n.jsx)(e.p,{children:(0,n.jsx)(e.a,{href:\\"https://twitter.com/ApachePinot\\",children:\\"Follow us on social media\\"})})]})}function w(a={}){let{wrapper:e}=a.components||{};return e?(0,n.jsx)(e,Object.assign({},a,{children:(0,n.jsx)(d,a)})):d(a)}var v=w;function L(a,e){throw new Error(\\"Expected \\"+(e?\\"component\\":\\"object\\")+\\" `\\"+a+\\"` to be defined: you likely forgot to import, pass, or provide it.\\")}return b(P);})();\\n;return Component;"},"_id":"blog/2023-09-19-Annoucing-Apache-Pinot-1-0.mdx","_raw":{"sourceFilePath":"blog/2023-09-19-Annoucing-Apache-Pinot-1-0.mdx","sourceFileName":"2023-09-19-Annoucing-Apache-Pinot-1-0.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2023-09-19-Annoucing-Apache-Pinot-1-0"},"type":"Blog","readingTime":{"text":"13 min read","minutes":12.255,"time":735300,"words":2451},"slug":"2023/09/19/Annoucing-Apache-Pinot-1-0","customSlug":"2023/09/19/Annoucing-Apache-Pinot-1-0","path":"blog/2023/09/19/Annoucing-Apache-Pinot-1-0","customPath":"blog/2023/09/19/Annoucing-Apache-Pinot-1-0","filePath":"blog/2023-09-19-Annoucing-Apache-Pinot-1-0.mdx","toc":[{"value":"What Makes a “1.0 Release?”","url":"#what-makes-a-10-release","depth":2},{"value":"Join Support","url":"#join-support","depth":2},{"value":"Upsert Improvements","url":"#upsert-improvements","depth":2},{"value":"Segment Compaction for Upsert Tables","url":"#segment-compaction-for-upsert-tables","depth":3},{"value":"DELETE Support for Upsert Tables","url":"#delete-support-for-upsert-tables","depth":3},{"value":"NULL Value Support","url":"#null-value-support","depth":2},{"value":"Aggregations","url":"#aggregations","depth":3},{"value":"Group By","url":"#group-by","depth":3},{"value":"Sorting","url":"#sorting","depth":3},{"value":"Index Pluggability","url":"#index-pluggability","depth":2},{"value":"Apache Pinot Spark 3 Connector and Passing Pinot Options","url":"#apache-pinot-spark-3-connector-and-passing-pinot-options","depth":2},{"value":"Petabyte-Scale Log Storage and Search in Pinot with CLP","url":"#petabyte-scale-log-storage-and-search-in-pinot-with-clp","depth":2},{"value":"Summary","url":"#summary","depth":2},{"value":"Resources","url":"#resources","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Announcing Apache Pinot 1.0™","datePublished":"2023-09-19T00:00:00.000Z","dateModified":"2023-09-19T00:00:00.000Z","description":"Introducing Apache Pinot 1.0 Release","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2023-09-19-Annoucing-Apache-Pinot-1-0"}},{"title":"Build a real-time analytics solution with Apache Pinot on AWS","date":"2024-08-07T00:00:00.000Z","tags":["Pinot","LinkedIn","real-time data platform","Realtime","Analytics","User-Facing Analytics"],"summary":"The AWS team wrote up a step-by-step guide showing you how you can build a real-time OLAP datastore on Amazon Web Services (AWS) using Apache Pinot on Amazon Elastic Compute Cloud (Amazon EC2) and do near real-time visualization using Tableau.","authors":["aws"],"body":{"raw":"\\nThe AWS team wrote up a step-by-step guide showing you how you can build a real-time OLAP datastore on Amazon Web Services (AWS) using Apache Pinot on Amazon Elastic Compute Cloud (Amazon EC2) and do near real-time visualization using Tableau. You can use Apache Pinot for batch processing use cases as well but, in this post, we will focus on a near real-time analytics use case.\\n\\nRead More at https://aws.amazon.com/blogs/big-data/build-a-real-time-analytics-solution-with-apache-pinot-on-aws/\\n\\n![AWSxPinot](https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2024/08/01/BDB-4015-image001.png)\\n","code":"var Component=(()=>{var m=Object.create;var i=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var h=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var b=(t,a)=>()=>(a||t((a={exports:{}}).exports,a),a.exports),A=(t,a)=>{for(var n in a)i(t,n,{get:a[n],enumerable:!0})},l=(t,a,n,s)=>{if(a&&typeof a==\\"object\\"||typeof a==\\"function\\")for(let o of p(a))!g.call(t,o)&&o!==n&&i(t,o,{get:()=>a[o],enumerable:!(s=d(a,o))||s.enumerable});return t};var w=(t,a,n)=>(n=t!=null?m(h(t)):{},l(a||!t||!t.__esModule?i(n,\\"default\\",{value:t,enumerable:!0}):n,t)),f=t=>l(i({},\\"__esModule\\",{value:!0}),t);var r=b((S,c)=>{c.exports=_jsx_runtime});var C={};A(C,{default:()=>z,frontmatter:()=>y});var e=w(r()),y={title:\\"Build a real-time analytics solution with Apache Pinot on AWS\\",date:new Date(17229888e5),authors:[\\"aws\\"],summary:\\"The AWS team wrote up a step-by-step guide showing you how you can build a real-time OLAP datastore on Amazon Web Services (AWS) using Apache Pinot on Amazon Elastic Compute Cloud (Amazon EC2) and do near real-time visualization using Tableau.\\",tags:[\\"Pinot\\",\\"LinkedIn\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\"]};function u(t){let a=Object.assign({p:\\"p\\",a:\\"a\\",img:\\"img\\"},t.components);return(0,e.jsxs)(e.Fragment,{children:[(0,e.jsx)(a.p,{children:\\"The AWS team wrote up a step-by-step guide showing you how you can build a real-time OLAP datastore on Amazon Web Services (AWS) using Apache Pinot on Amazon Elastic Compute Cloud (Amazon EC2) and do near real-time visualization using Tableau. You can use Apache Pinot for batch processing use cases as well but, in this post, we will focus on a near real-time analytics use case.\\"}),(0,e.jsxs)(a.p,{children:[\\"Read More at \\",(0,e.jsx)(a.a,{href:\\"https://aws.amazon.com/blogs/big-data/build-a-real-time-analytics-solution-with-apache-pinot-on-aws/\\",children:\\"https://aws.amazon.com/blogs/big-data/build-a-real-time-analytics-solution-with-apache-pinot-on-aws/\\"})]}),(0,e.jsx)(a.p,{children:(0,e.jsx)(a.img,{alt:\\"AWSxPinot\\",src:\\"https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2024/08/01/BDB-4015-image001.png\\"})})]})}function x(t={}){let{wrapper:a}=t.components||{};return a?(0,e.jsx)(a,Object.assign({},t,{children:(0,e.jsx)(u,t)})):u(t)}var z=x;return f(C);})();\\n;return Component;"},"_id":"blog/2024-08-07-AWSxPinot.mdx","_raw":{"sourceFilePath":"blog/2024-08-07-AWSxPinot.mdx","sourceFileName":"2024-08-07-AWSxPinot.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2024-08-07-AWSxPinot"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.355,"time":21300,"words":71},"slug":"2024/08/07/AWSxPinot","customSlug":"2024/08/07/AWSxPinot","path":"blog/2024/08/07/AWSxPinot","customPath":"blog/2024/08/07/AWSxPinot","filePath":"blog/2024-08-07-AWSxPinot.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Build a real-time analytics solution with Apache Pinot on AWS","datePublished":"2024-08-07T00:00:00.000Z","dateModified":"2024-08-07T00:00:00.000Z","description":"The AWS team wrote up a step-by-step guide showing you how you can build a real-time OLAP datastore on Amazon Web Services (AWS) using Apache Pinot on Amazon Elastic Compute Cloud (Amazon EC2) and do near real-time visualization using Tableau.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2024-08-07-AWSxPinot"}},{"title":"The Power of Apache Pinot: Why I Chose It for Real-Time Analytics","date":"2024-09-02T00:00:00.000Z","tags":["Pinot","Xische","real-time data platform","Realtime","Analytics","User-Facing Analytics","Elasticsearch","Dubai","Druid","Kafka"],"summary":"Unais Siddiqui is a Senior Software Engineer at Xische & Co., a hybrid boutique consulting company based in Dubai. For a recent project, Unais needed to employ real-time analytics.","authors":["unais"],"body":{"raw":"\\n![Why I chose it for Real-time analytics](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8gLvspV5QAkqwchHYbTGyQ.jpeg)\\n\\nUnais Siddiqui is a Senior Software Engineer at Xische & Co., a hybrid boutique consulting company based in Dubai. For a recent project, Unais needed to employ real-time analytics. [In this blog](https://medium.com/@unaisyoushasiddiqui/the-power-of-apache-pinot-why-i-chose-it-for-real-time-analytics-40c4865f08ce) he describes why he chose Apache Pinot over alternatives like Elasticsearch and Apache Druid, as well as the migration journey, integrating Apache Pinot and Apache Kafka, and the dramatic performance benefits he obtained.\\n","code":"var Component=(()=>{var l=Object.create;var o=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var p=Object.getPrototypeOf,y=Object.prototype.hasOwnProperty;var f=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),g=(a,e)=>{for(var t in e)o(a,t,{get:e[t],enumerable:!0})},r=(a,e,t,s)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let n of u(e))!y.call(a,n)&&n!==t&&o(a,n,{get:()=>e[n],enumerable:!(s=d(e,n))||s.enumerable});return a};var b=(a,e,t)=>(t=a!=null?l(p(a)):{},r(e||!a||!a.__esModule?o(t,\\"default\\",{value:a,enumerable:!0}):t,a)),j=a=>r(o({},\\"__esModule\\",{value:!0}),a);var h=f((q,c)=>{c.exports=_jsx_runtime});var D={};g(D,{default:()=>A,frontmatter:()=>w});var i=b(h()),w={title:\\"The Power of Apache Pinot: Why I Chose It for Real-Time Analytics\\",date:new Date(17252352e5),authors:[\\"unais\\"],summary:\\"Unais Siddiqui is a Senior Software Engineer at Xische & Co., a hybrid boutique consulting company based in Dubai. For a recent project, Unais needed to employ real-time analytics.\\",tags:[\\"Pinot\\",\\"Xische\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"Elasticsearch\\",\\"Dubai\\",\\"Druid\\",\\"Kafka\\"]};function m(a){let e=Object.assign({p:\\"p\\",img:\\"img\\",a:\\"a\\"},a.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.p,{children:(0,i.jsx)(e.img,{alt:\\"Why I chose it for Real-time analytics\\",src:\\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8gLvspV5QAkqwchHYbTGyQ.jpeg\\"})}),(0,i.jsxs)(e.p,{children:[\\"Unais Siddiqui is a Senior Software Engineer at Xische & Co., a hybrid boutique consulting company based in Dubai. For a recent project, Unais needed to employ real-time analytics. \\",(0,i.jsx)(e.a,{href:\\"https://medium.com/@unaisyoushasiddiqui/the-power-of-apache-pinot-why-i-chose-it-for-real-time-analytics-40c4865f08ce\\",children:\\"In this blog\\"}),\\" he describes why he chose Apache Pinot over alternatives like Elasticsearch and Apache Druid, as well as the migration journey, integrating Apache Pinot and Apache Kafka, and the dramatic performance benefits he obtained.\\"]})]})}function x(a={}){let{wrapper:e}=a.components||{};return e?(0,i.jsx)(e,Object.assign({},a,{children:(0,i.jsx)(m,a)})):m(a)}var A=x;return j(D);})();\\n;return Component;"},"_id":"blog/2024-09-02-the-power-of-apache-pinot-why-i-chose-it-for-real-time-analytics.mdx","_raw":{"sourceFilePath":"blog/2024-09-02-the-power-of-apache-pinot-why-i-chose-it-for-real-time-analytics.mdx","sourceFileName":"2024-09-02-the-power-of-apache-pinot-why-i-chose-it-for-real-time-analytics.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2024-09-02-the-power-of-apache-pinot-why-i-chose-it-for-real-time-analytics"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.36,"time":21600,"words":72},"slug":"2024/09/02/the-power-of-apache-pinot-why-i-chose-it-for-real-time-analytics","customSlug":"2024/09/02/the-power-of-apache-pinot-why-i-chose-it-for-real-time-analytics","path":"blog/2024/09/02/the-power-of-apache-pinot-why-i-chose-it-for-real-time-analytics","customPath":"blog/2024/09/02/the-power-of-apache-pinot-why-i-chose-it-for-real-time-analytics","filePath":"blog/2024-09-02-the-power-of-apache-pinot-why-i-chose-it-for-real-time-analytics.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"The Power of Apache Pinot: Why I Chose It for Real-Time Analytics","datePublished":"2024-09-02T00:00:00.000Z","dateModified":"2024-09-02T00:00:00.000Z","description":"Unais Siddiqui is a Senior Software Engineer at Xische & Co., a hybrid boutique consulting company based in Dubai. For a recent project, Unais needed to employ real-time analytics.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2024-09-02-the-power-of-apache-pinot-why-i-chose-it-for-real-time-analytics"}},{"title":"Pinot for Low-Latency Offline Table Analytics","date":"2024-09-03T00:00:00.000Z","tags":["Pinot","Uber","real-time data platform","Realtime","Analytics","User-Facing Analytics","Elasticsearch","Kafka"],"summary":"Apache Pinot™ is a real-time OLAP database capable of ingesting data from streams like Apache Kafka\xae and offline data sources like Apache Hive™. At Uber, Pinot has proven to be really versatile in handling a wide spectrum of use cases: from real-time use cases with over one million writes per second, 100+ QPS, and <500 ms latency, to use cases which require low-latency analytics on offline data. Pinot tables fall in three broad categories: real-time, offline and hybrid. Real-time tables support ingesting data from streams like Kafka, offline tables allow uploading pre-built “segments” via Pinot Controller’s HTTP APIs, and hybrid tables have both real-time and offline parts. Hybrid tables allow a single logical table (same name and schema) to ingest data from real-time streams as well as batch sources. This article shares how Uber uses Pinot’s offline tables to serve 100+ low-latency analytics use cases spanning all lines of businesses.","authors":["sultana","balci","uber"],"body":{"raw":"\\n![Pinot for Low-Latency Offline Table Analytics](https://blog.uber-cdn.com/cdn-cgi/image/width=2560,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/08/cover-photo-17247492663623-scaled.jpg)\\n\\nDiscover how Uber is using Apache Pinot for analysis of offline (batch) data. With 100+ offline table use cases, and 500+ offline tables, Uber uses an Apache Spark connector, which supports gRPC streaming, to fetch data from Pinot into their Hive clusters for an end-to-end streaming architecture.\\n\\nRead more at [Uber Engineering Blog](https://www.uber.com/en-PT/blog/pinot-for-low-latency/)\\n","code":"var Component=(()=>{var m=Object.create;var i=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var h=Object.getOwnPropertyNames;var b=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var p=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),g=(a,e)=>{for(var n in e)i(a,n,{get:e[n],enumerable:!0})},r=(a,e,n,o)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let s of h(e))!u.call(a,s)&&s!==n&&i(a,s,{get:()=>e[s],enumerable:!(o=d(e,s))||o.enumerable});return a};var w=(a,e,n)=>(n=a!=null?m(b(a)):{},r(e||!a||!a.__esModule?i(n,\\"default\\",{value:a,enumerable:!0}):n,a)),y=a=>r(i({},\\"__esModule\\",{value:!0}),a);var c=p((k,l)=>{l.exports=_jsx_runtime});var x={};g(x,{default:()=>v,frontmatter:()=>P});var t=w(c()),P={title:\\"Pinot for Low-Latency Offline Table Analytics\\",date:new Date(17253216e5),authors:[\\"sultana\\",\\"balci\\",\\"uber\\"],summary:\\"Apache Pinot\\\\u2122 is a real-time OLAP database capable of ingesting data from streams like Apache Kafka\\\\xAE and offline data sources like Apache Hive\\\\u2122. At Uber, Pinot has proven to be really versatile in handling a wide spectrum of use cases: from real-time use cases with over one million writes per second, 100+ QPS, and <500 ms latency, to use cases which require low-latency analytics on offline data. Pinot tables fall in three broad categories: real-time, offline and hybrid. Real-time tables support ingesting data from streams like Kafka, offline tables allow uploading pre-built \\\\u201Csegments\\\\u201D via Pinot Controller\\\\u2019s HTTP APIs, and hybrid tables have both real-time and offline parts. Hybrid tables allow a single logical table (same name and schema) to ingest data from real-time streams as well as batch sources. This article shares how Uber uses Pinot\\\\u2019s offline tables to serve 100+ low-latency analytics use cases spanning all lines of businesses.\\",tags:[\\"Pinot\\",\\"Uber\\",\\"real-time data platform\\",\\"Realtime\\",\\"Analytics\\",\\"User-Facing Analytics\\",\\"Elasticsearch\\",\\"Kafka\\"]};function f(a){let e=Object.assign({p:\\"p\\",img:\\"img\\",a:\\"a\\"},a.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:\\"Pinot for Low-Latency Offline Table Analytics\\",src:\\"https://blog.uber-cdn.com/cdn-cgi/image/width=2560,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/08/cover-photo-17247492663623-scaled.jpg\\"})}),(0,t.jsx)(e.p,{children:\\"Discover how Uber is using Apache Pinot for analysis of offline (batch) data. With 100+ offline table use cases, and 500+ offline tables, Uber uses an Apache Spark connector, which supports gRPC streaming, to fetch data from Pinot into their Hive clusters for an end-to-end streaming architecture.\\"}),(0,t.jsxs)(e.p,{children:[\\"Read more at \\",(0,t.jsx)(e.a,{href:\\"https://www.uber.com/en-PT/blog/pinot-for-low-latency/\\",children:\\"Uber Engineering Blog\\"})]})]})}function A(a={}){let{wrapper:e}=a.components||{};return e?(0,t.jsx)(e,Object.assign({},a,{children:(0,t.jsx)(f,a)})):f(a)}var v=A;return y(x);})();\\n;return Component;"},"_id":"blog/2024-09-03-pinot-for-low-latency-offline-table-analytics.mdx","_raw":{"sourceFilePath":"blog/2024-09-03-pinot-for-low-latency-offline-table-analytics.mdx","sourceFileName":"2024-09-03-pinot-for-low-latency-offline-table-analytics.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/2024-09-03-pinot-for-low-latency-offline-table-analytics"},"type":"Blog","readingTime":{"text":"1 min read","minutes":0.295,"time":17700,"words":59},"slug":"2024/09/03/pinot-for-low-latency-offline-table-analytics","customSlug":"2024/09/03/pinot-for-low-latency-offline-table-analytics","path":"blog/2024/09/03/pinot-for-low-latency-offline-table-analytics","customPath":"blog/2024/09/03/pinot-for-low-latency-offline-table-analytics","filePath":"blog/2024-09-03-pinot-for-low-latency-offline-table-analytics.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Pinot for Low-Latency Offline Table Analytics","datePublished":"2024-09-03T00:00:00.000Z","dateModified":"2024-09-03T00:00:00.000Z","description":"Apache Pinot™ is a real-time OLAP database capable of ingesting data from streams like Apache Kafka\xae and offline data sources like Apache Hive™. At Uber, Pinot has proven to be really versatile in handling a wide spectrum of use cases: from real-time use cases with over one million writes per second, 100+ QPS, and <500 ms latency, to use cases which require low-latency analytics on offline data. Pinot tables fall in three broad categories: real-time, offline and hybrid. Real-time tables support ingesting data from streams like Kafka, offline tables allow uploading pre-built “segments” via Pinot Controller’s HTTP APIs, and hybrid tables have both real-time and offline parts. Hybrid tables allow a single logical table (same name and schema) to ingest data from real-time streams as well as batch sources. This article shares how Uber uses Pinot’s offline tables to serve 100+ low-latency analytics use cases spanning all lines of businesses.","image":"/static/images/twitter-card.png","url":"https://pinot.apache.org/blog/2024-09-03-pinot-for-low-latency-offline-table-analytics"}}]'),G=JSON.parse('[{"name":"Raj Ramasubbu, Francisco Morillo, and Ismail Makhlouf (AWS)","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),b=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of p(e))!h.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(r=l(e,a))||r.enumerable});return t};var w=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),A=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((M,c)=>{c.exports=_jsx_runtime});var j={};b(j,{default:()=>S,frontmatter:()=>x});var i=w(m()),x={name:\\"Raj Ramasubbu, Francisco Morillo, and Ismail Makhlouf (AWS)\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function y(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var S=y;return A(j);})();\\n;return Component;"},"_id":"authors/aws.mdx","_raw":{"sourceFilePath":"authors/aws.mdx","sourceFileName":"aws.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/aws"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"aws","path":"authors/aws","filePath":"authors/aws.mdx","toc":[]},{"name":"Caner Balci","occupation":"Software Engineer","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var x=(n,t)=>()=>(t||n((t={exports:{}}).exports,t),t.exports),A=(n,t)=>{for(var e in t)o(n,e,{get:t[e],enumerable:!0})},s=(n,t,e,r)=>{if(t&&typeof t==\\"object\\"||typeof t==\\"function\\")for(let a of p(t))!f.call(n,a)&&a!==e&&o(n,a,{get:()=>t[a],enumerable:!(r=l(t,a))||r.enumerable});return n};var h=(n,t,e)=>(e=n!=null?u(g(n)):{},s(t||!n||!n.__esModule?o(e,\\"default\\",{value:n,enumerable:!0}):e,n)),j=n=>s(o({},\\"__esModule\\",{value:!0}),n);var d=x((D,c)=>{c.exports=_jsx_runtime});var y={};A(y,{default:()=>b,frontmatter:()=>S});var i=h(d()),S={name:\\"Caner Balci\\",occupation:\\"Software Engineer\\"};function m(n){let t=Object.assign({p:\\"p\\"},n.components);return(0,i.jsx)(t.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function _(n={}){let{wrapper:t}=n.components||{};return t?(0,i.jsx)(t,Object.assign({},n,{children:(0,i.jsx)(m,n)})):m(n)}var b=_;return j(y);})();\\n;return Component;"},"_id":"authors/balci.mdx","_raw":{"sourceFilePath":"authors/balci.mdx","sourceFileName":"balci.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/balci"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"balci","path":"authors/balci","filePath":"authors/balci.mdx","toc":[]},{"name":"Hubert Dulay","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of p(e))!h.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(r=l(e,a))||r.enumerable});return t};var y=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),b=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((_,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>S,frontmatter:()=>x});var i=y(m()),x={name:\\"Hubert Dulay\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function A(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var S=A;return b(j);})();\\n;return Component;"},"_id":"authors/bastani.mdx","_raw":{"sourceFilePath":"authors/bastani.mdx","sourceFileName":"bastani.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/bastani"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"bastani","path":"authors/bastani","filePath":"authors/bastani.mdx","toc":[]},{"name":"Sandeep Dabade","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var l=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of l(e))!h.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(r=p(e,a))||r.enumerable});return t};var b=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),x=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((_,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>S,frontmatter:()=>y});var i=b(m()),y={name:\\"Sandeep Dabade\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function A(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var S=A;return x(j);})();\\n;return Component;"},"_id":"authors/dabade.mdx","_raw":{"sourceFilePath":"authors/dabade.mdx","sourceFileName":"dabade.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/dabade"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"dabade","path":"authors/dabade","filePath":"authors/dabade.mdx","toc":[]},{"name":"Apache Pinot Team","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var l=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of l(e))!h.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(r=p(e,a))||r.enumerable});return t};var A=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),x=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((k,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>S,frontmatter:()=>y});var i=A(m()),y={name:\\"Apache Pinot Team\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function b(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var S=b;return x(j);})();\\n;return Component;"},"_id":"authors/default.mdx","_raw":{"sourceFilePath":"authors/default.mdx","sourceFileName":"default.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/default"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"default","path":"authors/default","filePath":"authors/default.mdx","toc":[]},{"name":"Hubert Dulay","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of p(e))!h.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(r=l(e,a))||r.enumerable});return t};var y=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),b=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((_,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>S,frontmatter:()=>x});var i=y(m()),x={name:\\"Hubert Dulay\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function A(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var S=A;return b(j);})();\\n;return Component;"},"_id":"authors/dulay.mdx","_raw":{"sourceFilePath":"authors/dulay.mdx","sourceFileName":"dulay.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/dulay"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"dulay","path":"authors/dulay","filePath":"authors/dulay.mdx","toc":[]},{"name":"Software Engineer","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var a=Object.defineProperty;var g=Object.getOwnPropertyDescriptor;var l=Object.getOwnPropertyNames;var p=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var h=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)a(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let o of l(e))!f.call(t,o)&&o!==n&&a(t,o,{get:()=>e[o],enumerable:!(r=g(e,o))||r.enumerable});return t};var x=(t,e,n)=>(n=t!=null?u(p(t)):{},s(e||!t||!t.__esModule?a(n,\\"default\\",{value:t,enumerable:!0}):n,t)),y=t=>s(a({},\\"__esModule\\",{value:!0}),t);var m=h((k,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>b,frontmatter:()=>A});var i=x(m()),A={name:\\"Software Engineer\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function S(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var b=S;return y(j);})();\\n;return Component;"},"_id":"authors/engineer.mdx","_raw":{"sourceFilePath":"authors/engineer.mdx","sourceFileName":"engineer.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/engineer"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"engineer","path":"authors/engineer","filePath":"authors/engineer.mdx","toc":[]},{"name":"Kishore Gopalakrishna","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of p(e))!h.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(r=l(e,a))||r.enumerable});return t};var x=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),y=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((_,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>S,frontmatter:()=>A});var i=x(m()),A={name:\\"Kishore Gopalakrishna\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function b(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var S=b;return y(j);})();\\n;return Component;"},"_id":"authors/gopalakrishna.mdx","_raw":{"sourceFilePath":"authors/gopalakrishna.mdx","sourceFileName":"gopalakrishna.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/gopalakrishna"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"gopalakrishna","path":"authors/gopalakrishna","filePath":"authors/gopalakrishna.mdx","toc":[]},{"name":"Barkha Herman","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of p(e))!h.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(r=l(e,a))||r.enumerable});return t};var x=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),y=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((_,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>S,frontmatter:()=>A});var i=x(m()),A={name:\\"Barkha Herman\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function b(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var S=b;return y(j);})();\\n;return Component;"},"_id":"authors/herman.mdx","_raw":{"sourceFilePath":"authors/herman.mdx","sourceFileName":"herman.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/herman"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"herman","path":"authors/herman","filePath":"authors/herman.mdx","toc":[]},{"name":"LinkedIn Engineering Team","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var g=Object.getOwnPropertyDescriptor;var l=Object.getOwnPropertyNames;var p=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of l(e))!h.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(r=g(e,a))||r.enumerable});return t};var x=(t,e,n)=>(n=t!=null?u(p(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),y=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((_,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>S,frontmatter:()=>A});var i=x(m()),A={name:\\"LinkedIn Engineering Team\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function b(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var S=b;return y(j);})();\\n;return Component;"},"_id":"authors/linkedin.mdx","_raw":{"sourceFilePath":"authors/linkedin.mdx","sourceFileName":"linkedin.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/linkedin"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"linkedin","path":"authors/linkedin","filePath":"authors/linkedin.mdx","toc":[]},{"name":"Mark Needham","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of p(e))!h.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(r=l(e,a))||r.enumerable});return t};var x=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),y=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((_,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>S,frontmatter:()=>A});var i=x(m()),A={name:\\"Mark Needham\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function b(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var S=b;return y(j);})();\\n;return Component;"},"_id":"authors/needham.mdx","_raw":{"sourceFilePath":"authors/needham.mdx","sourceFileName":"needham.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/needham"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"needham","path":"authors/needham","filePath":"authors/needham.mdx","toc":[]},{"name":"Kulbir Nijjer","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var a=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)a(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let o of p(e))!h.call(t,o)&&o!==n&&a(t,o,{get:()=>e[o],enumerable:!(r=l(e,o))||r.enumerable});return t};var b=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?a(n,\\"default\\",{value:t,enumerable:!0}):n,t)),j=t=>s(a({},\\"__esModule\\",{value:!0}),t);var m=f((k,c)=>{c.exports=_jsx_runtime});var S={};w(S,{default:()=>A,frontmatter:()=>x});var i=b(m()),x={name:\\"Kulbir Nijjer\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function y(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var A=y;return j(S);})();\\n;return Component;"},"_id":"authors/nijjer.mdx","_raw":{"sourceFilePath":"authors/nijjer.mdx","sourceFileName":"nijjer.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/nijjer"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"nijjer","path":"authors/nijjer","filePath":"authors/nijjer.mdx","toc":[]},{"name":"Neha Pawar","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of p(e))!h.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(r=l(e,a))||r.enumerable});return t};var x=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),y=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((k,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>S,frontmatter:()=>A});var i=x(m()),A={name:\\"Neha Pawar\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function b(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var S=b;return y(j);})();\\n;return Component;"},"_id":"authors/pawar.mdx","_raw":{"sourceFilePath":"authors/pawar.mdx","sourceFileName":"pawar.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/pawar"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"pawar","path":"authors/pawar","filePath":"authors/pawar.mdx","toc":[]},{"name":"Pinot Dev","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var a=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)a(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let o of p(e))!h.call(t,o)&&o!==n&&a(t,o,{get:()=>e[o],enumerable:!(r=l(e,o))||r.enumerable});return t};var x=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?a(n,\\"default\\",{value:t,enumerable:!0}):n,t)),y=t=>s(a({},\\"__esModule\\",{value:!0}),t);var m=f((_,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>S,frontmatter:()=>A});var i=x(m()),A={name:\\"Pinot Dev\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function b(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var S=b;return y(j);})();\\n;return Component;"},"_id":"authors/pinotdev.mdx","_raw":{"sourceFilePath":"authors/pinotdev.mdx","sourceFileName":"pinotdev.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/pinotdev"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"pinotdev","path":"authors/pinotdev","filePath":"authors/pinotdev.mdx","toc":[]},{"name":"Mayank Shrivastava","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of p(e))!h.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(r=l(e,a))||r.enumerable});return t};var y=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),x=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((v,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>b,frontmatter:()=>A});var i=y(m()),A={name:\\"Mayank Shrivastava\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function S(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var b=S;return x(j);})();\\n;return Component;"},"_id":"authors/shrivastava.mdx","_raw":{"sourceFilePath":"authors/shrivastava.mdx","sourceFileName":"shrivastava.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/shrivastava"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"shrivastava","path":"authors/shrivastava","filePath":"authors/shrivastava.mdx","toc":[]},{"name":"Ankit Sultana","occupation":"Staff Software Engineer","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var f=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var A=(t,n)=>()=>(n||t((n={exports:{}}).exports,n),n.exports),x=(t,n)=>{for(var e in n)o(t,e,{get:n[e],enumerable:!0})},s=(t,n,e,r)=>{if(n&&typeof n==\\"object\\"||typeof n==\\"function\\")for(let a of p(n))!g.call(t,a)&&a!==e&&o(t,a,{get:()=>n[a],enumerable:!(r=l(n,a))||r.enumerable});return t};var S=(t,n,e)=>(e=t!=null?u(f(t)):{},s(n||!t||!t.__esModule?o(e,\\"default\\",{value:t,enumerable:!0}):e,t)),h=t=>s(o({},\\"__esModule\\",{value:!0}),t);var d=A((z,c)=>{c.exports=_jsx_runtime});var y={};x(y,{default:()=>b,frontmatter:()=>j});var i=S(d()),j={name:\\"Ankit Sultana\\",occupation:\\"Staff Software Engineer\\"};function m(t){let n=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(n.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function _(t={}){let{wrapper:n}=t.components||{};return n?(0,i.jsx)(n,Object.assign({},t,{children:(0,i.jsx)(m,t)})):m(t)}var b=_;return h(y);})();\\n;return Component;"},"_id":"authors/sultana.mdx","_raw":{"sourceFilePath":"authors/sultana.mdx","sourceFileName":"sultana.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/sultana"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"sultana","path":"authors/sultana","filePath":"authors/sultana.mdx","toc":[]},{"name":"Weixiang Sun","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var g=Object.getOwnPropertyDescriptor;var l=Object.getOwnPropertyNames;var p=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of l(e))!h.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(r=g(e,a))||r.enumerable});return t};var x=(t,e,n)=>(n=t!=null?u(p(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),y=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((k,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>b,frontmatter:()=>A});var i=x(m()),A={name:\\"Weixiang Sun\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function S(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var b=S;return y(j);})();\\n;return Component;"},"_id":"authors/sun.mdx","_raw":{"sourceFilePath":"authors/sun.mdx","sourceFileName":"sun.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/sun"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"sun","path":"authors/sun","filePath":"authors/sun.mdx","toc":[]},{"name":"Uber Data Team","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of p(e))!h.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(r=l(e,a))||r.enumerable});return t};var b=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),x=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((_,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>S,frontmatter:()=>y});var i=b(m()),y={name:\\"Uber Data Team\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function A(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var S=A;return x(j);})();\\n;return Component;"},"_id":"authors/uber.mdx","_raw":{"sourceFilePath":"authors/uber.mdx","sourceFileName":"uber.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/uber"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"uber","path":"authors/uber","filePath":"authors/uber.mdx","toc":[]},{"name":"Unais Yousha Siddiqui","avatar":"/static/images/logomark.svg","occupation":"Senior Software Engineer","company":"National University of Computer and Emerging Sciences","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var g=Object.getOwnPropertyDescriptor;var l=Object.getOwnPropertyNames;var p=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let i of l(e))!h.call(t,i)&&i!==n&&o(t,i,{get:()=>e[i],enumerable:!(r=g(e,i))||r.enumerable});return t};var S=(t,e,n)=>(n=t!=null?u(p(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),x=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((k,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>b,frontmatter:()=>y});var a=S(m()),y={name:\\"Unais Yousha Siddiqui\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Senior Software Engineer\\",company:\\"National University of Computer and Emerging Sciences\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,a.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function A(t={}){let{wrapper:e}=t.components||{};return e?(0,a.jsx)(e,Object.assign({},t,{children:(0,a.jsx)(d,t)})):d(t)}var b=A;return x(j);})();\\n;return Component;"},"_id":"authors/unais.mdx","_raw":{"sourceFilePath":"authors/unais.mdx","sourceFileName":"unais.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/unais"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"unais","path":"authors/unais","filePath":"authors/unais.mdx","toc":[]},{"name":"Lakshmanan Velusamy","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let a of p(e))!h.call(t,a)&&a!==n&&o(t,a,{get:()=>e[a],enumerable:!(r=l(e,a))||r.enumerable});return t};var y=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),x=t=>s(o({},\\"__esModule\\",{value:!0}),t);var m=f((_,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>S,frontmatter:()=>A});var i=y(m()),A={name:\\"Lakshmanan Velusamy\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function b(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var S=b;return x(j);})();\\n;return Component;"},"_id":"authors/velusamy.mdx","_raw":{"sourceFilePath":"authors/velusamy.mdx","sourceFileName":"velusamy.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/velusamy"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"velusamy","path":"authors/velusamy","filePath":"authors/velusamy.mdx","toc":[]},{"name":"Robert Zych","avatar":"/static/images/logomark.svg","occupation":"Software Engineer","company":"Stanford University","email":"address@yoursite.com","twitter":"https://twitter.com/Twitter","linkedin":"https://www.linkedin.com","github":"https://github.com","body":{"raw":"\\nApache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\n","code":"var Component=(()=>{var u=Object.create;var a=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,h=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)a(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let o of p(e))!h.call(t,o)&&o!==n&&a(t,o,{get:()=>e[o],enumerable:!(r=l(e,o))||r.enumerable});return t};var y=(t,e,n)=>(n=t!=null?u(g(t)):{},s(e||!t||!t.__esModule?a(n,\\"default\\",{value:t,enumerable:!0}):n,t)),b=t=>s(a({},\\"__esModule\\",{value:!0}),t);var m=f((k,c)=>{c.exports=_jsx_runtime});var j={};w(j,{default:()=>S,frontmatter:()=>x});var i=y(m()),x={name:\\"Robert Zych\\",avatar:\\"/static/images/logomark.svg\\",occupation:\\"Software Engineer\\",company:\\"Stanford University\\",email:\\"address@yoursite.com\\",twitter:\\"https://twitter.com/Twitter\\",linkedin:\\"https://www.linkedin.com\\",github:\\"https://github.com\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\\"})}function A(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var S=A;return b(j);})();\\n;return Component;"},"_id":"authors/zych.mdx","_raw":{"sourceFilePath":"authors/zych.mdx","sourceFileName":"zych.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/zych"},"type":"Authors","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"zych","path":"authors/zych","filePath":"authors/zych.mdx","toc":[]}]');[...K,...G,...JSON.parse('[{"version":"0.1.0","date":"2019-03-08T00:00:00.000Z","href":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.1.0/apache-pinot-incubating-0.1.0-bin.tar.gz?action=download","officialSource":{"download":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.1.0/apache-pinot-incubating-0.1.0-src.tar.gz?action=download","sha512":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.1.0/apache-pinot-incubating-0.1.0-src.tar.gz.sha512?action=download","asc":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.1.0/apache-pinot-incubating-0.1.0-src.tar.gz.asc?action=download"},"binary":{"download":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.1.0/apache-pinot-incubating-0.1.0-bin.tar.gz?action=download","sha512":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.1.0/apache-pinot-incubating-0.1.0-bin.tar.gz.sha512?action=download","asc":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.1.0/apache-pinot-incubating-0.1.0-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"This is the first official release of Apache Pinot.","html":"<p>This is the first official release of Apache Pinot.</p>"},"body":{"raw":"\\nThis is the first official release of Apache Pinot.\\n","code":"var Component=(()=>{var d=Object.create;var o=Object.defineProperty;var g=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var b=Object.getPrototypeOf,l=Object.prototype.hasOwnProperty;var f=(a,t)=>()=>(t||a((t={exports:{}}).exports,t),t.exports),w=(a,t)=>{for(var i in t)o(a,i,{get:t[i],enumerable:!0})},p=(a,t,i,e)=>{if(t&&typeof t==\\"object\\"||typeof t==\\"function\\")for(let n of u(t))!l.call(a,n)&&n!==i&&o(a,n,{get:()=>t[n],enumerable:!(e=g(t,n))||e.enumerable});return a};var v=(a,t,i)=>(i=a!=null?d(b(a)):{},p(t||!a||!a.__esModule?o(i,\\"default\\",{value:a,enumerable:!0}):i,a)),m=a=>p(o({},\\"__esModule\\",{value:!0}),a);var h=f((y,r)=>{r.exports=_jsx_runtime});var _={};w(_,{default:()=>j,frontmatter:()=>x});var c=v(h()),x={version:\\"0.1.0\\",date:\\"03/08/2019\\",href:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.1.0/apache-pinot-incubating-0.1.0-bin.tar.gz?action=download\\",officialSource:{download:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.1.0/apache-pinot-incubating-0.1.0-src.tar.gz?action=download\\",sha512:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.1.0/apache-pinot-incubating-0.1.0-src.tar.gz.sha512?action=download\\",asc:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.1.0/apache-pinot-incubating-0.1.0-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.1.0/apache-pinot-incubating-0.1.0-bin.tar.gz?action=download\\",sha512:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.1.0/apache-pinot-incubating-0.1.0-bin.tar.gz.sha512?action=download\\",asc:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.1.0/apache-pinot-incubating-0.1.0-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"This is the first official release of Apache Pinot.\\"};function s(a){let t=Object.assign({p:\\"p\\"},a.components);return(0,c.jsx)(t.p,{children:\\"This is the first official release of Apache Pinot.\\"})}function z(a={}){let{wrapper:t}=a.components||{};return t?(0,c.jsx)(t,Object.assign({},a,{children:(0,c.jsx)(s,a)})):s(a)}var j=z;return m(_);})();\\n;return Component;"},"_id":"downloads/0.1.0.mdx","_raw":{"sourceFilePath":"downloads/0.1.0.mdx","sourceFileName":"0.1.0.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.1.0"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.045,"time":2700,"words":9},"slug":"0.1.0/","customSlug":"0.1.0/","path":"blog/0.1.0/","customPath":"blog/0.1.0/","filePath":"downloads/0.1.0.mdx","toc":[]},{"version":"0.10.0","date":"2022-03-19T00:00:00.000Z","href":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.10.0/apache-pinot-0.10.0-bin.tar.gz?action=download","officialSource":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.10.0/apache-pinot-0.10.0-src.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.10.0/apache-pinot-0.10.0-src.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.10.0/apache-pinot-0.10.0-src.tar.gz.asc?action=download"},"binary":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.10.0/apache-pinot-0.10.0-bin.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.10.0/apache-pinot-0.10.0-bin.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.10.0/apache-pinot-0.10.0-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"This release introduces some new great features, performance enhancements, UI improvments, and bug fixes which are described in details in the following sections.","html":"<p>This release introduces some new great features, performance enhancements, UI improvments, and bug fixes which are described in details in the following sections.</p>"},"body":{"raw":"\\nThis release introduces some new great features, performance enhancements, UI improvments, and bug fixes which are described in details in the following sections.\\n","code":"var Component=(()=>{var d=Object.create;var t=Object.defineProperty;var w=Object.getOwnPropertyDescriptor;var l=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var m=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),f=(a,e)=>{for(var n in e)t(a,n,{get:e[n],enumerable:!0})},s=(a,e,n,i)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let o of l(e))!u.call(a,o)&&o!==n&&t(a,o,{get:()=>e[o],enumerable:!(i=w(e,o))||i.enumerable});return a};var b=(a,e,n)=>(n=a!=null?d(g(a)):{},s(e||!a||!a.__esModule?t(n,\\"default\\",{value:a,enumerable:!0}):n,a)),x=a=>s(t({},\\"__esModule\\",{value:!0}),a);var p=m((M,r)=>{r.exports=_jsx_runtime});var _={};f(_,{default:()=>j,frontmatter:()=>y});var c=b(p()),y={version:\\"0.10.0\\",date:\\"03/19/2022\\",href:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.10.0/apache-pinot-0.10.0-bin.tar.gz?action=download\\",officialSource:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.10.0/apache-pinot-0.10.0-src.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.10.0/apache-pinot-0.10.0-src.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.10.0/apache-pinot-0.10.0-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.10.0/apache-pinot-0.10.0-bin.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.10.0/apache-pinot-0.10.0-bin.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.10.0/apache-pinot-0.10.0-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"This release introduces some new great features, performance enhancements, UI improvments, and bug fixes which are described in details in the following sections.\\"};function h(a){let e=Object.assign({p:\\"p\\"},a.components);return(0,c.jsx)(e.p,{children:\\"This release introduces some new great features, performance enhancements, UI improvments, and bug fixes which are described in details in the following sections.\\"})}function z(a={}){let{wrapper:e}=a.components||{};return e?(0,c.jsx)(e,Object.assign({},a,{children:(0,c.jsx)(h,a)})):h(a)}var j=z;return x(_);})();\\n;return Component;"},"_id":"downloads/0.10.0.mdx","_raw":{"sourceFilePath":"downloads/0.10.0.mdx","sourceFileName":"0.10.0.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.10.0"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.115,"time":6900,"words":23},"slug":"0.10.0/","customSlug":"0.10.0/","path":"blog/0.10.0/","customPath":"blog/0.10.0/","filePath":"downloads/0.10.0.mdx","toc":[]},{"version":"0.11.0","date":"2022-09-02T00:00:00.000Z","href":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.11.0/apache-pinot-0.11.0-bin.tar.gz?action=download","officialSource":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.11.0/apache-pinot-0.11.0-src.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.11.0/apache-pinot-0.11.0-src.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.11.0/apache-pinot-0.11.0-src.tar.gz.asc?action=download"},"binary":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.11.0/apache-pinot-0.11.0-bin.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.11.0/apache-pinot-0.11.0-bin.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.11.0/apache-pinot-0.11.0-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"Apache Pinot 0.11.0 has introduced many new features to extend the query abilities, e.g. the Multi-Stage query engine enables Pinot to do distributed joins, more sql syntax(DML support), query functions and indexes(Text index, Timestamp index) supported for new use cases. And as always, more integrations with other systems(E.g. Spark3, Flink).","html":"<p>Apache Pinot 0.11.0 has introduced many new features to extend the query abilities, e.g. the Multi-Stage query engine enables Pinot to do distributed joins, more sql syntax(DML support), query functions and indexes(Text index, Timestamp index) supported for new use cases. And as always, more integrations with other systems(E.g. Spark3, Flink).</p>"},"body":{"raw":"\\nApache Pinot 0.11.0 has introduced many new features to extend the query abilities, e.g. the Multi-Stage query engine enables Pinot to do distributed joins, more sql syntax(DML support), query functions and indexes(Text index, Timestamp index) supported for new use cases. And as always, more integrations with other systems(E.g. Spark3, Flink).\\n","code":"var Component=(()=>{var h=Object.create;var o=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var w=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var y=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),m=(t,e)=>{for(var a in e)o(t,a,{get:e[a],enumerable:!0})},r=(t,e,a,s)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let n of w(e))!g.call(t,n)&&n!==a&&o(t,n,{get:()=>e[n],enumerable:!(s=l(e,n))||s.enumerable});return t};var x=(t,e,a)=>(a=t!=null?h(u(t)):{},r(e||!t||!t.__esModule?o(a,\\"default\\",{value:t,enumerable:!0}):a,t)),f=t=>r(o({},\\"__esModule\\",{value:!0}),t);var c=y((S,p)=>{p.exports=_jsx_runtime});var z={};m(z,{default:()=>j,frontmatter:()=>b});var i=x(c()),b={version:\\"0.11.0\\",date:\\"09/02/2022\\",href:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.11.0/apache-pinot-0.11.0-bin.tar.gz?action=download\\",officialSource:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.11.0/apache-pinot-0.11.0-src.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.11.0/apache-pinot-0.11.0-src.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.11.0/apache-pinot-0.11.0-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.11.0/apache-pinot-0.11.0-bin.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.11.0/apache-pinot-0.11.0-bin.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.11.0/apache-pinot-0.11.0-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"Apache Pinot 0.11.0 has introduced many new features to extend the query abilities, e.g. the Multi-Stage query engine enables Pinot to do distributed joins, more sql syntax(DML support), query functions and indexes(Text index, Timestamp index) supported for new use cases. And as always, more integrations with other systems(E.g. Spark3, Flink).\\"};function d(t){let e=Object.assign({p:\\"p\\"},t.components);return(0,i.jsx)(e.p,{children:\\"Apache Pinot 0.11.0 has introduced many new features to extend the query abilities, e.g. the Multi-Stage query engine enables Pinot to do distributed joins, more sql syntax(DML support), query functions and indexes(Text index, Timestamp index) supported for new use cases. And as always, more integrations with other systems(E.g. Spark3, Flink).\\"})}function q(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var j=q;return f(z);})();\\n;return Component;"},"_id":"downloads/0.11.0.mdx","_raw":{"sourceFilePath":"downloads/0.11.0.mdx","sourceFileName":"0.11.0.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.11.0"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.25,"time":15000,"words":50},"slug":"0.11.0/","customSlug":"0.11.0/","path":"blog/0.11.0/","customPath":"blog/0.11.0/","filePath":"downloads/0.11.0.mdx","toc":[]},{"version":"0.12.0","date":"2023-01-19T00:00:00.000Z","href":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.0/apache-pinot-0.12.0-bin.tar.gz?action=download","officialSource":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.0/apache-pinot-0.12.0-src.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.0/apache-pinot-0.12.0-src.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.0/apache-pinot-0.12.0-src.tar.gz.asc?action=download"},"binary":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.0/apache-pinot-0.12.0-bin.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.0/apache-pinot-0.12.0-bin.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.0/apache-pinot-0.12.0-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"Apache Pinot Release 0.12.0","html":"<p>Apache Pinot Release 0.12.0</p>"},"body":{"raw":"\\nApache Pinot Release 0.12.0\\n","code":"var Component=(()=>{var w=Object.create;var e=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var l=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var y=(a,o)=>()=>(o||a((o={exports:{}}).exports,o),o.exports),f=(a,o)=>{for(var t in o)e(a,t,{get:o[t],enumerable:!0})},i=(a,o,t,p)=>{if(o&&typeof o==\\"object\\"||typeof o==\\"function\\")for(let n of l(o))!u.call(a,n)&&n!==t&&e(a,n,{get:()=>o[n],enumerable:!(p=d(o,n))||p.enumerable});return a};var b=(a,o,t)=>(t=a!=null?w(g(a)):{},i(o||!a||!a.__esModule?e(t,\\"default\\",{value:a,enumerable:!0}):t,a)),m=a=>i(e({},\\"__esModule\\",{value:!0}),a);var s=y((A,r)=>{r.exports=_jsx_runtime});var _={};f(_,{default:()=>j,frontmatter:()=>x});var c=b(s()),x={version:\\"0.12.0\\",date:\\"01/19/2023\\",href:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.0/apache-pinot-0.12.0-bin.tar.gz?action=download\\",officialSource:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.0/apache-pinot-0.12.0-src.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.0/apache-pinot-0.12.0-src.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.0/apache-pinot-0.12.0-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.0/apache-pinot-0.12.0-bin.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.0/apache-pinot-0.12.0-bin.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.0/apache-pinot-0.12.0-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"Apache Pinot Release 0.12.0\\"};function h(a){let o=Object.assign({p:\\"p\\"},a.components);return(0,c.jsx)(o.p,{children:\\"Apache Pinot Release 0.12.0\\"})}function z(a={}){let{wrapper:o}=a.components||{};return o?(0,c.jsx)(o,Object.assign({},a,{children:(0,c.jsx)(h,a)})):h(a)}var j=z;return m(_);})();\\n;return Component;"},"_id":"downloads/0.12.0.mdx","_raw":{"sourceFilePath":"downloads/0.12.0.mdx","sourceFileName":"0.12.0.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.12.0"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.02,"time":1200,"words":4},"slug":"0.12.0/","customSlug":"0.12.0/","path":"blog/0.12.0/","customPath":"blog/0.12.0/","filePath":"downloads/0.12.0.mdx","toc":[]},{"version":"0.12.1","date":"2023-03-12T00:00:00.000Z","href":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.1/apache-pinot-0.12.1-bin.tar.gz?action=download","officialSource":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.1/apache-pinot-0.12.1-src.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.1/apache-pinot-0.12.1-src.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.1/apache-pinot-0.12.1-src.tar.gz.asc?action=download"},"binary":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.1/apache-pinot-0.12.1-bin.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.1/apache-pinot-0.12.1-bin.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.1/apache-pinot-0.12.1-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"Apache Pinot Release 0.12.1","html":"<p>Apache Pinot Release 0.12.1</p>"},"body":{"raw":"\\nApache Pinot Release 0.12.1\\n","code":"var Component=(()=>{var w=Object.create;var e=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var l=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var y=(a,o)=>()=>(o||a((o={exports:{}}).exports,o),o.exports),f=(a,o)=>{for(var t in o)e(a,t,{get:o[t],enumerable:!0})},i=(a,o,t,p)=>{if(o&&typeof o==\\"object\\"||typeof o==\\"function\\")for(let n of l(o))!u.call(a,n)&&n!==t&&e(a,n,{get:()=>o[n],enumerable:!(p=d(o,n))||p.enumerable});return a};var b=(a,o,t)=>(t=a!=null?w(g(a)):{},i(o||!a||!a.__esModule?e(t,\\"default\\",{value:a,enumerable:!0}):t,a)),m=a=>i(e({},\\"__esModule\\",{value:!0}),a);var s=y((A,r)=>{r.exports=_jsx_runtime});var _={};f(_,{default:()=>j,frontmatter:()=>x});var c=b(s()),x={version:\\"0.12.1\\",date:\\"03/12/2023\\",href:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.1/apache-pinot-0.12.1-bin.tar.gz?action=download\\",officialSource:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.1/apache-pinot-0.12.1-src.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.1/apache-pinot-0.12.1-src.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.1/apache-pinot-0.12.1-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.1/apache-pinot-0.12.1-bin.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.1/apache-pinot-0.12.1-bin.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.12.1/apache-pinot-0.12.1-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"Apache Pinot Release 0.12.1\\"};function h(a){let o=Object.assign({p:\\"p\\"},a.components);return(0,c.jsx)(o.p,{children:\\"Apache Pinot Release 0.12.1\\"})}function z(a={}){let{wrapper:o}=a.components||{};return o?(0,c.jsx)(o,Object.assign({},a,{children:(0,c.jsx)(h,a)})):h(a)}var j=z;return m(_);})();\\n;return Component;"},"_id":"downloads/0.12.1.mdx","_raw":{"sourceFilePath":"downloads/0.12.1.mdx","sourceFileName":"0.12.1.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.12.1"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.02,"time":1200,"words":4},"slug":"0.12.1/","customSlug":"0.12.1/","path":"blog/0.12.1/","customPath":"blog/0.12.1/","filePath":"downloads/0.12.1.mdx","toc":[]},{"version":"0.2.0","date":"2019-11-11T00:00:00.000Z","href":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.2.0/apache-pinot-incubating-0.2.0-bin.tar.gz?action=download","officialSource":{"download":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.2.0/apache-pinot-incubating-0.2.0-src.tar.gz?action=download","sha512":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.2.0/apache-pinot-incubating-0.2.0-src.tar.gz.sha512?action=download","asc":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.2.0/apache-pinot-incubating-0.2.0-src.tar.gz.asc?action=download"},"binary":{"download":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.2.0/apache-pinot-incubating-0.2.0-bin.tar.gz?action=download","sha512":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.2.0/apache-pinot-incubating-0.2.0-bin.tar.gz.sha512?action=download","asc":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.2.0/apache-pinot-incubating-0.2.0-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"Added support for Kafka 2.0","html":"<p>Added support for Kafka 2.0</p>"},"body":{"raw":"\\nAdded support for Kafka 2.0\\n","code":"var Component=(()=>{var d=Object.create;var o=Object.defineProperty;var u=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var b=Object.getPrototypeOf,l=Object.prototype.hasOwnProperty;var f=(a,t)=>()=>(t||a((t={exports:{}}).exports,t),t.exports),w=(a,t)=>{for(var n in t)o(a,n,{get:t[n],enumerable:!0})},e=(a,t,n,p)=>{if(t&&typeof t==\\"object\\"||typeof t==\\"function\\")for(let i of g(t))!l.call(a,i)&&i!==n&&o(a,i,{get:()=>t[i],enumerable:!(p=u(t,i))||p.enumerable});return a};var v=(a,t,n)=>(n=a!=null?d(b(a)):{},e(t||!a||!a.__esModule?o(n,\\"default\\",{value:a,enumerable:!0}):n,a)),m=a=>e(o({},\\"__esModule\\",{value:!0}),a);var h=f((k,r)=>{r.exports=_jsx_runtime});var _={};w(_,{default:()=>j,frontmatter:()=>x});var c=v(h()),x={version:\\"0.2.0\\",date:\\"11/11/2019\\",href:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.2.0/apache-pinot-incubating-0.2.0-bin.tar.gz?action=download\\",officialSource:{download:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.2.0/apache-pinot-incubating-0.2.0-src.tar.gz?action=download\\",sha512:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.2.0/apache-pinot-incubating-0.2.0-src.tar.gz.sha512?action=download\\",asc:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.2.0/apache-pinot-incubating-0.2.0-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.2.0/apache-pinot-incubating-0.2.0-bin.tar.gz?action=download\\",sha512:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.2.0/apache-pinot-incubating-0.2.0-bin.tar.gz.sha512?action=download\\",asc:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.2.0/apache-pinot-incubating-0.2.0-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"Added support for Kafka 2.0\\"};function s(a){let t=Object.assign({p:\\"p\\"},a.components);return(0,c.jsx)(t.p,{children:\\"Added support for Kafka 2.0\\"})}function z(a={}){let{wrapper:t}=a.components||{};return t?(0,c.jsx)(t,Object.assign({},a,{children:(0,c.jsx)(s,a)})):s(a)}var j=z;return m(_);})();\\n;return Component;"},"_id":"downloads/0.2.0.mdx","_raw":{"sourceFilePath":"downloads/0.2.0.mdx","sourceFileName":"0.2.0.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.2.0"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.025,"time":1500,"words":5},"slug":"0.2.0/","customSlug":"0.2.0/","path":"blog/0.2.0/","customPath":"blog/0.2.0/","filePath":"downloads/0.2.0.mdx","toc":[]},{"version":"0.3.0","date":"2020-03-25T00:00:00.000Z","href":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.3.0/apache-pinot-incubating-0.3.0-bin.tar.gz?action=download","officialSource":{"download":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.3.0/apache-pinot-incubating-0.3.0-src.tar.gz?action=download","sha512":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.3.0/apache-pinot-incubating-0.3.0-src.tar.gz.sha512?action=download","asc":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.3.0/apache-pinot-incubating-0.3.0-src.tar.gz.asc?action=download"},"binary":{"download":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.3.0/apache-pinot-incubating-0.3.0-bin.tar.gz?action=download","sha512":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.3.0/apache-pinot-incubating-0.3.0-bin.tar.gz.sha512?action=download","asc":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.3.0/apache-pinot-incubating-0.3.0-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"The reason behind the architectural change from the previous release (0.2.0) and this release (0.3.0), is the possibility of extending Apache Pinot.","html":"<p>The reason behind the architectural change from the previous release (0.2.0) and this release (0.3.0), is the possibility of extending Apache Pinot.</p>"},"body":{"raw":"\\nThe reason behind the architectural change from the previous release (0.2.0) and this release (0.3.0), is the possibility of extending Apache Pinot.\\n","code":"var Component=(()=>{var d=Object.create;var o=Object.defineProperty;var g=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var b=Object.getPrototypeOf,l=Object.prototype.hasOwnProperty;var f=(a,t)=>()=>(t||a((t={exports:{}}).exports,t),t.exports),v=(a,t)=>{for(var n in t)o(a,n,{get:t[n],enumerable:!0})},r=(a,t,n,c)=>{if(t&&typeof t==\\"object\\"||typeof t==\\"function\\")for(let i of u(t))!l.call(a,i)&&i!==n&&o(a,i,{get:()=>t[i],enumerable:!(c=g(t,i))||c.enumerable});return a};var w=(a,t,n)=>(n=a!=null?d(b(a)):{},r(t||!a||!a.__esModule?o(n,\\"default\\",{value:a,enumerable:!0}):n,a)),m=a=>r(o({},\\"__esModule\\",{value:!0}),a);var h=f((M,p)=>{p.exports=_jsx_runtime});var _={};v(_,{default:()=>j,frontmatter:()=>x});var e=w(h()),x={version:\\"0.3.0\\",date:\\"03/25/2020\\",href:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.3.0/apache-pinot-incubating-0.3.0-bin.tar.gz?action=download\\",officialSource:{download:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.3.0/apache-pinot-incubating-0.3.0-src.tar.gz?action=download\\",sha512:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.3.0/apache-pinot-incubating-0.3.0-src.tar.gz.sha512?action=download\\",asc:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.3.0/apache-pinot-incubating-0.3.0-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.3.0/apache-pinot-incubating-0.3.0-bin.tar.gz?action=download\\",sha512:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.3.0/apache-pinot-incubating-0.3.0-bin.tar.gz.sha512?action=download\\",asc:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.3.0/apache-pinot-incubating-0.3.0-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"The reason behind the architectural change from the previous release (0.2.0) and this release (0.3.0), is the possibility of extending Apache Pinot.\\"};function s(a){let t=Object.assign({p:\\"p\\"},a.components);return(0,e.jsx)(t.p,{children:\\"The reason behind the architectural change from the previous release (0.2.0) and this release (0.3.0), is the possibility of extending Apache Pinot.\\"})}function z(a={}){let{wrapper:t}=a.components||{};return t?(0,e.jsx)(t,Object.assign({},a,{children:(0,e.jsx)(s,a)})):s(a)}var j=z;return m(_);})();\\n;return Component;"},"_id":"downloads/0.3.0.mdx","_raw":{"sourceFilePath":"downloads/0.3.0.mdx","sourceFileName":"0.3.0.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.3.0"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.11,"time":6600,"words":22},"slug":"0.3.0/","customSlug":"0.3.0/","path":"blog/0.3.0/","customPath":"blog/0.3.0/","filePath":"downloads/0.3.0.mdx","toc":[]},{"version":"0.4.0","date":"2020-06-02T00:00:00.000Z","href":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.4.0/apache-pinot-incubating-0.4.0-bin.tar.gz?action=download","officialSource":{"download":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.4.0/apache-pinot-incubating-0.4.0-src.tar.gz?action=download","sha512":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.4.0/apache-pinot-incubating-0.4.0-src.tar.gz.sha512?action=download","asc":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.4.0/apache-pinot-incubating-0.4.0-src.tar.gz.asc?action=download"},"binary":{"download":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.4.0/apache-pinot-incubating-0.4.0-bin.tar.gz?action=download","sha512":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.4.0/apache-pinot-incubating-0.4.0-bin.tar.gz.sha512?action=download","asc":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.4.0/apache-pinot-incubating-0.4.0-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"This release introduced various new features, including the theta-sketch based distinct count aggregation function, an S3 filesystem plugin, a unified star-tree index implementation, deprecation of TimeFieldSpec in favor of DateTimeFieldSpec, etc.","html":"<p>This release introduced various new features, including the theta-sketch based distinct count aggregation function, an S3 filesystem plugin, a unified star-tree index implementation, deprecation of TimeFieldSpec in favor of DateTimeFieldSpec, etc.</p>"},"body":{"raw":"\\nThis release introduced various new features, including the theta-sketch based distinct count aggregation function, an S3 filesystem plugin, a unified star-tree index implementation, deprecation of TimeFieldSpec in favor of DateTimeFieldSpec, etc.\\n","code":"var Component=(()=>{var h=Object.create;var e=Object.defineProperty;var u=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var b=Object.getPrototypeOf,l=Object.prototype.hasOwnProperty;var f=(t,a)=>()=>(a||t((a={exports:{}}).exports,a),a.exports),m=(t,a)=>{for(var i in a)e(t,i,{get:a[i],enumerable:!0})},r=(t,a,i,c)=>{if(a&&typeof a==\\"object\\"||typeof a==\\"function\\")for(let n of g(a))!l.call(t,n)&&n!==i&&e(t,n,{get:()=>a[n],enumerable:!(c=u(a,n))||c.enumerable});return t};var v=(t,a,i)=>(i=t!=null?h(b(t)):{},r(a||!t||!t.__esModule?e(i,\\"default\\",{value:t,enumerable:!0}):i,t)),w=t=>r(e({},\\"__esModule\\",{value:!0}),t);var s=f((_,p)=>{p.exports=_jsx_runtime});var T={};m(T,{default:()=>S,frontmatter:()=>x});var o=v(s()),x={version:\\"0.4.0\\",date:\\"06/02/2020\\",href:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.4.0/apache-pinot-incubating-0.4.0-bin.tar.gz?action=download\\",officialSource:{download:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.4.0/apache-pinot-incubating-0.4.0-src.tar.gz?action=download\\",sha512:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.4.0/apache-pinot-incubating-0.4.0-src.tar.gz.sha512?action=download\\",asc:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.4.0/apache-pinot-incubating-0.4.0-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.4.0/apache-pinot-incubating-0.4.0-bin.tar.gz?action=download\\",sha512:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.4.0/apache-pinot-incubating-0.4.0-bin.tar.gz.sha512?action=download\\",asc:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.4.0/apache-pinot-incubating-0.4.0-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"This release introduced various new features, including the theta-sketch based distinct count aggregation function, an S3 filesystem plugin, a unified star-tree index implementation, deprecation of TimeFieldSpec in favor of DateTimeFieldSpec, etc.\\"};function d(t){let a=Object.assign({p:\\"p\\"},t.components);return(0,o.jsx)(a.p,{children:\\"This release introduced various new features, including the theta-sketch based distinct count aggregation function, an S3 filesystem plugin, a unified star-tree index implementation, deprecation of TimeFieldSpec in favor of DateTimeFieldSpec, etc.\\"})}function z(t={}){let{wrapper:a}=t.components||{};return a?(0,o.jsx)(a,Object.assign({},t,{children:(0,o.jsx)(d,t)})):d(t)}var S=z;return w(T);})();\\n;return Component;"},"_id":"downloads/0.4.0.mdx","_raw":{"sourceFilePath":"downloads/0.4.0.mdx","sourceFileName":"0.4.0.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.4.0"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.155,"time":9300,"words":31},"slug":"0.4.0/","customSlug":"0.4.0/","path":"blog/0.4.0/","customPath":"blog/0.4.0/","filePath":"downloads/0.4.0.mdx","toc":[]},{"version":"0.5.0","date":"2020-09-03T00:00:00.000Z","href":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.5.0/apache-pinot-incubating-0.5.0-bin.tar.gz?action=download","officialSource":{"download":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.5.0/apache-pinot-incubating-0.5.0-src.tar.gz?action=download","sha512":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.5.0/apache-pinot-incubating-0.5.0-src.tar.gz.sha512?action=download","asc":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.5.0/apache-pinot-incubating-0.5.0-src.tar.gz.asc?action=download"},"binary":{"download":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.5.0/apache-pinot-incubating-0.5.0-bin.tar.gz?action=download","sha512":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.5.0/apache-pinot-incubating-0.5.0-bin.tar.gz.sha512?action=download","asc":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.5.0/apache-pinot-incubating-0.5.0-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"This release includes many new features on Pinot ingestion and connectors, query capabilities and admin functions.","html":"<p>This release includes many new features on Pinot ingestion and connectors, query capabilities and admin functions.</p>"},"body":{"raw":"\\nThis release includes many new features on Pinot ingestion and connectors, query capabilities and admin functions.\\n","code":"var Component=(()=>{var d=Object.create;var o=Object.defineProperty;var u=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var b=Object.getPrototypeOf,l=Object.prototype.hasOwnProperty;var f=(n,a)=>()=>(a||n((a={exports:{}}).exports,a),a.exports),w=(n,a)=>{for(var t in a)o(n,t,{get:a[t],enumerable:!0})},r=(n,a,t,e)=>{if(a&&typeof a==\\"object\\"||typeof a==\\"function\\")for(let i of g(a))!l.call(n,i)&&i!==t&&o(n,i,{get:()=>a[i],enumerable:!(e=u(a,i))||e.enumerable});return n};var m=(n,a,t)=>(t=n!=null?d(b(n)):{},r(a||!n||!n.__esModule?o(t,\\"default\\",{value:n,enumerable:!0}):t,n)),v=n=>r(o({},\\"__esModule\\",{value:!0}),n);var s=f((M,p)=>{p.exports=_jsx_runtime});var j={};w(j,{default:()=>y,frontmatter:()=>x});var c=m(s()),x={version:\\"0.5.0\\",date:\\"09/03/2020\\",href:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.5.0/apache-pinot-incubating-0.5.0-bin.tar.gz?action=download\\",officialSource:{download:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.5.0/apache-pinot-incubating-0.5.0-src.tar.gz?action=download\\",sha512:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.5.0/apache-pinot-incubating-0.5.0-src.tar.gz.sha512?action=download\\",asc:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.5.0/apache-pinot-incubating-0.5.0-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.5.0/apache-pinot-incubating-0.5.0-bin.tar.gz?action=download\\",sha512:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.5.0/apache-pinot-incubating-0.5.0-bin.tar.gz.sha512?action=download\\",asc:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.5.0/apache-pinot-incubating-0.5.0-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"This release includes many new features on Pinot ingestion and connectors, query capabilities and admin functions.\\"};function h(n){let a=Object.assign({p:\\"p\\"},n.components);return(0,c.jsx)(a.p,{children:\\"This release includes many new features on Pinot ingestion and connectors, query capabilities and admin functions.\\"})}function z(n={}){let{wrapper:a}=n.components||{};return a?(0,c.jsx)(a,Object.assign({},n,{children:(0,c.jsx)(h,n)})):h(n)}var y=z;return v(j);})();\\n;return Component;"},"_id":"downloads/0.5.0.mdx","_raw":{"sourceFilePath":"downloads/0.5.0.mdx","sourceFileName":"0.5.0.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.5.0"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.08,"time":4800,"words":16},"slug":"0.5.0/","customSlug":"0.5.0/","path":"blog/0.5.0/","customPath":"blog/0.5.0/","filePath":"downloads/0.5.0.mdx","toc":[]},{"version":"0.6.0","date":"2020-11-06T00:00:00.000Z","href":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.6.0/apache-pinot-incubating-0.6.0-bin.tar.gz?action=download","officialSource":{"download":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.6.0/apache-pinot-incubating-0.6.0-src.tar.gz?action=download","sha512":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.6.0/apache-pinot-incubating-0.6.0-src.tar.gz.sha512?action=download","asc":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.6.0/apache-pinot-incubating-0.6.0-src.tar.gz.asc?action=download"},"binary":{"download":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.6.0/apache-pinot-incubating-0.6.0-bin.tar.gz?action=download","sha512":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.6.0/apache-pinot-incubating-0.6.0-bin.tar.gz.sha512?action=download","asc":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.6.0/apache-pinot-incubating-0.6.0-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"This release introduced some excellent new features, including upsert, tiered storage, pinot-spark-connector, support of having clause, more validations on table config and schema","html":"<p>This release introduced some excellent new features, including upsert, tiered storage, pinot-spark-connector, support of having clause, more validations on table config and schema</p>"},"body":{"raw":"\\nThis release introduced some excellent new features, including upsert, tiered storage, pinot-spark-connector, support of having clause, more validations on table config and schema\\n","code":"var Component=(()=>{var d=Object.create;var o=Object.defineProperty;var u=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var b=Object.getPrototypeOf,l=Object.prototype.hasOwnProperty;var f=(a,n)=>()=>(n||a((n={exports:{}}).exports,n),n.exports),m=(a,n)=>{for(var t in n)o(a,t,{get:n[t],enumerable:!0})},r=(a,n,t,c)=>{if(n&&typeof n==\\"object\\"||typeof n==\\"function\\")for(let i of g(n))!l.call(a,i)&&i!==t&&o(a,i,{get:()=>n[i],enumerable:!(c=u(n,i))||c.enumerable});return a};var v=(a,n,t)=>(t=a!=null?d(b(a)):{},r(n||!a||!a.__esModule?o(t,\\"default\\",{value:a,enumerable:!0}):t,a)),w=a=>r(o({},\\"__esModule\\",{value:!0}),a);var s=f((k,p)=>{p.exports=_jsx_runtime});var _={};m(_,{default:()=>j,frontmatter:()=>x});var e=v(s()),x={version:\\"0.6.0\\",date:\\"11/06/2020\\",href:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.6.0/apache-pinot-incubating-0.6.0-bin.tar.gz?action=download\\",officialSource:{download:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.6.0/apache-pinot-incubating-0.6.0-src.tar.gz?action=download\\",sha512:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.6.0/apache-pinot-incubating-0.6.0-src.tar.gz.sha512?action=download\\",asc:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.6.0/apache-pinot-incubating-0.6.0-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.6.0/apache-pinot-incubating-0.6.0-bin.tar.gz?action=download\\",sha512:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.6.0/apache-pinot-incubating-0.6.0-bin.tar.gz.sha512?action=download\\",asc:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.6.0/apache-pinot-incubating-0.6.0-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"This release introduced some excellent new features, including upsert, tiered storage, pinot-spark-connector, support of having clause, more validations on table config and schema\\"};function h(a){let n=Object.assign({p:\\"p\\"},a.components);return(0,e.jsx)(n.p,{children:\\"This release introduced some excellent new features, including upsert, tiered storage, pinot-spark-connector, support of having clause, more validations on table config and schema\\"})}function z(a={}){let{wrapper:n}=a.components||{};return n?(0,e.jsx)(n,Object.assign({},a,{children:(0,e.jsx)(h,a)})):h(a)}var j=z;return w(_);})();\\n;return Component;"},"_id":"downloads/0.6.0.mdx","_raw":{"sourceFilePath":"downloads/0.6.0.mdx","sourceFileName":"0.6.0.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.6.0"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.115,"time":6900,"words":23},"slug":"0.6.0/","customSlug":"0.6.0/","path":"blog/0.6.0/","customPath":"blog/0.6.0/","filePath":"downloads/0.6.0.mdx","toc":[]},{"version":"0.7.1","date":"2021-04-07T00:00:00.000Z","href":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.7.1/apache-pinot-incubating-0.7.1-bin.tar.gz?action=download","officialSource":{"download":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.7.1/apache-pinot-incubating-0.7.1-src.tar.gz?action=download","sha512":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.7.1/apache-pinot-incubating-0.7.1-src.tar.gz.sha512?action=download","asc":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.7.1/apache-pinot-incubating-0.7.1-src.tar.gz.asc?action=download"},"binary":{"download":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.7.1/apache-pinot-incubating-0.7.1-bin.tar.gz?action=download","sha512":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.7.1/apache-pinot-incubating-0.7.1-bin.tar.gz.sha512?action=download","asc":"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.7.1/apache-pinot-incubating-0.7.1-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"This release introduced several awesome new features, including JSON index, lookup-based join support, geospatial support, TLS support for pinot connections, and various performance optimizations and improvements.","html":"<p>This release introduced several awesome new features, including JSON index, lookup-based join support, geospatial support, TLS support for pinot connections, and various performance optimizations and improvements.</p>"},"body":{"raw":"\\nThis release introduced several awesome new features, including JSON index, lookup-based join support, geospatial support, TLS support for pinot connections, and various performance optimizations and improvements.\\n","code":"var Component=(()=>{var d=Object.create;var o=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var b=Object.getPrototypeOf,l=Object.prototype.hasOwnProperty;var m=(a,n)=>()=>(n||a((n={exports:{}}).exports,n),n.exports),f=(a,n)=>{for(var t in n)o(a,t,{get:n[t],enumerable:!0})},p=(a,n,t,c)=>{if(n&&typeof n==\\"object\\"||typeof n==\\"function\\")for(let i of g(n))!l.call(a,i)&&i!==t&&o(a,i,{get:()=>n[i],enumerable:!(c=h(n,i))||c.enumerable});return a};var v=(a,n,t)=>(t=a!=null?d(b(a)):{},p(n||!a||!a.__esModule?o(t,\\"default\\",{value:a,enumerable:!0}):t,a)),w=a=>p(o({},\\"__esModule\\",{value:!0}),a);var s=m((O,r)=>{r.exports=_jsx_runtime});var S={};f(S,{default:()=>j,frontmatter:()=>x});var e=v(s()),x={version:\\"0.7.1\\",date:\\"04/07/2021\\",href:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.7.1/apache-pinot-incubating-0.7.1-bin.tar.gz?action=download\\",officialSource:{download:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.7.1/apache-pinot-incubating-0.7.1-src.tar.gz?action=download\\",sha512:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.7.1/apache-pinot-incubating-0.7.1-src.tar.gz.sha512?action=download\\",asc:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.7.1/apache-pinot-incubating-0.7.1-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.7.1/apache-pinot-incubating-0.7.1-bin.tar.gz?action=download\\",sha512:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.7.1/apache-pinot-incubating-0.7.1-bin.tar.gz.sha512?action=download\\",asc:\\"https://archive.apache.org/dist/incubator/pinot/apache-pinot-incubating-0.7.1/apache-pinot-incubating-0.7.1-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"This release introduced several awesome new features, including JSON index, lookup-based join support, geospatial support, TLS support for pinot connections, and various performance optimizations and improvements.\\"};function u(a){let n=Object.assign({p:\\"p\\"},a.components);return(0,e.jsx)(n.p,{children:\\"This release introduced several awesome new features, including JSON index, lookup-based join support, geospatial support, TLS support for pinot connections, and various performance optimizations and improvements.\\"})}function z(a={}){let{wrapper:n}=a.components||{};return n?(0,e.jsx)(n,Object.assign({},a,{children:(0,e.jsx)(u,a)})):u(a)}var j=z;return w(S);})();\\n;return Component;"},"_id":"downloads/0.7.1.mdx","_raw":{"sourceFilePath":"downloads/0.7.1.mdx","sourceFileName":"0.7.1.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.7.1"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.13,"time":7800,"words":26},"slug":"0.7.1/","customSlug":"0.7.1/","path":"blog/0.7.1/","customPath":"blog/0.7.1/","filePath":"downloads/0.7.1.mdx","toc":[]},{"version":"0.8.0","date":"2021-08-12T00:00:00.000Z","href":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.8.0/apache-pinot-0.8.0-bin.tar.gz?action=download","officialSource":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.8.0/apache-pinot-0.8.0-src.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.8.0/apache-pinot-0.8.0-src.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.8.0/apache-pinot-0.8.0-src.tar.gz.asc?action=download"},"binary":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.8.0/apache-pinot-0.8.0-bin.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.8.0/apache-pinot-0.8.0-bin.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.8.0/apache-pinot-0.8.0-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"This release introduced several awesome new features, including compatibility tests, enhanced complex type and Json support, partial upsert support, and new stream ingestion plugins (AWS Kinesis, Apache Pulsar).","html":"<p>This release introduced several awesome new features, including compatibility tests, enhanced complex type and Json support, partial upsert support, and new stream ingestion plugins (AWS Kinesis, Apache Pulsar).</p>"},"body":{"raw":"\\nThis release introduced several awesome new features, including compatibility tests, enhanced complex type and Json support, partial upsert support, and new stream ingestion plugins (AWS Kinesis, Apache Pulsar).\\n","code":"var Component=(()=>{var d=Object.create;var o=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var w=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var m=(a,t)=>()=>(t||a((t={exports:{}}).exports,t),t.exports),y=(a,t)=>{for(var n in t)o(a,n,{get:t[n],enumerable:!0})},i=(a,t,n,s)=>{if(t&&typeof t==\\"object\\"||typeof t==\\"function\\")for(let e of w(t))!g.call(a,e)&&e!==n&&o(a,e,{get:()=>t[e],enumerable:!(s=h(t,e))||s.enumerable});return a};var f=(a,t,n)=>(n=a!=null?d(u(a)):{},i(t||!a||!a.__esModule?o(n,\\"default\\",{value:a,enumerable:!0}):n,a)),b=a=>i(o({},\\"__esModule\\",{value:!0}),a);var r=m((v,c)=>{c.exports=_jsx_runtime});var _={};y(_,{default:()=>j,frontmatter:()=>x});var p=f(r()),x={version:\\"0.8.0\\",date:\\"08/12/2021\\",href:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.8.0/apache-pinot-0.8.0-bin.tar.gz?action=download\\",officialSource:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.8.0/apache-pinot-0.8.0-src.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.8.0/apache-pinot-0.8.0-src.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.8.0/apache-pinot-0.8.0-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.8.0/apache-pinot-0.8.0-bin.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.8.0/apache-pinot-0.8.0-bin.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.8.0/apache-pinot-0.8.0-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"This release introduced several awesome new features, including compatibility tests, enhanced complex type and Json support, partial upsert support, and new stream ingestion plugins (AWS Kinesis, Apache Pulsar).\\"};function l(a){let t=Object.assign({p:\\"p\\"},a.components);return(0,p.jsx)(t.p,{children:\\"This release introduced several awesome new features, including compatibility tests, enhanced complex type and Json support, partial upsert support, and new stream ingestion plugins (AWS Kinesis, Apache Pulsar).\\"})}function z(a={}){let{wrapper:t}=a.components||{};return t?(0,p.jsx)(t,Object.assign({},a,{children:(0,p.jsx)(l,a)})):l(a)}var j=z;return b(_);})();\\n;return Component;"},"_id":"downloads/0.8.0.mdx","_raw":{"sourceFilePath":"downloads/0.8.0.mdx","sourceFileName":"0.8.0.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.8.0"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.14,"time":8400,"words":28},"slug":"0.8.0/","customSlug":"0.8.0/","path":"blog/0.8.0/","customPath":"blog/0.8.0/","filePath":"downloads/0.8.0.mdx","toc":[]},{"version":"0.9.0","date":"2021-11-12T00:00:00.000Z","href":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.0/apache-pinot-0.9.0-bin.tar.gz?action=download","officialSource":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.0/apache-pinot-0.9.0-src.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.0/apache-pinot-0.9.0-src.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.0/apache-pinot-0.9.0-src.tar.gz.asc?action=download"},"binary":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.0/apache-pinot-0.9.0-bin.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.0/apache-pinot-0.9.0-bin.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.0/apache-pinot-0.9.0-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"This release introduces a new features: Segment Merge and Rollup to simplify users day to day operational work. A new metrics plugin is added to support dropwizard. As usual, new functionalities and many UI/ Performance improvements.","html":"<p>This release introduces a new features: Segment Merge and Rollup to simplify users day to day operational work. A new metrics plugin is added to support dropwizard. As usual, new functionalities and many UI/ Performance improvements.</p>"},"body":{"raw":"\\nThis release introduces a new features: Segment Merge and Rollup to simplify users day to day operational work. A new metrics plugin is added to support dropwizard. As usual, new functionalities and many UI/ Performance improvements.\\n","code":"var Component=(()=>{var l=Object.create;var e=Object.defineProperty;var w=Object.getOwnPropertyDescriptor;var h=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var m=(a,o)=>()=>(o||a((o={exports:{}}).exports,o),o.exports),y=(a,o)=>{for(var n in o)e(a,n,{get:o[n],enumerable:!0})},i=(a,o,n,r)=>{if(o&&typeof o==\\"object\\"||typeof o==\\"function\\")for(let t of h(o))!g.call(a,t)&&t!==n&&e(a,t,{get:()=>o[t],enumerable:!(r=w(o,t))||r.enumerable});return a};var f=(a,o,n)=>(n=a!=null?l(u(a)):{},i(o||!a||!a.__esModule?e(n,\\"default\\",{value:a,enumerable:!0}):n,a)),z=a=>i(e({},\\"__esModule\\",{value:!0}),a);var c=m((A,s)=>{s.exports=_jsx_runtime});var M={};y(M,{default:()=>j,frontmatter:()=>b});var p=f(c()),b={version:\\"0.9.0\\",date:\\"11/12/2021\\",href:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.0/apache-pinot-0.9.0-bin.tar.gz?action=download\\",officialSource:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.0/apache-pinot-0.9.0-src.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.0/apache-pinot-0.9.0-src.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.0/apache-pinot-0.9.0-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.0/apache-pinot-0.9.0-bin.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.0/apache-pinot-0.9.0-bin.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.0/apache-pinot-0.9.0-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"This release introduces a new features: Segment Merge and Rollup to simplify users day to day operational work. A new metrics plugin is added to support dropwizard. As usual, new functionalities and many UI/ Performance improvements.\\"};function d(a){let o=Object.assign({p:\\"p\\"},a.components);return(0,p.jsx)(o.p,{children:\\"This release introduces a new features: Segment Merge and Rollup to simplify users day to day operational work. A new metrics plugin is added to support dropwizard. As usual, new functionalities and many UI/ Performance improvements.\\"})}function x(a={}){let{wrapper:o}=a.components||{};return o?(0,p.jsx)(o,Object.assign({},a,{children:(0,p.jsx)(d,a)})):d(a)}var j=x;return z(M);})();\\n;return Component;"},"_id":"downloads/0.9.0.mdx","_raw":{"sourceFilePath":"downloads/0.9.0.mdx","sourceFileName":"0.9.0.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.9.0"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.18,"time":10800,"words":36},"slug":"0.9.0/","customSlug":"0.9.0/","path":"blog/0.9.0/","customPath":"blog/0.9.0/","filePath":"downloads/0.9.0.mdx","toc":[]},{"version":"0.9.1","date":"2021-12-12T00:00:00.000Z","href":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.1/apache-pinot-0.9.1-bin.tar.gz?action=download","officialSource":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.1/apache-pinot-0.9.1-src.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.1/apache-pinot-0.9.1-src.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.1/apache-pinot-0.9.1-src.tar.gz.asc?action=download"},"binary":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.1/apache-pinot-0.9.1-bin.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.1/apache-pinot-0.9.1-bin.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.1/apache-pinot-0.9.1-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"This release fixes the major issue of CVE-2021-44228 and a major bug fixing of pinot admin exit code issue #7798.","html":"<p>This release fixes the major issue of CVE-2021-44228 and a major bug fixing of pinot admin exit code issue #7798.</p>"},"body":{"raw":"\\nThis release fixes the major issue of CVE-2021-44228(https://github.com/advisories/GHSA-jfh8-c2jp-5v3q) and a major bug fixing of pinot admin exit code issue(#7798(https://github.com/apache/pinot/pull/7798)).\\n","code":"var Component=(()=>{var d=Object.create;var i=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var w=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var f=(a,o)=>()=>(o||a((o={exports:{}}).exports,o),o.exports),m=(a,o)=>{for(var t in o)i(a,t,{get:o[t],enumerable:!0})},p=(a,o,t,c)=>{if(o&&typeof o==\\"object\\"||typeof o==\\"function\\")for(let e of w(o))!g.call(a,e)&&e!==t&&i(a,e,{get:()=>o[e],enumerable:!(c=l(o,e))||c.enumerable});return a};var j=(a,o,t)=>(t=a!=null?d(u(a)):{},p(o||!a||!a.__esModule?i(t,\\"default\\",{value:a,enumerable:!0}):t,a)),x=a=>p(i({},\\"__esModule\\",{value:!0}),a);var h=f((C,s)=>{s.exports=_jsx_runtime});var _={};m(_,{default:()=>z,frontmatter:()=>b});var n=j(h()),b={version:\\"0.9.1\\",date:\\"12/12/2021\\",href:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.1/apache-pinot-0.9.1-bin.tar.gz?action=download\\",officialSource:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.1/apache-pinot-0.9.1-src.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.1/apache-pinot-0.9.1-src.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.1/apache-pinot-0.9.1-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.1/apache-pinot-0.9.1-bin.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.1/apache-pinot-0.9.1-bin.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.1/apache-pinot-0.9.1-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"This release fixes the major issue of CVE-2021-44228 and a major bug fixing of pinot admin exit code issue #7798.\\"};function r(a){let o=Object.assign({p:\\"p\\",a:\\"a\\"},a.components);return(0,n.jsxs)(o.p,{children:[\\"This release fixes the major issue of CVE-2021-44228(\\",(0,n.jsx)(o.a,{href:\\"https://github.com/advisories/GHSA-jfh8-c2jp-5v3q\\",children:\\"https://github.com/advisories/GHSA-jfh8-c2jp-5v3q\\"}),\\") and a major bug fixing of pinot admin exit code issue(#7798(\\",(0,n.jsx)(o.a,{href:\\"https://github.com/apache/pinot/pull/7798\\",children:\\"https://github.com/apache/pinot/pull/7798\\"}),\\")).\\"]})}function y(a={}){let{wrapper:o}=a.components||{};return o?(0,n.jsx)(o,Object.assign({},a,{children:(0,n.jsx)(r,a)})):r(a)}var z=y;return x(_);})();\\n;return Component;"},"_id":"downloads/0.9.1.mdx","_raw":{"sourceFilePath":"downloads/0.9.1.mdx","sourceFileName":"0.9.1.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.9.1"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.095,"time":5700,"words":19},"slug":"0.9.1/","customSlug":"0.9.1/","path":"blog/0.9.1/","customPath":"blog/0.9.1/","filePath":"downloads/0.9.1.mdx","toc":[]},{"version":"0.9.2","date":"2021-12-15T00:00:00.000Z","href":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.2/apache-pinot-0.9.2-bin.tar.gz?action=download","officialSource":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.2/apache-pinot-0.9.2-src.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.2/apache-pinot-0.9.2-src.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.2/apache-pinot-0.9.2-src.tar.gz.asc?action=download"},"binary":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.2/apache-pinot-0.9.2-bin.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.2/apache-pinot-0.9.2-bin.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.2/apache-pinot-0.9.2-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"This is a bug fixing release contains: Upgrade log4j to 2.16.0 to fix CVE-2021-45046 (#7903), upgrade swagger-ui to 3.23.11 to fix CVE-2019-17495 (#7902), fix the bug that RealtimeToOfflineTask failed to progress with large time bucket gaps (#7814).","html":"<p>This is a bug fixing release contains: Upgrade log4j to 2.16.0 to fix CVE-2021-45046 (#7903), upgrade swagger-ui to 3.23.11 to fix CVE-2019-17495 (#7902), fix the bug that RealtimeToOfflineTask failed to progress with large time bucket gaps (#7814).</p>"},"body":{"raw":"\\nThis is a bug fixing release contains:\\n\\n-   Upgrade log4j to 2.16.0 to fix CVE-2021-45046 (#7903)\\n-   Upgrade swagger-ui to 3.23.11 to fix CVE-2019-17495 (#7902)\\n-   Fix the bug that RealtimeToOfflineTask failed to progress with large time bucket gaps (#7814).\\n","code":"var Component=(()=>{var h=Object.create;var i=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var w=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var f=(t,a)=>()=>(a||t((a={exports:{}}).exports,a),a.exports),x=(t,a)=>{for(var e in a)i(t,e,{get:a[e],enumerable:!0})},r=(t,a,e,c)=>{if(a&&typeof a==\\"object\\"||typeof a==\\"function\\")for(let n of g(a))!u.call(t,n)&&n!==e&&i(t,n,{get:()=>a[n],enumerable:!(c=d(a,n))||c.enumerable});return t};var b=(t,a,e)=>(e=t!=null?h(w(t)):{},r(a||!t||!t.__esModule?i(e,\\"default\\",{value:t,enumerable:!0}):e,t)),m=t=>r(i({},\\"__esModule\\",{value:!0}),t);var p=f((T,s)=>{s.exports=_jsx_runtime});var _={};x(_,{default:()=>z,frontmatter:()=>j});var o=b(p()),j={version:\\"0.9.2\\",date:\\"12/15/2021\\",href:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.2/apache-pinot-0.9.2-bin.tar.gz?action=download\\",officialSource:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.2/apache-pinot-0.9.2-src.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.2/apache-pinot-0.9.2-src.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.2/apache-pinot-0.9.2-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.2/apache-pinot-0.9.2-bin.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.2/apache-pinot-0.9.2-bin.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.2/apache-pinot-0.9.2-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"This is a bug fixing release contains: Upgrade log4j to 2.16.0 to fix CVE-2021-45046 (#7903), upgrade swagger-ui to 3.23.11 to fix CVE-2019-17495 (#7902), fix the bug that RealtimeToOfflineTask failed to progress with large time bucket gaps (#7814).\\"};function l(t){let a=Object.assign({p:\\"p\\",ul:\\"ul\\",li:\\"li\\"},t.components);return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(a.p,{children:\\"This is a bug fixing release contains:\\"}),(0,o.jsxs)(a.ul,{children:[(0,o.jsx)(a.li,{children:\\"Upgrade log4j to 2.16.0 to fix CVE-2021-45046 (#7903)\\"}),(0,o.jsx)(a.li,{children:\\"Upgrade swagger-ui to 3.23.11 to fix CVE-2019-17495 (#7902)\\"}),(0,o.jsx)(a.li,{children:\\"Fix the bug that RealtimeToOfflineTask failed to progress with large time bucket gaps (#7814).\\"})]})]})}function y(t={}){let{wrapper:a}=t.components||{};return a?(0,o.jsx)(a,Object.assign({},t,{children:(0,o.jsx)(l,t)})):l(t)}var z=y;return m(_);})();\\n;return Component;"},"_id":"downloads/0.9.2.mdx","_raw":{"sourceFilePath":"downloads/0.9.2.mdx","sourceFileName":"0.9.2.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.9.2"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":"0.9.2/","customSlug":"0.9.2/","path":"blog/0.9.2/","customPath":"blog/0.9.2/","filePath":"downloads/0.9.2.mdx","toc":[]},{"version":"0.9.3","date":"2021-12-24T00:00:00.000Z","href":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.3/apache-pinot-0.9.3-bin.tar.gz?action=download","officialSource":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.3/apache-pinot-0.9.3-src.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.3/apache-pinot-0.9.3-src.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.3/apache-pinot-0.9.3-src.tar.gz.asc?action=download"},"binary":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.3/apache-pinot-0.9.3-bin.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.3/apache-pinot-0.9.3-bin.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.3/apache-pinot-0.9.3-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"This is a bug fixing release contains: Update Log4j to 2.17.0 to address CVE-2021-45105 (#7933).","html":"<p>This is a bug fixing release contains: Update Log4j to 2.17.0 to address CVE-2021-45105 (#7933).</p>"},"body":{"raw":"\\nThis is a bug fixing release contains:\\n\\n-   Update Log4j to 2.17.0 to address CVE-2021-45105 (#7933)\\n","code":"var Component=(()=>{var d=Object.create;var c=Object.defineProperty;var l=Object.getOwnPropertyDescriptor;var w=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var x=(a,o)=>()=>(o||a((o={exports:{}}).exports,o),o.exports),f=(a,o)=>{for(var n in o)c(a,n,{get:o[n],enumerable:!0})},s=(a,o,n,i)=>{if(o&&typeof o==\\"object\\"||typeof o==\\"function\\")for(let e of w(o))!u.call(a,e)&&e!==n&&c(a,e,{get:()=>o[e],enumerable:!(i=l(o,e))||i.enumerable});return a};var b=(a,o,n)=>(n=a!=null?d(g(a)):{},s(o||!a||!a.__esModule?c(n,\\"default\\",{value:a,enumerable:!0}):n,a)),j=a=>s(c({},\\"__esModule\\",{value:!0}),a);var r=x((L,p)=>{p.exports=_jsx_runtime});var _={};f(_,{default:()=>z,frontmatter:()=>m});var t=b(r()),m={version:\\"0.9.3\\",date:\\"12/24/2021\\",href:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.3/apache-pinot-0.9.3-bin.tar.gz?action=download\\",officialSource:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.3/apache-pinot-0.9.3-src.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.3/apache-pinot-0.9.3-src.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.3/apache-pinot-0.9.3-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.3/apache-pinot-0.9.3-bin.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.3/apache-pinot-0.9.3-bin.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-0.9.3/apache-pinot-0.9.3-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"This is a bug fixing release contains: Update Log4j to 2.17.0 to address CVE-2021-45105 (#7933).\\"};function h(a){let o=Object.assign({p:\\"p\\",ul:\\"ul\\",li:\\"li\\"},a.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(o.p,{children:\\"This is a bug fixing release contains:\\"}),(0,t.jsx)(o.ul,{children:(0,t.jsx)(o.li,{children:\\"Update Log4j to 2.17.0 to address CVE-2021-45105 (#7933)\\"})})]})}function y(a={}){let{wrapper:o}=a.components||{};return o?(0,t.jsx)(o,Object.assign({},a,{children:(0,t.jsx)(h,a)})):h(a)}var z=y;return j(_);})();\\n;return Component;"},"_id":"downloads/0.9.3.mdx","_raw":{"sourceFilePath":"downloads/0.9.3.mdx","sourceFileName":"0.9.3.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/0.9.3"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.08,"time":4800,"words":16},"slug":"0.9.3/","customSlug":"0.9.3/","path":"blog/0.9.3/","customPath":"blog/0.9.3/","filePath":"downloads/0.9.3.mdx","toc":[]},{"version":"1.0.0","date":"2023-09-12T00:00:00.000Z","href":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.0.0/apache-pinot-1.0.0-bin.tar.gz?action=download","officialSource":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.0.0/apache-pinot-1.0.0-src.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.0.0/apache-pinot-1.0.0-src.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.0.0/apache-pinot-1.0.0-src.tar.gz.asc?action=download"},"binary":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.0.0/apache-pinot-1.0.0-bin.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.0.0/apache-pinot-1.0.0-bin.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.0.0/apache-pinot-1.0.0-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"Apache Pinot Release 1.0.0","html":"<p>Apache Pinot Release 1.0.0</p>"},"body":{"raw":"\\nApache Pinot Release 1.0.0\\n","code":"var Component=(()=>{var w=Object.create;var e=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var l=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var y=(a,o)=>()=>(o||a((o={exports:{}}).exports,o),o.exports),f=(a,o)=>{for(var t in o)e(a,t,{get:o[t],enumerable:!0})},i=(a,o,t,p)=>{if(o&&typeof o==\\"object\\"||typeof o==\\"function\\")for(let n of l(o))!u.call(a,n)&&n!==t&&e(a,n,{get:()=>o[n],enumerable:!(p=d(o,n))||p.enumerable});return a};var b=(a,o,t)=>(t=a!=null?w(g(a)):{},i(o||!a||!a.__esModule?e(t,\\"default\\",{value:a,enumerable:!0}):t,a)),m=a=>i(e({},\\"__esModule\\",{value:!0}),a);var s=y((A,r)=>{r.exports=_jsx_runtime});var _={};f(_,{default:()=>j,frontmatter:()=>x});var c=b(s()),x={version:\\"1.0.0\\",date:\\"09/12/2023\\",href:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.0.0/apache-pinot-1.0.0-bin.tar.gz?action=download\\",officialSource:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.0.0/apache-pinot-1.0.0-src.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.0.0/apache-pinot-1.0.0-src.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.0.0/apache-pinot-1.0.0-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.0.0/apache-pinot-1.0.0-bin.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.0.0/apache-pinot-1.0.0-bin.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.0.0/apache-pinot-1.0.0-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"Apache Pinot Release 1.0.0\\"};function h(a){let o=Object.assign({p:\\"p\\"},a.components);return(0,c.jsx)(o.p,{children:\\"Apache Pinot Release 1.0.0\\"})}function z(a={}){let{wrapper:o}=a.components||{};return o?(0,c.jsx)(o,Object.assign({},a,{children:(0,c.jsx)(h,a)})):h(a)}var j=z;return m(_);})();\\n;return Component;"},"_id":"downloads/1.0.0.mdx","_raw":{"sourceFilePath":"downloads/1.0.0.mdx","sourceFileName":"1.0.0.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/1.0.0"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.02,"time":1200,"words":4},"slug":"1.0.0/","customSlug":"1.0.0/","path":"blog/1.0.0/","customPath":"blog/1.0.0/","filePath":"downloads/1.0.0.mdx","toc":[]},{"version":"1.1.0","date":"2024-03-25T00:00:00.000Z","href":"http://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.1.0/apache-pinot-1.1.0-bin.tar.gz?action=download","officialSource":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.1.0/apache-pinot-1.1.0-src.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.1.0/apache-pinot-1.1.0-src.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.1.0/apache-pinot-1.1.0-src.tar.gz.asc?action=download"},"binary":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.1.0/apache-pinot-1.1.0-bin.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.1.0/apache-pinot-1.1.0-bin.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.1.0/apache-pinot-1.1.0-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"This release comes with several features, SQL /UI/Perf enhancements Bugfixes across areas ranging from Multistage Query Engine to Ingestion, Storage format, SQL support, etc.","html":"<p>This release comes with several features, SQL /UI/Perf enhancements Bugfixes across areas ranging from Multistage Query Engine to Ingestion, Storage format, SQL support, etc.</p>"},"body":{"raw":"\\nThis release comes with several features, SQL /UI/Perf enhancements Bugfixes across areas ranging from Multistage Query Engine to Ingestion, Storage format, SQL support, etc.\\n","code":"var Component=(()=>{var l=Object.create;var n=Object.defineProperty;var w=Object.getOwnPropertyDescriptor;var d=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var f=(a,t)=>()=>(t||a((t={exports:{}}).exports,t),t.exports),m=(a,t)=>{for(var o in t)n(a,o,{get:t[o],enumerable:!0})},s=(a,t,o,c)=>{if(t&&typeof t==\\"object\\"||typeof t==\\"function\\")for(let e of d(t))!u.call(a,e)&&e!==o&&n(a,e,{get:()=>t[e],enumerable:!(c=w(t,e))||c.enumerable});return a};var y=(a,t,o)=>(o=a!=null?l(g(a)):{},s(t||!a||!a.__esModule?n(o,\\"default\\",{value:a,enumerable:!0}):o,a)),x=a=>s(n({},\\"__esModule\\",{value:!0}),a);var i=f((L,p)=>{p.exports=_jsx_runtime});var Q={};m(Q,{default:()=>S,frontmatter:()=>b});var r=y(i()),b={version:\\"1.1.0\\",date:\\"03/25/2024\\",href:\\"http://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.1.0/apache-pinot-1.1.0-bin.tar.gz?action=download\\",officialSource:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.1.0/apache-pinot-1.1.0-src.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.1.0/apache-pinot-1.1.0-src.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.1.0/apache-pinot-1.1.0-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.1.0/apache-pinot-1.1.0-bin.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.1.0/apache-pinot-1.1.0-bin.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.1.0/apache-pinot-1.1.0-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"This release comes with several features, SQL /UI/Perf enhancements Bugfixes across areas ranging from Multistage Query Engine to Ingestion, Storage format, SQL support, etc.\\"};function h(a){let t=Object.assign({p:\\"p\\"},a.components);return(0,r.jsx)(t.p,{children:\\"This release comes with several features, SQL /UI/Perf enhancements Bugfixes across areas ranging from Multistage Query Engine to Ingestion, Storage format, SQL support, etc.\\"})}function z(a={}){let{wrapper:t}=a.components||{};return t?(0,r.jsx)(t,Object.assign({},a,{children:(0,r.jsx)(h,a)})):h(a)}var S=z;return x(Q);})();\\n;return Component;"},"_id":"downloads/1.1.0.mdx","_raw":{"sourceFilePath":"downloads/1.1.0.mdx","sourceFileName":"1.1.0.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/1.1.0"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.12,"time":7200,"words":24},"slug":"1.1.0/","customSlug":"1.1.0/","path":"blog/1.1.0/","customPath":"blog/1.1.0/","filePath":"downloads/1.1.0.mdx","toc":[]},{"version":"1.2.0","date":"2024-08-20T00:00:00.000Z","href":"http://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.2.0/apache-pinot-1.2.0-bin.tar.gz?action=download","officialSource":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.2.0/apache-pinot-1.2.0-src.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.2.0/apache-pinot-1.2.0-src.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.2.0/apache-pinot-1.2.0-src.tar.gz.asc?action=download"},"binary":{"download":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.2.0/apache-pinot-1.2.0-bin.tar.gz?action=download","sha512":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.2.0/apache-pinot-1.2.0-bin.tar.gz.sha512?action=download","asc":"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.2.0/apache-pinot-1.2.0-bin.tar.gz.asc?action=download"},"releaseNotes":{"raw":"This release comes with several Improvements and Bug Fixes for the Multistage Engine, Upserts and Compaction. There are a ton of other small features and general bug fixes.","html":"<p>This release comes with several Improvements and Bug Fixes for the Multistage Engine, Upserts and Compaction. There are a ton of other small features and general bug fixes.</p>"},"body":{"raw":"\\nThis release comes with several Improvements and Bug Fixes for the Multistage Engine, Upserts and Compaction. There are a ton of other small features and general bug fixes.\\n","code":"var Component=(()=>{var l=Object.create;var n=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var w=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var m=(a,e)=>()=>(e||a((e={exports:{}}).exports,e),e.exports),f=(a,e)=>{for(var t in e)n(a,t,{get:e[t],enumerable:!0})},c=(a,e,t,s)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let o of w(e))!u.call(a,o)&&o!==t&&n(a,o,{get:()=>e[o],enumerable:!(s=d(e,o))||s.enumerable});return a};var x=(a,e,t)=>(t=a!=null?l(g(a)):{},c(e||!a||!a.__esModule?n(t,\\"default\\",{value:a,enumerable:!0}):t,a)),b=a=>c(n({},\\"__esModule\\",{value:!0}),a);var i=m((_,p)=>{p.exports=_jsx_runtime});var v={};f(v,{default:()=>j,frontmatter:()=>y});var r=x(i()),y={version:\\"1.2.0\\",date:\\"08/20/2024\\",href:\\"http://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.2.0/apache-pinot-1.2.0-bin.tar.gz?action=download\\",officialSource:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.2.0/apache-pinot-1.2.0-src.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.2.0/apache-pinot-1.2.0-src.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.2.0/apache-pinot-1.2.0-src.tar.gz.asc?action=download\\"},binary:{download:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.2.0/apache-pinot-1.2.0-bin.tar.gz?action=download\\",sha512:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.2.0/apache-pinot-1.2.0-bin.tar.gz.sha512?action=download\\",asc:\\"https://www.apache.org/dyn/closer.lua/pinot/apache-pinot-1.2.0/apache-pinot-1.2.0-bin.tar.gz.asc?action=download\\"},releaseNotes:\\"This release comes with several Improvements and Bug Fixes for the Multistage Engine, Upserts and Compaction. There are a ton of other small features and general bug fixes.\\"};function h(a){let e=Object.assign({p:\\"p\\"},a.components);return(0,r.jsx)(e.p,{children:\\"This release comes with several Improvements and Bug Fixes for the Multistage Engine, Upserts and Compaction. There are a ton of other small features and general bug fixes.\\"})}function z(a={}){let{wrapper:e}=a.components||{};return e?(0,r.jsx)(e,Object.assign({},a,{children:(0,r.jsx)(h,a)})):h(a)}var j=z;return b(v);})();\\n;return Component;"},"_id":"downloads/1.2.0.mdx","_raw":{"sourceFilePath":"downloads/1.2.0.mdx","sourceFileName":"1.2.0.mdx","sourceFileDir":"downloads","contentType":"mdx","flattenedPath":"downloads/1.2.0"},"type":"Downloads","readingTime":{"text":"1 min read","minutes":0.14,"time":8400,"words":28},"slug":"1.2.0/","customSlug":"1.2.0/","path":"blog/1.2.0/","customPath":"blog/1.2.0/","filePath":"downloads/1.2.0.mdx","toc":[]}]')];var Z=a(8071);let Q=e=>{let n=K.find(n=>n.slug===e),a=(null==n?void 0:n.authors)||["default"];return a.map(e=>{let n=G.find(n=>n.slug===e);return(0,Z.gT)(n)})};var Y=e=>{let{post:n}=e,{slug:a,title:s,authors:i,date:o,readingTime:r,customSlug:c}=n,l=Q(a);return(0,t.jsx)(_.Z,{href:"/blog/".concat(a),"aria-label":s,className:"px-5 sm:px-0",children:(0,t.jsx)(R,{className:"h-full border-neutral-500 p-5",children:(0,t.jsxs)(z,{className:"h-full justify-between p-0",children:[(0,t.jsxs)("div",{children:[(0,t.jsx)(U,{className:"pb-2 text-xl font-semibold leading-8 text-stone-900",children:s}),(0,t.jsx)(W,{className:"leading-[1.1rem] text-stone-900",children:l.map(e=>e.name).join(", ")})]}),(0,t.jsxs)(W,{className:"leading-[1.1rem]",children:[(0,M.ZP)(o,"MMMM do, yyyy")," • ",r.text]})]})})})},J=e=>{let{posts:n}=e;return(0,t.jsxs)("section",{"aria-labelledby":"blog-section-title",className:"md:mx-auto md:max-w-screen-outerLiveArea",children:[(0,t.jsx)("h4",{id:"blog-section-title",className:"m-12 text-center text-[2rem] font-bold leading-10 lg:mt-24",children:"Pinot Blog"}),(0,t.jsx)("div",{className:"grid grid-cols-1 gap-[1.875rem] md:grid-cols-3 lg:px-24",children:n.slice(0,3).map(e=>(0,t.jsx)(Y,{post:e},e.slug))}),(0,t.jsx)("div",{className:"mt-8 pb-14 text-center md:pb-32",children:(0,t.jsx)(o.z,{variant:"link",asChild:!0,className:"text-base font-semibold leading-tight text-vine-100",children:(0,t.jsxs)(c(),{href:"/blog",children:["Browse All",(0,t.jsx)(u.Z,{className:"mr-2 h-5 w-5"})]})})})]})},$=e=>{let{posts:n}=e;return(0,t.jsxs)("div",{children:[(0,t.jsx)(h,{}),(0,t.jsx)(g,{videoUrl:i().video.videoUrl,title:i().video.title}),(0,t.jsx)(k,{}),(0,t.jsx)(C,{}),(0,t.jsx)(E,{}),(0,t.jsx)(q,{title:i().codeSection.header}),(0,t.jsx)(J,{posts:n})]})}},2134:function(e,n,a){"use strict";a.d(n,{cn:function(){return i}});var t=a(3920),s=a(550);function i(){for(var e=arguments.length,n=Array(e),a=0;a<e;a++)n[a]=arguments[a];return(0,s.m6)((0,t.W)(n))}},1530:function(e,n,a){"use strict";var t=a(7437),s=a(1396),i=a.n(s);n.Z=e=>{let{href:n,...a}=e,s=n&&n.startsWith("/"),o=n&&n.startsWith("#");return s?(0,t.jsx)(i(),{href:n,...a}):o?(0,t.jsx)("a",{href:n,...a}):(0,t.jsx)("a",{target:"_blank",rel:"noopener noreferrer",href:n,...a})}},3611:function(e,n,a){"use strict";a.d(n,{z:function(){return l}});var t=a(7437),s=a(2265),i=a(7690),o=a(7111),r=a(2134);let c=(0,o.j)("inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50",{variants:{variant:{default:"bg-primary text-primary-foreground hover:bg-vine-120",destructive:"bg-destructive text-destructive-foreground hover:bg-destructive/90",outline:"border border-slate-50 border-input bg-background hover:bg-accent hover:text-accent-foreground",secondary:"bg-secondary text-secondary-foreground hover:bg-secondary/80",ghost:"hover:bg-accent hover:text-accent-foreground",link:"text-primary underline-offset-4 hover:text-vine-120"},size:{default:"h-10 px-4 py-2",sm:"h-9 rounded-md px-3",lg:"rounded-md",xl:"rounded-md px-8 py-4","2xl":"h-14 rounded-md px-12",icon:"h-10 w-10"}},defaultVariants:{variant:"default",size:"default"}}),l=s.forwardRef((e,n)=>{let{className:a,variant:s,size:o,asChild:l=!1,...d}=e,p=l?i.g7:"button";return(0,t.jsx)(p,{className:(0,r.cn)(c({variant:s,size:o,className:a})),ref:n,...d})});l.displayName="Button"},2914:function(e,n,a){"use strict";var t=a(2601);let s={title:"Apache Pinot™",author:"Apache Pinot™",headerTitle:"",description:"Realtime distributed OLAP datastore",language:"en-us",theme:"light",siteUrl:"https://pinot.apache.org",siteRepo:"https://github.com/apache/pinot-site/tree/dev/website",siteLogo:"/static/images/logo.png",socialBanner:"/static/images/twitter-card.png",mastodon:"https://mastodon.social/explore",email:"",github:"https://github.com/apache/pinot",twitter:"https://twitter.com/Twitter",facebook:"https://facebook.com",youtube:"https://youtube.com",linkedin:"https://www.linkedin.com",locale:"en-US",video:{videoUrl:"https://www.youtube.com/embed/_lqdfq2c9cQ",title:"What is Apache Pinot?",description:"Apache Pinot"},cta:{getStarted:"https://docs.pinot.apache.org/basics/getting-started",learnMore:"https://docs.pinot.apache.org/",slackInvite:"https://apache-pinot.slack.com/join/shared_invite/zt-5z7pav2f-yYtjZdVA~EDmrGkho87Vzw#/shared-invite/email"},codeSection:{header:"Start Your Real-Time Analytics Journey."},analytics:{googleAnalytics:{googleAnalyticsId:"G-ZXG79NJEBY"}},newsletter:{provider:"buttondown"},comments:{provider:"",giscusConfig:{repo:t.env.NEXT_PUBLIC_GISCUS_REPO,repositoryId:t.env.NEXT_PUBLIC_GISCUS_REPOSITORY_ID,category:t.env.NEXT_PUBLIC_GISCUS_CATEGORY,categoryId:t.env.NEXT_PUBLIC_GISCUS_CATEGORY_ID,mapping:"pathname",reactions:"1",metadata:"0",theme:"light",darkTheme:"transparent_dark",themeURL:"",lang:"en"}},search:{provider:"algolia",algoliaConfig:{appId:"CKRA00L2X9",apiKey:"6531f8f7783a88d76629190843f1801e",indexName:"prod_apache_pinot_docs"}},announcement:{buttonText:"learn more",link:"https://github.com/apache/pinot/releases/tag/release-1.2.0"},communityLinks:[{name:"Slack",icon:"/static/images/socials/slack.svg",link:"https://join.slack.com/t/apache-pinot/shared_invite/zt-5z7pav2f-yYtjZdVA~EDmrGkho87Vzw"},{name:"GitHub",icon:"/static/images/socials/github.svg",link:"https://github.com/apache/pinot"},{name:"Meetups",icon:"/static/images/socials/meetup.svg",link:"https://www.meetup.com/apache-pinot/"},{name:"RTA Summit",icon:"/static/images/socials/rta.svg",link:"https://rtasummit.com",isWide:!0}],shareStory:{link:"https://forms.gle/75MbXyz7BztNQ78k9"}};e.exports=s}},function(e){e.O(0,[326,413,980,502,971,472,744],function(){return e(e.s=3372)}),_N_E=e.O()}]);